{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---\n",
        "\n",
        "# Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions\n",
        "\n",
        ":::{.callout-note}\n",
        "These test functions were used during the Dagstuhl Seminar 25451 Bayesian Optimisation (Nov 02 â€“ Nov 07, 2025), see [here](https://www.dagstuhl.de/25451).\n",
        "\n",
        "This notebook demonstrates the use of `SpotOptim` with sklearn's Gaussian Process Regressor as a surrogate model.\n",
        ":::\n",
        "\n",
        "## SpotOptim with Sklearn Kriging in 6 Dimensions: Rosenbrock Function\n",
        "\n",
        "This section demonstrates how to use the `SpotOptim` class with sklearn's Gaussian Process Regressor (using Matern kernel) as a surrogate on the 6-dimensional Rosenbrock function.\n",
        "We use a maximum of 100 function evaluations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import json\n",
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.function import rosenbrock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the 6D Rosenbrock Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dim = 6\n",
        "lower = np.full(dim, -2.0)\n",
        "upper = np.full(dim, 2.0)\n",
        "bounds = list(zip(lower, upper))\n",
        "fun = rosenbrock\n",
        "max_iter = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up SpotOptim Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_initial = dim\n",
        "seed = 321"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sklearn Gaussian Process Regressor as Surrogate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: kriging-matern-6d-rosen_run\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
        "\n",
        "# Use a Matern kernel instead of the standard RBF kernel\n",
        "kernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n",
        "    length_scale=1.0, \n",
        "    length_scale_bounds=(1e-4, 1e2), \n",
        "    nu=2.5\n",
        ")\n",
        "surrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)\n",
        "\n",
        "# Create SpotOptim instance with sklearn surrogate\n",
        "opt_rosen = SpotOptim(\n",
        "    fun=fun,\n",
        "    bounds=bounds,\n",
        "    n_initial=n_initial,\n",
        "    max_iter=max_iter,\n",
        "    surrogate=surrogate,\n",
        "    seed=seed,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "result_rosen = opt_rosen.optimize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"[6D] Sklearn Kriging: min y = {result_rosen.fun:.4f} at x = {result_rosen.x}\")\n",
        "print(f\"Number of function evaluations: {result_rosen.nfev}\")\n",
        "print(f\"Number of iterations: {result_rosen.nit}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Optimization Progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the optimization progress\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogy(np.minimum.accumulate(opt_rosen.y_), 'b-', linewidth=2)\n",
        "plt.xlabel('Function Evaluations', fontsize=12)\n",
        "plt.ylabel('Best Objective Value (log scale)', fontsize=12)\n",
        "plt.title('6D Rosenbrock: Sklearn Kriging Progress', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of Multiple Repeats\n",
        "\n",
        "To perform 30 repeats and collect statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Perform 30 independent runs\n",
        "n_repeats = 30\n",
        "results = []\n",
        "\n",
        "print(f\"Running {n_repeats} independent optimizations...\")\n",
        "for i in range(n_repeats):\n",
        "    kernel_i = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n",
        "        length_scale=1.0, \n",
        "        length_scale_bounds=(1e-4, 1e2), \n",
        "        nu=2.5\n",
        "    )\n",
        "    surrogate_i = GaussianProcessRegressor(kernel=kernel_i, n_restarts_optimizer=100)\n",
        "    \n",
        "    opt_i = SpotOptim(\n",
        "        fun=fun,\n",
        "        bounds=bounds,\n",
        "        n_initial=n_initial,\n",
        "        max_iter=max_iter,\n",
        "        surrogate=surrogate_i,\n",
        "        seed=seed + i,  # Different seed for each run\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    result_i = opt_i.optimize()\n",
        "    results.append(result_i.fun)\n",
        "    \n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Completed {i + 1}/{n_repeats} runs\")\n",
        "\n",
        "# Compute statistics\n",
        "mean_result = np.mean(results)\n",
        "std_result = np.std(results)\n",
        "min_result = np.min(results)\n",
        "max_result = np.max(results)\n",
        "\n",
        "print(f\"\\nResults over {n_repeats} runs:\")\n",
        "print(f\"  Mean of best values: {mean_result:.6f}\")\n",
        "print(f\"  Std of best values:  {std_result:.6f}\")\n",
        "print(f\"  Min of best values:  {min_result:.6f}\")\n",
        "print(f\"  Max of best values:  {max_result:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SpotOptim with Sklearn Kriging in 10 Dimensions: Michalewicz Function\n",
        "\n",
        "This section demonstrates how to use the `SpotOptim` class with sklearn's Gaussian Process Regressor (using Matern kernel) as a surrogate on the 10-dimensional Michalewicz function.\n",
        "We use a maximum of 300 function evaluations.\n",
        "\n",
        "### Define the 10D Michalewicz Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotoptim.function import michalewicz\n",
        "\n",
        "dim = 10\n",
        "lower = np.full(dim, 0.0)\n",
        "upper = np.full(dim, np.pi)\n",
        "bounds = list(zip(lower, upper))\n",
        "fun = michalewicz\n",
        "max_iter = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up SpotOptim Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_initial = dim\n",
        "seed = 321"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sklearn Gaussian Process Regressor as Surrogate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: kriging-matern-10d-michalewicz_run\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
        "\n",
        "# Use a Matern kernel instead of the standard RBF kernel\n",
        "kernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n",
        "    length_scale=1.0, \n",
        "    length_scale_bounds=(1e-4, 1e2), \n",
        "    nu=2.5\n",
        ")\n",
        "surrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)\n",
        "\n",
        "# Create SpotOptim instance with sklearn surrogate\n",
        "opt_micha = SpotOptim(\n",
        "    fun=fun,\n",
        "    bounds=bounds,\n",
        "    n_initial=n_initial,\n",
        "    max_iter=max_iter,\n",
        "    surrogate=surrogate,\n",
        "    seed=seed,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "result_micha = opt_micha.optimize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"[10D] Sklearn Kriging: min y = {result_micha.fun:.4f} at x = {result_micha.x}\")\n",
        "print(f\"Number of function evaluations: {result_micha.nfev}\")\n",
        "print(f\"Number of iterations: {result_micha.nit}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Optimization Progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the optimization progress\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.minimum.accumulate(opt_micha.y_), 'b-', linewidth=2)\n",
        "plt.xlabel('Function Evaluations', fontsize=12)\n",
        "plt.ylabel('Best Objective Value', fontsize=12)\n",
        "plt.title('10D Michalewicz: Sklearn Kriging Progress', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of Multiple Repeats\n",
        "\n",
        "To perform 30 repeats and collect statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Perform 30 independent runs\n",
        "n_repeats = 30\n",
        "results = []\n",
        "\n",
        "print(f\"Running {n_repeats} independent optimizations...\")\n",
        "for i in range(n_repeats):\n",
        "    kernel_i = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n",
        "        length_scale=1.0, \n",
        "        length_scale_bounds=(1e-4, 1e2), \n",
        "        nu=2.5\n",
        "    )\n",
        "    surrogate_i = GaussianProcessRegressor(kernel=kernel_i, n_restarts_optimizer=100)\n",
        "    \n",
        "    opt_i = SpotOptim(\n",
        "        fun=fun,\n",
        "        bounds=bounds,\n",
        "        n_initial=n_initial,\n",
        "        max_iter=max_iter,\n",
        "        surrogate=surrogate_i,\n",
        "        seed=seed + i,  # Different seed for each run\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    result_i = opt_i.optimize()\n",
        "    results.append(result_i.fun)\n",
        "    \n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Completed {i + 1}/{n_repeats} runs\")\n",
        "\n",
        "# Compute statistics\n",
        "mean_result = np.mean(results)\n",
        "std_result = np.std(results)\n",
        "min_result = np.min(results)\n",
        "max_result = np.max(results)\n",
        "\n",
        "print(f\"\\nResults over {n_repeats} runs:\")\n",
        "print(f\"  Mean of best values: {mean_result:.6f}\")\n",
        "print(f\"  Std of best values:  {std_result:.6f}\")\n",
        "print(f\"  Min of best values:  {min_result:.6f}\")\n",
        "print(f\"  Max of best values:  {max_result:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison: SpotOptim vs SpotPython\n",
        "\n",
        "The `SpotOptim` package provides a scipy-compatible interface for Bayesian optimization with the following key features:\n",
        "\n",
        "1. **Scipy-compatible API**: Returns `OptimizeResult` objects that work seamlessly with scipy's optimization ecosystem\n",
        "2. **Custom Surrogates**: Supports any sklearn-compatible surrogate model (as demonstrated with GaussianProcessRegressor)\n",
        "3. **Flexible Interface**: Simplified parameter specification with bounds, n_initial, and max_iter\n",
        "4. **Analytical Test Functions**: Built-in test functions (rosenbrock, ackley, michalewicz) for benchmarking\n",
        "\n",
        "The main differences from spotpython are:\n",
        "\n",
        "- **SpotOptim**: Uses `bounds`, `n_initial`, `max_iter` parameters with scipy-style interface\n",
        "- **SpotPython**: Uses `fun_control`, `design_control`, `surrogate_control` with more complex configuration\n",
        "\n",
        "Both packages support custom surrogates and provide powerful Bayesian optimization capabilities.\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated how to:\n",
        "\n",
        "1. Use `SpotOptim` with sklearn's Gaussian Process Regressor (Matern kernel) as a surrogate\n",
        "2. Optimize 6D Rosenbrock function with 100 evaluations\n",
        "3. Optimize 10D Michalewicz function with 300 evaluations\n",
        "4. Visualize optimization progress\n",
        "5. Perform multiple independent runs for statistical analysis\n",
        "\n",
        "The results show that `SpotOptim` with sklearn surrogates provides effective Bayesian optimization for challenging benchmark functions.\n",
        "\n",
        "## Jupyter Notebook\n",
        "\n",
        ":::{.callout-note}\n",
        "\n",
        "* This Quarto document is part of the spotoptim package benchmarking suite\n",
        "* Source available at: [spotoptim GitHub Repository](https://github.com/sequential-parameter-optimization/spotoptim)\n",
        "\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/workspace/spotoptim-cookbook/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}