{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"SpotOptim Step-by-Step Optimization Process\"\n",
        "author: Bartz-Beielstein, Thomas\n",
        "date: \"November 19, 2025\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    code-fold: false\n",
        "    number-sections: true\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This document provides a comprehensive step-by-step explanation of the optimization process in the `SpotOptim` class. We'll use the 2-dimensional Rosenbrock function as our example and cover all methods involved in each stage of optimization.\n",
        "\n",
        "**Topics Covered:**\n",
        "\n",
        "- Standard optimization workflow\n",
        "- Handling noisy functions with repeats\n",
        "- Handling function evaluation failures (NaN/inf values)\n",
        "\n",
        "# Setup and Test Functions\n",
        "\n",
        "Let's start by defining our test functions, including variants with noise and occasional failures.\n",
        "The two-dimensional Rosenbrock function is defined as:\n",
        "$$\n",
        "f(x, y) = (a - x)^2 + b(y - x^2)^2\n",
        "$$\n",
        "where typically \\(a = 1\\) and \\(b = 100\\).\n",
        "The generalized form for n dimensions is:\n",
        "$$\n",
        "f(X) = \\sum_{i=1}^{N-1} \\left[100 \\cdot (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\\right]\n",
        "$$\n",
        "The documentation can be found here: [DOC](https://sequential-parameter-optimization.github.io/spotoptim/reference/spotoptim/function/analytical/#spotoptim.function.analytical.rosenbrock)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.function import rosenbrock\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set random seed for reproducibility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the standard Rosenbrock function, we define two variants:\n",
        "\n",
        "1. the noisy Rosenbrock function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def rosenbrock_noisy(X, noise_std=0.1):\n",
        "    \"\"\"\n",
        "    Rosenbrock with Gaussian noise for testing noisy optimization.\n",
        "    \"\"\"\n",
        "    X = np.atleast_2d(X)\n",
        "    base_values = rosenbrock(X)\n",
        "    noise = np.random.normal(0, noise_std, size=base_values.shape)\n",
        "    return base_values + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and 2. the Rosenbrock function with occasional failures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def rosenbrock_with_failures(X, failure_prob=0.15):\n",
        "    \"\"\"\n",
        "    Rosenbrock that occasionally returns NaN to simulate evaluation failures.\n",
        "    \"\"\"\n",
        "    X = np.atleast_2d(X)\n",
        "    values = rosenbrock(X)\n",
        "\n",
        "    # Randomly inject failures\n",
        "    for i in range(len(values)):\n",
        "        if np.random.random() < failure_prob:\n",
        "            values[i] = np.nan\n",
        "\n",
        "    return values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Standard Optimization Workflow\n",
        "\n",
        "Let's trace through a complete optimization run to understand each step.\n",
        "\n",
        "## Phase: Initialization and Setup\n",
        "\n",
        "When you create a `SpotOptim` instance, several initialization steps occur during the `__init__()` method, see [DOC](https://sequential-parameter-optimization.github.io/spotoptim/reference/spotoptim/SpotOptim/#spotoptim.SpotOptim.SpotOptim).\n",
        "\n",
        "1. Objective function (`fun`) and  bounds are stored.\n",
        "2. Acquisition function (`acquisition`) is stored (default is `y`).\n",
        "3. Determine if noise handling is active (based on `repeats_initial` and `repeats_surrogate`)\n",
        "4. For dimensions with tuple bounds (factor variables), internal integer mappings are created and bounds are replaced with (0, n_levels-1). This is handled by `_process_factor_bounds()`. So, e.g., `[('red', 'green', 'blue')]` is mapped to the  integer interval `[(0, 2)]` internally.\n",
        "5. The dimension of the problem (`n_dim`) is inferred from the bounds.\n",
        "6. If `var_type` is not provided, it defaults to all \"float\" (continuous) variables, except for factor variables which are set to \"factor\" via `_process_factor_bounds()`.\n",
        "7. Default variable names (`var_name`) are set if not provided.\n",
        "8. Default variable transformations (`var_transform`) are set if not provided.\n",
        "9. Transformations are applied to bounds based on `var_transform` settings. Natural bounds are stored in `_original_lower` and `_original_upper`.\n",
        "10. Dimension reduction by identifying fixed dimensions (if any) is performed via `_setup_dimension_reduction()`.\n",
        "11. The surrogate is initialized (default: Gaussian Process with Matérn kernel) as follows:\n",
        "```python\n",
        "kernel = ConstantKernel(\n",
        "    constant_value=1.0, constant_value_bounds=(1e-3, 1e3)\n",
        ") * Matern(length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=2.5)\n",
        "self.surrogate = GaussianProcessRegressor(\n",
        "    kernel=kernel,\n",
        "    n_restarts_optimizer=10,\n",
        "    normalize_y=True,\n",
        "    random_state=self.seed,\n",
        ")\n",
        "```\n",
        "12. The Design generator is initialized (default: Latin Hypercube Sampling).\n",
        "13. The storage for results ins initialized. This includes the following attributes:\n",
        "    - `X_`: Evaluated design points\n",
        "    - `y_`: Corresponding function values\n",
        "    - `y_mo`: For multi-objective functions, stores all objectives\n",
        "    - `best_x_`: Best point found so far\n",
        "    - `best_y_`: Best function value found so far\n",
        "    - `n_iter_`: Number of iterations completed\n",
        "    - `mean_X`, `mean_y`, `var_y`: For noisy functions, mean and variance tracking\n",
        "    - `min_mean_X`: Best mean point for noisy functions\n",
        "    - `min_mean_y`: Best mean value for noisy functions\n",
        "    - `min_var_y`: Variance at best mean point\n",
        "    - `min_X`: Best point found (deterministic)\n",
        "    - `min_y`: Best function value found (deterministic)\n",
        "    - `counter`: Total number of function evaluations\n",
        "    - `success_rate`: Ratio of successful evaluations\n",
        "    - `success_counter`: Count of successful evaluations\n",
        "    - `window_size`: For moving average of success rate\n",
        "    - `success_history`: History of success/failure for evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create optimizer\n",
        "opt = SpotOptim(\n",
        "    fun=rosenbrock,\n",
        "    bounds=[(-2, 2), (1, 2)],\n",
        "    n_initial=10,\n",
        "    max_iter=30,\n",
        "    verbose=True,\n",
        "    seed=42,\n",
        "    var_trans=[\"id\", \"log\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase: Initial Design Generation\n",
        "\n",
        "### Method: `get_initial_design()`\n",
        "\n",
        "This method generates or processes the initial sample points.\n",
        "It is manually called here for demonstration (normally done inside `optimize()`).\n",
        "\n",
        "**What happens in `get_initial_design()`:**\n",
        "\n",
        "1. If `X0=None`: Generate space-filling design using Latin Hypercube Sampling (LHS)\n",
        "2. If `x0` (starting point) provided: Include it as first point and transform user's points to internal scale\n",
        "4. Apply dimension reduction if configured\n",
        "5. Round integer/factor variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X0 = opt.get_initial_design(X0=None)\n",
        "\n",
        "print(f\"Generated {len(X0)} initial design points using Latin Hypercube Sampling\")\n",
        "print(f\"Design shape: {X0.shape}\")\n",
        "print(f\"\\nFirst 3 points (internal scale):\")\n",
        "print(X0[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note, because `bounds` were set to `[(-2, 2), (-2, 2)]` and `n_initial=10`, the generated points are within this range and the design has two-dimensional shape (10, 2).\n",
        "\n",
        "* Print initial design in original scale and in internal scale:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X0_original = opt._inverse_transform_X(X0)\n",
        "print(f\"\\nFirst 3 points (original scale):\")\n",
        "print(X0_original[:3])\n",
        "print(f\"\\nFirst 3 points (internal scale):\")\n",
        "print(X0[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Plot initial design in original scale:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(X0_original[:, 0], X0_original[:, 1], c='blue', label='Initial Design Points')\n",
        "plt.xlabel(\"X1\")\n",
        "plt.ylabel(\"X2\")\n",
        "plt.title(\"Initial Design Points (Original Scale)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Initial Design Curation\n",
        "\n",
        "### Method: `_curate_initial_design()`\n",
        "\n",
        "This method ensures we have sufficient unique points and handles repeats.\n",
        "\n",
        "**What happens in `_curate_initial_design()`:**\n",
        "\n",
        "1. Remove duplicate points (can occur after rounding integers)\n",
        "2. Generate additional points if duplicates reduced count below `n_initial`\n",
        "3. Repeat each point `repeats_initial` times if > 1 (for noisy functions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X0_curated = opt._curate_initial_design(X0)\n",
        "print(f\"Curated design shape: {X0_curated.shape}\")\n",
        "print(f\"Unique points: {len(np.unique(X0_curated, axis=0))}\")\n",
        "print(f\"Total points (with repeats): {len(X0_curated)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4: Initial Design Evaluation\n",
        "\n",
        "### Method: `_evaluate_function()`\n",
        "\n",
        "Evaluates the objective function at all initial design points.\n",
        "The points are converted back to the original scale for evaluation.\n",
        "\n",
        "**What happens in `_evaluate_function()`:**\n",
        "\n",
        "1. Convert points from internal to original scale\n",
        "2. Call objective function with batch of points\n",
        "3. Convert multi-objective to single-objective if needed\n",
        "4. Return array of function values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X0_original = opt._inverse_transform_X(X0_curated)\n",
        "y0 = opt._evaluate_function(X0_curated)\n",
        "\n",
        "print(f\"Evaluated {len(y0)} points\")\n",
        "print(f\"Function values shape: {y0.shape}\")\n",
        "print(f\"First 5 points with function values:\")\n",
        "for i in range(min(5, len(y0))):\n",
        "    print(f\"  Point {i+1}: {X0_original[i]} → f(x)={y0[i]:.6f}\")\n",
        "print(f\"\\nBest initial value: {np.min(y0):.6f}\")\n",
        "print(f\"Worst initial value: {np.max(y0):.6f}\")\n",
        "print(f\"Mean initial value: {np.mean(y0):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Handling Failed Evaluations\n",
        "\n",
        "### Method: `_handle_NA_initial_design(X0,y0)`\n",
        "\n",
        "Removes points that returned NaN or inf values.\n",
        "In contrasts to later phases, no penalties are applied here; invalid points of the initial design are simply removed.\n",
        "\n",
        "**What happens in `_handle_NA_initial_design()`:**\n",
        "\n",
        "1. Identify NaN/inf values in function evaluations\n",
        "2. Remove corresponding design points\n",
        "3. Return cleaned arrays and original count\n",
        "4. Note: No penalties applied in initial design - invalid points simply removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_before = len(y0)\n",
        "X0_clean, y0_clean, n_evaluated = opt._handle_NA_initial_design(X0_curated, y0)\n",
        "\n",
        "print(f\"Points before filtering: {n_before}\")\n",
        "print(f\"Points after filtering: {len(y0_clean)}\")\n",
        "print(f\"Removed: {n_before - len(y0_clean)} NaN/inf values\")\n",
        "print(f\"\\nAll remaining values finite: {np.all(np.isfinite(y0_clean))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 6: Validation Check\n",
        "\n",
        "### Method: `_check_size_initial_design(y0, n_evaluated)`\n",
        "\n",
        "Ensures we have enough valid points to continue.\n",
        "The minimum required is the smaller of:\n",
        "\n",
        "* typical minimum for surrogate fitting (3 for multi-dimensional, 2 for 1D), or \n",
        "* what the user requested (n_initial).\n",
        "\n",
        "**What happens in `_check_size_initial_design()`:**\n",
        "\n",
        "1. Check if at least 1 valid point exists\n",
        "2. Raise error if all initial evaluations failed\n",
        "3. Print warnings if many points were invalid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    opt._check_size_initial_design(y0_clean, n_evaluated)\n",
        "    print(f\"✓ Validation passed: {len(y0_clean)} valid points available\")\n",
        "    print(f\"  Minimum required: 1 point\")\n",
        "    print(f\"  Original evaluated: {n_evaluated} points\")\n",
        "except ValueError as e:\n",
        "    print(f\"✗ Validation failed: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 7: Storage Initialization\n",
        "\n",
        "### Method:  `_init_storage()`\n",
        "\n",
        "Store evaluated points and initialize tracking variables.\n",
        "\n",
        "**What happens during storage initialization:**\n",
        "\n",
        "1. `_init_storage()`: Initialize statistics tracking variables. \n",
        "\n",
        "\n",
        "* Initialize storage (as done in `optimize()`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize storage and statistics using the new _init_storage() method\n",
        "opt._init_storage(X0_clean, y0_clean)\n",
        "\n",
        "print(f\"X_ (evaluated points): shape {opt.X_.shape}\")\n",
        "print(f\"y_ (function values): shape {opt.y_.shape}\")\n",
        "print(f\"n_iter_ (iterations): {opt.n_iter_}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase: Statistics Update\n",
        "\n",
        "### Method: `update_stats()`\n",
        "\n",
        "Update statistics like means and variances for noisy evaluations.\n",
        "\n",
        "*** What happens in `update_stats()`:***\n",
        "\n",
        "1. If `noise` is set (i.e., `repeats_initial` > 1):\n",
        "    - Compute mean and variance of function values for each unique point\n",
        "    - Store in `mean_X`, `mean_y`, and `var_y`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\nStatistics updated:\")\n",
        "if opt.noise:\n",
        "    print(f\"  - mean_X: {opt.mean_X.shape}\")\n",
        "    print(f\"  - mean_y: {opt.mean_y.shape}\")\n",
        "    print(f\"  - var_y: {opt.var_y.shape}\")\n",
        "else:\n",
        "    print(f\"  - No noise tracking (repeats=1)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase: Log initial Design to TensorBoard\n",
        "\n",
        "### Method: `_log_initial_design_tensorboard()`\n",
        "\n",
        "This method logs the initial design points and their evaluations to TensorBoard for visualization.\n",
        "\n",
        "\n",
        "\n",
        "## Phase: Initial Best Point\n",
        "\n",
        "### Method: `_get_best_xy_initial_design()`\n",
        "\n",
        "Identify and report the best point from initial design.\n",
        "\n",
        "**What happens in `_get_best_xy_initial_design()`:**\n",
        "\n",
        "1. Find minimum value in `y_` (or `mean_y` if noise)\n",
        "2. Store as `best_y_`\n",
        "3. Store corresponding point as `best_x_`\n",
        "4. Print progress if verbose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "opt._get_best_xy_initial_design()\n",
        "\n",
        "print(f\"Best point found: {opt.best_x_}\")\n",
        "print(f\"Best value found: {opt.best_y_:.6f}\")\n",
        "print(f\"\\nOptimum location: [1, 1]\")\n",
        "print(f\"Optimum value: 0\")\n",
        "print(f\"Current gap: {opt.best_y_ - 0:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Illustration of the Initial Design Phase Results\n",
        "\n",
        "To visualize the results, we generate a contour plot with contour lines of the objective function and mark the best point. The other evaluated points are shown as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a grid of points for contour plotting\n",
        "x = np.linspace(-2, 2, 400)\n",
        "y = np.linspace(-2, 2, 400)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "grid_points = np.column_stack([X.ravel(), Y.ravel()])\n",
        "Z = rosenbrock(grid_points).reshape(X.shape)\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Contour plot\n",
        "contour = plt.contour(X, Y, Z, levels=np.logspace(-0.5, 3.5, 20), cmap='viridis')\n",
        "plt.clabel(contour, inline=True, fontsize=8)\n",
        "\n",
        "# Plot evaluated points from the initial design phase:\n",
        "plt.scatter(opt.X_[:, 0], opt.X_[:, 1], c='blue', label='Evaluated Points', alpha=0.6)\n",
        "# Mark best point\n",
        "plt.scatter(opt.best_x_[0], opt.best_x_[1], c='red', s=100, label='Best Point', edgecolors='black')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.title('Objective Function Contours with Evaluated Points')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sequential Optimization Loop\n",
        "\n",
        "After initialization, the main optimization loop begins. Each iteration follows these steps:\n",
        "\n",
        "## Step: Surrogate Model Fitting\n",
        "\n",
        "### Method: `_fit_scheduler()`\n",
        "\n",
        "Fit surrogate model using appropriate data based on noise handling.\n",
        "\n",
        "*** What happens in `_fit_scheduler()`:***\n",
        "\n",
        "First, the method transforms the input data `X` to the internal scale used by the optimizer. Then, it decides which data to use for fitting the surrogate model based on whether noise handling is enabled:\n",
        "\n",
        "1. If `noise` is set (i.e., `repeats_surrogate` > 1):\n",
        "    - Fit surrogate using mean points (`mean_X`, `mean_y`)\n",
        "2. Else:\n",
        "    - Fit surrogate using all evaluated points (`X_`, `y_`)\n",
        "\n",
        "`_fit_scheduler()` then calls `_fit_surrogate()` with the selected data.\n",
        "\n",
        "### Method: `_fit_surrogate()`\n",
        "\n",
        "Fit a surrogate model (Gaussian Process) to current data.\n",
        "\n",
        "**What happens in `_fit_surrogate()`:**\n",
        "\n",
        "1. If `max_surrogate_points` set and exceeded: Select subset of points using the `_selection_dispatcher()` method.\n",
        "2. Fit surrogate model using `surrogate.fit(X, y)`\n",
        "3. Surrogate learns the function landscape and uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_for_surrogate = opt._transform_X(opt.X_)\n",
        "opt._fit_surrogate(X_for_surrogate, opt.y_)\n",
        "\n",
        "print(f\"Surrogate fitted with {len(opt.y_)} points\")\n",
        "print(f\"Surrogate type: {type(opt.surrogate).__name__}\")\n",
        "print(f\"Kernel: {opt.surrogate.kernel_}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method: `_selection_dispatcher()`\n",
        "\n",
        "**What happens in `_selection_dispatcher()`:**\n",
        "\n",
        "1. If `max_surrogate_points` is set and exceeded:\n",
        "   - Select a subset of points from `X_` and `y_` for fitting the surrogate model.\n",
        "   - Strategies may include random sampling, clustering, or other heuristics to reduce the dataset size while preserving important information.\n",
        "\n",
        "\n",
        "**Surrogate Model Selection:**\n",
        "\n",
        "- Default: Gaussian Process with Matérn kernel\n",
        "- Provides: Mean prediction $\\mu(x)$ and uncertainty $\\sigma(x)$\n",
        "- Can be replaced with Random Forest, Kriging, etc.\n",
        "\n",
        "* The fitted surrogate can be plotted with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "opt.plot_surrogate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step: Apply OCBA\n",
        "\n",
        "### Method: `_apply_ocba()`\n",
        "\n",
        "**What happens in `_apply_ocba()`:**\n",
        "\n",
        "1. Compute the optimality criteria for each point in the design space.\n",
        "2. Select the most promising points based on the criteria.\n",
        "3. Update the surrogate model with the selected points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_ocba = opt._apply_ocba()\n",
        "if X_ocba is not None:\n",
        "    print(f\"OCBA selected {X_ocba.shape[0]} points for re-evaluation\")\n",
        "    print(f\"OCBA points shape: {X_ocba.shape}\")\n",
        "else:\n",
        "    print(\"OCBA not applied (noise=False or ocba_delta=0)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step: Predict with Uncertainty\n",
        "\n",
        "### Method: `_predict_with_uncertainty()`\n",
        "\n",
        "Make predictions at new locations with uncertainty estimates.\n",
        "\n",
        "\n",
        "**What happens in `_predict_with_uncertainty()`:**\n",
        "\n",
        "1. Call `surrogate.predict(X, return_std=True)`\n",
        "2. Returns mean μ(x) and standard deviation σ(x)\n",
        "3. Used by acquisition function to balance exploitation (low μ) and exploration (high σ)\n",
        "\n",
        "\n",
        "Here we test prediction at a few points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test = np.array([[0.5, 0.5], [1.0, 1.0], [-0.5, 0.5]])\n",
        "mu, sigma = opt._predict_with_uncertainty(X_test)\n",
        "\n",
        "print(f\"Test points: {X_test.shape}\")\n",
        "print(f\"\\nPredictions (μ ± σ):\")\n",
        "for i, (x, m, s) in enumerate(zip(X_test, mu, sigma)):\n",
        "    print(f\"  x={x} → μ={m:.4f}, σ={s:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step: Next Point Suggestion\n",
        "\n",
        "### Method: `_suggest_next_point()`\n",
        "\n",
        "Optimize acquisition function to find next evaluation point.\n",
        "\n",
        "**What happens in `_suggest_next_point()`:**\n",
        "\n",
        "1. Use `differential_evolution` to optimize acquisition function\n",
        "2. Find point that maximizes EI (or minimizes predicted value for 'y')\n",
        "3. Apply rounding for integer/factor variables\n",
        "4. Check distance to existing points (avoid duplicates)\n",
        "5. If duplicate or too close: Use fallback strategy\n",
        "6. Return suggested point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_next = opt._suggest_next_point()\n",
        "print(f\"Next point suggested: {x_next}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predict at suggested point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mu_next, sigma_next = opt._predict_with_uncertainty(x_next.reshape(1, -1))\n",
        "print(f\"\\nPrediction at suggested point:\")\n",
        "print(f\"  μ(x_next) = {mu_next[0]:.4f}\")\n",
        "print(f\"  σ(x_next) = {sigma_next[0]:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Fallback Strategies** (if acquisition optimization fails):\n",
        "\n",
        "- `'best'`: Re-evaluate current best point\n",
        "- `'mean'`: Select point with best predicted mean\n",
        "- `'random'`: Random point in search space\n",
        "\n",
        "\n",
        "## Step: Acquisition Function Evaluation\n",
        "\n",
        "### Method: `_acquisition_function()`\n",
        "\n",
        "Compute acquisition function value to guide search.\n",
        "The acquisition function is used as an objective function by the optimizer on the surrogate, e.g., differential evolution. It determines where to sample next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate acquisition at test points\n",
        "print(f\"Acquisition type: {opt.acquisition} (Expected Improvement)\")\n",
        "print(f\"\\nAcquisition values at test points:\")\n",
        "\n",
        "for x in X_test:\n",
        "    acq_val = opt._acquisition_function(x)\n",
        "    print(f\"  x={x} → acq={acq_val:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Acquisition function can be used to balance:\n",
        "\n",
        "* exploitation, i.e., low predicted mean $\\mu(x)$ and\n",
        "* exploration, i.e., high uncertainty $\\sigma(x)$\n",
        "\n",
        "\n",
        "**Acquisition Functions Available:**\n",
        "\n",
        "1. **Expected Improvement (EI)** - Default, best balance\n",
        "$$\n",
        "\\text{EI}(x) = (f^* - \\mu(x))\\Phi(Z) + \\sigma(x)\\phi(Z)\n",
        "$$\n",
        "where $Z = \\frac{f^* - \\mu(x)}{\\sigma(x)}$\n",
        "\n",
        "2. **Probability of Improvement (PI)** - More exploitative\n",
        "$$\n",
        "\\text{PI}(x) = \\Phi\\left(\\frac{f^* - \\mu(x)}{\\sigma(x)}\\right)\n",
        "$$\n",
        "\n",
        "3. **Mean ('y')** - Pure exploitation\n",
        "$$\n",
        "\\text{acq}(x) = \\mu(x)\n",
        "$$\n",
        "\n",
        "\n",
        "## Step: Update Repeats for Infill Points\n",
        "\n",
        "### Method: `_update_repeats_infill_points()`\n",
        "\n",
        "Repeat the infill point for noisy function evaluation if `repeats_surrogate > 1`.\n",
        "\n",
        "**What happens in `_update_repeats_infill_points()`:**\n",
        "\n",
        "1. Takes the suggested next point (`x_next`)\n",
        "2. If `repeats_surrogate > 1`: Creates multiple copies for repeated evaluation\n",
        "3. Otherwise: Returns point as 2D array (shape: 1 × n_features)\n",
        "4. Returns array ready for function evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_next_repeated = opt._update_repeats_infill_points(x_next)\n",
        "print(f\"Shape before repeating: {x_next.shape}\")\n",
        "print(f\"Shape after repeating: {x_next_repeated.shape}\")\n",
        "print(f\"Number of evaluations planned: {x_next_repeated.shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Append OCBA Points to Infill Points\n",
        "\n",
        "Combines OCBA selected points with the next suggested point for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if X_ocba is not None:\n",
        "    x_next_repeated = np.append(X_ocba, x_next_repeated, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step: Evaluation of New Points\n",
        "\n",
        "### Method: `_evaluate_function()` (again)\n",
        "\n",
        "Evaluate the objective function at the suggested points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_next_2d = x_next.reshape(1, -1)\n",
        "y_next = opt._evaluate_function(x_next_2d)\n",
        "\n",
        "print(f\"Evaluated point: {x_next}\")\n",
        "print(f\"Function value: {y_next[0]:.6f}\")\n",
        "print(f\"Current best: {opt.best_y_:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step: Handle Failed Evaluations (Sequential)\n",
        "\n",
        "### Method: `_handle_NA_new_points()`\n",
        "\n",
        "Handle NaN/inf values in new evaluations with penalty approach.\n",
        "\n",
        "**What happens in `_handle_NA_new_points()`:**\n",
        "\n",
        "1. **Apply penalty** to NaN/inf values (unlike initial design)\n",
        "   - Penalty = max(history) + 3×std(history) + random noise\n",
        "2. **Remove** remaining invalid values after penalty\n",
        "3. **Return None** if all evaluations failed → skip iteration\n",
        "4. **Continue** if any valid evaluations exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x_clean, y_clean = opt._handle_NA_new_points(x_next_2d, y_next)\n",
        "\n",
        "if x_clean is not None:\n",
        "    print(f\"✓ Valid evaluations: {len(y_clean)}\")\n",
        "    print(f\"  All values finite: {np.all(np.isfinite(y_clean))}\")\n",
        "else:\n",
        "    print(f\"✗ All evaluations failed - iteration would be skipped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why penalties in sequential phase?**\n",
        "\n",
        "- Preserves optimization history\n",
        "- Allows surrogate to learn \"bad\" regions\n",
        "- Random noise prevents identical penalties\n",
        "\n",
        "\n",
        "\n",
        "## Step: Update Success Rate\n",
        "\n",
        "### Method: `_update_success_rate(y0)`\n",
        "\n",
        "Update success rate BEFORE updating storage (initial design - all should be successes since starting from scratch)\n",
        "\n",
        "**What happens in `_update_success_rate()`:**\n",
        "\n",
        "1. Calculate success rate as ratio of valid evaluations to total evaluated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "opt._update_success_rate(y0_clean)\n",
        "print(f\"\\nSuccess rate updated: {opt.success_rate:.2%} (valid evaluations / total evaluations)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step: Update Storage\n",
        "\n",
        "### Internal updates\n",
        "\n",
        "Add new evaluations to storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "opt._update_storage(x_next_repeated, y_next)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update Statistics\n",
        "\n",
        "Update statistics after new evaluations.\n",
        "\n",
        "### What happens in `update_stats()`:\n",
        "\n",
        "**Always updated:**\n",
        "\n",
        "- `min_y`: Best (minimum) function value\n",
        "- `min_X`: Design point with best value\n",
        "- `counter`: Total number of evaluations\n",
        "\n",
        "**For noisy functions only (if `noise=True`):**\n",
        "\n",
        "- `mean_X`: Unique design points\n",
        "- `mean_y`: Mean values per design point\n",
        "- `var_y`: Variance per design point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "opt.update_stats()\n",
        "print(f\"Basic statistics:\")\n",
        "print(f\"  min_y: {opt.min_y:.6f}\")\n",
        "print(f\"  min_X: {opt.min_X}\")\n",
        "print(f\"  counter: {opt.counter}\")\n",
        "\n",
        "if opt.noise:\n",
        "    print(f\"\\nNoise statistics:\")\n",
        "    print(f\"  mean_X shape: {opt.mean_X.shape}\")\n",
        "    print(f\"  mean_y shape: {opt.mean_y.shape}\")\n",
        "    print(f\"  var_y shape: {opt.var_y.shape}\")\n",
        "else:\n",
        "    print(f\"\\nNoise handling: disabled (deterministic function)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step: Update Best Solution\n",
        "\n",
        "### Method: `_update_best_main_loop()`\n",
        "\n",
        "Update the best solution if improvement found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best_before = opt.best_y_\n",
        "opt._update_best_main_loop(x_clean, y_clean)\n",
        "\n",
        "print(f\"Best before: {best_before:.6f}\")\n",
        "print(f\"Best after: {opt.best_y_:.6f}\")\n",
        "\n",
        "if opt.best_y_ < best_before:\n",
        "    print(f\"\\n✓ New best found!\")\n",
        "    print(f\"  Location: {opt.best_x_}\")\n",
        "    print(f\"  Value: {opt.best_y_:.6f}\")\n",
        "else:\n",
        "    print(f\"\\n○ Best unchanged\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loop Termination Conditions:**\n",
        "\n",
        "The optimization continues until:\n",
        "\n",
        "1. `len(y_) >= max_iter` (reached evaluation budget), OR\n",
        "2. `elapsed_time >= max_time` (reached time limit)\n",
        "\n",
        "# Complete Optimization Example\n",
        "\n",
        "Now let's run a complete optimization to see all steps in action:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create fresh optimizer\n",
        "opt_complete = SpotOptim(\n",
        "    fun=rosenbrock,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=8,\n",
        "    max_iter=25,\n",
        "    acquisition='ei',\n",
        "    verbose=False,  # Set to False for cleaner output\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "result = opt_complete.optimize()\n",
        "\n",
        "print(f\"\\nOptimization Result:\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Best point found: {result.x}\")\n",
        "print(f\"Best value: {result.fun:.6f}\")\n",
        "print(f\"True optimum: [1.0, 1.0]\")\n",
        "print(f\"True minimum: 0.0\")\n",
        "print(f\"Gap to optimum: {result.fun:.6f}\")\n",
        "print(f\"\\nFunction evaluations: {result.nfev}\")\n",
        "print(f\"Sequential iterations: {result.nit}\")\n",
        "print(f\"Success: {result.success}\")\n",
        "print(f\"Message: {result.message}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Noisy Functions with Repeats\n",
        "\n",
        "When dealing with noisy objective functions, SpotOptim can evaluate each point multiple times and track statistics.\n",
        "\n",
        "## Configuration for Noisy Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "NOISE_STD = 10.0\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NOISY FUNCTION OPTIMIZATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nConfiguration for noisy optimization with noise std = {NOISE_STD}:\")\n",
        "\n",
        "\n",
        "# Wrapper to add noise\n",
        "def rosenbrock_noisy_wrapper(X):\n",
        "    return rosenbrock_noisy(X, noise_std=NOISE_STD)\n",
        "\n",
        "opt_noisy = SpotOptim(\n",
        "    fun=rosenbrock_noisy_wrapper,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=6,\n",
        "    max_iter=20,\n",
        "    repeats_initial=3,      # Evaluate each initial point 3 times\n",
        "    repeats_surrogate=2,    # Evaluate each sequential point 2 times\n",
        "    verbose=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"Configuration for noisy optimization:\")\n",
        "print(f\"  repeats_initial: {opt_noisy.repeats_initial}\")\n",
        "print(f\"  repeats_surrogate: {opt_noisy.repeats_surrogate}\")\n",
        "print(f\"  noise: {opt_noisy.noise}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Noisy Optimization Workflow Differences\n",
        "\n",
        "### Modified Initial Design\n",
        "\n",
        "With `repeats_initial > 1`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_noisy = opt_noisy.optimize()\n",
        "\n",
        "print(f\"\\nInitial design with repeats:\")\n",
        "print(f\"  n_initial = {opt_noisy.n_initial}\")\n",
        "print(f\"  repeats_initial = {opt_noisy.repeats_initial}\")\n",
        "print(f\"  Total initial evaluations: {opt_noisy.n_initial * opt_noisy.repeats_initial}\")\n",
        "\n",
        "print(f\"\\nStatistics tracked:\")\n",
        "print(f\"  mean_X shape: {opt_noisy.mean_X.shape} (unique points)\")\n",
        "print(f\"  mean_y shape: {opt_noisy.mean_y.shape} (mean values)\")\n",
        "print(f\"  var_y shape: {opt_noisy.var_y.shape} (variances)\")\n",
        "\n",
        "print(f\"\\nExample statistics for first point:\")\n",
        "idx = 0\n",
        "print(f\"  Point: {opt_noisy.mean_X[idx]}\")\n",
        "print(f\"  Mean value: {opt_noisy.mean_y[idx]:.4f}\")\n",
        "print(f\"  Variance: {opt_noisy.var_y[idx]:.4f}\")\n",
        "print(f\"  Std dev: {np.sqrt(opt_noisy.var_y[idx]):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Differences with Noise:**\n",
        "\n",
        "1. **Repeated Evaluations**: Each point evaluated multiple times\n",
        "2. **Statistics Tracking**:\n",
        "   - `mean_X`: Unique evaluation locations\n",
        "   - `mean_y`: Mean function values at each location\n",
        "   - `var_y`: Variance of function values\n",
        "   - `n_eval`: Number of evaluations per location\n",
        "3. **Surrogate Fitting**: Uses `mean_y` instead of `y_`\n",
        "4. **Best Selection**: Based on `mean_y` not individual `y_`\n",
        "\n",
        "### Update Statistics Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"After optimization:\")\n",
        "print(f\"  Total evaluations: {len(opt_noisy.y_)}\")\n",
        "print(f\"  Unique points: {len(opt_noisy.mean_X)}\")\n",
        "print(f\"  Average repeats per point: {len(opt_noisy.y_) / len(opt_noisy.mean_X):.2f}\")\n",
        "\n",
        "print(f\"\\nVariance statistics:\")\n",
        "print(f\"  Mean variance: {np.mean(opt_noisy.var_y):.6f}\")\n",
        "print(f\"  Max variance: {np.max(opt_noisy.var_y):.6f}\")\n",
        "print(f\"  Min variance: {np.min(opt_noisy.var_y):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimal Computing Budget Allocation (OCBA)\n",
        "\n",
        "OCBA intelligently allocates additional evaluations to distinguish between competing solutions.\n",
        "\n",
        "## OCBA Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OPTIMAL COMPUTING BUDGET ALLOCATION (OCBA)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "opt_ocba = SpotOptim(\n",
        "    fun=rosenbrock_noisy_wrapper,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=8,\n",
        "    max_iter=30,\n",
        "    repeats_initial=2,\n",
        "    repeats_surrogate=1,\n",
        "    ocba_delta=3,           # Allocate 3 additional evaluations per iteration\n",
        "    verbose=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"OCBA Configuration:\")\n",
        "print(f\"  ocba_delta: {opt_ocba.ocba_delta}\")\n",
        "print(f\"  Purpose: Intelligently re-evaluate existing points\")\n",
        "print(f\"  Benefit: Better distinguish between similar solutions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OCBA Method\n",
        "\n",
        "### Method: `_apply_ocba()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_ocba = opt_ocba.optimize()\n",
        "\n",
        "print(f\"\\nOCBA applied during optimization\")\n",
        "print(f\"  Final total evaluations: {result_ocba.nfev}\")\n",
        "print(f\"  Expected without OCBA: ~{opt_ocba.n_initial * opt_ocba.repeats_initial + result_ocba.nit * opt_ocba.repeats_surrogate}\")\n",
        "print(f\"  Additional OCBA evaluations: ~{result_ocba.nit * opt_ocba.ocba_delta}\")\n",
        "\n",
        "print(f\"\\nOCBA intelligently allocated extra evaluations to:\")\n",
        "print(f\"  - Current best candidate (confirm it's truly best)\")\n",
        "print(f\"  - Close competitors (distinguish between similar solutions)\")\n",
        "print(f\"  - High-variance points (reduce uncertainty)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**OCBA Algorithm:**\n",
        "\n",
        "1. Identify best solution (lowest mean value)\n",
        "2. Calculate allocation ratios based on:\n",
        "   - Distance to best solution\n",
        "   - Variance of each solution\n",
        "3. Allocate `ocba_delta` additional evaluations\n",
        "4. Returns points to re-evaluate\n",
        "5. Requires: ≥3 points with variance > 0\n",
        "\n",
        "**OCBA Activation Conditions:**\n",
        "- `noise = True` (repeats > 1)\n",
        "- `ocba_delta > 0`\n",
        "- At least 3 design points exist\n",
        "- All points have variance > 0\n",
        "\n",
        "# Handling Function Evaluation Failures\n",
        "\n",
        "SpotOptim robustly handles functions that occasionally fail (return NaN/inf).\n",
        "\n",
        "## Example with Failures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "opt_failures = SpotOptim(\n",
        "    fun=rosenbrock_with_failures,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=12,\n",
        "    max_iter=35,\n",
        "    verbose=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "result_failures = opt_failures.optimize()\n",
        "\n",
        "print(f\"\\nOptimization with ~15% random failure rate:\")\n",
        "print(f\"  Function evaluations: {result_failures.nfev}\")\n",
        "print(f\"  Sequential iterations: {result_failures.nit}\")\n",
        "print(f\"  Success: {result_failures.success}\")\n",
        "\n",
        "# Count how many values are non-finite in raw evaluations\n",
        "n_total = len(opt_failures.y_)\n",
        "n_finite = np.sum(np.isfinite(opt_failures.y_))\n",
        "print(f\"\\nEvaluation statistics:\")\n",
        "print(f\"  Total evaluations: {n_total}\")\n",
        "print(f\"  Finite values: {n_finite}\")\n",
        "print(f\"  Note: Failed evaluations handled transparently\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Failure Handling in Initial Design\n",
        "\n",
        "### Method: `_handle_NA_initial_design()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Initial design failure handling:\")\n",
        "print(\"  1. Identify NaN/inf values\")\n",
        "print(\"  2. Remove invalid points entirely\")\n",
        "print(\"  3. Continue with valid points only\")\n",
        "print(\"  4. No penalties applied\")\n",
        "print(\"  5. Require at least 1 valid point\")\n",
        "\n",
        "print(\"\\nRationale:\")\n",
        "print(\"  - Initial design should be clean\")\n",
        "print(\"  - Invalid regions identified naturally\")\n",
        "print(\"  - Surrogate trained on good data only\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Failure Handling in Sequential Phase\n",
        "\n",
        "### Method: `_handle_NA_new_points()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Sequential phase failure handling:\")\n",
        "print(\"  1. Apply penalty to NaN/inf values\")\n",
        "print(\"     - Penalty = max(history) + 3×std(history)\")\n",
        "print(\"     - Add random noise to avoid duplicates\")\n",
        "print(\"  2. Remove remaining invalid values\")\n",
        "print(\"  3. Skip iteration if all evaluations failed\")\n",
        "print(\"  4. Continue if any valid evaluations\")\n",
        "\n",
        "print(\"\\nPenalty approach benefits:\")\n",
        "print(\"  ✓ Preserves optimization history\")\n",
        "print(\"  ✓ Surrogate learns to avoid bad regions\")\n",
        "print(\"  ✓ Better exploration-exploitation balance\")\n",
        "print(\"  ✓ More robust convergence\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Penalty Application\n",
        "\n",
        "### Method: `_apply_penalty_NA()`\n",
        "\n",
        "Let's demonstrate penalty calculation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simulate historical values\n",
        "y_history_sim = np.array([10.0, 15.0, 8.0, 12.0, 20.0, 9.0])\n",
        "y_new_sim = np.array([7.0, np.nan, 11.0, np.inf])\n",
        "\n",
        "print(\"Historical values:\", y_history_sim)\n",
        "print(\"New evaluations:\", y_new_sim)\n",
        "\n",
        "# Apply penalty\n",
        "y_repaired = opt_failures._apply_penalty_NA(\n",
        "    y_new_sim, \n",
        "    y_history=y_history_sim,\n",
        "    penalty_value=None,  # Compute adaptively\n",
        "    sd=0.1\n",
        ")\n",
        "\n",
        "print(f\"\\nAfter penalty application:\", y_repaired)\n",
        "print(f\"All finite: {np.all(np.isfinite(y_repaired))}\")\n",
        "\n",
        "# Show penalty calculation\n",
        "max_hist = np.max(y_history_sim)\n",
        "std_hist = np.std(y_history_sim, ddof=1)\n",
        "penalty_base = max_hist + 3 * std_hist\n",
        "\n",
        "print(f\"\\nPenalty calculation:\")\n",
        "print(f\"  max(history) = {max_hist:.2f}\")\n",
        "print(f\"  std(history) = {std_hist:.2f}\")\n",
        "print(f\"  Base penalty = {max_hist:.2f} + 3×{std_hist:.2f} = {penalty_base:.2f}\")\n",
        "print(f\"  Actual penalty = {penalty_base:.2f} + noise\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Method Summary\n",
        "\n",
        "## Methods Called During `optimize()`\n",
        "\n",
        "### Preparation Phase\n",
        "1. `get_initial_design()` - Generate/process initial sample points\n",
        "2. `_curate_initial_design()` - Remove duplicates, handle repeats\n",
        "3. `_evaluate_function()` - Evaluate objective function\n",
        "4. `_handle_NA_initial_design()` - Remove NaN/inf from initial design\n",
        "5. `_check_size_initial_design()` - Validate sufficient points\n",
        "6. `_init_storage()` - Initialize storage (X_, y_, n_iter_)\n",
        "7. `update_stats()` - Compute mean/variance for noisy functions\n",
        "8. `_init_tensorboard()` - Log initial design to TensorBoard (if enabled)\n",
        "9. `_get_best_xy_initial_design()` - Identify initial best\n",
        "\n",
        "### Sequential Optimization Loop (each iteration)\n",
        "10. `_fit_scheduler()` - Select data and fit surrogate based on noise handling\n",
        "    - Internally calls `_transform_X()` - Transform to internal scale\n",
        "    - Internally calls `_fit_surrogate()` - Fit Gaussian Process to data\n",
        "11. `_apply_ocba()` - OCBA allocation (if enabled)\n",
        "12. `_suggest_next_point()` - Optimize acquisition function\n",
        "    - Internally calls `_acquisition_function()`\n",
        "    - Internally calls `_predict_with_uncertainty()`\n",
        "13. `_update_repeats_infill_points()` - Repeat suggested point for noisy functions\n",
        "14. `_evaluate_function()` - Evaluate at suggested point(s)\n",
        "15. `_handle_NA_new_points()` - Handle failures with penalties\n",
        "    - Internally calls `_apply_penalty_NA()`\n",
        "    - Internally calls `_remove_nan()`\n",
        "16. `_update_success_rate()` - Update success tracking\n",
        "17. `_update_storage()` - Append new evaluations to storage\n",
        "    - Internally calls `_inverse_transform_X()` - Convert back to original scale\n",
        "18. `update_stats()` - Update mean/variance statistics\n",
        "19. `_write_tensorboard_hparams()` - Log hyperparameters (if enabled)\n",
        "20. `_write_tensorboard_scalars()` - Log scalar metrics (if enabled)\n",
        "21. `_update_best_main_loop()` - Update best solution\n",
        "\n",
        "### Finalization\n",
        "22. `to_all_dim()` - Expand to full dimensions (if dimensionality reduction used)\n",
        "23. `_determine_termination()` - Determine termination reason\n",
        "24. `_close_tensorboard_writer()` - Close logging (if enabled)\n",
        "25. `_map_to_factor_values()` - Convert factors back to strings\n",
        "26. Return `OptimizeResult` object\n",
        "\n",
        "## Helper Methods Used\n",
        "\n",
        "- `_generate_initial_design()` - LHS generation\n",
        "- `_repair_non_numeric()` - Round integer/factor variables\n",
        "- `_select_new()` - Check for duplicate points\n",
        "- `_handle_acquisition_failure()` - Fallback strategies\n",
        "- `to_red_dim()` - Dimension reduction (if enabled)\n",
        "- `_selection_dispatcher()` - Subset selection for large datasets\n",
        "\n",
        "# Termination Conditions\n",
        "\n",
        "## Method: `_determine_termination()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TERMINATION CONDITIONS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nMethod: _determine_termination()\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(\"Optimization terminates when:\")\n",
        "print(\"  1. len(y_) >= max_iter (evaluation budget exhausted)\")\n",
        "print(\"  2. elapsed_time >= max_time (time limit reached)\")\n",
        "print(\"  3. Whichever comes first\")\n",
        "\n",
        "print(f\"\\nExample from previous run:\")\n",
        "print(f\"  Message: {result_failures.message}\")\n",
        "print(f\"  Evaluations: {result_failures.nfev}/{opt_failures.max_iter}\")\n",
        "print(f\"  Iterations: {result_failures.nit}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Performance Comparison on Noisy Functions\n",
        "\n",
        "Let's compare standard, noisy, and noisy+OCBA optimization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Standard optimization\n",
        "opt_std = SpotOptim(\n",
        "    fun=rosenbrock_noisy_wrapper,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=8,\n",
        "    max_iter=50,\n",
        "    repeats_initial=1,\n",
        "    repeats_surrogate=1,\n",
        "    verbose=False,\n",
        "    seed=10\n",
        ")\n",
        "result_std = opt_std.optimize()\n",
        "\n",
        "# With repeats (no OCBA)\n",
        "opt_rep = SpotOptim(\n",
        "    fun=rosenbrock_noisy_wrapper,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=8,\n",
        "    max_iter=50,\n",
        "    repeats_initial=2,\n",
        "    repeats_surrogate=1,\n",
        "    ocba_delta=0,\n",
        "    verbose=False,\n",
        "    seed=10\n",
        ")\n",
        "result_rep = opt_rep.optimize()\n",
        "\n",
        "# With repeats + OCBA\n",
        "opt_ocba_comp = SpotOptim(\n",
        "    fun=rosenbrock_noisy_wrapper,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    n_initial=8,\n",
        "    max_iter=50,\n",
        "    repeats_initial=1,\n",
        "    repeats_surrogate=1,\n",
        "    ocba_delta=1,\n",
        "    verbose=False,\n",
        "    seed=10\n",
        ")\n",
        "result_ocba_comp = opt_ocba_comp.optimize()\n",
        "\n",
        "# Evaluate the found optima with the TRUE (noise-free) Rosenbrock function\n",
        "# to get the actual quality of the solutions\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"TRUE FUNCTION VALUE EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nRe-evaluating found optima with noise-free Rosenbrock function:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Evaluate each solution with the TRUE function (no noise)\n",
        "true_val_std = rosenbrock(result_std.x.reshape(1, -1))[0]\n",
        "true_val_rep = rosenbrock(result_rep.x.reshape(1, -1))[0]\n",
        "true_val_ocba = rosenbrock(result_ocba_comp.x.reshape(1, -1))[0]\n",
        "\n",
        "print(f\"\\nStandard (no repeats):\")\n",
        "print(f\"  Found x: {result_std.x}\")\n",
        "print(f\"  Noisy value (from optimization): {result_std.fun:.6f}\")\n",
        "print(f\"  TRUE value (noise-free): {true_val_std:.6f}\")\n",
        "\n",
        "print(f\"\\nWith repeats (no OCBA):\")\n",
        "print(f\"  Found x: {result_rep.x}\")\n",
        "print(f\"  Noisy value (from optimization): {result_rep.fun:.6f}\")\n",
        "print(f\"  TRUE value (noise-free): {true_val_rep:.6f}\")\n",
        "\n",
        "print(f\"\\nWith repeats + OCBA:\")\n",
        "print(f\"  Found x: {result_ocba_comp.x}\")\n",
        "print(f\"  Noisy value (from optimization): {result_ocba_comp.fun:.6f}\")\n",
        "print(f\"  TRUE value (noise-free): {true_val_ocba:.6f}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"PERFORMANCE COMPARISON SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nComparison on noisy Rosenbrock (σ={NOISE_STD}):\")\n",
        "print(f\"{'Method':<30} {'Noisy Value':<15} {'TRUE Value':<15} {'Evaluations':<15}\")\n",
        "print(f\"{'-'*75}\")\n",
        "print(f\"{'Standard (no repeats)':<30} {result_std.fun:<15.6f} {true_val_std:<15.6f} {result_std.nfev:<15}\")\n",
        "print(f\"{'With repeats (no OCBA)':<30} {result_rep.fun:<15.6f} {true_val_rep:<15.6f} {result_rep.nfev:<15}\")\n",
        "print(f\"{'With repeats + OCBA':<30} {result_ocba_comp.fun:<15.6f} {true_val_ocba:<15.6f} {result_ocba_comp.nfev:<15}\")\n",
        "print(f\"{'-'*75}\")\n",
        "print(f\"{'True optimum':<30} {'0.0':<15} {'0.0':<15}\")\n",
        "\n",
        "print(\"\\nKey observations:\")\n",
        "print(\"  • Noisy values (from optimization) are misleading due to noise\")\n",
        "print(\"  • TRUE values show actual solution quality\")\n",
        "print(\"  • Repeats help find better solutions despite noise\")\n",
        "print(\"  • OCBA focuses evaluations on distinguishing best solutions\")\n",
        "print(\"  • More evaluations generally lead to better TRUE performance\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "## Complete Workflow Diagram\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│                     SPOTOPTIM WORKFLOW                          │\n",
        "└─────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "INITIALIZATION PHASE\n",
        "  │\n",
        "  ├─► get_initial_design()\n",
        "  │     └─► Generate LHS or process user design\n",
        "  │\n",
        "  ├─► _curate_initial_design()\n",
        "  │     └─► Remove duplicates, add repeats\n",
        "  │\n",
        "  ├─► _evaluate_function()\n",
        "  │     └─► Evaluate objective function\n",
        "  │\n",
        "  ├─► _handle_NA_initial_design()\n",
        "  │     └─► Remove NaN/inf points\n",
        "  │\n",
        "  ├─► _check_size_initial_design()\n",
        "  │     └─► Validate sufficient points\n",
        "  │\n",
        "  ├─► _init_storage()\n",
        "  │     └─► Initialize X_, y_, n_iter_\n",
        "  │\n",
        "  ├─► update_stats()\n",
        "  │     └─► Compute mean/variance (if noise)\n",
        "  │\n",
        "  ├─► _init_tensorboard() [if enabled]\n",
        "  │     └─► Log initial design to TensorBoard\n",
        "  │\n",
        "  └─► _get_best_xy_initial_design()\n",
        "        └─► Identify initial best\n",
        "\n",
        "\n",
        "SEQUENTIAL OPTIMIZATION LOOP (until max_iter or max_time)\n",
        "  │\n",
        "  ├─► _fit_scheduler()\n",
        "  │     ├─► _transform_X() - Transform to internal scale\n",
        "  │     └─► _fit_surrogate() - Fit GP to current data\n",
        "  │\n",
        "  ├─► _apply_ocba() [if enabled]\n",
        "  │     └─► Allocate additional evaluations\n",
        "  │\n",
        "  ├─► _suggest_next_point()\n",
        "  │     ├─► _acquisition_function()\n",
        "  │     │     └─► _predict_with_uncertainty()\n",
        "  │     └─► Optimize to find next point\n",
        "  │\n",
        "  ├─► _update_repeats_infill_points()\n",
        "  │     └─► Repeat point if repeats_surrogate > 1\n",
        "  │\n",
        "  ├─► _evaluate_function()\n",
        "  │     └─► Evaluate at suggested point(s)\n",
        "  │\n",
        "  ├─► _handle_NA_new_points()\n",
        "  │     ├─► _apply_penalty_NA()\n",
        "  │     └─► _remove_nan()\n",
        "  │\n",
        "  ├─► _update_success_rate()\n",
        "  │     └─► Track evaluation success\n",
        "  │\n",
        "  ├─► _update_storage()\n",
        "  │     └─► Append new evaluations (with scale conversion)\n",
        "  │\n",
        "  ├─► update_stats()\n",
        "  │     └─► Update mean/variance\n",
        "  │\n",
        "  ├─► _write_tensorboard_hparams() [if enabled]\n",
        "  │     └─► Log hyperparameters\n",
        "  │\n",
        "  ├─► _write_tensorboard_scalars() [if enabled]\n",
        "  │     └─► Log scalar metrics\n",
        "  │\n",
        "  └─► _update_best_main_loop()\n",
        "        └─► Update best if improved\n",
        "\n",
        "\n",
        "FINALIZATION\n",
        "  │\n",
        "  ├─► to_all_dim() [if dimensionality reduction used]\n",
        "  │     └─► Expand to full dimensions\n",
        "  │\n",
        "  ├─► _determine_termination()\n",
        "  │     └─► Set termination message\n",
        "  │\n",
        "  ├─► _close_tensorboard_writer() [if enabled]\n",
        "  │     └─► Close TensorBoard logging\n",
        "  │\n",
        "  ├─► _map_to_factor_values() [if factors used]\n",
        "  │     └─► Convert factors back to strings\n",
        "  │\n",
        "  └─► Return OptimizeResult\n",
        "```\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "### 1. Initial Design\n",
        "- **Latin Hypercube Sampling**: Space-filling design for efficient exploration\n",
        "- **Curation**: Remove duplicates from integer/factor rounding\n",
        "- **Failure Handling**: Remove invalid points, no penalties\n",
        "\n",
        "### 2. Surrogate Model\n",
        "- **Default**: Gaussian Process with Matérn kernel\n",
        "- **Provides**: Mean μ(x) and uncertainty σ(x) predictions\n",
        "- **Purpose**: Learn function landscape with limited evaluations\n",
        "\n",
        "### 3. Acquisition Function\n",
        "- **EI**: Expected Improvement (default) - best balance\n",
        "- **PI**: Probability of Improvement - more exploitative\n",
        "- **Mean**: Pure exploitation of surrogate predictions\n",
        "\n",
        "### 4. Noise Handling\n",
        "- **Repeats**: Evaluate each point multiple times\n",
        "- **Statistics**: Track mean and variance\n",
        "- **OCBA**: Intelligently allocate additional evaluations\n",
        "\n",
        "### 5. Failure Handling\n",
        "- **Initial Phase**: Remove invalid points\n",
        "- **Sequential Phase**: Apply adaptive penalties with noise\n",
        "- **Robustness**: Continue optimization despite failures\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "1. **For deterministic functions**:\n",
        "   - Use default settings (no repeats)\n",
        "   - Acquisition = 'ei'\n",
        "   - Focus on n_initial and max_iter\n",
        "\n",
        "2. **For noisy functions**:\n",
        "   - Set repeats_initial ≥ 2\n",
        "   - Set repeats_surrogate ≥ 1\n",
        "   - Consider OCBA with ocba_delta ≥ 2\n",
        "\n",
        "3. **For unreliable functions**:\n",
        "   - SpotOptim handles failures automatically\n",
        "   - No special configuration needed\n",
        "   - Penalties guide search away from bad regions\n",
        "\n",
        "4. **For expensive functions**:\n",
        "   - Increase n_initial (better initial model)\n",
        "   - Use 'ei' acquisition (best sample efficiency)\n",
        "   - Consider max_time limit\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "SpotOptim provides a robust and flexible framework for surrogate-based optimization with:\n",
        "\n",
        "✓ Efficient space-filling initial designs (LHS)  \n",
        "✓ Powerful Gaussian Process surrogate models  \n",
        "✓ Smart acquisition functions (EI, PI, Mean)  \n",
        "✓ Automatic noise handling with statistics  \n",
        "✓ Intelligent budget allocation (OCBA)  \n",
        "✓ Robust failure handling  \n",
        "✓ Comprehensive progress tracking\n",
        "\n",
        "The modular design allows easy customization while maintaining robust defaults for most use cases."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/workspace/spotoptim-cookbook/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}