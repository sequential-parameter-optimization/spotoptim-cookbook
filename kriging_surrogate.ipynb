{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Kriging Surrogate Models in SpotOptim\n",
        "sidebar_position: 6\n",
        "eval: true\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "SpotOptim provides a powerful Kriging (Gaussian Process) surrogate model that can significantly enhance optimization performance. This tutorial introduces the `Kriging` class, explains its theory and parameters, and demonstrates how to use it effectively with SpotOptim.\n",
        "\n",
        "### What is Kriging?\n",
        "\n",
        "Kriging, also known as Gaussian Process regression, is a sophisticated interpolation method that:\n",
        "\n",
        "- **Predicts function values** at untested points based on observed data\n",
        "- **Provides uncertainty estimates** indicating confidence in predictions\n",
        "- **Models smooth functions** common in engineering and scientific optimization\n",
        "- **Handles noisy observations** through regression approaches\n",
        "\n",
        "The mathematical foundation of Kriging is based on the assumption that the objective function $f(\\mathbf{x})$ can be modeled as:\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\mu + Z(\\mathbf{x})\n",
        "$$\n",
        "\n",
        "where $\\mu$ is a constant mean and $Z(\\mathbf{x})$ is a Gaussian process with correlation structure. The correlation between two points $\\mathbf{x}_i$ and $\\mathbf{x}_j$ is typically modeled using a Gaussian (RBF) correlation function:\n",
        "\n",
        "$$\n",
        "R(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp\\left(-\\sum_{k=1}^{d} \\theta_k |x_{i,k} - x_{j,k}|^2\\right)\n",
        "$$\n",
        "\n",
        "where $\\theta_k > 0$ are the correlation length parameters that control smoothness in each dimension.\n",
        "\n",
        "### Why Use Kriging in SpotOptim?\n",
        "\n",
        "1. **Better Surrogate Models**: More accurate predictions than simple interpolation\n",
        "2. **Uncertainty Quantification**: Know where the model is uncertain\n",
        "3. **Mixed Variable Types**: Handle continuous, integer, and categorical variables\n",
        "4. **Multiple Methods**: Choose between interpolation, regression, and reinterpolation\n",
        "5. **Customizable**: Control regularization, correlation parameters, and more\n",
        "\n",
        "## Basic Usage\n",
        "\n",
        "### Creating a Simple Kriging Model\n",
        "\n",
        "Let's start with the most basic usage - creating a Kriging model with default settings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "# Simple objective function\n",
        "def sphere(X):\n",
        "    \"\"\"Sphere function: f(x) = sum(x^2)\"\"\"\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "# Create Kriging surrogate with defaults\n",
        "kriging = Kriging(seed=42)\n",
        "\n",
        "# Use with SpotOptim\n",
        "optimizer = SpotOptim(\n",
        "    fun=sphere,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    surrogate=kriging,  # Use Kriging instead of default GP\n",
        "    max_iter=20,\n",
        "    n_initial=10,\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()\n",
        "print(f\"\\nBest solution: {result.x}\")\n",
        "print(f\"Best value: {result.fun:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default vs Custom Surrogate\n",
        "\n",
        "SpotOptim uses a Gaussian Process Regressor by default. Here's how Kriging compares:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def rosenbrock(X):\n",
        "    \"\"\"Rosenbrock function: (1-x)^2 + 100(y-x^2)^2\"\"\"\n",
        "    x = X[:, 0]\n",
        "    y = X[:, 1]\n",
        "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
        "\n",
        "# With default Gaussian Process\n",
        "opt_default = SpotOptim(\n",
        "    fun=rosenbrock,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    max_iter=30,\n",
        "    n_initial=15,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "result_default = opt_default.optimize()\n",
        "\n",
        "# With Kriging surrogate\n",
        "kriging = Kriging(method='regression', seed=42)\n",
        "opt_kriging = SpotOptim(\n",
        "    fun=rosenbrock,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    surrogate=kriging,\n",
        "    max_iter=30,\n",
        "    n_initial=15,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "result_kriging = opt_kriging.optimize()\n",
        "\n",
        "print(\"Comparison:\")\n",
        "print(f\"Default GP:  f(x) = {result_default.fun:.6f}\")\n",
        "print(f\"Kriging:     f(x) = {result_kriging.fun:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both approaches work well, but Kriging offers more control over the surrogate behavior.\n",
        "\n",
        "## Understanding Kriging Parameters\n",
        "\n",
        "### Method: Interpolation vs Regression\n",
        "\n",
        "The `method` parameter controls how Kriging handles data:\n",
        "\n",
        "- **\"interpolation\"**: Exact interpolation, passes through all training points\n",
        "- **\"regression\"**: Allows smoothing, better for noisy data\n",
        "- **\"reinterpolation\"**: Hybrid approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim.surrogate import Kriging\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create noisy training data\n",
        "np.random.seed(42)\n",
        "X_train = np.linspace(0, 2*np.pi, 10).reshape(-1, 1)\n",
        "y_train = np.sin(X_train.ravel()) + 0.1 * np.random.randn(10)\n",
        "\n",
        "# Test data for smooth predictions\n",
        "X_test = np.linspace(0, 2*np.pi, 100).reshape(-1, 1)\n",
        "y_true = np.sin(X_test.ravel())\n",
        "\n",
        "# Compare methods\n",
        "methods = ['interpolation', 'regression', 'reinterpolation']\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for ax, method in zip(axes, methods):\n",
        "    model = Kriging(method=method, seed=42, model_fun_evals=50)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred, y_std = model.predict(X_test, return_std=True)\n",
        "    \n",
        "    # Plot\n",
        "    ax.plot(X_test, y_true, 'k--', label='True function', linewidth=2)\n",
        "    ax.plot(X_test, y_pred, 'b-', label='Prediction', linewidth=2)\n",
        "    ax.fill_between(X_test.ravel(), \n",
        "                     y_pred - 2*y_std, \n",
        "                     y_pred + 2*y_std, \n",
        "                     alpha=0.3, label='95% CI')\n",
        "    ax.scatter(X_train, y_train, c='r', s=50, zorder=5, label='Training data')\n",
        "    ax.set_title(f'Method: {method}')\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Key differences:\")\n",
        "print(\"- Interpolation: Passes exactly through training points\")\n",
        "print(\"- Regression: Smooths over noisy data (recommended)\")\n",
        "print(\"- Reinterpolation: Balances between the two\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Recommendation**: Use `method='regression'` for most optimization problems, especially with noisy objectives.\n",
        "\n",
        "### Noise Parameter and Regularization\n",
        "\n",
        "The `noise` parameter adds a small nugget effect for numerical stability:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def noisy_ackley(X):\n",
        "    \"\"\"Ackley function with observation noise\"\"\"\n",
        "    a = 20\n",
        "    b = 0.2\n",
        "    c = 2 * np.pi\n",
        "    n = X.shape[1]\n",
        "    \n",
        "    sum_sq = np.sum(X**2, axis=1)\n",
        "    sum_cos = np.sum(np.cos(c * X), axis=1)\n",
        "    \n",
        "    base = -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n",
        "    noise = np.random.normal(0, 0.5, size=base.shape)  # Add noise\n",
        "    return base + noise\n",
        "\n",
        "# Very small noise (near interpolation)\n",
        "kriging_small = Kriging(noise=1e-10, method='interpolation', seed=42)\n",
        "opt_small = SpotOptim(\n",
        "    fun=noisy_ackley,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    surrogate=kriging_small,\n",
        "    max_iter=25,\n",
        "    n_initial=12,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "result_small = opt_small.optimize()\n",
        "\n",
        "# Larger noise (more robust to noise)\n",
        "kriging_large = Kriging(noise=0.01, method='interpolation', seed=42)\n",
        "opt_large = SpotOptim(\n",
        "    fun=noisy_ackley,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    surrogate=kriging_large,\n",
        "    max_iter=25,\n",
        "    n_initial=12,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "result_large = opt_large.optimize()\n",
        "\n",
        "print(\"Impact of noise parameter:\")\n",
        "print(f\"Small noise (1e-10): f(x) = {result_small.fun:.6f}\")\n",
        "print(f\"Large noise (0.01):  f(x) = {result_large.fun:.6f}\")\n",
        "print(\"\\nNote: For noisy functions, use 'regression' method instead,\")\n",
        "print(\"      which automatically optimizes the Lambda (nugget) parameter.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Best Practice**: For noisy functions, use `method='regression'` which automatically optimizes the regularization parameter instead of fixing it.\n",
        "\n",
        "### Correlation Length Parameters (Theta)\n",
        "\n",
        "The `theta` parameters control smoothness. SpotOptim optimizes these automatically:\n",
        "\n",
        "- **min_theta**: Minimum log₁₀(θ) value (default: -3.0 → θ = 0.001)\n",
        "- **max_theta**: Maximum log₁₀(θ) value (default: 2.0 → θ = 100)\n",
        "\n",
        "Smaller θ → smoother function, larger θ → more wiggly function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "# Sample data\n",
        "X_train = np.array([[0.0], [0.5], [1.0], [1.5], [2.0]])\n",
        "y_train = np.sin(X_train.ravel())\n",
        "\n",
        "# Tight bounds (smoother)\n",
        "model_smooth = Kriging(min_theta=-1.0, max_theta=0.0, seed=42, model_fun_evals=30)\n",
        "model_smooth.fit(X_train, y_train)\n",
        "\n",
        "# Wide bounds (more flexible)\n",
        "model_flexible = Kriging(min_theta=-3.0, max_theta=2.0, seed=42, model_fun_evals=30)\n",
        "model_flexible.fit(X_train, y_train)\n",
        "\n",
        "print(\"Theta bounds and optimal values:\")\n",
        "print(f\"Smooth model:   bounds=[-1.0, 0.0], theta={model_smooth.theta_}\")\n",
        "print(f\"Flexible model: bounds=[-3.0, 2.0], theta={model_flexible.theta_}\")\n",
        "print(\"\\nThe optimizer automatically finds the best theta within the bounds.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Default Values**: The defaults `min_theta=-3.0` and `max_theta=2.0` work well for most problems.\n",
        "\n",
        "### Isotropic vs Anisotropic Correlation\n",
        "\n",
        "- **Isotropic** (`isotropic=True`): Single θ for all dimensions (faster, fewer parameters)\n",
        "- **Anisotropic** (`isotropic=False`): Different θ per dimension (more flexible, default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "# 3D problem\n",
        "np.random.seed(42)\n",
        "X_train = np.random.rand(15, 3) * 10 - 5\n",
        "y_train = X_train[:, 0]**2 + 0.1*X_train[:, 1]**2 + 2*X_train[:, 2]**2\n",
        "\n",
        "# Isotropic: one theta for all dimensions\n",
        "model_iso = Kriging(isotropic=True, seed=42, model_fun_evals=40)\n",
        "model_iso.fit(X_train, y_train)\n",
        "\n",
        "# Anisotropic: different theta per dimension\n",
        "model_aniso = Kriging(isotropic=False, seed=42, model_fun_evals=40)\n",
        "model_aniso.fit(X_train, y_train)\n",
        "\n",
        "print(\"Correlation structure:\")\n",
        "print(f\"Isotropic:   n_theta={model_iso.n_theta}, theta={model_iso.theta_}\")\n",
        "print(f\"Anisotropic: n_theta={model_aniso.n_theta}, theta={model_aniso.theta_}\")\n",
        "print(\"\\nAnisotropic can capture different smoothness in each dimension.\")\n",
        "\n",
        "# Test predictions\n",
        "X_test = np.array([[0.0, 0.0, 0.0]])\n",
        "y_iso = model_iso.predict(X_test)\n",
        "y_aniso = model_aniso.predict(X_test)\n",
        "print(f\"\\nPrediction at origin:\")\n",
        "print(f\"Isotropic:   {y_iso[0]:.4f}\")\n",
        "print(f\"Anisotropic: {y_aniso[0]:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**When to Use**:\n",
        "\n",
        "- Use **isotropic** for faster fitting when dimensions have similar characteristics\n",
        "- Use **anisotropic** (default) when dimensions behave differently\n",
        "\n",
        "## Advanced Features\n",
        "\n",
        "### Mixed Variable Types\n",
        "\n",
        "Kriging supports mixed variable types: continuous (`float`), integer (`int`), and categorical (`factor`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def mixed_objective(X):\n",
        "    \"\"\"\n",
        "    Optimize a system with:\n",
        "    - x0: continuous learning rate (0.001 to 0.1)\n",
        "    - x1: integer number of layers (1 to 5)\n",
        "    - x2: categorical activation (0=ReLU, 1=Tanh, 2=Sigmoid)\n",
        "    \"\"\"\n",
        "    X = np.atleast_2d(X)\n",
        "    learning_rate = X[:, 0]\n",
        "    n_layers = X[:, 1]\n",
        "    activation = X[:, 2]\n",
        "    \n",
        "    # Simplified model: prefer lr~0.01, 3 layers, ReLU\n",
        "    loss = (learning_rate - 0.01)**2 + (n_layers - 3)**2\n",
        "    loss += np.where(activation == 0, 0.0,  # ReLU is best\n",
        "                     np.where(activation == 1, 0.5,  # Tanh is ok\n",
        "                              1.0))  # Sigmoid is worst\n",
        "    return loss\n",
        "\n",
        "# Define bounds and types\n",
        "bounds = [\n",
        "    (0.001, 0.1),  # learning_rate (float)\n",
        "    (1, 5),        # n_layers (int)\n",
        "    (0, 2)         # activation (factor: 0, 1, or 2)\n",
        "]\n",
        "\n",
        "var_type = ['float', 'int', 'factor']\n",
        "\n",
        "# Create Kriging with mixed types\n",
        "kriging_mixed = Kriging(\n",
        "    method='regression',\n",
        "    var_type=var_type,\n",
        "    seed=42,\n",
        "    model_fun_evals=50\n",
        ")\n",
        "\n",
        "# Optimize\n",
        "optimizer = SpotOptim(\n",
        "    fun=mixed_objective,\n",
        "    bounds=bounds,\n",
        "    var_type=var_type,\n",
        "    surrogate=kriging_mixed,\n",
        "    max_iter=30,\n",
        "    n_initial=15,\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()\n",
        "\n",
        "print(f\"\\nOptimal configuration:\")\n",
        "print(f\"Learning rate: {result.x[0]:.4f}\")\n",
        "print(f\"Num layers:    {int(result.x[1])}\")\n",
        "print(f\"Activation:    {int(result.x[2])} (0=ReLU, 1=Tanh, 2=Sigmoid)\")\n",
        "print(f\"Loss:          {result.fun:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Points**:\n",
        "\n",
        "- Set `var_type` in both Kriging and SpotOptim\n",
        "- Factor variables use specialized distance metrics (default: Canberra)\n",
        "- Integer variables are treated as ordered but discrete\n",
        "\n",
        "### Customizing the Distance Metric for Factors\n",
        "\n",
        "For categorical variables, you can choose different distance metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "# Categorical data: 2 factor variables\n",
        "X_train = np.array([\n",
        "    [0, 0],  # Category A, Color Red\n",
        "    [1, 0],  # Category B, Color Red\n",
        "    [0, 1],  # Category A, Color Blue\n",
        "    [1, 1],  # Category B, Color Blue\n",
        "    [2, 2],  # Category C, Color Green\n",
        "])\n",
        "y_train = np.array([1.0, 1.5, 1.2, 2.0, 3.5])\n",
        "\n",
        "# Different distance metrics\n",
        "metrics = ['canberra', 'hamming']\n",
        "\n",
        "for metric in metrics:\n",
        "    model = Kriging(\n",
        "        method='regression',\n",
        "        var_type=['factor', 'factor'],\n",
        "        metric_factorial=metric,\n",
        "        seed=42,\n",
        "        model_fun_evals=40\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Test prediction\n",
        "    X_test = np.array([[1, 1]])\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    print(f\"Metric: {metric:10s} | Prediction at [1,1]: {y_pred[0]:.4f}\")\n",
        "\n",
        "print(\"\\nAvailable metrics: 'canberra' (default), 'hamming', 'jaccard', etc.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling High-Dimensional Problems\n",
        "\n",
        "For high-dimensional problems, Kriging can become computationally expensive. Here are strategies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def high_dim_sphere(X):\n",
        "    \"\"\"10-dimensional sphere function\"\"\"\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "# Strategy 1: Use isotropic correlation (fewer parameters)\n",
        "kriging_iso = Kriging(\n",
        "    method='regression',\n",
        "    isotropic=True,  # Single theta for all 10 dimensions\n",
        "    seed=42,\n",
        "    model_fun_evals=50  # Faster optimization\n",
        ")\n",
        "\n",
        "optimizer_iso = SpotOptim(\n",
        "    fun=high_dim_sphere,\n",
        "    bounds=[(-5, 5)] * 10,  # 10 dimensions\n",
        "    surrogate=kriging_iso,\n",
        "    max_iter=50,\n",
        "    n_initial=30,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "result_iso = optimizer_iso.optimize()\n",
        "\n",
        "# Strategy 2: Use max_surrogate_points to limit training set size\n",
        "kriging_limited = Kriging(method='regression', seed=42)\n",
        "\n",
        "optimizer_limited = SpotOptim(\n",
        "    fun=high_dim_sphere,\n",
        "    bounds=[(-5, 5)] * 10,\n",
        "    surrogate=kriging_limited,\n",
        "    max_iter=50,\n",
        "    n_initial=30,\n",
        "    max_surrogate_points=100,  # Limit surrogate training set\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "result_limited = optimizer_limited.optimize()\n",
        "\n",
        "print(\"High-dimensional optimization strategies:\")\n",
        "print(f\"Isotropic Kriging:      f(x) = {result_iso.fun:.6f}\")\n",
        "print(f\"Limited training set:   f(x) = {result_limited.fun:.6f}\")\n",
        "print(\"\\nFor >5 dimensions, consider isotropic=True or limit training set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Uncertainty Quantification\n",
        "\n",
        "Kriging provides uncertainty estimates, useful for exploration vs exploitation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim.surrogate import Kriging\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1D example for visualization\n",
        "np.random.seed(42)\n",
        "X_train = np.array([[0.0], [1.0], [3.0], [5.0], [6.0]])\n",
        "y_train = np.sin(X_train.ravel()) + 0.05 * np.random.randn(5)\n",
        "\n",
        "# Fit Kriging model\n",
        "model = Kriging(method='regression', seed=42, model_fun_evals=50)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Dense test points\n",
        "X_test = np.linspace(-0.5, 6.5, 200).reshape(-1, 1)\n",
        "y_pred, y_std = model.predict(X_test, return_std=True)\n",
        "\n",
        "# True function\n",
        "y_true = np.sin(X_test.ravel())\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(X_test, y_true, 'k--', label='True function', linewidth=2)\n",
        "plt.plot(X_test, y_pred, 'b-', label='Kriging prediction', linewidth=2)\n",
        "plt.fill_between(X_test.ravel(), \n",
        "                 y_pred - 2*y_std, \n",
        "                 y_pred + 2*y_std, \n",
        "                 alpha=0.3, color='blue', label='95% confidence')\n",
        "plt.scatter(X_train, y_train, c='red', s=100, zorder=5, \n",
        "           edgecolors='black', label='Training points')\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.title('Kriging Predictions with Uncertainty', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(X_test, y_std, 'r-', linewidth=2)\n",
        "plt.scatter(X_train, np.zeros_like(X_train), c='blue', s=100, \n",
        "           zorder=5, edgecolors='black', label='Training points')\n",
        "plt.xlabel('x', fontsize=12)\n",
        "plt.ylabel('Standard Deviation', fontsize=12)\n",
        "plt.title('Uncertainty Estimates', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Key observations:\")\n",
        "print(\"- Uncertainty is low near training points\")\n",
        "print(\"- Uncertainty is high far from training data\")\n",
        "print(\"- This guides acquisition functions (e.g., EI exploits low uncertainty)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical Examples\n",
        "\n",
        "### Example 1: Optimizing the Rastrigin Function\n",
        "\n",
        "The Rastrigin function is highly multimodal - a challenging test case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def rastrigin(X):\n",
        "    \"\"\"\n",
        "    Rastrigin function: highly multimodal\n",
        "    Global minimum: f(0,...,0) = 0\n",
        "    \"\"\"\n",
        "    A = 10\n",
        "    n = X.shape[1]\n",
        "    return A * n + np.sum(X**2 - A * np.cos(2 * np.pi * X), axis=1)\n",
        "\n",
        "# Configure Kriging for multimodal function\n",
        "kriging = Kriging(\n",
        "    method='regression',      # Smooth over local variations\n",
        "    min_theta=-3.0,          # Allow flexible correlation\n",
        "    max_theta=2.0,\n",
        "    seed=42,\n",
        "    model_fun_evals=100      # More budget for better surrogate\n",
        ")\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=rastrigin,\n",
        "    bounds=[(-5.12, 5.12), (-5.12, 5.12)],\n",
        "    surrogate=kriging,\n",
        "    acquisition='ei',         # Expected Improvement for exploration\n",
        "    max_iter=60,\n",
        "    n_initial=30,\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()\n",
        "\n",
        "print(f\"\\nRastrigin optimization:\")\n",
        "print(f\"Best solution: {result.x}\")\n",
        "print(f\"Best value:    {result.fun:.6f} (global optimum: 0.0)\")\n",
        "print(f\"Distance to optimum: {np.linalg.norm(result.x):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Robust Optimization with Noise\n",
        "\n",
        "When optimizing noisy functions, Kriging's regression mode helps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def noisy_beale(X):\n",
        "    \"\"\"\n",
        "    Beale function with Gaussian noise\n",
        "    Global minimum: f(3, 0.5) = 0\n",
        "    \"\"\"\n",
        "    x = X[:, 0]\n",
        "    y = X[:, 1]\n",
        "    \n",
        "    term1 = (1.5 - x + x * y)**2\n",
        "    term2 = (2.25 - x + x * y**2)**2\n",
        "    term3 = (2.625 - x + x * y**3)**2\n",
        "    \n",
        "    base = term1 + term2 + term3\n",
        "    noise = np.random.normal(0, 0.5, size=base.shape)\n",
        "    \n",
        "    return base + noise\n",
        "\n",
        "# Use regression method for noisy objectives\n",
        "kriging_robust = Kriging(\n",
        "    method='regression',        # Automatically optimizes Lambda (nugget)\n",
        "    min_Lambda=-9.0,           # Allow small regularization\n",
        "    max_Lambda=-2.0,           # But not too large\n",
        "    seed=42,\n",
        "    model_fun_evals=80\n",
        ")\n",
        "\n",
        "# Use repeated evaluations for noise handling\n",
        "optimizer = SpotOptim(\n",
        "    fun=noisy_beale,\n",
        "    bounds=[(-4.5, 4.5), (-4.5, 4.5)],\n",
        "    surrogate=kriging_robust,\n",
        "    max_iter=50,\n",
        "    n_initial=20,\n",
        "    repeats_initial=3,         # Evaluate each initial point 3 times\n",
        "    repeats_surrogate=2,       # Evaluate each new point 2 times\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()\n",
        "\n",
        "print(f\"\\nNoisy Beale optimization:\")\n",
        "print(f\"Best solution: {result.x}\")\n",
        "print(f\"Best mean value: {optimizer.min_mean_y:.6f}\")\n",
        "print(f\"Variance at best: {optimizer.min_var_y:.6f}\")\n",
        "print(f\"True optimum: [3.0, 0.5]\")\n",
        "print(f\"Distance: {np.linalg.norm(result.x - np.array([3.0, 0.5])):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 3: Real-World Machine Learning Hyperparameter Tuning\n",
        "\n",
        "Optimize hyperparameters for a neural network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def ml_objective(X):\n",
        "    \"\"\"\n",
        "    Simulate training a neural network\n",
        "    Variables:\n",
        "    - x0: learning_rate (log scale: 1e-4 to 1e-1)\n",
        "    - x1: num_layers (integer: 1 to 5)\n",
        "    - x2: hidden_size (integer: 16, 32, 64, 128, 256)\n",
        "    - x3: dropout_rate (float: 0.0 to 0.5)\n",
        "    \n",
        "    Returns validation error\n",
        "    \"\"\"\n",
        "    X = np.atleast_2d(X)\n",
        "    lr = X[:, 0]\n",
        "    n_layers = X[:, 1]\n",
        "    hidden_size = X[:, 2]\n",
        "    dropout = X[:, 3]\n",
        "    \n",
        "    # Simulate validation error (lower is better)\n",
        "    # Optimal around: lr=0.001, 3 layers, 64 hidden, 0.2 dropout\n",
        "    error = (np.log10(lr) + 3)**2  # Prefer lr ~ 0.001\n",
        "    error += (n_layers - 3)**2     # Prefer 3 layers\n",
        "    error += ((hidden_size - 64) / 32)**2  # Prefer 64 hidden units\n",
        "    error += (dropout - 0.2)**2 * 10  # Prefer 0.2 dropout\n",
        "    \n",
        "    # Add some noise to simulate training variance\n",
        "    error += np.random.normal(0, 0.1, size=error.shape)\n",
        "    \n",
        "    return error\n",
        "\n",
        "# Setup optimization\n",
        "bounds = [\n",
        "    (1e-4, 1e-1),  # learning_rate\n",
        "    (1, 5),        # num_layers\n",
        "    (16, 256),     # hidden_size\n",
        "    (0.0, 0.5)     # dropout_rate\n",
        "]\n",
        "\n",
        "var_type = ['float', 'int', 'int', 'float']\n",
        "\n",
        "# Use Kriging with mixed types\n",
        "kriging_ml = Kriging(\n",
        "    method='regression',\n",
        "    var_type=var_type,\n",
        "    seed=42,\n",
        "    model_fun_evals=60\n",
        ")\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=ml_objective,\n",
        "    bounds=bounds,\n",
        "    var_type=var_type,\n",
        "    var_trans=['log10', None, None, None],  # Log scale for learning rate\n",
        "    surrogate=kriging_ml,\n",
        "    max_iter=40,\n",
        "    n_initial=20,\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()\n",
        "\n",
        "print(f\"\\nOptimal hyperparameters:\")\n",
        "print(f\"Learning rate: {result.x[0]:.6f}\")\n",
        "print(f\"Num layers:    {int(result.x[1])}\")\n",
        "print(f\"Hidden size:   {int(result.x[2])}\")\n",
        "print(f\"Dropout rate:  {result.x[3]:.3f}\")\n",
        "print(f\"Validation error: {result.fun:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 4: Comparing Kriging Methods\n",
        "\n",
        "Let's compare all three Kriging methods on the same problem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def levy(X):\n",
        "    \"\"\"\n",
        "    Levy function N. 13\n",
        "    Global minimum: f(1, 1) = 0\n",
        "    \"\"\"\n",
        "    x = X[:, 0]\n",
        "    y = X[:, 1]\n",
        "    \n",
        "    w1 = 1 + (x - 1) / 4\n",
        "    w2 = 1 + (y - 1) / 4\n",
        "    \n",
        "    term1 = np.sin(np.pi * w1)**2\n",
        "    term2 = (w1 - 1)**2 * (1 + 10 * np.sin(np.pi * w1 + 1)**2)\n",
        "    term3 = (w2 - 1)**2 * (1 + np.sin(2 * np.pi * w2)**2)\n",
        "    \n",
        "    return term1 + term2 + term3\n",
        "\n",
        "methods = ['interpolation', 'regression', 'reinterpolation']\n",
        "results_methods = []\n",
        "\n",
        "for method in methods:\n",
        "    kriging = Kriging(\n",
        "        method=method,\n",
        "        seed=42,\n",
        "        model_fun_evals=60\n",
        "    )\n",
        "    \n",
        "    optimizer = SpotOptim(\n",
        "        fun=levy,\n",
        "        bounds=[(-10, 10), (-10, 10)],\n",
        "        surrogate=kriging,\n",
        "        max_iter=40,\n",
        "        n_initial=20,\n",
        "        seed=42,\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    result = optimizer.optimize()\n",
        "    results_methods.append((method, result.fun, result.x))\n",
        "    \n",
        "    print(f\"{method:15s} | f(x) = {result.fun:8.6f} | x = {result.x}\")\n",
        "\n",
        "print(f\"\\nGlobal optimum: f(1, 1) = 0.0\")\n",
        "print(\"\\nAll methods find good solutions, but 'regression' is most robust.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 5: Sensitivity to Theta Bounds\n",
        "\n",
        "Theta bounds control the range of smoothness. Let's see their impact:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "def griewank(X):\n",
        "    \"\"\"Griewank function\"\"\"\n",
        "    sum_sq = np.sum(X**2 / 4000, axis=1)\n",
        "    prod_cos = np.prod(np.cos(X / np.sqrt(np.arange(1, X.shape[1] + 1))), axis=1)\n",
        "    return sum_sq - prod_cos + 1\n",
        "\n",
        "# Different theta bounds\n",
        "theta_configs = [\n",
        "    (-2.0, 1.0, \"Tight (smoother)\"),\n",
        "    (-3.0, 2.0, \"Default\"),\n",
        "    (-4.0, 3.0, \"Wide (more flexible)\")\n",
        "]\n",
        "\n",
        "for min_theta, max_theta, label in theta_configs:\n",
        "    kriging = Kriging(\n",
        "        method='regression',\n",
        "        min_theta=min_theta,\n",
        "        max_theta=max_theta,\n",
        "        seed=42,\n",
        "        model_fun_evals=50\n",
        "    )\n",
        "    \n",
        "    optimizer = SpotOptim(\n",
        "        fun=griewank,\n",
        "        bounds=[(-600, 600), (-600, 600)],\n",
        "        surrogate=kriging,\n",
        "        max_iter=35,\n",
        "        n_initial=18,\n",
        "        seed=42,\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    result = optimizer.optimize()\n",
        "    print(f\"{label:20s} [{min_theta:5.1f}, {max_theta:4.1f}] | f(x) = {result.fun:8.6f}\")\n",
        "\n",
        "print(\"\\nDefault bounds work well for most problems.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Surrogates\n",
        "\n",
        "### Kriging vs Gaussian Process vs Random Forest\n",
        "\n",
        "Let's compare different surrogate models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging, SimpleKriging\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def schwefel(X):\n",
        "    \"\"\"Schwefel function\"\"\"\n",
        "    return 418.9829 * X.shape[1] - np.sum(X * np.sin(np.sqrt(np.abs(X))), axis=1)\n",
        "\n",
        "bounds = [(-500, 500), (-500, 500)]\n",
        "\n",
        "# 1. Kriging (full-featured)\n",
        "kriging = Kriging(method='regression', seed=42, model_fun_evals=60)\n",
        "opt_kriging = SpotOptim(fun=schwefel, bounds=bounds, surrogate=kriging,\n",
        "                        max_iter=35, n_initial=18, seed=42, verbose=False)\n",
        "result_kriging = opt_kriging.optimize()\n",
        "\n",
        "# 2. SimpleKriging (lightweight)\n",
        "simple_kriging = SimpleKriging(noise=1e-10, seed=42)\n",
        "opt_simple = SpotOptim(fun=schwefel, bounds=bounds, surrogate=simple_kriging,\n",
        "                       max_iter=35, n_initial=18, seed=42, verbose=False)\n",
        "result_simple = opt_simple.optimize()\n",
        "\n",
        "# 3. Gaussian Process (sklearn default)\n",
        "kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10,\n",
        "                               normalize_y=True, random_state=42)\n",
        "opt_gp = SpotOptim(fun=schwefel, bounds=bounds, surrogate=gp,\n",
        "                   max_iter=35, n_initial=18, seed=42, verbose=False)\n",
        "result_gp = opt_gp.optimize()\n",
        "\n",
        "# 4. Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "opt_rf = SpotOptim(fun=schwefel, bounds=bounds, surrogate=rf,\n",
        "                   max_iter=35, n_initial=18, seed=42, verbose=False)\n",
        "result_rf = opt_rf.optimize()\n",
        "\n",
        "print(\"Surrogate Model Comparison:\")\n",
        "print(f\"Kriging (full):     f(x) = {result_kriging.fun:8.2f}\")\n",
        "print(f\"SimpleKriging:      f(x) = {result_simple.fun:8.2f}\")\n",
        "print(f\"Gaussian Process:   f(x) = {result_gp.fun:8.2f}\")\n",
        "print(f\"Random Forest:      f(x) = {result_rf.fun:8.2f}\")\n",
        "print(f\"\\nGlobal optimum: f(420.9687, 420.9687) = 0.0\")\n",
        "print(\"\\nKriging offers:\")\n",
        "print(\"- Mixed variable types (continuous, integer, categorical)\")\n",
        "print(\"- Multiple methods (interpolation, regression, reinterpolation)\")\n",
        "print(\"- Explicit control over regularization and correlation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices\n",
        "\n",
        "### 1. Choosing the Right Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# For smooth, deterministic functions\n",
        "kriging = Kriging(method='interpolation', noise=1e-10, seed=42)\n",
        "\n",
        "# For general optimization (RECOMMENDED)\n",
        "kriging = Kriging(method='regression', seed=42)\n",
        "\n",
        "# For noisy functions with repeated evaluations\n",
        "kriging = Kriging(method='regression', seed=42)\n",
        "# Use with repeats_initial and repeats_surrogate in SpotOptim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Setting Model Complexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# For low-dimensional problems (<5D)\n",
        "kriging = Kriging(\n",
        "    method='regression',\n",
        "    isotropic=False,           # Anisotropic (default)\n",
        "    model_fun_evals=100,       # More budget for better fit\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# For high-dimensional problems (>5D)\n",
        "kriging = Kriging(\n",
        "    method='regression',\n",
        "    isotropic=True,            # Fewer parameters\n",
        "    model_fun_evals=50,        # Faster fitting\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Handling Different Variable Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Mixed types example\n",
        "bounds = [\n",
        "    (0.0, 10.0),    # continuous\n",
        "    (1, 10),        # integer\n",
        "    (0, 3)          # categorical (4 categories)\n",
        "]\n",
        "\n",
        "var_type = ['float', 'int', 'factor']\n",
        "\n",
        "kriging = Kriging(\n",
        "    method='regression',\n",
        "    var_type=var_type,\n",
        "    metric_factorial='canberra',  # For factor variables\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=objective,\n",
        "    bounds=bounds,\n",
        "    var_type=var_type,\n",
        "    surrogate=kriging,\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Reproducibility\n",
        "\n",
        "Always set the seed for reproducible results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Both Kriging and SpotOptim should have seeds\n",
        "kriging = Kriging(method='regression', seed=42)\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=objective,\n",
        "    bounds=bounds,\n",
        "    surrogate=kriging,\n",
        "    seed=42  # Same seed or different seed\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Monitoring Surrogate Quality\n",
        "\n",
        "Check the negative log-likelihood after fitting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "# Sample data\n",
        "X = np.random.rand(20, 2) * 10 - 5\n",
        "y = np.sum(X**2, axis=1)\n",
        "\n",
        "model = Kriging(method='regression', seed=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(f\"Negative log-likelihood: {model.negLnLike:.4f}\")\n",
        "print(f\"Optimized theta: {model.theta_}\")\n",
        "print(f\"Optimized Lambda: {model.Lambda_:.4f}\")\n",
        "print(f\"Condition number of Psi: {model.cnd_Psi:.2e}\")\n",
        "\n",
        "print(\"\\nLower negLnLike = better fit\")\n",
        "print(\"Check condition number for numerical stability\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Issues and Solutions\n",
        "\n",
        "### Issue 1: Slow Fitting for Large Datasets\n",
        "\n",
        "**Problem**: Kriging becomes slow with many training points.\n",
        "\n",
        "**Solution**: Limit surrogate training set size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Use max_surrogate_points in SpotOptim\n",
        "optimizer = SpotOptim(\n",
        "    fun=objective,\n",
        "    bounds=bounds,\n",
        "    surrogate=kriging,\n",
        "    max_surrogate_points=200,  # Limit to 200 points\n",
        "    selection_method='distant', # or 'best'\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 2: Poor Predictions for Categorical Variables\n",
        "\n",
        "**Problem**: Kriging doesn't handle factors well.\n",
        "\n",
        "**Solution**: Try different distance metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Try different metrics\n",
        "for metric in ['canberra', 'hamming', 'jaccard']:\n",
        "    kriging = Kriging(\n",
        "        method='regression',\n",
        "        var_type=['float', 'factor'],\n",
        "        metric_factorial=metric,\n",
        "        seed=42\n",
        "    )\n",
        "    # Test performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 3: Numerical Instability\n",
        "\n",
        "**Problem**: Correlation matrix is nearly singular.\n",
        "\n",
        "**Solution**: Increase regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# For interpolation method\n",
        "kriging = Kriging(\n",
        "    method='interpolation',\n",
        "    noise=1e-6,  # Increase from default 1e-8\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Or use regression method (recommended)\n",
        "kriging = Kriging(\n",
        "    method='regression',\n",
        "    min_Lambda=-6.0,  # Don't go too small\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 4: Overfitting to Noisy Data\n",
        "\n",
        "**Problem**: Kriging fits noise instead of underlying function.\n",
        "\n",
        "**Solution**: Use regression method with reasonable Lambda bounds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "kriging = Kriging(\n",
        "    method='regression',\n",
        "    min_Lambda=-5.0,  # Not too small\n",
        "    max_Lambda=-1.0,  # Not too large\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Use `method='regression'`** for most optimization problems\n",
        "2. **Set `seed`** for reproducibility\n",
        "3. **Use `var_type`** for mixed variable types\n",
        "4. **Default parameters** work well for most cases\n",
        "5. **Use `isotropic=True`** for high-dimensional problems (>5D)\n",
        "\n",
        "### Quick Reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "from spotoptim import SpotOptim\n",
        "from spotoptim.surrogate import Kriging\n",
        "\n",
        "# Recommended configuration for general use\n",
        "kriging = Kriging(\n",
        "    method='regression',        # Smooths over noise\n",
        "    seed=42                     # Reproducibility\n",
        ")\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=objective,\n",
        "    bounds=bounds,\n",
        "    surrogate=kriging,\n",
        "    max_iter=50,\n",
        "    n_initial=20,\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parameter Cheat Sheet\n",
        "\n",
        "| Parameter | Default | When to Change |\n",
        "|-----------|---------|----------------|\n",
        "| `method` | `'regression'` | Use `'interpolation'` for exact fit |\n",
        "| `noise` | `sqrt(eps)` | Rarely; use `method='regression'` instead |\n",
        "| `min_theta` | `-3.0` | Adjust if default range doesn't work |\n",
        "| `max_theta` | `2.0` | Adjust if default range doesn't work |\n",
        "| `isotropic` | `False` | Set `True` for >5 dimensions |\n",
        "| `var_type` | `['num']` | Set for mixed variable types |\n",
        "| `metric_factorial` | `'canberra'` | Try `'hamming'` for factors |\n",
        "| `model_fun_evals` | `100` | Reduce for faster fitting |\n",
        "| `seed` | `124` | Always set for reproducibility |\n",
        "\n",
        "### Further Reading\n",
        "\n",
        "- Forrester, A., Sobester, A., & Keane, A. (2008). *Engineering Design via Surrogate Modelling*. Wiley.\n",
        "- Jones, D. R., Schonlau, M., & Welch, W. J. (1998). Efficient global optimization of expensive black-box functions. *Journal of Global optimization*, 13(4), 455-492.\n",
        "- Rasmussen, C. E., & Williams, C. K. I. (2006). *Gaussian Processes for Machine Learning*. MIT Press.\n",
        "\n",
        "For more examples and documentation, visit the [SpotOptim GitHub repository](https://github.com/sequential-parameter-optimization/spotoptim)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/workspace/spotoptim/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}