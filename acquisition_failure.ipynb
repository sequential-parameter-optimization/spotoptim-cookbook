{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Acquisition Failure Handling in SpotOptim\n",
        "sidebar_position: 5\n",
        "eval: true\n",
        "---\n",
        "\n",
        "\n",
        "SpotOptim provides sophisticated fallback strategies for handling acquisition function failures during optimization. This ensures robust optimization even when the surrogate model struggles to suggest new points.\n",
        "\n",
        "## What is Acquisition Failure?\n",
        "\n",
        "During surrogate-based optimization, the acquisition function suggests new points to evaluate. However, sometimes the suggested point is **too close** to existing points (within `tolerance_x` distance), which would provide little new information. When this happens, SpotOptim uses a **fallback strategy** to propose an alternative point.\n",
        "\n",
        "## Fallback Strategies\n",
        "\n",
        "SpotOptim supports two fallback strategies, controlled by the `acquisition_failure_strategy` parameter:\n",
        "\n",
        "### 1. Random Space-Filling Design (Default)\n",
        "\n",
        "**Strategy name**: `\"random\"`\n",
        "\n",
        "This strategy uses Latin Hypercube Sampling (LHS) to generate a new space-filling point. LHS ensures good coverage of the search space by dividing each dimension into equal-probability intervals.\n",
        "\n",
        "**When to use**:\n",
        "\n",
        "- General-purpose optimization\n",
        "- When you want simplicity and good space-filling properties\n",
        "- Default choice for most problems\n",
        "\n",
        "**Example**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotoptim import SpotOptim\n",
        "import numpy as np\n",
        "\n",
        "def sphere(X):\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=sphere,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    max_iter=50,\n",
        "    n_initial=10,\n",
        "    acquisition_failure_strategy=\"random\",  # Default\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Morris-Mitchell Minimizing Point\n",
        "\n",
        "**Strategy name**: `\"mm\"`\n",
        "\n",
        "This strategy finds a point that **maximizes the minimum distance** to all existing points. It evaluates 100 candidate points and selects the one with the largest minimum distance to the already-evaluated points, providing excellent space-filling properties.\n",
        "\n",
        "**When to use**:\n",
        "\n",
        "- When you want to ensure maximum exploration\n",
        "- For problems where avoiding clustering of points is critical\n",
        "- When the search space has been heavily sampled in some regions\n",
        "\n",
        "**Example**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotoptim import SpotOptim\n",
        "import numpy as np\n",
        "\n",
        "def rosenbrock(X):\n",
        "    x = X[:, 0]\n",
        "    y = X[:, 1]\n",
        "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=rosenbrock,\n",
        "    bounds=[(-2, 2), (-2, 2)],\n",
        "    max_iter=100,\n",
        "    n_initial=20,\n",
        "    acquisition_failure_strategy=\"mm\",  # Morris-Mitchell\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = optimizer.optimize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How It Works\n",
        "\n",
        "The acquisition failure handling is integrated into the optimization process:\n",
        "\n",
        "1. **Acquisition optimization**: SpotOptim uses differential evolution to optimize the acquisition function\n",
        "2. **Distance check**: The proposed point is checked against existing points using `tolerance_x`\n",
        "3. **Fallback activation**: If the point is too close, `_handle_acquisition_failure()` is called\n",
        "4. **Strategy execution**: The configured fallback strategy generates a new point\n",
        "5. **Evaluation**: The fallback point is evaluated and added to the dataset\n",
        "\n",
        "## Comparison of Strategies\n",
        "\n",
        "| Aspect | Random (LHS) | Morris-Mitchell |\n",
        "|--------|--------------|-----------------|\n",
        "| **Computation** | Very fast | Moderate (100 candidates) |\n",
        "| **Space-filling** | Good | Excellent |\n",
        "| **Exploration** | Balanced | Maximum distance |\n",
        "| **Clustering avoidance** | Good | Best |\n",
        "| **Recommended for** | General use | Heavily sampled spaces |\n",
        "\n",
        "## Complete Example: Comparing Strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from spotoptim import SpotOptim\n",
        "\n",
        "def ackley(X):\n",
        "    \"\"\"Ackley function - multimodal test function\"\"\"\n",
        "    a = 20\n",
        "    b = 0.2\n",
        "    c = 2 * np.pi\n",
        "    n = X.shape[1]\n",
        "    \n",
        "    sum_sq = np.sum(X**2, axis=1)\n",
        "    sum_cos = np.sum(np.cos(c * X), axis=1)\n",
        "    \n",
        "    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n",
        "\n",
        "# Test with random strategy\n",
        "print(\"=\" * 60)\n",
        "print(\"Testing with Random Space-Filling Strategy\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "opt_random = SpotOptim(\n",
        "    fun=ackley,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    max_iter=50,\n",
        "    n_initial=15,\n",
        "    acquisition_failure_strategy=\"random\",\n",
        "    tolerance_x=0.1,  # Relatively large tolerance to trigger failures\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result_random = opt_random.optimize()\n",
        "\n",
        "print(f\"\\nRandom Strategy Results:\")\n",
        "print(f\"  Best value: {result_random.fun:.6f}\")\n",
        "print(f\"  Best point: {result_random.x}\")\n",
        "print(f\"  Total evaluations: {result_random.nfev}\")\n",
        "\n",
        "# Test with Morris-Mitchell strategy\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Testing with Morris-Mitchell Strategy\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "opt_mm = SpotOptim(\n",
        "    fun=ackley,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    max_iter=50,\n",
        "    n_initial=15,\n",
        "    acquisition_failure_strategy=\"mm\",\n",
        "    tolerance_x=0.1,  # Same tolerance\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result_mm = opt_mm.optimize()\n",
        "\n",
        "print(f\"\\nMorris-Mitchell Strategy Results:\")\n",
        "print(f\"  Best value: {result_mm.fun:.6f}\")\n",
        "print(f\"  Best point: {result_mm.x}\")\n",
        "print(f\"  Total evaluations: {result_mm.nfev}\")\n",
        "\n",
        "# Compare\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Comparison\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Random strategy:        {result_random.fun:.6f}\")\n",
        "print(f\"Morris-Mitchell strategy: {result_mm.fun:.6f}\")\n",
        "if result_random.fun < result_mm.fun:\n",
        "    print(\"→ Random strategy found better solution\")\n",
        "else:\n",
        "    print(\"→ Morris-Mitchell strategy found better solution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Usage: Setting Tolerance\n",
        "\n",
        "The `tolerance_x` parameter controls when the fallback strategy is triggered. A larger tolerance means points need to be farther apart, triggering the fallback more often:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def simple_objective(X):\n",
        "    \"\"\"Simple quadratic function for demonstration\"\"\"\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "bounds_demo = [(-5, 5), (-5, 5)]\n",
        "\n",
        "# Strict tolerance (smaller value) - fewer fallbacks\n",
        "optimizer_strict = SpotOptim(\n",
        "    fun=simple_objective,\n",
        "    bounds=bounds_demo,\n",
        "    tolerance_x=1e-6,  # Very small - almost never triggers fallback\n",
        "    acquisition_failure_strategy=\"mm\",\n",
        "    max_iter=20,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Relaxed tolerance (larger value) - more fallbacks\n",
        "optimizer_relaxed = SpotOptim(\n",
        "    fun=simple_objective,\n",
        "    bounds=bounds_demo,\n",
        "    tolerance_x=0.5,  # Larger - triggers fallback more often\n",
        "    acquisition_failure_strategy=\"mm\",\n",
        "    max_iter=20,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"Strict tolerance setup complete\")\n",
        "print(f\"Relaxed tolerance setup complete\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices\n",
        "\n",
        "### 1. Use Random for Most Problems\n",
        "\n",
        "The random strategy (default) is sufficient for most optimization problems:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def my_objective(X):\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=my_objective,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    acquisition_failure_strategy=\"random\",  # Good default choice\n",
        "    max_iter=20,\n",
        "    seed=42\n",
        ")\n",
        "print(\"Random strategy optimizer created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Use Morris-Mitchell for Intensive Sampling\n",
        "\n",
        "When you have a large budget and want maximum exploration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def expensive_objective(X):\n",
        "    \"\"\"Simulated expensive objective function\"\"\"\n",
        "    return np.sum((X - 1)**2, axis=1)\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=expensive_objective,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    max_iter=30,  # Large budget\n",
        "    acquisition_failure_strategy=\"mm\",  # Maximize space coverage\n",
        "    seed=42\n",
        ")\n",
        "print(\"Morris-Mitchell optimizer for intensive sampling created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Monitor Fallback Activations\n",
        "\n",
        "Enable verbose mode to see when fallbacks are triggered:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def test_objective(X):\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "optimizer = SpotOptim(\n",
        "    fun=test_objective,\n",
        "    bounds=[(-5, 5), (-5, 5)],\n",
        "    acquisition_failure_strategy=\"mm\",\n",
        "    max_iter=20,\n",
        "    verbose=True,  # Shows fallback messages\n",
        "    seed=42\n",
        ")\n",
        "print(\"Optimizer with verbose mode created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Adjust Tolerance Based on Problem Scale\n",
        "\n",
        "For problems with small search spaces, use smaller tolerance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def scale_objective(X):\n",
        "    return np.sum(X**2, axis=1)\n",
        "\n",
        "# Small search space\n",
        "optimizer_small = SpotOptim(\n",
        "    fun=scale_objective,\n",
        "    bounds=[(-1, 1), (-1, 1)],\n",
        "    tolerance_x=0.01,  # Small tolerance for small space\n",
        "    acquisition_failure_strategy=\"random\",\n",
        "    max_iter=20,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Large search space\n",
        "optimizer_large = SpotOptim(\n",
        "    fun=scale_objective,\n",
        "    bounds=[(-100, 100), (-100, 100)],\n",
        "    tolerance_x=1.0,  # Larger tolerance for large space\n",
        "    acquisition_failure_strategy=\"mm\",\n",
        "    max_iter=20,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"Small space optimizer created (bounds: [-1, 1])\")\n",
        "print(f\"Large space optimizer created (bounds: [-100, 100])\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Technical Details\n",
        "\n",
        "### Morris-Mitchell Implementation\n",
        "\n",
        "The Morris-Mitchell strategy:\n",
        "\n",
        "1. Generates 100 candidate points using Latin Hypercube Sampling\n",
        "2. For each candidate, calculates the minimum distance to all existing points\n",
        "3. Selects the candidate with the maximum minimum distance\n",
        "\n",
        "This ensures the new point is as far as possible from the densest region of evaluated points.\n",
        "\n",
        "### Random Strategy Implementation\n",
        "\n",
        "The random strategy:\n",
        "\n",
        "1. Generates a single point using Latin Hypercube Sampling\n",
        "2. Ensures the point is within bounds\n",
        "3. Applies variable type repairs (rounding for int/factor variables)\n",
        "\n",
        "This is computationally efficient while maintaining good space-filling properties.\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **Default strategy** (`\"random\"`): Fast, good space-filling, suitable for most problems\n",
        "- **Morris-Mitchell** (`\"mm\"`): Better space-filling, maximizes minimum distance, ideal for intensive sampling\n",
        "- **Trigger**: Activated when acquisition-proposed point is too close to existing points (within `tolerance_x`)\n",
        "- **Control**: Set via `acquisition_failure_strategy` parameter\n",
        "- **Monitoring**: Enable `verbose=True` to see when fallbacks occur\n",
        "\n",
        "Choose the strategy that best matches your optimization goals:\n",
        "- Use `\"random\"` for general-purpose optimization\n",
        "- Use `\"mm\"` when you want maximum exploration and have a generous function evaluation budget"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/workspace/spotoptim/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}