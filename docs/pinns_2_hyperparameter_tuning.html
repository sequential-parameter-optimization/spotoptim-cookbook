<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>13&nbsp; Hyperparameter Tuning for Physics-Informed Neural Networks – Sequential Parameter Optimization Cookbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./acquisition_failure.html" rel="next">
<link href="./pinns_1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-58b8d76c6f3e5a567bac4a37e40b55a6.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="13&nbsp; Hyperparameter Tuning for Physics-Informed Neural Networks – Sequential Parameter Optimization Cookbook">
<meta name="twitter:description" content="Using SpotOptim to Optimize PINN Architecture and Training">
<meta name="twitter:image" content="pinns_2_hyperparameter_tuning_files/figure-html/pinn-optimization-history-pinn2-output-1.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./reproducibility.html">Sequential Parameter Optimization Toolbox (SPOT)</a></li><li class="breadcrumb-item"><a href="./pinns_2_hyperparameter_tuning.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning for Physics-Informed Neural Networks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Sequential Parameter Optimization Cookbook</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/sequential-parameter-optimization/spotpython" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Sequential-Parameter-Optimization-Cookbook.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Numerical Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Simulation and Surrogate Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling Plans</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_constructing_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Constructing a Surrogate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_num_rsm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Response Surface Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_poly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Polynomial Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_rbf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Radial Basis Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_infill.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Infill Criteria</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequential Parameter Optimization Toolbox (SPOT)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reproducibility in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pinns_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Physics-Informed Neural Networks (PINNs) Demo 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pinns_2_hyperparameter_tuning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning for Physics-Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acquisition_failure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Acquisition Failure Handling in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diabetes_dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Diabetes Dataset Utilities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./factor_variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Factor Variables for Categorical Hyperparameters</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Variable Transformations for Search Space Scaling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kriging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Kriging Surrogate Integration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learning_rate_mapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Learning Rate Mapping for Unified Optimizer Interface</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unified_learning_rate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Unified Learning Rate Interface in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiobjective.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multi-Objective Optimization Support in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./plot_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Surrogate Model Visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./point_selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Point Selection Implementation in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./save_load.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Save and Load in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./success_rate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Success Rate Tracking in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tensorboard_clean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">TensorBoard Log Cleaning Feature in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tensorboard.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">TensorBoard Logging in SpotOptim</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./var_type.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Variable Type (var_type) Implementation in SpotOptim</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">14</span> Overview</a>
  <ul class="collapse">
  <li><a href="#key-features" id="toc-key-features" class="nav-link" data-scroll-target="#key-features"><span class="header-section-number">14.1</span> Key Features</a>
  <ul class="collapse">
  <li><a href="#pytorch-dataset-and-dataloader" id="toc-pytorch-dataset-and-dataloader" class="nav-link" data-scroll-target="#pytorch-dataset-and-dataloader"><span class="header-section-number">14.1.1</span> 1. PyTorch Dataset and DataLoader</a></li>
  <li><a href="#automatic-transformation-handling" id="toc-automatic-transformation-handling" class="nav-link" data-scroll-target="#automatic-transformation-handling"><span class="header-section-number">14.1.2</span> 2. Automatic Transformation Handling</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#the-problem" id="toc-the-problem" class="nav-link" data-scroll-target="#the-problem"><span class="header-section-number">15</span> The Problem</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup"><span class="header-section-number">16</span> Setup</a></li>
  <li><a href="#data-generation" id="toc-data-generation" class="nav-link" data-scroll-target="#data-generation"><span class="header-section-number">17</span> Data Generation</a>
  <ul class="collapse">
  <li><a href="#custom-dataset-classes" id="toc-custom-dataset-classes" class="nav-link" data-scroll-target="#custom-dataset-classes"><span class="header-section-number">17.1</span> Custom Dataset Classes</a></li>
  </ul></li>
  <li><a href="#define-the-pinn-training-function" id="toc-define-the-pinn-training-function" class="nav-link" data-scroll-target="#define-the-pinn-training-function"><span class="header-section-number">18</span> Define the PINN Training Function</a></li>
  <li><a href="#hyperparameter-optimization-with-spotoptim" id="toc-hyperparameter-optimization-with-spotoptim" class="nav-link" data-scroll-target="#hyperparameter-optimization-with-spotoptim"><span class="header-section-number">19</span> Hyperparameter Optimization with SpotOptim</a>
  <ul class="collapse">
  <li><a href="#define-the-objective-function" id="toc-define-the-objective-function" class="nav-link" data-scroll-target="#define-the-objective-function"><span class="header-section-number">19.1</span> Define the Objective Function</a></li>
  <li><a href="#run-the-optimization" id="toc-run-the-optimization" class="nav-link" data-scroll-target="#run-the-optimization"><span class="header-section-number">19.2</span> Run the Optimization</a></li>
  </ul></li>
  <li><a href="#results-analysis" id="toc-results-analysis" class="nav-link" data-scroll-target="#results-analysis"><span class="header-section-number">20</span> Results Analysis</a>
  <ul class="collapse">
  <li><a href="#best-configuration" id="toc-best-configuration" class="nav-link" data-scroll-target="#best-configuration"><span class="header-section-number">20.1</span> Best Configuration</a>
  <ul class="collapse">
  <li><a href="#results-table-with-importance-scores" id="toc-results-table-with-importance-scores" class="nav-link" data-scroll-target="#results-table-with-importance-scores"><span class="header-section-number">20.1.1</span> Results Table with Importance Scores</a></li>
  </ul></li>
  <li><a href="#optimization-history" id="toc-optimization-history" class="nav-link" data-scroll-target="#optimization-history"><span class="header-section-number">20.2</span> Optimization History</a></li>
  <li><a href="#surrogate-visualization" id="toc-surrogate-visualization" class="nav-link" data-scroll-target="#surrogate-visualization"><span class="header-section-number">20.3</span> Surrogate Visualization</a></li>
  <li><a href="#parameter-distribution-analysis" id="toc-parameter-distribution-analysis" class="nav-link" data-scroll-target="#parameter-distribution-analysis"><span class="header-section-number">20.4</span> Parameter Distribution Analysis</a></li>
  </ul></li>
  <li><a href="#train-final-model-with-best-hyperparameters" id="toc-train-final-model-with-best-hyperparameters" class="nav-link" data-scroll-target="#train-final-model-with-best-hyperparameters"><span class="header-section-number">21</span> Train Final Model with Best Hyperparameters</a></li>
  <li><a href="#evaluate-final-model" id="toc-evaluate-final-model" class="nav-link" data-scroll-target="#evaluate-final-model"><span class="header-section-number">22</span> Evaluate Final Model</a></li>
  <li><a href="#visualize-final-solution" id="toc-visualize-final-solution" class="nav-link" data-scroll-target="#visualize-final-solution"><span class="header-section-number">23</span> Visualize Final Solution</a></li>
  <li><a href="#comparison-with-baseline" id="toc-comparison-with-baseline" class="nav-link" data-scroll-target="#comparison-with-baseline"><span class="header-section-number">24</span> Comparison with Baseline</a></li>
  <li><a href="#hyperparameter-sensitivity-analysis" id="toc-hyperparameter-sensitivity-analysis" class="nav-link" data-scroll-target="#hyperparameter-sensitivity-analysis"><span class="header-section-number">25</span> Hyperparameter Sensitivity Analysis</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">26</span> Summary</a>
  <ul class="collapse">
  <li><a href="#key-findings" id="toc-key-findings" class="nav-link" data-scroll-target="#key-findings"><span class="header-section-number">26.1</span> Key Findings</a></li>
  <li><a href="#recommendations" id="toc-recommendations" class="nav-link" data-scroll-target="#recommendations"><span class="header-section-number">26.2</span> Recommendations</a></li>
  <li><a href="#using-these-results" id="toc-using-these-results" class="nav-link" data-scroll-target="#using-these-results"><span class="header-section-number">26.3</span> Using These Results</a></li>
  <li><a href="#using-var_trans-for-your-hyperparameter-optimization" id="toc-using-var_trans-for-your-hyperparameter-optimization" class="nav-link" data-scroll-target="#using-var_trans-for-your-hyperparameter-optimization"><span class="header-section-number">26.4</span> Using var_trans for Your Hyperparameter Optimization</a></li>
  <li><a href="#future-directions" id="toc-future-directions" class="nav-link" data-scroll-target="#future-directions"><span class="header-section-number">26.5</span> Future Directions</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./reproducibility.html">Sequential Parameter Optimization Toolbox (SPOT)</a></li><li class="breadcrumb-item"><a href="./pinns_2_hyperparameter_tuning.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning for Physics-Informed Neural Networks</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning for Physics-Informed Neural Networks</span></h1>
<p class="subtitle lead">Using SpotOptim to Optimize PINN Architecture and Training</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> Overview</h1>
<p>This tutorial demonstrates how to use SpotOptim for hyperparameter optimization of Physics-Informed Neural Networks (PINNs). We’ll optimize the network architecture and training parameters to find the best configuration for solving an ordinary differential equation.</p>
<p>Building on the basic PINN demo, we’ll now systematically search for optimal:</p>
<ul>
<li>Number of neurons per hidden layer</li>
<li>Number of hidden layers</li>
<li>Activation function (categorical)</li>
<li>Optimizer algorithm (categorical)</li>
<li>Learning rate (log-scale)</li>
<li>Physics loss weight (log-scale)</li>
</ul>
<section id="key-features" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="key-features"><span class="header-section-number">14.1</span> Key Features</h2>
<section id="pytorch-dataset-and-dataloader" class="level3" data-number="14.1.1">
<h3 data-number="14.1.1" class="anchored" data-anchor-id="pytorch-dataset-and-dataloader"><span class="header-section-number">14.1.1</span> 1. PyTorch Dataset and DataLoader</h3>
<p>Following PyTorch best practices from the <a href="https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html">official tutorial</a>, this tutorial implements:</p>
<ul>
<li><strong>Custom Dataset Classes</strong>: Separate classes for supervised data (<code>PINNDataset</code>) and collocation points (<code>CollocationDataset</code>)</li>
<li><strong>DataLoader Integration</strong>: Efficient batch processing with configurable batch size, shuffling, and parallel loading</li>
<li><strong>Proper Data Separation</strong>: Clean separation of training, validation, and collocation data</li>
<li><strong>Gradient Tracking</strong>: Automatic gradient handling for collocation points needed in physics loss</li>
</ul>
<p>Benefits:</p>
<ul>
<li><strong>Modularity</strong>: Clean separation between data and model code</li>
<li><strong>Efficiency</strong>: Batch processing and optional parallel data loading</li>
<li><strong>Scalability</strong>: Easy to extend to larger datasets</li>
<li><strong>Best Practices</strong>: Follows PyTorch conventions used across the ecosystem</li>
</ul>
</section>
<section id="automatic-transformation-handling" class="level3" data-number="14.1.2">
<h3 data-number="14.1.2" class="anchored" data-anchor-id="automatic-transformation-handling"><span class="header-section-number">14.1.2</span> 2. Automatic Transformation Handling</h3>
<p>This tutorial also showcases SpotOptim’s <code>var_trans</code> feature for automatic variable transformations. Learning rates and regularization parameters are often best explored on a log scale, but manually transforming values is tedious and error-prone. With <code>var_trans</code>, you simply specify:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>var_trans <span class="op">=</span> [<span class="va">None</span>, <span class="va">None</span>, <span class="st">"log10"</span>, <span class="st">"log10"</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>SpotOptim then:</p>
<ul>
<li>Optimizes internally in log-transformed space (efficient exploration)</li>
<li>Passes original-scale values to your objective function (no manual conversion needed)</li>
<li>Displays all results in original scale (easy interpretation)</li>
</ul>
<p>This eliminates the need for manual <code>10**x</code> conversions throughout your code!</p>
</section>
</section>
</section>
<section id="the-problem" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> The Problem</h1>
<p>We’re solving the same ODE as in the basic PINN demo:</p>
<p><span class="math display">\[
\frac{dy}{dt} + 0.1 y - \sin\left(\frac{\pi t}{2}\right) = 0
\]</span></p>
<p>with initial condition <span class="math inline">\(y(0) = 0\)</span>.</p>
</section>
<section id="setup" class="level1" data-number="16">
<h1 data-number="16"><span class="header-section-number">16</span> Setup</h1>
<div id="setup-pinn2" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spotoptim <span class="im">import</span> SpotOptim</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spotoptim.nn.linear_regressor <span class="im">import</span> LinearRegressor</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set number of epochs for training</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>N_EPOCHS<span class="op">=</span><span class="dv">2000</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="data-generation" class="level1" data-number="17">
<h1 data-number="17"><span class="header-section-number">17</span> Data Generation</h1>
<p>Following PyTorch best practices, we’ll create custom Dataset classes for our PINN data.</p>
<section id="custom-dataset-classes" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="custom-dataset-classes"><span class="header-section-number">17.1</span> Custom Dataset Classes</h2>
<p>We’ll create two dataset types:</p>
<ol type="1">
<li><code>PINNDataset</code> for supervised data (training and validation)</li>
<li><code>CollocationDataset</code> for physics-informed collocation points</li>
</ol>
<div id="data-generation-pinn2" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> oscillator(</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    n_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">3000</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    t_min: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    t_max: <span class="bu">float</span> <span class="op">=</span> <span class="fl">30.0</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    y0: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    alpha: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    omega: <span class="bu">float</span> <span class="op">=</span> np.pi <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[torch.Tensor, torch.Tensor]:</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Solve ODE: dy/dt + alpha*y - sin(omega*t) = 0</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">    using RK2 (midpoint method).</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">        t_tensor: Time points, shape (n_steps, 1)</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">        y_tensor: Solution values, shape (n_steps, 1)</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    t_step <span class="op">=</span> (t_max <span class="op">-</span> t_min) <span class="op">/</span> n_steps</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    t_points <span class="op">=</span> np.arange(t_min, t_min <span class="op">+</span> n_steps <span class="op">*</span> t_step, t_step)[:n_steps]</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> [y0]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t_current_step_end <span class="kw">in</span> t_points[<span class="dv">1</span>:]:</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        t_midpoint <span class="op">=</span> t_current_step_end <span class="op">-</span> t_step <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        y_prev <span class="op">=</span> y[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        slope_at_t_mid <span class="op">=</span> <span class="op">-</span>alpha <span class="op">*</span> y_prev <span class="op">+</span> np.sin(omega <span class="op">*</span> t_midpoint)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        y_intermediate <span class="op">=</span> y_prev <span class="op">+</span> (t_step <span class="op">/</span> <span class="fl">2.0</span>) <span class="op">*</span> slope_at_t_mid</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        slope_at_t_end <span class="op">=</span> <span class="op">-</span>alpha <span class="op">*</span> y_intermediate <span class="op">+</span> np.sin(omega <span class="op">*</span> t_current_step_end)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        y_next <span class="op">=</span> y_prev <span class="op">+</span> t_step <span class="op">*</span> slope_at_t_end</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        y.append(y_next)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    t_tensor <span class="op">=</span> torch.tensor(t_points, dtype<span class="op">=</span>torch.float32).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    y_tensor <span class="op">=</span> torch.tensor(y, dtype<span class="op">=</span>torch.float32).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t_tensor, y_tensor</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PINNDataset(Dataset):</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""PyTorch Dataset for PINN supervised data (training/validation).</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="co">    This dataset stores time-solution pairs (t, y) for supervised learning.</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a><span class="co">        t (torch.Tensor): Time points, shape (n_samples, 1)</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co">        y (torch.Tensor): Solution values, shape (n_samples, 1)</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, t: torch.Tensor, y: torch.Tensor):</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.t <span class="op">=</span> t</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.t)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx: <span class="bu">int</span>) <span class="op">-&gt;</span> Tuple[torch.Tensor, torch.Tensor]:</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.t[idx], <span class="va">self</span>.y[idx]</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CollocationDataset(Dataset):</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""PyTorch Dataset for PINN collocation points.</span></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="co">    This dataset stores time points where physics loss is evaluated.</span></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a><span class="co">    Gradients are required for computing derivatives in the PDE.</span></span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a><span class="co">        t (torch.Tensor): Collocation time points, shape (n_points, 1)</span></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, t: torch.Tensor):</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store collocation points with gradient tracking</span></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.t <span class="op">=</span> t.requires_grad_(<span class="va">True</span>)</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.t)</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx: <span class="bu">int</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return single collocation point (still requires_grad)</span></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.t[idx].unsqueeze(<span class="dv">0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Generate exact solution using RK2</p>
<div id="33d57820" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x_exact, y_exact <span class="op">=</span> oscillator()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training data (sparse sampling)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>t_train <span class="op">=</span> x_exact[<span class="dv">0</span>:<span class="dv">3000</span>:<span class="dv">119</span>]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> y_exact[<span class="dv">0</span>:<span class="dv">3000</span>:<span class="dv">119</span>]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create validation data (different sampling for unbiased evaluation)</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>t_val <span class="op">=</span> x_exact[<span class="dv">50</span>:<span class="dv">3000</span>:<span class="dv">120</span>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> y_exact[<span class="dv">50</span>:<span class="dv">3000</span>:<span class="dv">120</span>]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create collocation points for physics loss</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>t_physics <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">30</span>, <span class="dv">50</span>).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Dataset objects</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> PINNDataset(t_train, y_train)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> PINNDataset(t_val, y_val)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>collocation_dataset <span class="op">=</span> CollocationDataset(t_physics)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training dataset size: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation dataset size: </span><span class="sc">{</span><span class="bu">len</span>(val_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Collocation dataset size: </span><span class="sc">{</span><span class="bu">len</span>(collocation_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Sample from training dataset:"</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>t_sample, y_sample <span class="op">=</span> train_dataset[<span class="dv">0</span>]</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  t: </span><span class="sc">{</span>t_sample<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">, y: </span><span class="sc">{</span>y_sample<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training dataset size: 26
Validation dataset size: 25
Collocation dataset size: 50

Sample from training dataset:
  t: 0.0000, y: 0.0000</code></pre>
</div>
</div>
</section>
</section>
<section id="define-the-pinn-training-function" class="level1" data-number="18">
<h1 data-number="18"><span class="header-section-number">18</span> Define the PINN Training Function</h1>
<p>This function creates DataLoaders and trains a PINN with given hyperparameters. Following PyTorch best practices, we use DataLoader for efficient batch processing.</p>
<div id="pinn-training-function-pinn2" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_pinn(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    l1: <span class="bu">int</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    num_layers: <span class="bu">int</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    activation: <span class="bu">str</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    optimizer_name: <span class="bu">str</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    lr_unified: <span class="bu">float</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    alpha: <span class="bu">float</span>,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    n_epochs: <span class="bu">int</span> <span class="op">=</span> N_EPOCHS,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">16</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Train a PINN with specified hyperparameters using DataLoaders.</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">        l1: Number of neurons per hidden layer</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">        num_layers: Number of hidden layers</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">        activation: Activation function ("Tanh", "ReLU", "Sigmoid", "GELU")</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">        optimizer_name: Optimizer algorithm ("Adam", "SGD", "RMSprop", "AdamW")</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">        lr_unified: Unified learning rate multiplier</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">        alpha: Weight for physics loss</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">        n_epochs: Number of training epochs</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">        batch_size: Batch size for DataLoader</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose: Whether to print progress</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">        Validation mean squared error</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set seed for reproducibility</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create DataLoaders</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        train_dataset,</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        num_workers<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        pin_memory<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        val_dataset,</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        num_workers<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>        pin_memory<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For collocation points, we can use full batch since it's small</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    collocation_loader <span class="op">=</span> DataLoader(</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>        collocation_dataset,</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="bu">len</span>(collocation_dataset),</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>        num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LinearRegressor(</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>        input_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>        output_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>        l1<span class="op">=</span>l1,</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>        num_hidden_layers<span class="op">=</span>num_layers,</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>        activation<span class="op">=</span>activation,</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>        lr<span class="op">=</span>lr_unified</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get optimizer</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> model.get_optimizer(optimizer_name)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop</span></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get collocation points (full batch)</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        t_physics_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(collocation_loader))</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure gradients are enabled</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>        t_physics_batch <span class="op">=</span> t_physics_batch.requires_grad_(<span class="va">True</span>)</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate over training batches</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch_t, batch_y <span class="kw">in</span> train_loader:</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Data Loss</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(batch_t)</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>            loss_data <span class="op">=</span> torch.mean((y_pred <span class="op">-</span> batch_y)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Physics Loss (computed on full collocation set)</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>            y_physics <span class="op">=</span> model(t_physics_batch)</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>            dy_dt <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>                y_physics,</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>                t_physics_batch,</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>                torch.ones_like(y_physics),</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>                create_graph<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>                retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>            )[<span class="dv">0</span>]</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>            <span class="co"># PDE residual: dy/dt + 0.1*y - sin(pi*t/2) = 0</span></span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>            physics_residual <span class="op">=</span> dy_dt <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> y_physics <span class="op">-</span> torch.sin(np.pi <span class="op">*</span> t_physics_batch <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>            loss_physics <span class="op">=</span> torch.mean(physics_residual<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Total Loss</span></span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_data <span class="op">+</span> alpha <span class="op">*</span> loss_physics</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>            epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose <span class="kw">and</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">2000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>            avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">: Avg Loss = </span><span class="sc">{</span>avg_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate on validation set</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a>    val_mse <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch_t, batch_y <span class="kw">in</span> val_loader:</span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(batch_t)</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>            val_mse <span class="op">+=</span> torch.mean((batch_y <span class="op">-</span> y_pred)<span class="op">**</span><span class="dv">2</span>).item()</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>    val_mse <span class="op">/=</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> val_mse</span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function with default parameters</span></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing PINN training function with DataLoaders..."</span>)</span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a>test_error <span class="op">=</span> train_pinn(</span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>    l1<span class="op">=</span><span class="dv">32</span>, </span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a>    num_layers<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">"Tanh"</span>,</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a>    optimizer_name<span class="op">=</span><span class="st">"Adam"</span>,</span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a>    lr_unified<span class="op">=</span><span class="fl">3.0</span>, </span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.06</span>,</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a>    n_epochs<span class="op">=</span>N_EPOCHS, </span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test validation MSE: </span><span class="sc">{</span>test_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing PINN training function with DataLoaders...
  Epoch 2000/2000: Avg Loss = 0.185009

Test validation MSE: 0.169622</code></pre>
</div>
</div>
</section>
<section id="hyperparameter-optimization-with-spotoptim" class="level1" data-number="19">
<h1 data-number="19"><span class="header-section-number">19</span> Hyperparameter Optimization with SpotOptim</h1>
<p>Now we’ll use SpotOptim to find the best hyperparameters:</p>
<section id="define-the-objective-function" class="level2" data-number="19.1">
<h2 data-number="19.1" class="anchored" data-anchor-id="define-the-objective-function"><span class="header-section-number">19.1</span> Define the Objective Function</h2>
<div id="pinn-objective-function-pinn2" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_pinn(X):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Objective function for SpotOptim.</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">        X: Array of hyperparameter configurations, shape (n_configs, 6)</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">           Each row: [l1, num_layers, activation, optimizer, lr_unified, alpha]</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">           Note: SpotOptim handles log transformations and factor mapping automatically</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">        Array of validation errors</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, params <span class="kw">in</span> <span class="bu">enumerate</span>(X):</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract parameters (already in original scale thanks to var_trans)</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Factor variables (activation, optimizer) are returned as strings</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        l1 <span class="op">=</span> <span class="bu">int</span>(params[<span class="dv">0</span>])                    <span class="co"># Number of neurons</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        num_layers <span class="op">=</span> <span class="bu">int</span>(params[<span class="dv">1</span>])            <span class="co"># Number of hidden layers</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        activation <span class="op">=</span> params[<span class="dv">2</span>]                 <span class="co"># Activation function</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        optimizer_name <span class="op">=</span> params[<span class="dv">3</span>]             <span class="co"># Optimizer algorithm</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        lr_unified <span class="op">=</span> params[<span class="dv">4</span>]                 <span class="co"># Learning rate</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> params[<span class="dv">5</span>]                      <span class="co"># Physics weight</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Configuration </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(X)<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  l1=</span><span class="sc">{</span>l1<span class="sc">}</span><span class="ss">, num_layers=</span><span class="sc">{</span>num_layers<span class="sc">}</span><span class="ss">, activation=</span><span class="sc">{</span>activation<span class="sc">}</span><span class="ss">, "</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  optimizer=</span><span class="sc">{</span>optimizer_name<span class="sc">}</span><span class="ss">, lr_unified=</span><span class="sc">{</span>lr_unified<span class="sc">:.4f}</span><span class="ss">, alpha=</span><span class="sc">{</span>alpha<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train PINN with these hyperparameters</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        val_error <span class="op">=</span> train_pinn(</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>            l1<span class="op">=</span>l1,</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>            num_layers<span class="op">=</span>num_layers,</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>            activation<span class="op">=</span>activation,</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>            optimizer_name<span class="op">=</span>optimizer_name,</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>            lr_unified<span class="op">=</span>lr_unified,</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span>alpha,</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>            n_epochs<span class="op">=</span>N_EPOCHS,</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>            verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Validation MSE: </span><span class="sc">{</span>val_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>        results.append(val_error)</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(results)</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the objective function</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing objective function with 2 configurations..."</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> np.array([</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">32</span>, <span class="dv">2</span>, <span class="st">"Tanh"</span>, <span class="st">"Adam"</span>, <span class="fl">3.0</span>, <span class="fl">0.06</span>],    <span class="co"># Baseline config</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">64</span>, <span class="dv">3</span>, <span class="st">"ReLU"</span>, <span class="st">"AdamW"</span>, <span class="fl">2.0</span>, <span class="fl">0.04</span>]    <span class="co"># Alternative config</span></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>], dtype<span class="op">=</span><span class="bu">object</span>)</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> objective_pinn(X_test)</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test results: </span><span class="sc">{</span>test_results<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing objective function with 2 configurations...

Configuration 1/2:
  l1=32, num_layers=2, activation=Tanh, 
  optimizer=Adam, lr_unified=3.0000, alpha=0.0600
  Validation MSE: 0.169622

Configuration 2/2:
  l1=64, num_layers=3, activation=ReLU, 
  optimizer=AdamW, lr_unified=2.0000, alpha=0.0400
  Validation MSE: 0.147564

Test results: [0.16962173 0.1475635 ]</code></pre>
</div>
</div>
</section>
<section id="run-the-optimization" class="level2" data-number="19.2">
<h2 data-number="19.2" class="anchored" data-anchor-id="run-the-optimization"><span class="header-section-number">19.2</span> Run the Optimization</h2>
<div id="pinn-hyperparameter-optimization-pinn2" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define search space with var_trans for automatic log-scale handling</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">16</span>, <span class="dv">128</span>),                                      <span class="co"># l1: neurons per layer (16 to 128)</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span>, <span class="dv">4</span>),                                         <span class="co"># num_layers: 1 to 4 hidden layers</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Tanh"</span>, <span class="st">"ReLU"</span>, <span class="st">"Sigmoid"</span>, <span class="st">"GELU"</span>),         <span class="co"># activation: activation function</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Adam"</span>, <span class="st">"SGD"</span>, <span class="st">"RMSprop"</span>, <span class="st">"AdamW"</span>),          <span class="co"># optimizer: optimizer algorithm</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">0.1</span>, <span class="fl">10.0</span>),                                    <span class="co"># lr_unified: learning rate (0.1 to 10)</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">0.01</span>, <span class="fl">1.0</span>)                                     <span class="co"># alpha: physics weight (0.01 to 1.0)</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>var_type <span class="op">=</span> [<span class="st">"int"</span>, <span class="st">"int"</span>, <span class="st">"factor"</span>, <span class="st">"factor"</span>, <span class="st">"num"</span>, <span class="st">"num"</span>]</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>var_name <span class="op">=</span> [<span class="st">"l1"</span>, <span class="st">"num_layers"</span>, <span class="st">"activation"</span>, <span class="st">"optimizer"</span>, <span class="st">"lr_unified"</span>, <span class="st">"alpha"</span>]</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Use var_trans to handle log-scale transformations automatically</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Factor variables don't need transformations (None)</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>var_trans <span class="op">=</span> [<span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span>, <span class="st">"log10"</span>, <span class="st">"log10"</span>]</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create optimizer</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> SpotOptim(</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    fun<span class="op">=</span>objective_pinn,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>bounds,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    var_type<span class="op">=</span>var_type,</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    var_name<span class="op">=</span>var_name,</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    var_trans<span class="op">=</span>var_trans,  <span class="co"># Automatic log-scale handling!</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    n_initial<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Factor variable at dimension 2:
  Levels: ['Tanh', 'ReLU', 'Sigmoid', 'GELU']
  Mapped to integers: 0 to 3
Factor variable at dimension 3:
  Levels: ['Adam', 'SGD', 'RMSprop', 'AdamW']
  Mapped to integers: 0 to 3
TensorBoard logging disabled</code></pre>
</div>
</div>
<p>Display search space configuration. The <code>trans</code>column shows applied transformations. <code>lr_unified</code> and <code>alpha</code> use log10 transformation internally. This enables efficient exploration of log-scale parameters. All values shown are in original scale (not transformed).</p>
<div id="61e5244f" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display search space configuration</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>design_table <span class="op">=</span> optimizer.print_design_table(tablefmt<span class="op">=</span><span class="st">"github"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(design_table)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>| name       | type   | lower   | upper   | default   | trans   |
|------------|--------|---------|---------|-----------|---------|
| l1         | int    | 16.0    | 128.0   | 72        | -       |
| num_layers | int    | 1.0     | 4.0     | 2         | -       |
| activation | factor | Tanh    | GELU    | Sigmoid   | -       |
| optimizer  | factor | Adam    | AdamW   | RMSprop   | -       |
| lr_unified | num    | 0.1     | 10.0    | 5.05      | log10   |
| alpha      | num    | 0.01    | 1.0     | 0.505     | log10   |</code></pre>
</div>
</div>
<p>Run optimization</p>
<div id="pinn-run-optimization-pinn2" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> optimizer.optimize()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Configuration 1/10:
  l1=19, num_layers=3, activation=ReLU, 
  optimizer=SGD, lr_unified=9.5756, alpha=0.1603
  Validation MSE: 0.212684

Configuration 2/10:
  l1=30, num_layers=3, activation=ReLU, 
  optimizer=Adam, lr_unified=0.8430, alpha=0.0412
  Validation MSE: 0.189506

Configuration 3/10:
  l1=110, num_layers=4, activation=ReLU, 
  optimizer=AdamW, lr_unified=1.9457, alpha=0.3866
  Validation MSE: 0.155698

Configuration 4/10:
  l1=74, num_layers=1, activation=Sigmoid, 
  optimizer=RMSprop, lr_unified=0.1014, alpha=0.1050
  Validation MSE: 0.190902

Configuration 5/10:
  l1=41, num_layers=3, activation=Sigmoid, 
  optimizer=RMSprop, lr_unified=0.5877, alpha=0.7301
  Validation MSE: 0.123401

Configuration 6/10:
  l1=52, num_layers=1, activation=Sigmoid, 
  optimizer=RMSprop, lr_unified=0.2023, alpha=0.0145
  Validation MSE: 0.191662

Configuration 7/10:
  l1=71, num_layers=2, activation=Sigmoid, 
  optimizer=SGD, lr_unified=3.2551, alpha=0.4300
  Validation MSE: 0.217354

Configuration 8/10:
  l1=120, num_layers=3, activation=ReLU, 
  optimizer=AdamW, lr_unified=0.3330, alpha=0.0220
  Validation MSE: 0.165832

Configuration 9/10:
  l1=98, num_layers=2, activation=Tanh, 
  optimizer=SGD, lr_unified=4.3915, alpha=0.0293
  Validation MSE: 0.186928

Configuration 10/10:
  l1=87, num_layers=2, activation=GELU, 
  optimizer=SGD, lr_unified=1.4861, alpha=0.0949
  Validation MSE: nan
Warning: Found 1 NaN/inf value(s), replacing with inf + noise
Warning: Removed 1 sample(s) with NaN/inf values
Initial best: f(x) = 0.123401

Configuration 1/1:
  l1=41, num_layers=4, activation=GELU, 
  optimizer=AdamW, lr_unified=0.1893, alpha=0.9411
  Validation MSE: 0.149702
Iteration 1: f(x) = 0.149702

Configuration 1/1:
  l1=41, num_layers=2, activation=Sigmoid, 
  optimizer=RMSprop, lr_unified=1.0971, alpha=0.3324
  Validation MSE: 0.168198
Iteration 2: f(x) = 0.168198

Configuration 1/1:
  l1=41, num_layers=3, activation=Sigmoid, 
  optimizer=RMSprop, lr_unified=0.4315, alpha=0.9034
  Validation MSE: 0.147431
Iteration 3: f(x) = 0.147431

Configuration 1/1:
  l1=120, num_layers=4, activation=ReLU, 
  optimizer=RMSprop, lr_unified=0.7084, alpha=0.0223
  Validation MSE: 0.192493
Iteration 4: f(x) = 0.192493

Configuration 1/1:
  l1=41, num_layers=3, activation=Sigmoid, 
  optimizer=AdamW, lr_unified=0.1922, alpha=0.0607
  Validation MSE: 0.203450
Iteration 5: f(x) = 0.203450

Configuration 1/1:
  l1=111, num_layers=3, activation=ReLU, 
  optimizer=RMSprop, lr_unified=0.6980, alpha=0.1358
  Validation MSE: 0.188511
Iteration 6: f(x) = 0.188511

Configuration 1/1:
  l1=42, num_layers=2, activation=ReLU, 
  optimizer=AdamW, lr_unified=0.9678, alpha=0.0769
  Validation MSE: 0.182839
Iteration 7: f(x) = 0.182839

Configuration 1/1:
  l1=40, num_layers=3, activation=GELU, 
  optimizer=RMSprop, lr_unified=0.1368, alpha=0.9287
  Validation MSE: 0.120842
Iteration 8: New best f(x) = 0.120842

Configuration 1/1:
  l1=41, num_layers=3, activation=Sigmoid, 
  optimizer=RMSprop, lr_unified=0.6786, alpha=0.6441
  Validation MSE: 0.145306
Iteration 9: f(x) = 0.145306

Configuration 1/1:
  l1=121, num_layers=4, activation=Sigmoid, 
  optimizer=AdamW, lr_unified=0.1978, alpha=0.0391
  Validation MSE: 0.203172
Iteration 10: f(x) = 0.203172

Configuration 1/1:
  l1=41, num_layers=1, activation=ReLU, 
  optimizer=AdamW, lr_unified=0.2271, alpha=0.6241
  Validation MSE: 0.199705
Iteration 11: f(x) = 0.199705</code></pre>
</div>
</div>
</section>
</section>
<section id="results-analysis" class="level1" data-number="20">
<h1 data-number="20"><span class="header-section-number">20</span> Results Analysis</h1>
<section id="best-configuration" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="best-configuration"><span class="header-section-number">20.1</span> Best Configuration</h2>
<p>Display best hyperparameters using print_best() method. With <code>var_trans</code>, results are already in original scale!</p>
<div id="pinn-best-configuration-pinn2" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>optimizer.print_best(result)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Best Solution Found:
--------------------------------------------------
  l1: 40
  num_layers: 3
  activation: GELU
  optimizer: RMSprop
  lr_unified: 0.1368
  alpha: 0.9287
  Objective Value: 0.1208
  Total Evaluations: 20</code></pre>
</div>
</div>
<p>Store values for later use in visualizations. Values are already in original scale thanks to <code>var_trans</code>. Factor variables are returned as strings.</p>
<div id="748cfb98" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>best_l1 <span class="op">=</span> <span class="bu">int</span>(result.x[<span class="dv">0</span>])</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>best_num_layers <span class="op">=</span> <span class="bu">int</span>(result.x[<span class="dv">1</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>best_activation <span class="op">=</span> result.x[<span class="dv">2</span>]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>best_optimizer <span class="op">=</span> result.x[<span class="dv">3</span>]</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>best_lr_unified <span class="op">=</span> result.x[<span class="dv">4</span>]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="op">=</span> result.x[<span class="dv">5</span>]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>best_val_error <span class="op">=</span> result.fun</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best activation: </span><span class="sc">{</span>best_activation<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best optimizer: </span><span class="sc">{</span>best_optimizer<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best activation: GELU
Best optimizer: RMSprop</code></pre>
</div>
</div>
<section id="results-table-with-importance-scores" class="level3" data-number="20.1.1">
<h3 data-number="20.1.1" class="anchored" data-anchor-id="results-table-with-importance-scores"><span class="header-section-number">20.1.1</span> Results Table with Importance Scores</h3>
<p>Display comprehensive results table with importance scores</p>
<div id="pinn-results-table-pinn2" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>table <span class="op">=</span> optimizer.print_results_table(show_importance<span class="op">=</span><span class="va">True</span>, tablefmt<span class="op">=</span><span class="st">"github"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(table)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>| name       | type   | lower   | upper   | tuned               | trans   |   importance | stars   |
|------------|--------|---------|---------|---------------------|---------|--------------|---------|
| l1         | int    | 16.0    | 128.0   | 40                  | -       |         8.30 | *       |
| num_layers | int    | 1.0     | 4.0     | 3                   | -       |        13.75 | *       |
| activation | factor | Tanh    | GELU    | GELU                | -       |        19.91 | *       |
| optimizer  | factor | Adam    | AdamW   | RMSprop             | -       |         8.90 | *       |
| lr_unified | num    | 0.1     | 10.0    | 0.13678714783116164 | log10   |        16.93 | *       |
| alpha      | num    | 0.01    | 1.0     | 0.9287492634451227  | log10   |        32.21 | *       |

Interpretation: ***: &gt;95%, **: &gt;50%, *: &gt;1%, .: &gt;0.1%</code></pre>
</div>
</div>
</section>
</section>
<section id="optimization-history" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="optimization-history"><span class="header-section-number">20.2</span> Optimization History</h2>
<div id="cell-pinn-optimization-history-pinn2" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>optimizer.plot_progress(log_y<span class="op">=</span><span class="va">True</span>, ylabel<span class="op">=</span><span class="st">"Validation MSE"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-optimization-history-pinn2-output-1.png" id="pinn-optimization-history-pinn2" width="948" height="565" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="surrogate-visualization" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="surrogate-visualization"><span class="header-section-number">20.3</span> Surrogate Visualization</h2>
<p>Visualize the surrogate model’s learned response surface for the most important hyperparameter combinations:</p>
<div id="pinn-surrogate-visualization-pinn2" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 3 most important hyperparameter combinations</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>optimizer.plot_important_hyperparameter_contour(max_imp<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Plotting surrogate contours for top 3 most important parameters:
  alpha: importance = 32.21% (type: num)
  activation: importance = 19.91% (type: factor)
  lr_unified: importance = 16.93% (type: num)

Generating 3 surrogate plots...
  Plotting alpha vs activation</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-surrogate-visualization-pinn2-output-2.png" id="pinn-surrogate-visualization-pinn2-1" width="990" height="819" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Plotting alpha vs lr_unified</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-surrogate-visualization-pinn2-output-4.png" id="pinn-surrogate-visualization-pinn2-2" width="1131" height="950" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Plotting activation vs lr_unified</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-surrogate-visualization-pinn2-output-6.png" id="pinn-surrogate-visualization-pinn2-3" width="960" height="853" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="parameter-distribution-analysis" class="level2" data-number="20.4">
<h2 data-number="20.4" class="anchored" data-anchor-id="parameter-distribution-analysis"><span class="header-section-number">20.4</span> Parameter Distribution Analysis</h2>
<div id="cell-pinn-parameter-scatter-pinn2" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>optimizer.plot_parameter_scatter(</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    result,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    ylabel<span class="op">=</span><span class="st">"Validation MSE"</span>,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"plasma"</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">12</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-parameter-scatter-pinn2-output-1.png" id="pinn-parameter-scatter-pinn2" width="1333" height="1138" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="train-final-model-with-best-hyperparameters" class="level1" data-number="21">
<h1 data-number="21"><span class="header-section-number">21</span> Train Final Model with Best Hyperparameters</h1>
<p>Now let’s train a final model with the optimized hyperparameters using DataLoaders:</p>
<div id="cell-pinn-final-model-training-pinn2" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training final model with best hyperparameters using DataLoaders..."</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training for 30,000 epochs..."</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataLoaders for final training</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>final_batch_size <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>train_loader_final <span class="op">=</span> DataLoader(</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    train_dataset,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>final_batch_size,</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>collocation_loader_final <span class="op">=</span> DataLoader(</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    collocation_dataset,</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">len</span>(collocation_dataset),</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model with best hyperparameters</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>final_model <span class="op">=</span> LinearRegressor(</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>    input_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>    output_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    l1<span class="op">=</span>best_l1,</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    num_hidden_layers<span class="op">=</span>best_num_layers,</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    activation<span class="op">=</span>best_activation,</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>best_lr_unified</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>optimizer_final <span class="op">=</span> final_model.get_optimizer(best_optimizer)</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Training with history tracking</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>loss_history <span class="op">=</span> []</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>n_epochs_final <span class="op">=</span> <span class="dv">30000</span></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs_final):</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    final_model.train()</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get collocation points</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>    t_physics_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(collocation_loader_final))</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>    t_physics_batch <span class="op">=</span> t_physics_batch.requires_grad_(<span class="va">True</span>)</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over training batches</span></span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_t, batch_y <span class="kw">in</span> train_loader_final:</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>        optimizer_final.zero_grad()</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Data Loss</span></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> final_model(batch_t)</span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>        loss_data <span class="op">=</span> torch.mean((y_pred <span class="op">-</span> batch_y)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Physics Loss</span></span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>        y_physics <span class="op">=</span> final_model(t_physics_batch)</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>        dy_dt <span class="op">=</span> torch.autograd.grad(</span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>            y_physics,</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>            t_physics_batch,</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>            torch.ones_like(y_physics),</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>            create_graph<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>            retain_graph<span class="op">=</span><span class="va">True</span></span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a>        )[<span class="dv">0</span>]</span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a>        physics_residual <span class="op">=</span> dy_dt <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> y_physics <span class="op">-</span> torch.sin(np.pi <span class="op">*</span> t_physics_batch <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>        loss_physics <span class="op">=</span> torch.mean(physics_residual<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Total Loss</span></span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_data <span class="op">+</span> best_alpha <span class="op">*</span> loss_physics</span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a>        optimizer_final.step()</span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Record average loss every 100 epochs</span></span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(train_loader_final)</span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a>        loss_history.append(avg_loss)</span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">5000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(train_loader_final)</span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs_final<span class="sc">}</span><span class="ss">: Avg Loss = </span><span class="sc">{</span>avg_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training completed!"</span>)</span>
<span id="cb28-85"><a href="#cb28-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-86"><a href="#cb28-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training history</span></span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_history, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iteration (×100)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Average Total Loss per Batch'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Final Model Training History'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb28-92"><a href="#cb28-92" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb28-93"><a href="#cb28-93" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb28-94"><a href="#cb28-94" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-95"><a href="#cb28-95" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training final model with best hyperparameters using DataLoaders...
Training for 30,000 epochs...
  Epoch 5000/30000: Avg Loss = 0.151573
  Epoch 10000/30000: Avg Loss = 0.025751
  Epoch 15000/30000: Avg Loss = 0.022447
  Epoch 20000/30000: Avg Loss = 0.035008
  Epoch 25000/30000: Avg Loss = 0.034133
  Epoch 30000/30000: Avg Loss = 0.017587
Training completed!</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-final-model-training-pinn2-output-2.png" id="pinn-final-model-training-pinn2" width="948" height="469" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="evaluate-final-model" class="level1" data-number="22">
<h1 data-number="22"><span class="header-section-number">22</span> Evaluate Final Model</h1>
<div id="pinn-final-model-evaluation-pinn2" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create validation DataLoader for evaluation</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>val_loader_final <span class="op">=</span> DataLoader(</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    val_dataset,</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="bu">len</span>(val_dataset),</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on validation set</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>final_model.<span class="bu">eval</span>()</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation MSE using DataLoader</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    val_mse_total <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_t, batch_y <span class="kw">in</span> val_loader_final:</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> final_model(batch_t)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>        val_mse_total <span class="op">+=</span> torch.mean((y_pred <span class="op">-</span> batch_y)<span class="op">**</span><span class="dv">2</span>).item()</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    final_val_mse <span class="op">=</span> val_mse_total <span class="op">/</span> <span class="bu">len</span>(val_loader_final)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on full domain for visualization</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    y_pred_full <span class="op">=</span> final_model(x_exact)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    full_mse <span class="op">=</span> torch.mean((y_pred_full <span class="op">-</span> y_exact)<span class="op">**</span><span class="dv">2</span>).item()</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute maximum absolute error</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    max_error <span class="op">=</span> torch.<span class="bu">max</span>(torch.<span class="bu">abs</span>(y_pred_full <span class="op">-</span> y_exact)).item()</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Final Model Performance:"</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Validation MSE: </span><span class="sc">{</span>final_val_mse<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Full domain MSE: </span><span class="sc">{</span>full_mse<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Maximum absolute error: </span><span class="sc">{</span>max_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final Model Performance:
--------------------------------------------------
  Validation MSE: 0.004629
  Full domain MSE: 0.004570
  Maximum absolute error: 0.185277</code></pre>
</div>
</div>
</section>
<section id="visualize-final-solution" class="level1" data-number="23">
<h1 data-number="23"><span class="header-section-number">23</span> Visualize Final Solution</h1>
<div id="cell-pinn-final-model-visualization-pinn2" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>final_model.<span class="bu">eval</span>()</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> final_model(x_exact)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Solution comparison</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> axes[<span class="dv">0</span>]</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_exact.numpy(), y_exact.numpy(), <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, </span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Exact solution'</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_exact.numpy(), y_pred.numpy(), <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'PINN prediction (optimized)'</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training data from dataset</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>ax1.scatter(train_dataset.t.numpy(), train_dataset.y.numpy(), </span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">'tab:orange'</span>, s<span class="op">=</span><span class="dv">80</span>, label<span class="op">=</span><span class="st">'Training data'</span>, </span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>            zorder<span class="op">=</span><span class="dv">5</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot collocation points</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>t_collocation <span class="op">=</span> collocation_dataset.t.detach()</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>ax1.scatter(t_collocation.numpy(), </span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>            final_model(t_collocation).detach().numpy(),</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">'green'</span>, marker<span class="op">=</span><span class="st">'x'</span>, s<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="st">'Collocation points'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, zorder<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Time t'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Solution y(t)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Optimized PINN Solution vs Exact Solution'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>ax1.legend(fontsize<span class="op">=</span><span class="dv">11</span>, loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Error</span></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> axes[<span class="dv">1</span>]</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> torch.<span class="bu">abs</span>(y_pred <span class="op">-</span> y_exact)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>ax2.plot(x_exact.numpy(), error.numpy(), <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>ax2.axhline(y<span class="op">=</span>max_error, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Max error = </span><span class="sc">{</span>max_error<span class="sc">:.6f}</span><span class="ss">'</span>)</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Time t'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Absolute Error |y_exact - y_PINN|'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Approximation Error (Optimized Model)'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>ax2.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-final-model-visualization-pinn2-output-1.png" id="pinn-final-model-visualization-pinn2" width="1143" height="950" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comparison-with-baseline" class="level1" data-number="24">
<h1 data-number="24"><span class="header-section-number">24</span> Comparison with Baseline</h1>
<p>Let’s compare the optimized configuration with a baseline:</p>
<div id="cell-pinn-baseline-comparison-pinn2" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training baseline model for comparison..."</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Baseline configuration (from basic PINN demo)</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>baseline_config <span class="op">=</span> {</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'l1'</span>: <span class="dv">32</span>,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'num_layers'</span>: <span class="dv">3</span>,</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'activation'</span>: <span class="st">'Tanh'</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'optimizer'</span>: <span class="st">'Adam'</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lr_unified'</span>: <span class="fl">3.0</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'alpha'</span>: <span class="fl">0.06</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Baseline Configuration:"</span>)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key, val <span class="kw">in</span> baseline_config.items():</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>val<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Train baseline</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>baseline_error <span class="op">=</span> train_pinn(</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    l1<span class="op">=</span>baseline_config[<span class="st">'l1'</span>],</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    num_layers<span class="op">=</span>baseline_config[<span class="st">'num_layers'</span>],</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    activation<span class="op">=</span>baseline_config[<span class="st">'activation'</span>],</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    optimizer_name<span class="op">=</span>baseline_config[<span class="st">'optimizer'</span>],</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    lr_unified<span class="op">=</span>baseline_config[<span class="st">'lr_unified'</span>],</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span>baseline_config[<span class="st">'alpha'</span>],</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    n_epochs<span class="op">=</span>N_EPOCHS,</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Validation MSE Comparison:"</span>)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Baseline: </span><span class="sc">{</span>baseline_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Optimized: </span><span class="sc">{</span>best_val_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Improvement: </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> best_val_error<span class="op">/</span>baseline_error)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Bar plot comparison</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>configs <span class="op">=</span> [<span class="st">'Baseline'</span>, <span class="st">'Optimized'</span>]</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>errors <span class="op">=</span> [baseline_error, best_val_error]</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'tab:blue'</span>, <span class="st">'tab:green'</span>]</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> ax.bar(configs, errors, color<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.7</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Add value labels on bars</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, error <span class="kw">in</span> <span class="bu">zip</span>(bars, errors):</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>    height <span class="op">=</span> bar.get_height()</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>    ax.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, height,</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'</span><span class="sc">{</span>error<span class="sc">:.6f}</span><span class="ss">'</span>,</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>            ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontsize<span class="op">=</span><span class="dv">11</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Validation MSE'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Model Comparison: Baseline vs Optimized'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training baseline model for comparison...

Baseline Configuration:
  l1: 32
  num_layers: 3
  activation: Tanh
  optimizer: Adam
  lr_unified: 3.0
  alpha: 0.06

Validation MSE Comparison:
--------------------------------------------------
  Baseline: 0.144893
  Optimized: 0.120842
  Improvement: 16.6%</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-baseline-comparison-pinn2-output-2.png" id="pinn-baseline-comparison-pinn2" width="759" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="hyperparameter-sensitivity-analysis" class="level1" data-number="25">
<h1 data-number="25"><span class="header-section-number">25</span> Hyperparameter Sensitivity Analysis</h1>
<p>Let’s analyze how sensitive the model is to each hyperparameter:</p>
<div id="cell-pinn-sensitivity-analysis-pinn2" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute correlation between parameters and error</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> spearmanr</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get optimization history and parameters</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> optimizer.y_</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>all_params <span class="op">=</span> optimizer.X_</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter metadata</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'l1 (neurons)'</span>, <span class="st">'num_layers'</span>, <span class="st">'activation'</span>, <span class="st">'optimizer'</span>, <span class="st">'lr_unified'</span>, <span class="st">'alpha'</span>]</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>param_indices <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>transforms <span class="op">=</span> [<span class="kw">lambda</span> x: x, <span class="kw">lambda</span> x: x, <span class="kw">lambda</span> x: x, <span class="kw">lambda</span> x: x, <span class="kw">lambda</span> x: x, <span class="kw">lambda</span> x: x]</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (ax, name, param_idx, transform) <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">zip</span>(axes.flat, param_names, param_indices, transforms)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    param_values <span class="op">=</span> all_params[:, param_idx]</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    errors <span class="op">=</span> history</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle different parameter types</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">&lt;</span> <span class="dv">2</span>:  <span class="co"># Integer parameters (l1, num_layers)</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>        corr, p_value <span class="op">=</span> spearmanr(param_values, errors)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>        ax.scatter(param_values, errors, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">40</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>        ax.scatter([result.x[param_idx]], [best_val_error], </span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>                  color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">200</span>, marker<span class="op">=</span><span class="st">'*'</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, </span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>                  label<span class="op">=</span><span class="st">'Best'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>        ax.set_yscale(<span class="st">'log'</span>)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> idx <span class="op">&lt;</span> <span class="dv">4</span>:  <span class="co"># Factor parameters (activation, optimizer)</span></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For categorical variables, create a box plot or strip plot</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>        unique_vals <span class="op">=</span> np.unique(param_values)</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> {val: i <span class="cf">for</span> i, val <span class="kw">in</span> <span class="bu">enumerate</span>(unique_vals)}</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>        numeric_vals <span class="op">=</span> np.array([positions[val] <span class="cf">for</span> val <span class="kw">in</span> param_values])</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>        ax.scatter(numeric_vals, errors, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">40</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get best value - handle both string and potential numeric representations</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>        best_val <span class="op">=</span> result.x[param_idx]</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure best_val is in positions dict, if not, add it</span></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_val <span class="kw">not</span> <span class="kw">in</span> positions:</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># This shouldn't happen, but handle gracefully</span></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>            positions[best_val] <span class="op">=</span> <span class="bu">len</span>(positions)</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>            unique_vals <span class="op">=</span> np.append(unique_vals, best_val)</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>        best_pos <span class="op">=</span> positions[best_val]</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>        ax.scatter([best_pos], [best_val_error], </span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>                  color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">200</span>, marker<span class="op">=</span><span class="st">'*'</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, </span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>                  label<span class="op">=</span><span class="st">'Best'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>        ax.set_xticks(<span class="bu">range</span>(<span class="bu">len</span>(unique_vals)))</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>        ax.set_xticklabels(unique_vals, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>        ax.set_yscale(<span class="st">'log'</span>)</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For categorical, correlation doesn't apply</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>        corr, p_value <span class="op">=</span> np.nan, np.nan</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># Log-scale parameters (lr_unified, alpha)</span></span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>        corr, p_value <span class="op">=</span> spearmanr(np.log10(param_values), np.log10(errors))</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>        ax.scatter(param_values, errors, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">40</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>        ax.scatter([result.x[param_idx]], [best_val_error], </span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>                  color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">200</span>, marker<span class="op">=</span><span class="st">'*'</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, </span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>                  label<span class="op">=</span><span class="st">'Best'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>        ax.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>        ax.set_yscale(<span class="st">'log'</span>)</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(name, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Validation MSE'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> np.isnan(corr):</span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> Sensitivity</span><span class="ch">\n</span><span class="ss">Correlation: </span><span class="sc">{</span>corr<span class="sc">:.3f}</span><span class="ss"> (p=</span><span class="sc">{</span>p_value<span class="sc">:.3f}</span><span class="ss">)'</span>, </span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>                    fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> Sensitivity'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Sensitivity Analysis (Spearman Correlation):"</span>)</span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param_idx <span class="kw">in</span> <span class="bu">zip</span>(param_names, param_indices):</span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a>    param_values <span class="op">=</span> all_params[:, param_idx]</span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle different parameter types</span></span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> param_idx <span class="op">&lt;</span> <span class="dv">2</span>:  <span class="co"># Integer parameters</span></span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a>        corr, p_value <span class="op">=</span> spearmanr(param_values, history)</span>
<span id="cb35-85"><a href="#cb35-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> param_idx <span class="op">&lt;</span> <span class="dv">4</span>:  <span class="co"># Factor parameters (skip correlation)</span></span>
<span id="cb35-86"><a href="#cb35-86" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>name<span class="sc">:20s}</span><span class="ss">: (categorical variable, use visual inspection)"</span>)</span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># Log-scale parameters</span></span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a>        corr, p_value <span class="op">=</span> spearmanr(np.log10(param_values), np.log10(history))</span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-91"><a href="#cb35-91" aria-hidden="true" tabindex="-1"></a>    significance <span class="op">=</span> <span class="st">"***"</span> <span class="cf">if</span> p_value <span class="op">&lt;</span> <span class="fl">0.001</span> <span class="cf">else</span> <span class="st">"**"</span> <span class="cf">if</span> p_value <span class="op">&lt;</span> <span class="fl">0.01</span> <span class="cf">else</span> <span class="st">"*"</span> <span class="cf">if</span> p_value <span class="op">&lt;</span> <span class="fl">0.05</span> <span class="cf">else</span> <span class="st">""</span></span>
<span id="cb35-92"><a href="#cb35-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>name<span class="sc">:20s}</span><span class="ss">: </span><span class="sc">{</span>corr<span class="sc">:+.3f}</span><span class="ss"> (p=</span><span class="sc">{</span>p_value<span class="sc">:.3f}</span><span class="ss">) </span><span class="sc">{</span>significance<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pinns_2_hyperparameter_tuning_files/figure-html/pinn-sensitivity-analysis-pinn2-output-1.png" id="pinn-sensitivity-analysis-pinn2" width="1426" height="946" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Sensitivity Analysis (Spearman Correlation):
--------------------------------------------------
  l1 (neurons)        : +0.188 (p=0.429) 
  num_layers          : -0.225 (p=0.341) 
  activation          : (categorical variable, use visual inspection)
  optimizer           : (categorical variable, use visual inspection)
  lr_unified          : +0.170 (p=0.474) 
  alpha               : -0.502 (p=0.024) *</code></pre>
</div>
</div>
</section>
<section id="summary" class="level1" data-number="26">
<h1 data-number="26"><span class="header-section-number">26</span> Summary</h1>
<section id="key-findings" class="level2" data-number="26.1">
<h2 data-number="26.1" class="anchored" data-anchor-id="key-findings"><span class="header-section-number">26.1</span> Key Findings</h2>
<div id="pinn-summary-pinn2" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"HYPERPARAMETER OPTIMIZATION SUMMARY"</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. BEST CONFIGURATION FOUND:"</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Neurons per layer (l1): </span><span class="sc">{</span>best_l1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Number of hidden layers: </span><span class="sc">{</span>best_num_layers<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Activation function: </span><span class="sc">{</span>best_activation<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Optimizer: </span><span class="sc">{</span>best_optimizer<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Learning rate: </span><span class="sc">{</span>best_lr_unified<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Physics weight (alpha): </span><span class="sc">{</span>best_alpha<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. PERFORMANCE:"</span>)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Validation MSE: </span><span class="sc">{</span>best_val_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Full domain MSE: </span><span class="sc">{</span>full_mse<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Maximum absolute error: </span><span class="sc">{</span>max_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. OPTIMIZATION STATISTICS:"</span>)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Total evaluations: </span><span class="sc">{</span>result<span class="sc">.</span>nfev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Initial best: </span><span class="sc">{</span>history[<span class="dv">0</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Final best: </span><span class="sc">{</span>best_val_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Improvement: </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> best_val_error<span class="op">/</span>history[<span class="dv">0</span>])<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. COMPARISON TO BASELINE:"</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Baseline MSE: </span><span class="sc">{</span>baseline_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Optimized MSE: </span><span class="sc">{</span>best_val_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Improvement: </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> best_val_error<span class="op">/</span>baseline_error)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
HYPERPARAMETER OPTIMIZATION SUMMARY
======================================================================

1. BEST CONFIGURATION FOUND:
   - Neurons per layer (l1): 40
   - Number of hidden layers: 3
   - Activation function: GELU
   - Optimizer: RMSprop
   - Learning rate: 0.1368
   - Physics weight (alpha): 0.9287

2. PERFORMANCE:
   - Validation MSE: 0.120842
   - Full domain MSE: 0.004570
   - Maximum absolute error: 0.185277

3. OPTIMIZATION STATISTICS:
   - Total evaluations: 20
   - Initial best: 0.212684
   - Final best: 0.120842
   - Improvement: 43.2%

4. COMPARISON TO BASELINE:
   - Baseline MSE: 0.144893
   - Optimized MSE: 0.120842
   - Improvement: 16.6%

======================================================================</code></pre>
</div>
</div>
</section>
<section id="recommendations" class="level2" data-number="26.2">
<h2 data-number="26.2" class="anchored" data-anchor-id="recommendations"><span class="header-section-number">26.2</span> Recommendations</h2>
<p>Based on the hyperparameter optimization results:</p>
<ol type="1">
<li><strong>Network Architecture</strong>:
<ul>
<li>The optimal architecture was found with <code>{best_l1}</code> neurons and <code>{best_num_layers}</code> hidden layers</li>
<li>Best activation function: <code>{best_activation}</code></li>
<li>This balances model capacity with training efficiency</li>
</ul></li>
<li><strong>Optimizer Selection</strong>:
<ul>
<li>Best optimizer: <code>{best_optimizer}</code></li>
<li>Different optimizers have different convergence characteristics for PINNs</li>
</ul></li>
<li><strong>Learning Rate</strong>:
<ul>
<li>Optimal unified learning rate: <code>{best_lr_unified:.4f}</code></li>
<li>This translates to an actual Adam learning rate of <code>{best_lr_unified * 0.001:.6f}</code></li>
</ul></li>
<li><strong>Physics Loss Weight</strong>:
<ul>
<li>Optimal alpha: <code>{best_alpha:.4f}</code></li>
<li>This balances data fitting with physics constraint satisfaction</li>
</ul></li>
<li><strong>Training Strategy</strong>:
<ul>
<li>Start with a broad search space to explore different architectures</li>
<li>Use <code>var_trans</code> with “log10” for learning rate and physics weight parameters</li>
<li>This enables efficient exploration of log-scale parameters without manual transformations</li>
<li>Validate on held-out data to prevent overfitting to training points</li>
</ul></li>
<li><strong>Benefits of var_trans and Factor Variables</strong>:
<ul>
<li><strong>Factor variables</strong>: Categorical choices (activation, optimizer) handled automatically</li>
<li>SpotOptim maps strings to integers internally and back to strings in results</li>
<li><strong>Cleaner code</strong>: No manual <code>10**x</code> conversions in objective function</li>
<li><strong>Fewer errors</strong>: Eliminates confusion about which scale values are in</li>
<li><strong>Better optimization</strong>: Searches efficiently in transformed space</li>
<li><strong>Easier interpretation</strong>: All results displayed in original scale</li>
</ul></li>
</ol>
</section>
<section id="using-these-results" class="level2" data-number="26.3">
<h2 data-number="26.3" class="anchored" data-anchor-id="using-these-results"><span class="header-section-number">26.3</span> Using These Results</h2>
<p>To use the optimized configuration in your own PINN problems:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create optimized PINN</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegressor(</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    input_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    output_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    l1<span class="op">=</span>{best_l1},</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    num_hidden_layers<span class="op">=</span>{best_num_layers},</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">"</span><span class="sc">{best_activation}</span><span class="st">"</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>{best_lr_unified:<span class="fl">.4</span><span class="er">f</span>}</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> model.get_optimizer(<span class="st">"</span><span class="sc">{best_optimizer}</span><span class="st">"</span>)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use alpha={best_alpha:.4f} for physics loss weight</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> data_loss <span class="op">+</span> {best_alpha:<span class="fl">.4</span><span class="er">f</span>} <span class="op">*</span> physics_loss</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="using-var_trans-for-your-hyperparameter-optimization" class="level2" data-number="26.4">
<h2 data-number="26.4" class="anchored" data-anchor-id="using-var_trans-for-your-hyperparameter-optimization"><span class="header-section-number">26.4</span> Using var_trans for Your Hyperparameter Optimization</h2>
<p>When setting up optimization for your own PINN problems:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spotoptim <span class="im">import</span> SpotOptim</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define search space with factor variables and log-scale parameters</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">16</span>, <span class="dv">128</span>),                                    <span class="co"># neurons (integer)</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span>, <span class="dv">4</span>),                                       <span class="co"># layers (integer)</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Tanh"</span>, <span class="st">"ReLU"</span>, <span class="st">"Sigmoid"</span>, <span class="st">"GELU"</span>),       <span class="co"># activation (factor)</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Adam"</span>, <span class="st">"SGD"</span>, <span class="st">"RMSprop"</span>, <span class="st">"AdamW"</span>),        <span class="co"># optimizer (factor)</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">0.1</span>, <span class="fl">10.0</span>),                                  <span class="co"># learning rate (log-scale)</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">0.01</span>, <span class="fl">1.0</span>)                                   <span class="co"># physics weight (log-scale)</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>var_type <span class="op">=</span> [<span class="st">"int"</span>, <span class="st">"int"</span>, <span class="st">"factor"</span>, <span class="st">"factor"</span>, <span class="st">"num"</span>, <span class="st">"num"</span>]</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>var_trans <span class="op">=</span> [<span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span>, <span class="st">"log10"</span>, <span class="st">"log10"</span>]</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> SpotOptim(</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    fun<span class="op">=</span>your_objective_function,</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>bounds,</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>    var_type<span class="op">=</span>var_type,</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    var_trans<span class="op">=</span>var_trans,  <span class="co"># Automatic log-scale and factor handling!</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    n_initial<span class="op">=</span><span class="dv">10</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> opt.optimize()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Your objective function receives parameters in <strong>original scale</strong> - no manual transformations needed!</p>
</section>
<section id="future-directions" class="level2" data-number="26.5">
<h2 data-number="26.5" class="anchored" data-anchor-id="future-directions"><span class="header-section-number">26.5</span> Future Directions</h2>
<p>Consider exploring:</p>
<ol type="1">
<li><strong>Adaptive physics weights</strong> that change during training</li>
<li><strong>Architecture search</strong> including skip connections or residual blocks</li>
<li><strong>Batch size optimization</strong> as an additional hyperparameter</li>
<li><strong>Multi-objective optimization</strong> balancing accuracy and computational cost</li>
<li><strong>Transfer learning</strong> from pre-optimized configurations</li>
<li><strong>Learning rate schedules</strong> with different decay strategies</li>
</ol>
<hr>
<p><strong>Note</strong>: The specific optimal values depend on the problem, data distribution, and computational budget. Always validate results on held-out test data.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./pinns_1.html" class="pagination-link" aria-label="Physics-Informed Neural Networks (PINNs) Demo 1">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Physics-Informed Neural Networks (PINNs) Demo 1</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./acquisition_failure.html" class="pagination-link" aria-label="Acquisition Failure Handling in SpotOptim">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Acquisition Failure Handling in SpotOptim</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, T. Bartz-Beielstein</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/bartzbeielstein">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>