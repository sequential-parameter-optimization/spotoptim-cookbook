[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sequential Parameter Optimization Cookbook",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "002_awwe.html",
    "href": "002_awwe.html",
    "title": "1  Aircraft Wing Weight Example",
    "section": "",
    "text": "1.1 AWWE Equation\n\\[ W = 0.036 S_W^{0.758} \\times W_{fw}^{0.0035} \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times  q^{0.006}  \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49}\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-equation",
    "href": "002_awwe.html#awwe-equation",
    "title": "1  Aircraft Wing Weight Example",
    "section": "",
    "text": "Example from (Forr08a?)\nUnderstand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters:",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "href": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.2 AWWE Parameters and Equations (Part 1)",
    "text": "1.2 AWWE Parameters and Equations (Part 1)\n\n\n\nTable 1.1: Aircraft Wing Weight Parameters\n\n\n\n\n\n\n\n\n\n\n\n\nSymbol\nParameter\nBaseline\nMinimum\nMaximum\n\n\n\n\n\\(S_W\\)\nWing area (\\(ft^2\\))\n174\n150\n200\n\n\n\\(W_{fw}\\)\nWeight of fuel in wing (lb)\n252\n220\n300\n\n\n\\(A\\)\nAspect ratio\n7.52\n6\n10\n\n\n\\(\\Lambda\\)\nQuarter-chord sweep (deg)\n0\n-10\n10\n\n\n\\(q\\)\nDynamic pressure at cruise (\\(lb/ft^2\\))\n34\n16\n45\n\n\n\\(\\lambda\\)\nTaper ratio\n0.672\n0.5\n1\n\n\n\\(R_{tc}\\)\nAerofoil thickness to chord ratio\n0.12\n0.08\n0.18\n\n\n\\(N_z\\)\nUltimate load factor\n3.8\n2.5\n6\n\n\n\\(W_{dg}\\)\nFlight design gross weight (lb)\n2000\n1700\n2500\n\n\n\\(W_p\\)\npaint weight (lb/ft^2)\n0.064\n0.025\n0.08\n\n\n\n\n\n\nThe study begins with a baseline Cessna C172 Skyhawk Aircraft as its reference point. It aims to investigate the impact of wing area and fuel weight on the overall weight of the aircraft. Two crucial parameters in this analysis are the aspect ratio (\\(A\\)), defined as the ratio of the wing’s length to the average chord (thickness of the airfoil), and the taper ratio (\\(\\lambda\\)), which represents the ratio of the maximum to the minimum thickness of the airfoil or the maximum to minimum chord.\nIt’s important to note that the equation used in this context is not a computer simulation but will be treated as one for the purpose of illustration. This approach involves employing a true mathematical equation, even if it’s considered unknown, as a useful tool for generating realistic settings to test the methodology. The functional form of this equation was derived by “calibrating” known physical relationships to curves obtained from existing aircraft data, as referenced in (raym06a?). Essentially, it acts as a surrogate for actual measurements of aircraft weight.\nExamining the mathematical properties of the AWWE (Aircraft Weight With Wing Area and Fuel Weight Equation), it is evident that the response is highly nonlinear concerning its inputs. While it’s common to apply the logarithm to simplify equations with complex exponents, even when modeling the logarithm, which transforms powers into slope coefficients and products into sums, the response remains nonlinear due to the presence of trigonometric terms. Given the combination of nonlinearity and high input dimension, simple linear and quadratic response surface approximations are likely to be inadequate for this analysis.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#goals-understanding-and-optimization",
    "href": "002_awwe.html#goals-understanding-and-optimization",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.3 Goals: Understanding and Optimization",
    "text": "1.3 Goals: Understanding and Optimization\nThe primary goals of this study revolve around understanding and optimization:\n\nUnderstanding: One of the straightforward objectives is to gain a deep understanding of the input-output relationships in this context. Given the global perspective implied by this setting, it becomes evident that a more sophisticated model is almost necessary. At this stage, let’s focus on this specific scenario to establish a clear understanding.\nOptimization: Another application of this analysis could be optimization. There may be an interest in minimizing the weight of the aircraft, but it’s likely that there will be constraints in place. For example, the presence of wings with a nonzero area is essential for the aircraft to be capable of flying. In situations involving (constrained) optimization, a global perspective and, consequently, the use of flexible modeling are vital.\n\nThe provided Python code serves as a genuine computer implementation that “solves” a mathematical model. It accepts arguments encoded in the unit cube, with defaults used to represent baseline settings, as detailed in the table labeled as Table 1.1. To map values from the interval \\([a, b]\\) to the interval \\([0, 1]\\), the following formula can be employed:\n\\[\ny = f(x) = \\frac{x - a}{b - a}.\n\\tag{1.1}\\] To reverse this mapping and obtain the original values, the formula \\[\ng(y) = a + (b - a) y\n\\tag{1.2}\\] can be used. The function wingwt() expects inputs from the unit cube, which are then transformed back to their original scales using Equation 1.2. The function is defined as follows:\n\ndef wingwt(Sw=0.48, Wfw=0.4, A=0.38, L=0.5, q=0.62, l=0.344,  Rtc=0.4, Nz=0.37, Wdg=0.38):\n    # put coded inputs back on natural scale\n    Sw = Sw * (200 - 150) + 150 \n    Wfw = Wfw * (300 - 220) + 220 \n    A = A * (10 - 6) + 6 \n    L = (L * (10 - (-10)) - 10) * np.pi/180\n    q = q * (45 - 16) + 16 \n    l = l * (1 - 0.5) + 0.5  \n    Rtc = Rtc * (0.18 - 0.08) + 0.08\n    Nz = Nz * (6 - 2.5) + 2.5\n    Wdg = Wdg*(2500 - 1700) + 1700\n    # calculation on natural scale\n    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A/np.cos(L)**2)**0.6 * q**0.006 \n    W = W * l**0.04 * (100*Rtc/np.cos(L))**(-0.3) * (Nz*Wdg)**(0.49)\n    return(W)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#properties-of-the-python-solver",
    "href": "002_awwe.html#properties-of-the-python-solver",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.4 Properties of the Python “Solver”",
    "text": "1.4 Properties of the Python “Solver”\nThe compute time required by the “wingwt” solver is extremely short and can be considered trivial in terms of computational resources. The approximation error is exceptionally small, effectively approaching machine precision, which indicates the high accuracy of the solver’s results.\nTo simulate time-consuming evaluations, a deliberate delay is introduced by incorporating a sleep(3600) command, which effectively synthesizes a one-hour execution time for a particular evaluation.\nMoving on to the AWWE visualization, plotting in two dimensions is considerably simpler than dealing with nine dimensions. To aid in creating visual representations, the code provided below establishes a grid within the unit square to facilitate the generation of sliced visuals. This involves generating a “meshgrid” as outlined in the code.\n\nx = np.linspace(0, 1, 3)\ny = np.linspace(0, 1, 3)\nX, Y = np.meshgrid(x, y)\nzp = zip(np.ravel(X), np.ravel(Y))\nlist(zp)\n\n[(np.float64(0.0), np.float64(0.0)),\n (np.float64(0.5), np.float64(0.0)),\n (np.float64(1.0), np.float64(0.0)),\n (np.float64(0.0), np.float64(0.5)),\n (np.float64(0.5), np.float64(0.5)),\n (np.float64(1.0), np.float64(0.5)),\n (np.float64(0.0), np.float64(1.0)),\n (np.float64(0.5), np.float64(1.0)),\n (np.float64(1.0), np.float64(1.0))]\n\n\nThe coding used to transform inputs from natural units is largely a matter of taste, so long as it’s easy to undo for reporting back on original scales\n\n%matplotlib inline\n# plt.style.use('seaborn-white')\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 1, 100)\nX, Y = np.meshgrid(x, y)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "href": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))",
    "text": "1.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))\nWe will vary \\(N_z\\) and \\(A\\), with other inputs fixed at their baseline values.\n\nz = wingwt(A = X, Nz = Y)\nfig = plt.figure(figsize=(7., 5.))\nplt.contourf(X, Y, z, 20, cmap='jet')\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\nplt.title(\"Load factor (Nz) vs. Aspect Ratio (A)\")\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\nContour plots can be refined, e.g., by adding explicit contour lines as shown in the following figure.\n\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar()\n\n\n\n\n\n\n\n\nThe interpretation of the AWWE plot can be summarized as follows:\n\nThe figure displays the weight response as a function of two variables, \\(N_z\\) and \\(A\\), using an image-contour plot.\nThe slight curvature observed in the contours suggests an interaction between these two variables.\nNotably, the range of outputs depicted in the figure, spanning from approximately 160 to 320, nearly encompasses the entire range of outputs observed from various input settings within the full 9-dimensional input space.\nThe plot indicates that aircraft wings tend to be heavier when the aspect ratios (\\(A\\)) are high.\nThis observation aligns with the idea that wings are designed to withstand and accommodate high gravitational forces (\\(g\\)-forces, large \\(N_z\\)), and there may be a compounding effect where larger values of \\(N_z\\) contribute to increased wing weight.\nIt’s plausible that this phenomenon is related to the design considerations of fighter jets, which cannot have the efficient and lightweight glider-like wings typically found in other types of aircraft.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "href": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.6 Plot 2: Taper Ratio and Fuel Weight",
    "text": "1.6 Plot 2: Taper Ratio and Fuel Weight\n\nThe same experiment for two other inputs, e.g., taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\n\n\nz = wingwt(Wfw = X,  Nz = Y)\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"WfW\")\nplt.ylabel(\"l\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar();\n\n\n\n\n\n\n\n\n\nInterpretation of Taper Ratio (\\(l\\)) and Fuel Weight (\\(W_{fw}\\))\n\nApparently, neither input has much effect on wing weight:\n\nwith \\(\\lambda\\) having a marginally greater effect, covering less than 4 percent of the span of weights observed in the \\(A \\times N_z\\) plane\n\nThere’s no interaction evident in \\(\\lambda \\times W_{fw}\\)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#the-big-picture-combining-all-variables",
    "href": "002_awwe.html#the-big-picture-combining-all-variables",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.7 The Big Picture: Combining all Variables",
    "text": "1.7 The Big Picture: Combining all Variables\n\npl = [\"Sw\", \"Wfw\", \"A\", \"L\", \"q\", \"l\",  \"Rtc\", \"Nz\", \"Wdg\"]\n\n\nZ = []\nZlab = []\nl = len(pl)\n# lc = math.comb(l,2)\nfor i in range(l):\n    for j in range(i+1, l):\n    # for j in range(l):\n        # print(pl[i], pl[j])\n        d = {pl[i]: X, pl[j]: Y}\n        Z.append(wingwt(**d))\n        Zlab.append([pl[i],pl[j]])\n\nNow we can generate all 36 combinations, e.g., our first example is combination p = 19.\n\np = 19\nZlab[p]\n\n['A', 'Nz']\n\n\nTo help interpret outputs from experiments such as this one—to level the playing field when comparing outputs from other pairs of inputs—code below sets up a color palette that can be re-used from one experiment to the next. We use the arguments vmin=180 and vmax =360 to implement comparibility\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nLet’s plot the second example, taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\nThis is combination 11:\n\n\np = 11\nZlab[p]\n\n['Wfw', 'l']\n\n\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nUsing a global colormap indicates that these variables have minor effects on the wing weight.\nImportant factors can be detected by visual inspection\nPlotting the Big Picture: we can plot all 36 combinations in one figure.\n\n\nfig = plt.figure(figsize=(20., 20.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(6,6),  # creates 2x2 grid of axes\n                 axes_pad=0.5,  # pad between axes in inch.\n                 share_all=True,\n                 label_mode=\"all\",\n                 ) \ni = 0\nfor ax, im in zip(grid, Z):\n    # Iterating over the grid returns the Axes.\n    ax.set_xlabel(Zlab[i][0])\n    ax.set_ylabel(Zlab[i][1])\n    # ax.set_title(Zlab[i][1] + \" vs. \" + Zlab[i][0])\n    ax.contourf(X, Y, im, 30, cmap = \"jet\",  vmin = 180, vmax = 360)\n    i = i + 1\n       \nplt.show()",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-landscape",
    "href": "002_awwe.html#awwe-landscape",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.8 AWWE Landscape",
    "text": "1.8 AWWE Landscape\n\nOur Observations\n\nThe load factor \\(N_z\\), which determines the magnitude of the maximum aerodynamic load on the wing, is very active and involved in interactions with other variables.\n\n\nClassic example: the interaction of \\(N_z\\) with the aspect ratio \\(A\\) indicates a heavy wing for high aspect ratios and large \\(g\\)-forces\nThis is the reaon why highly manoeuvrable fighter jets cannot have very efficient, glider wings)\n\n\nAspect ratio \\(A\\) and airfoil thickness to chord ratio \\(R_{tc}\\) have nonlinear interactions.\nMost important variables:\n\n\nUltimate load factor \\(N_z\\), wing area \\(S_w\\), and flight design gross weight\\(W_{dg}\\).\n\n\nLittle impact: dynamic pressure \\(q\\), taper ratio \\(l\\), and quarter-chord sweep \\(L\\).\n\nExpert Knowledge\n\nAircraft designers know that the overall weight of the aircraft and the wing area must be kept to a minimum\nthe latter usually dictated by constraints such as required stall speed, landing distance, turn rate, etc.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#summary-of-the-first-experiments",
    "href": "002_awwe.html#summary-of-the-first-experiments",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.9 Summary of the First Experiments",
    "text": "1.9 Summary of the First Experiments\n\nFirst, we considered two pairs of inputs, out of 36 total pairs\nThen, the “Big Picture”:\n\nFor each pair we evaluated wingwt 10,000 times\n\nDoing the same for all pairs would require 360K evaluations:\n\nnot a reasonable number with a real computer simulation that takes any non-trivial amount of time to evaluate\nOnly 1s per evaluation: \\(&gt;100\\) hours\n\nMany solvers take minutes/hours/days to execute a single run\nAnd: three-way interactions?\nConsequence: a different strategy is needed",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#exercise",
    "href": "002_awwe.html#exercise",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.10 Exercise",
    "text": "1.10 Exercise\n\n1.10.1 Adding Paint Weight\n\nPaint weight is not considered.\nAdd Paint Weight \\(W_p\\) to formula (the updated formula is shown below) and update the functions and plots in the notebook.\n\n\\[ W = 0.036S_W^{0.758} \\times W_{fw}^{0.0035} \\times \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times q^{0.006} \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49} + S_w W_p\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#jupyter-notebook",
    "href": "002_awwe.html#jupyter-notebook",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.11 Jupyter Notebook",
    "text": "1.11 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html",
    "href": "001_surrogate.html",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "",
    "text": "2.1 Surrogates",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#surrogates",
    "href": "001_surrogate.html#surrogates",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "",
    "text": "Gathering data is expensive, and sometimes getting exactly the data you want is impossible or unethical\nSurrogate: substitute for the real thing\nIn statistics, draws from predictive equations derived from a fitted model can act as a surrogate for the data-generating mechanism\nBenefits of the surrogate approach:\n\nSurrogate could represent a cheaper way to explore relationships, and entertain “what ifs?”\nSurrogates favor faithful yet pragmatic reproduction of dynamics:\n\ninterpretation,\nestablishing causality, or\nidentification\n\nMany numerical simulators are deterministic, whereas field observations are noisy or have measurement error\n\n\n\n2.1.1 Costs of Simulation\n\nComputer simulations are generally cheaper (but not always!) than physical observation\nSome computer simulations can be just as expensive as field experimentation, but computer modeling is regarded as easier because:\n\nthe experimental apparatus is better understood\nmore aspects may be controlled.\n\n\n\n\n2.1.2 Mathematical Models and Meta-Models\n\nUse of mathematical models leveraging numerical solvers has been commonplace for some time\nMathematical models became more complex, requiring more resources to simulate/solve numerically\nPractitioners increasingly relied on meta-models built off of limited simulation campaigns\n\n\n\n2.1.3 Surrogates = Trained Meta-models\n\nData collected via expensive computer evaluations tuned flexible functional forms that could be used in lieu of further simulation to\n\nsave money or computational resources;\ncope with an inability to perform future runs (expired licenses, off-line or over-impacted supercomputers)\n\nTrained meta-models became known as surrogates\n\n\n\n2.1.4 Computer Experiments\n\nComputer experiment: design, running, and fitting meta-models.\n\nLike an ordinary statistical experiment, except the data are generated by computer codes rather than physical or field observations, or surveys\n\nSurrogate modeling is statistical modeling of computer experiments\n\n\n\n2.1.5 Limits of Mathematical Modeling\n\nMathematical biologists, economists and others had reached the limit of equilibrium-based mathematical modeling with cute closed-form solutions\nStochastic simulations replace deterministic solvers based on FEM, Navier–Stokes or Euler methods\nAgent-based simulation models are used to explore predator-prey (Lotka–Voltera) dynamics, spread of disease, management of inventory or patients in health insurance markets\nConsequence: the distinction between surrogate and statistical model is all but gone\n\n\n\n2.1.6 Why Computer Simulations are Necessary\n\nYou can’t seed a real community with Ebola and watch what happens\nIf there’s (real) field data, say on a historical epidemic, further experimentation may be almost entirely limited to the mathematical and computer modeling side\nClassical statistical methods offer little guidance\n\n\n\n2.1.7 Simulation Requirements\n\nSimulation should\n\nenable rich diagnostics to help criticize that models\nunderstanding its sensitivity to inputs and other configurations\nproviding the ability to optimize and\nrefine both automatically and with expert intervention\n\nAnd it has to do all that while remaining computationally tractable\nOne perspective is so-called response surface methods (RSMs):\na poster child from industrial statistics’ heyday, well before information technology became a dominant industry",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#applications-of-surrogate-models",
    "href": "001_surrogate.html#applications-of-surrogate-models",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "2.2 Applications of Surrogate Models",
    "text": "2.2 Applications of Surrogate Models\nThe four most common usages of surrogate models are:\n\nAugmenting Expensive Simulations: Surrogate models act as a ‘curve fit’ to approximate the results of expensive simulation codes, enabling predictions without rerunning the primary source. This provides significant speed improvements while maintaining useful accuracy.\nCalibration of Predictive Codes: Surrogates bridge the gap between simpler, faster but less accurate models and more accurate, slower models. This multi-fidelity approach allows for improved accuracy without the full computational expense.\nHandling Noisy or Missing Data: Surrogates smooth out random or systematic errors in experimental or computational data, filling gaps and revealing overall trends while filtering out extraneous details.\nData Mining and Insight Generation: Surrogates help identify functional relationships between variables and their impact on results. They enable engineers to focus on critical variables and visualize data trends effectively.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#dace-and-rsm",
    "href": "001_surrogate.html#dace-and-rsm",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "2.3 DACE and RSM",
    "text": "2.3 DACE and RSM\nMathematical models implemented in computer codes are used to circumvent the need for expensive field data collection. These models are particularly useful when dealing with highly nonlinear response surfaces, high signal-to-noise ratios (which often involve deterministic evaluations), and a global scope. As a result, a new approach is required in comparison to Response Surface Methodology (RSM), which is discussed in Section 5.1.\nWith the improvement in computing power and simulation fidelity, researchers gain higher confidence and a better understanding of the dynamics in physical, biological, and social systems. However, the expansion of configuration spaces and increasing input dimensions necessitates more extensive designs. High-performance computing (HPC) allows for thousands of runs, whereas previously only tens were possible. This shift towards larger models and training data presents new computational challenges.\nResearch questions for DACE (Design and Analysis of Computer Experiments) include how to design computer experiments that make efficient use of computation and how to meta-model computer codes to save on simulation effort. The choice of surrogate model for computer codes significantly impacts the optimal experiment design, and the preferred model-design pairs can vary depending on the specific goal.\nThe combination of computer simulation, design, and modeling with field data from similar real-world experiments introduces a new category of computer model tuning problems. The ultimate goal is to automate these processes to the greatest extent possible, allowing for the deployment of HPC with minimal human intervention.\nOne of the remaining differences between RSM and DACE lies in how they handle noise. DACE employs replication, a technique that would not be used in a deterministic setting, to separate signal from noise. Traditional RSM is best suited for situations where a substantial proportion of the variability in the data is due to noise, and where the acquisition of data values can be severely limited. Consequently, RSM is better suited for a different class of problems, aligning with its intended purposes.\nTwo very good texts on computer experiments and surrogate modeling are (Sant03a?) and (Forr08a?). The former is the canonical reference in the statistics literature and the latter is perhaps more popular in engineering.\n\nExample 2.1 (Example: DACE and RSM) Imagine you are a chemical engineer tasked with optimizing a chemical process to maximize yield. You can control temperature and pressure, but repeated experiments show variability in yield due to inconsistencies in raw materials.\n\nUsing RSM: You would use RSM to design a series of experiments varying temperature and pressure. You would then fit a response surface (a mathematical model) to the data, helping you understand how changes in temperature and pressure affect yield. Using this model, you can identify optimal conditions for maximizing yield despite the noise.\nUsing DACE: If instead you use a computational model to simulate the chemical process and want to account for numerical noise or uncertainty in model parameters, you might use DACE. You would run simulations at different conditions, possibly repeating them to assess variability and build a surrogate model that accurately predicts yields, which can be optimized to find the best conditions.\n\n\n\n2.3.1 Noise Handling in RSM and DACE\nNoise in RSM: In experimental settings, noise often arises due to variability in experimental conditions, measurement errors, or other uncontrollable factors. This noise can significantly affect the response variable, \\(Y\\). Replication is a standard procedure for handling noise in RSM. In the context of computer experiments, noise might not be present in the traditional sense since simulations can be deterministic. However, variability can arise from uncertainty in input parameters or model inaccuracies. DACE predominantly utilizes advanced interpolation to construct accurate models of deterministic data, sometimes considering statistical noise modeling if needed.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#updating-a-surrogate-model",
    "href": "001_surrogate.html#updating-a-surrogate-model",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "2.4 Updating a Surrogate Model",
    "text": "2.4 Updating a Surrogate Model\nA surrogate model is updated by incorporating new data points, known as infill points, into the model to improve its accuracy and predictive capabilities. This process is iterative and involves the following steps:\n\nIdentify Regions of Interest: The surrogate model is analyzed to determine areas where it is inaccurate or where further exploration is needed. This could be regions with high uncertainty or areas where the model predicts promising results (e.g., potential optima).\nSelect Infill Points: Infill points are new data points chosen based on specific criteria, such as:\nExploitation: Sampling near predicted optima to refine the solution. Exploration: Sampling in regions of high uncertainty to improve the model globally. Balanced Approach: Combining exploitation and exploration to ensure both local and global improvements.\nEvaluate the True Function: The true function (e.g., a simulation or experiment) is evaluated at the selected infill points to obtain their corresponding outputs.\nUpdate the Surrogate Model: The surrogate model is retrained or updated using the new data, including the infill points, to improve its accuracy.\nRepeat: The process is repeated until the model meets predefined accuracy criteria or the computational budget is exhausted.\n\n\nDefinition 2.1 (Infill Points) Infill points are strategically chosen new data points added to the surrogate model. They are selected to:\n\nReduce uncertainty in the model.\nImprove predictions in regions of interest.\nEnhance the model’s ability to identify optima or trends.\n\n\nThe selection of infill points is often guided by infill criteria, such as:\n\nExpected Improvement (EI): Maximizing the expected improvement over the current best solution.\nUncertainty Reduction: Sampling where the model’s predictions have high variance.\nProbability of Improvement (PI): Sampling where the probability of improving the current best solution is highest.\n\nThe iterative infill-points updating process ensures that the surrogate model becomes increasingly accurate and useful for optimization or decision-making tasks.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_sampling.html",
    "href": "001_sampling.html",
    "title": "3  Sampling Plans",
    "section": "",
    "text": "3.1 Ideas and Concepts\nThe goal of a sampling plan is to efficiently explore the input space to understand the behavior of the computer code and build a surrogate model that accurately represents the code’s behavior. Traditionally, Response Surface Methodology (RSM) has been used to design sampling plans for computer experiments. These sampling plans are based on procedures that generate points by means of a rectangular grid or a factorial design.\nHowever, more recently, Design and Analysis of Computer Experiments (DACE) has emerged as a more flexible and powerful approach for designing sampling plans.\nEngineering design often requires the construction of a surrogate model \\(\\hat{f}\\) to approximate the expensive response of a black-box function \\(f\\). The function \\(f(x)\\) represents a continuous metric (e.g., quality, cost, or performance) defined over a design space \\(D \\subset \\mathbb{R}^k\\), where \\(x\\) is a \\(k\\)-dimensional vector of design variables. Since evaluating \\(f\\) is costly, only a sparse set of samples is used to construct \\(\\hat{f}\\), which can then provide inexpensive predictions for any \\(x \\in D\\).\nThe process involves:\nA sampling plan\n\\[\nX =\n\\left\\{\n  x^{(i)} \\in D | i = 1, \\ldots, n\n\\right\\}\n\\]\ndetermines the spatial arrangement of observations. While some models require a minimum number of data points \\(n\\), once this threshold is met, a surrogate model can be constructed to approximate \\(f\\) efficiently.\nA well-posed model does not always perform well because its ability to generalize depends heavily on the sampling plan used to collect data. If the sampling plan is poorly designed, the model may fail to capture critical behaviors in the design space. For example:",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#ideas-and-concepts",
    "href": "001_sampling.html#ideas-and-concepts",
    "title": "3  Sampling Plans",
    "section": "",
    "text": "Definition 3.1 (Sampling Plan) In the context of computer experiments, the term sampling plan refers to the set of input values, say \\(X\\),at which the computer code is evaluated.\n\n\n\n\n\n\nSampling discrete observations:\nUsing these samples to construct an approximation \\(\\hat{f}\\).\nEnsuring the surrogate model is well-posed, meaning it is mathematically valid and can generalize predictions effectively.\n\n\n\n\n\n\nExtreme Sampling: Measuring performance only at the extreme values of parameters may miss important behaviors in the center of the design space, leading to incomplete understanding.\nUneven Sampling: Concentrating samples in certain regions while neglecting others forces the model to extrapolate over unsampled areas, potentially resulting in inaccurate or misleading predictions. Additionally, in some cases, the data may come from external sources or be limited in scope, leaving little control over the sampling plan. This can further restrict the model’s ability to generalize effectively.\n\n\n3.1.1 The ‘Curse of Dimensionality’ and How to Avoid It\nThe “curse of dimensionality” refers to the exponential increase in computational complexity and data requirements as the number of dimensions (variables) in a problem grows. For a one-dimensional space, sampling \\(n\\) locations may suffice for accurate predictions. In high-dimensional spaces, the amount of data needed to maintain the same level of accuracy or coverage increases dramatically. For example, if a one-dimensional space requires \\(n\\) samples for a certain accuracy, a \\(k\\)-dimensional space would require \\(n^k\\) samples. This makes tasks like optimization, sampling, and modeling computationally expensive and often impractical in high-dimensional settings.\n\nExample 3.1 (Example: Curse of Dimensionality) Consider a simple example where we want to model the cost of a car tire based on its wheel diameter. If we have one variable (wheel diameter), we might need 10 simulations to get a good estimate of the cost. Now, if we add 8 more variables (e.g., tread pattern, rubber type, etc.), the number of simulations required increases to \\(10^8\\) (10 million). This is because the number of combinations of design variables grows exponentially with the number of dimensions. This means that the computational budget required to evaluate all combinations of design variables becomes infeasible. In this case, it would take 11,416 years to complete the simulations, making it impractical to explore the design space fully.\n\n\n\n3.1.2 Physical versus Computational Experiments\nPhysical experiments are prone to experimental errors from three main sources:\n\nHuman error: Mistakes made by the experimenter.\nRandom error: Measurement inaccuracies that vary unpredictably.\nSystematic error: Consistent bias due to flaws in the experimental setup.\n\nThe key distinction is repeatability: systematic errors remain constant across repetitions, while random errors vary.\nComputational experiments, on the other hand, are deterministic and free from random errors. However, they are still affected by:\n\nHuman error: Bugs in code or incorrect boundary conditions.\nSystematic error: Biases from model simplifications (e.g., inviscid flow approximations) or finite resolution (e.g., insufficient mesh resolution).\n\nThe term “noise” is used differently in physical and computational contexts. In physical experiments, it refers to random errors, while in computational experiments, it often refers to systematic errors.\nUnderstanding these differences is crucial for designing experiments and applying techniques like Gaussian process-based approximations. For physical experiments, replication mitigates random errors, but this is unnecessary for deterministic computational experiments.\n\n\n3.1.3 Designing Preliminary Experiments (Screening)\nMinimizing the number of design variables \\(x_1, x_2, \\dots, x_k\\) is crucial before modeling the objective function \\(f\\). This process, called screening, aims to reduce dimensionality without compromising the analysis. If \\(f\\) is at least once differentiable over the design domain \\(D\\), the partial derivative \\(\\frac{\\partial f}{\\partial x_i}\\) can be used to classify variables:\n\nNegligible Variables: If \\(\\frac{\\partial f}{\\partial x_i} = 0, \\, \\forall x \\in D\\), the variable \\(x_i\\) can be safely neglected.\nLinear Additive Variables: If \\(\\frac{\\partial f}{\\partial x_i} = \\text{constant} \\neq 0, \\, \\forall x \\in D\\), the effect of \\(x_i\\) is linear and additive.\nNonlinear Variables: If \\(\\frac{\\partial f}{\\partial x_i} = g(x_i), \\, \\forall x \\in D\\), where \\(g(x_i)\\) is a non-constant function, \\(f\\) is nonlinear in \\(x_i\\).\nInteractive Nonlinear Variables: If \\(\\frac{\\partial f}{\\partial x_i} = g(x_i, x_j, \\dots), /, \\forall x \\in D\\), where \\(g(x_i, x_j, \\dots)\\) is a function involving interactions with other variables, \\(f\\) is nonlinear in \\(x_i\\) and interacts with \\(x_j\\).\n\nMeasuring \\(\\frac{\\partial f}{\\partial x_i}\\) across the entire design space is often infeasible due to limited budgets. The percentage of time allocated to screening depends on the problem: If many variables are expected to be inactive, thorough screening can significantly improve model accuracy by reducing dimensionality. If most variables are believed to impact the objective, focus should shift to modeling instead. Screening is a trade-off between computational cost and model accuracy, and its effectiveness depends on the specific problem context.\n\n3.1.3.1 Estimating the Distribution of Elementary Effects\nIn order to simplify the presentation of what follows, we make, without loss of generality, the assumption that the design space \\(D = [0, 1]^k\\); that is, we normalize all variables into the unit cube. We shall adhere to this convention for the rest of the book and strongly urge the reader to do likewise when implementing any algorithms described here, as this step not only yields clearer mathematics in some cases but also safeguards against scaling issues.\nBefore proceeding with the description of the Morris algorithm, we need to define an important statistical concept. Let us restrict our design space \\(D\\) to a \\(k\\)-dimensional, \\(p\\)-level full factorial grid, that is,\n\\[\nx_i \\in \\{0, \\frac{1}{p-1}, \\frac{2}{p-1}, \\dots, 1\\}, \\quad \\text{ for } i = 1, \\dots, k.\n\\]\n\nDefinition 3.2 (Elementary Effect) For a given baseline value \\(x \\in D\\), let \\(d_i(x)\\) denote the elementary effect of \\(x_i\\), where:\n\\[\nd_i(x) = \\frac{f(x_1, \\dots, x_i + \\Delta, \\dots, x_k) - f(x_1, \\dots, x_i - \\Delta, \\dots, x_k)}{2\\Delta}, \\quad i = 1, \\dots, k,\n\\tag{3.1}\\] where \\(\\Delta\\) is the step size, which is defined as the distance between two adjacent levels in the grid. In other words, we have:\nwith \\[\\Delta = \\frac{\\xi}{p-1}, \\quad \\xi \\in \\mathbb{N}^*, \\quad \\text{and} \\quad x \\in D , \\text{ such that its components } x_i \\leq 1 - \\Delta.\n\\]\n\\(\\Delta\\) is the step size. The elementary effect \\(d_i(x)\\) measures the sensitivity of the function \\(f\\) to changes in the variable \\(x_i\\) at the point \\(x\\).\n\nMorris’s method aims to estimate the parameters of the distribution of elementary effects associated with each variable. A large measure of central tendency indicates that a variable has a significant influence on the objective function across the design space, while a large measure of spread suggests that the variable is involved in interactions or contributes to the nonlinearity of \\(f\\). In practice, the sample mean and standard deviation of a set of \\(d_i(x)\\) values, calculated in different parts of the design space, are used for this estimation.\nTo ensure efficiency, the preliminary sampling plan \\(X\\) should be designed so that each evaluation of the objective function \\(f\\) contributes to the calculation of two elementary effects, rather than just one (as would occur with a naive random spread of baseline \\(x\\) values and adding \\(\\Delta\\) to one variable). Additionally, the sampling plan should provide a specified number (e.g., \\(r\\)) of elementary effects for each variable, independently drawn with replacement. For a detailed discussion on constructing such a sampling plan, readers are encouraged to consult Morris’s original paper (Morris, 1991). Here, we focus on describing the process itself.\nThe random orientation of the sampling plan \\(B\\) can be constructed as follows:\n\nLet \\(B\\) be a \\((k+1) \\times k\\) matrix of 0s and 1s, where for each column \\(i\\), two rows differ only in their \\(i\\)-th entries.\nCompute a random orientation of \\(B\\), denoted \\(B^*\\):\n\n\\[\nB^* =\n\\left(\n1_{k+1,k} x^* + (\\Delta/2)\n\\left[\n(2B-1_{k+1,k})\nD^* +\n1_{k+1,k}\n\\right]\n\\right)\nP^*,\n\\]\nwhere:\n\n\\(D^*\\) is a \\(k\\)-dimensional diagonal matrix with diagonal elements \\(\\pm 1\\) (equal probability),\n\\(\\mathbf{1}\\) is a matrix of 1s,\n\\(x^*\\) is a randomly chosen point in the \\(p\\)-level design space (limited by \\(\\Delta\\)),\n\\(P^*\\) is a \\(k \\times k\\) random permutation matrix with one 1 per column and row.\n\nspotpython provides a Python implementation to compute \\(B^*\\), see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/effects.py.\nHere is the corresponding code:\n\ndef randorient(k, p, xi, seed=None):\n    # Initialize random number generator with the provided seed\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    else:\n        rng = np.random.default_rng()\n\n    # Step length\n    Delta = xi / (p - 1)\n\n    m = k + 1\n\n    # A truncated p-level grid in one dimension\n    xs = np.arange(0, 1 - Delta, 1 / (p - 1))\n    xsl = len(xs)\n    if xsl &lt; 1:\n        print(f\"xi = {xi}.\")\n        print(f\"p = {p}.\")\n        print(f\"Delta = {Delta}.\")\n        print(f\"p - 1 = {p - 1}.\")\n        raise ValueError(f\"The number of levels xsl is {xsl}, but it must be greater than 0.\")\n\n    # Basic sampling matrix\n    B = np.vstack((np.zeros((1, k)), np.tril(np.ones((k, k)))))\n\n    # Randomization\n\n    # Matrix with +1s and -1s on the diagonal with equal probability\n    Dstar = np.diag(2 * rng.integers(0, 2, size=k) - 1)\n\n    # Random base value\n    xstar = xs[rng.integers(0, xsl, size=k)]\n\n    # Permutation matrix\n    Pstar = np.zeros((k, k))\n    rp = rng.permutation(k)\n    for i in range(k):\n        Pstar[i, rp[i]] = 1\n\n    # A random orientation of the sampling matrix\n    Bstar = (np.ones((m, 1)) @ xstar.reshape(1, -1) +\n        (Delta / 2) * ((2 * B - np.ones((m, k))) @ Dstar +\n        np.ones((m, k)))) @ Pstar\n\n    return Bstar\n\nThe code following snippet generates a random orientation of a sampling matrix Bstar using the randorient() function. The input parameters are:\n\nk = 3: The number of design variables (dimensions).\np = 3: The number of levels in the grid for each variable.\nxi = 1: A parameter used to calculate the step size Delta.\n\nStep-size calculation is performed as follows: Delta = xi / (p - 1) = 1 / (3 - 1) = 0.5, which determines the spacing between levels in the grid.\nNext, random sampling matrix construction is computed:\n\nA truncated grid is created with levels [0, 0.5] (based on Delta).\nA basic sampling matrix B is constructed, which is a lower triangular matrix with 0s and 1s.\n\nThen, randomization is applied:\n\nDstar: A diagonal matrix with random entries of +1 or -1.\nxstar: A random starting point from the grid.\nPstar: A random permutation matrix.\n\nRandom orientation is applied to the basic sampling matrix B to create Bstar. This involves scaling, shifting, and permuting the rows and columns of B.\nThe final output is the matrix Bstar, which represents a random orientation of the sampling plan. Each row corresponds to a sampled point in the design space, and each column corresponds to a design variable.\n\nExample 3.2 (Random Orientation of the Sampling Matrix in 2-D)  \n\nk = 2\np = 3\nxi = 1\nBstar = randorient(k, p, xi, seed=123)\nprint(f\"Random orientation of the sampling matrix:\\n{Bstar}\")\n\nRandom orientation of the sampling matrix:\n[[0.5 0. ]\n [0.  0. ]\n [0.  0.5]]\n\n\nWe can visualize the random orientation of the sampling matrix in 2-D as shown in Figure 3.1.\n\nplt.figure(figsize=(6, 6))\nplt.scatter(Bstar[:, 0], Bstar[:, 1], color='blue', s=50, label='Hypercube Points')\nfor i in range(Bstar.shape[0]):\n    plt.text(Bstar[i, 0] + 0.01, Bstar[i, 1] + 0.01, str(i), fontsize=9)\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.grid()\n\n\n\n\n\n\n\nFigure 3.1: Random orientation of the sampling matrix in 2-D. The labels indicate the row index of the points.\n\n\n\n\n\n\n\nExample 3.3 (Random Orientation of the Sampling Matrix)  \n\nk = 3\np = 3\nxi = 1\nBstar = randorient(k, p, xi)\nprint(f\"Random orientation of the sampling matrix:\\n{Bstar}\")\n\nRandom orientation of the sampling matrix:\n[[0.5 0.  0. ]\n [0.5 0.5 0. ]\n [0.  0.5 0. ]\n [0.  0.5 0.5]]\n\n\n\nTo obtain \\(r\\) elementary effects for each variable, the screening plan is built from \\(r\\) random orientations:\n\\[\nX =\n\\begin{pmatrix}\nB^*_1 \\\\\nB^*_2 \\\\\n\\vdots \\\\\nB^*_r\n\\end{pmatrix}\n\\]\nThe function screeningplan() generates a screening plan by calling the randorient() function r times. It creates a list of random orientations and then concatenates them into a single array, which represents the screening plan. The screening plan implementation in Python is as follows (see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/effects.py):\n\ndef screeningplan(k, p, xi, r):\n    # Empty list to accumulate screening plan rows\n    X = []\n    for i in range(r):\n        X.append(randorient(k, p, xi))\n    # Concatenate list of arrays into a single array\n    X = np.vstack(X)\n    return X\n\nIt works like follows:\n\nThe value of the objective function \\(f\\) is computed for each row of the screening plan matrix \\(X\\). These values are stored in a column vector \\(t\\) of size \\((r * (k + 1)) \\times 1\\), where:\n\nr is the number of random orientations.\nk is the number of design variables.\n\n\nThe elementary effects are calculated using the following formula:\n\nFor each random orientation, adjacent rows of the screening plan matrix X and their corresponding function values from t are used.\nThese values are inserted into Equation 3.1 to compute elementary effects for each variable. An elementary effect measures the sensitivity of the objective function to changes in a specific variable.\n\nResults can be used for a statistical analysis. After collecting a sample of \\(r\\) elementary effects for each variable:\n\nThe sample mean (central tendency) is computed to indicate the overall influence of the variable.\nThe sample standard deviation (spread) is computed to capture variability, which may indicate interactions or nonlinearity.\n\nThe results (sample means and standard deviations) are plotted on a chart for comparison. This helps identify which variables have the most significant impact on the objective function and whether their effects are linear or involve interactions. This is implemented in the function screening_plot() in Python, which uses the helper function _screening() to calculate the elementary effects and their statistics.\n\ndef _screening(X, fun, xi, p, labels, bounds=None) -&gt; tuple:\n    \"\"\"Helper function to calculate elementary effects for a screening design.\n\n    Args:\n        X (np.ndarray): The screening plan matrix, typically structured\n            within a [0,1]^k box.\n        fun (object): The objective function to evaluate at each\n            design point in the screening plan.\n        xi (float): The elementary effect step length factor.\n        p (int): Number of discrete levels along each dimension.\n        labels (list of str): A list of variable names corresponding to\n            the design variables.\n        bounds (np.ndarray): A 2xk matrix where the first row contains\n            lower bounds and the second row contains upper bounds for\n            each variable.\n\n    Returns:\n        tuple: A tuple containing two arrays:\n            - sm: The mean of the elementary effects for each variable.\n            - ssd: The standard deviation of the elementary effects for\n            each variable.\n    \"\"\"\n    k = X.shape[1]\n    r = X.shape[0] // (k + 1)\n\n    # Scale each design point\n    t = np.zeros(X.shape[0])\n    for i in range(X.shape[0]):\n        if bounds is not None:\n            X[i, :] = bounds[0, :] + X[i, :] * (bounds[1, :] - bounds[0, :])\n        t[i] = fun(X[i, :])\n\n    # Elementary effects\n    F = np.zeros((k, r))\n    for i in range(r):\n        for j in range(i * (k + 1), i * (k + 1) + k):\n            idx = np.where(X[j, :] - X[j + 1, :] != 0)[0][0]\n            F[idx, i] = (t[j + 1] - t[j]) / (xi / (p - 1))\n\n    # Statistical measures (divide by n)\n    ssd = np.std(F, axis=1, ddof=0)\n    sm = np.mean(F, axis=1)\n    return sm, ssd\n\n\ndef screening_plot(X, fun, xi, p, labels, bounds=None, show=True) -&gt; None:\n    \"\"\"Generates a plot with elementary effect screening metrics.\n\n    This function calculates the mean and standard deviation of the\n    elementary effects for a given set of design variables and plots\n    the results.\n\n    Args:\n        X (np.ndarray):\n            The screening plan matrix, typically structured within a [0,1]^k box.\n        fun (object):\n            The objective function to evaluate at each design point in the screening plan.\n        xi (float):\n            The elementary effect step length factor.\n        p (int):\n            Number of discrete levels along each dimension.\n        labels (list of str):\n            A list of variable names corresponding to the design variables.\n        bounds (np.ndarray):\n            A 2xk matrix where the first row contains lower bounds and\n            the second row contains upper bounds for each variable.\n        show (bool):\n            If True, the plot is displayed. Defaults to True.\n\n    Returns:\n        None: The function generates a plot of the results.\n    \"\"\"\n    k = X.shape[1]\n    sm, ssd = _screening(X=X, fun=fun, xi=xi, p=p, labels=labels, bounds=bounds)\n    plt.figure()\n    for i in range(k):\n        plt.text(sm[i], ssd[i], labels[i], fontsize=10)\n    plt.axis([min(sm), 1.1 * max(sm), min(ssd), 1.1 * max(ssd)])\n    plt.xlabel(\"Sample means\")\n    plt.ylabel(\"Sample standard deviations\")\n    plt.gca().tick_params(labelsize=10)\n    plt.grid(True)\n    if show:\n        plt.show()\n\n\n\n\n3.1.4 Special Considerations When Deploying Screening Algorithms\nWhen implementing the screening algorithm described above, two specific scenarios require special attention:\n\nDuplicate Design Points: If the dimensionality \\(k\\) of the space is relatively low and you can afford a large number of elementary effects \\(r\\), we should be be aware of the increased probability of duplicate design points appearing in the sampling plan \\(X\\). *Since the responses at sample points are deterministic, there’s no value in evaluating the same point multiple times. Fortunately, this issue is relatively uncommon in practice, as screening high-dimensional spaces typically requires large numbers of elementary effects, which naturally reduces the likelihood of duplicates.\nFailed Simulations: Numerical simulation codes occasionally fail to return valid results due to meshing errors, non-convergence of partial differential equation solvers, numerical instabilities, or parameter combinations outside the stable operating range.\n\nFrom a screening perspective, this is particularly problematic because an entire random orientation \\(B^*\\) becomes compromised if even a single point within it fails to evaluate properly. Implementing error handling strategies or fallback methods to manage such cases should be considered.\nFor robust screening studies, monitoring simulation success rates and having contingency plans for failed evaluations are important aspects of the experimental design process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#analyzing-variable-importance-in-aircraft-wing-weight",
    "href": "001_sampling.html#analyzing-variable-importance-in-aircraft-wing-weight",
    "title": "3  Sampling Plans",
    "section": "3.2 Analyzing Variable Importance in Aircraft Wing Weight",
    "text": "3.2 Analyzing Variable Importance in Aircraft Wing Weight\nLet us consider the following analytical expression used as a conceptual level estimate of the weight of a light aircraft wing as discussed in Chapter 1.\n\nfun = Analytical()\nk = 10\np = 10\nxi = 1\nr = 25\nX = screeningplan(k=k, p=p, xi=xi, r=r)  # shape (r x (k+1), k)\nvalue_range = np.array([\n    [150, 220,   6, -10, 16, 0.5, 0.08, 2.5, 1700, 0.025],\n    [200, 300,  10,  10, 45, 1.0, 0.18, 6.0, 2500, 0.08 ],\n])\nlabels = [\n    \"S_W\", \"W_fw\", \"A\", \"Lambda\",\n    \"q\",   \"lambda\", \"tc\", \"N_z\",\n    \"W_dg\", \"W_p\"\n]\nscreening_plot(\n    X=X,\n    fun=fun.fun_wingwt,\n    bounds=value_range,\n    xi=xi,\n    p=p,\n    labels=labels,\n)\n\n\n\n\n\n\n\nFigure 3.2: Estimated means and standard deviations of the elementary effects for the 10 design variables of the wing weight function. Example based on (Forr08a?).\n\n\n\n\n\n\n\n\n\n\n\nNoteNondeterministic Results\n\n\n\nThe code will generate a slightly different screening plan each time, as it uses random orientations of the sampling matrix \\(B\\).\n\n\nFigure 3.2 provides valuable insights into variable activity without requiring domain expertise. The screening study with \\(r = 25\\) elementary effects reveals distinct patterns in how variables affect wing weight:\n\nVariables with Minimal Impact: A clearly defined group of variables clusters around the origin - indicating their minimal impact on wing weight:\n\nPaint weight (\\(W_p\\)) - as expected, contributes little to overall wing weight\nDynamic pressure (\\(q\\)) - within our chosen range, this has limited effect (essentially representing different cruise altitudes at the same speed)\nTaper ratio (\\(\\lambda\\)) and quarter-chord sweep (\\(\\Lambda\\)) - these geometric parameters have minor influence within the narrow range (-10° to 10°) typical of light aircraft\n\nVariables with Linear Effects:\n\nWhile still close to the origin, fuel weight (\\(W_{fw}\\)) shows a slightly larger central tendency with very low standard deviation. This indicates moderate importance but minimal involvement in interactions with other variables.\n\nVariables with Nonlinear/Interactive Effects:\n\nAspect ratio (\\(A\\)) and airfoil thickness ratio (\\(R_{tc}\\)) show similar importance levels, but their high standard deviations suggest significant nonlinear behavior and interactions with other variables.\n\nDominant Variables: The most significant impacts come from:\n\nFlight design gross weight (\\(W_{dg}\\))\nWing area (\\(S_W\\))\nUltimate load factor (\\(N_z\\))\n\n\nThese variables show both large central tendency values and high standard deviations, indicating strong direct effects and complex interactions. The interaction between aspect ratio and load factor is particularly important - high values of both create extremely heavy wings, explaining why highly maneuverable fighter jets cannot use glider-like wing designs.\nWhat makes this screening approach valuable is its ability to identify critical variables without requiring engineering knowledge or expensive modeling. In real-world applications, we rarely have the luxury of creating comprehensive parameter space visualizations, which is precisely why surrogate modeling is needed. After identifying the active variables through screening, we can design a focused sampling plan for these key variables. This forms the foundation for building an accurate surrogate model of the objective function.\nWhen the objective function is particularly expensive to evaluate, we might recycle the runs performed during screening for the actual model fitting step. This is most effective when some variables prove to have no impact at all. However, since completely inactive variables are rare in practice, engineers must carefully balance the trade-off between reusing expensive simulation runs and introducing potential noise into the model.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#designing-a-sampling-plan",
    "href": "001_sampling.html#designing-a-sampling-plan",
    "title": "3  Sampling Plans",
    "section": "3.3 Designing a Sampling Plan",
    "text": "3.3 Designing a Sampling Plan\n\n3.3.1 Stratification\nA feature shared by all of the approximation models discussed in (Forr08a?) is that they are more accurate in the vicinity of the points where we have evaluated the objective function. In later chapters we will delve into the laws that quantify our decaying trust in the model as we move away from a known, sampled point, but for the purposes of the present discussion we shall merely draw the intuitive conclusion that a uniform level of model accuracy throughout the design space requires a uniform spread of points. A sampling plan possessing this feature is said to be space-filling.\nThe most straightforward way of sampling a design space in a uniform fashion is by means of a rectangular grid of points. This is the full factorial sampling technique.\nHere is the simplified version of a Python function that will sample the unit hypercube at all levels in all dimensions, with the \\(k\\)-vector \\(q\\) containing the number of points required along each dimension, see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/sampling.py.\nThe variable Edges specifies whether we want the points to be equally spaced from edge to edge (Edges=1) or we want them to be in the centres of \\(n = q_1 \\times q_2 \\times \\ldots \\times q_k\\) bins filling the unit hypercube (for any other value of Edges).\n\ndef fullfactorial(q_param, Edges=1) -&gt; np.ndarray:\n    \"\"\"Generates a full factorial sampling plan in the unit cube.\n\n    Args:\n        q (list or np.ndarray):\n            A list or array containing the number of points along each dimension (k-vector).\n        Edges (int, optional):\n            Determines spacing of points. If `Edges=1`, points are equally spaced from edge to edge (default).\n            Otherwise, points will be in the centers of n = q[0]*q[1]*...*q[k-1] bins filling the unit cube.\n\n    Returns:\n        (np.ndarray): Full factorial sampling plan as an array of shape (n, k), where n is the total number of points and k is the number of dimensions.\n\n    Raises:\n        ValueError: If any dimension in `q` is less than 2.\n    \"\"\"\n    q_levels = np.array(q_param) # Use a distinct variable for original levels\n    if np.min(q_levels) &lt; 2:\n        raise ValueError(\"You must have at least two points per dimension.\")\n    \n    n = np.prod(q_levels)\n    k = len(q_levels)\n    X = np.zeros((n, k))\n    \n    # q_for_prod_calc is used for calculating repetitions, includes the phantom element.\n    # This matches the logic of the user-provided snippet where 'q' was modified.\n    q_for_prod_calc = np.append(q_levels, 1)\n\n    for j in range(k): # k is the original number of dimensions\n        # current_dim_levels is the number of levels for the current dimension j\n        # In the user's snippet, q[j] correctly refers to the original level count\n        # as j ranges from 0 to k-1, and q_for_prod_calc[j] = q_levels[j] for this range.\n        current_dim_levels = q_for_prod_calc[j] \n        \n        if Edges == 1:\n            one_d_slice = np.linspace(0, 1, int(current_dim_levels))\n        else:\n            # Corrected calculation for bin centers\n            if current_dim_levels == 1: # Should not be hit if np.min(q_levels) &gt;= 2\n                one_d_slice = np.array([0.5])\n            else:\n                one_d_slice = np.linspace(1 / (2 * current_dim_levels), \n                                          1 - 1 / (2 * current_dim_levels), \n                                          int(current_dim_levels))\n        \n        column = np.array([])\n        # The product q_for_prod_calc[j + 1 : k] correctly calculates \n        # the product of remaining original dimensions' levels.\n        num_consecutive_repeats = np.prod(q_for_prod_calc[j + 1 : k])\n        \n        # This loop structure replicates the logic from the user's snippet\n        while len(column) &lt; n:\n            for ll_idx in range(int(current_dim_levels)): # Iterate through levels of current dimension\n                val_to_repeat = one_d_slice[ll_idx]\n                column = np.append(column, np.ones(int(num_consecutive_repeats)) * val_to_repeat)\n        X[:, j] = column\n    return X\n\n\nq = [3, 2]\nX = fullfactorial(q, Edges=0)\nprint(X)\n\n[[0.16666667 0.25      ]\n [0.16666667 0.75      ]\n [0.5        0.25      ]\n [0.5        0.75      ]\n [0.83333333 0.25      ]\n [0.83333333 0.75      ]]\n\n\nFigure 3.3 shows the points in the unit hypercube for the case of 3x2 points.\n\n\n\n\n\n\n\n\nFigure 3.3: 2D Full Factorial Sampling (3x2 Points). Edges = 0\n\n\n\n\n\n\nX = fullfactorial(q, Edges=1)\nprint(X)\n\n[[0.  0. ]\n [0.  1. ]\n [0.5 0. ]\n [0.5 1. ]\n [1.  0. ]\n [1.  1. ]]\n\n\nFigure 3.4 shows the points in the unit hypercube for the case of 3x2 points with edges.\n\n\n\n\n\n\n\n\nFigure 3.4: 2D Full Factorial Sampling (3x2 Points). Edges = 1\n\n\n\n\n\nThe full factorial sampling plan method generates a uniform sampling design by creating a grid of points across all dimensions. For example, calling fullfactorial([3, 4, 5], 1) produces a three-dimensional sampling plan with 3, 4, and 5 levels along each dimension, respectively. While this approach satisfies the uniformity criterion, it has two significant limitations:\n\nRestricted Design Sizes: The method only works for designs where the total number of points \\(n\\) can be expressed as the product of the number of levels in each dimension, i.e., \\(n = q_1 \\times q_2 \\times \\cdots \\times q_k\\).\nOverlapping Projections: When the sampling points are projected onto individual axes, sets of points may overlap, reducing the effectiveness of the sampling plan. This can lead to non-uniform coverage in the projections, which may not fully represent the design space.\n\n\n\n3.3.2 Latin Squares and Random Latin Hypercubes\nTo improve the uniformity of projections for any individual variable, the range of that variable can be divided into a large number of equal-sized bins, and random subsamples of equal size can be generated within these bins. This method is called stratified random sampling. Extending this idea to all dimensions results in a stratified sampling plan, commonly implemented using Latin hypercube sampling.\n\nDefinition 3.3 (Latin Squares and Hypercubes) In the context of statistical sampling, a square grid containing sample positions is a Latin square if (and only if) there is only one sample in each row and each column. A Latin hypercube is the generalisation of this concept to an arbitrary number of dimensions, whereby each sample is the only one in each axis-aligned hyperplane containing it\n\nFor two-dimensional discrete variables, a Latin square ensures uniform projections. An \\((n \\times n)\\) Latin square is constructed by filling each row and column with a permutation of \\(\\{1, 2, \\dots, n\\}\\), ensuring each number appears only once per row and column.\n\nExample 3.4 (Latin Square) For \\(n = 4\\), a Latin square might look like this:\n2   1   3   4\n3   2   4   1\n1   4   2   3\n4   3   1   2\n\nLatin Hypercubes are the multidimensional extension of Latin squares. The design space is divided into equal-sized hypercubes (bins), and one point is placed in each bin. The placement ensures that moving along any axis from an occupied bin does not encounter another occupied bin. This guarantees uniform projections across all dimensions. To construct a Latin hypercube, the following steps are taken:\n\nRepresent the sampling plan as an \\(n \\times k\\) matrix \\(X\\), where \\(n\\) is the number of points and \\(k\\) is the number of dimensions.\nFill each column of \\(X\\) with random permutations of \\(\\{1, 2, \\dots, n\\}\\).\nNormalize the plan into the unit hypercube \\([0, 1]^k\\).\n\nThis approach ensures multidimensional stratification and uniformity in projections. Here is the code:\n\ndef rlh(n: int, k: int, edges: int = 0) -&gt; np.ndarray:\n    # Initialize array\n    X = np.zeros((n, k), dtype=float)\n\n    # Fill with random permutations\n    for i in range(k):\n        X[:, i] = np.random.permutation(n)\n\n    # Adjust normalization based on the edges flag\n    if edges == 1:\n        # [X=0..n-1] -&gt; [0..1]\n        X = X / (n - 1)\n    else:\n        # Points at true midpoints\n        # [X=0..n-1] -&gt; [0.5/n..(n-0.5)/n]\n        X = (X + 0.5) / n\n\n    return X\n\n\nExample 3.5 (Random Latin Hypercube) The following code can be used to generate a 2D Latin hypercube with 5 points and edges=0:\n\nX = rlh(n=5, k=2, edges=0)\nprint(X)\n\n[[0.9 0.9]\n [0.3 0.7]\n [0.5 0.3]\n [0.1 0.1]\n [0.7 0.5]]\n\n\nFigure 3.5 shows the points in the unit hypercube for the case of 5 points with edges=0.\n\n\n\n\n\n\n\n\nFigure 3.5: 2D Latin Hypercube Sampling (5 Points, Edges=0)\n\n\n\n\n\n\n\nExample 3.6 (Random Latin Hypercube with Edges) The following code can be used to generate a 2D Latin hypercube with 5 points and edges=1:\n\nX = rlh(n=5, k=2, edges=1)\nprint(X)\n\n[[0.25 1.  ]\n [1.   0.5 ]\n [0.75 0.  ]\n [0.   0.75]\n [0.5  0.25]]\n\n\nFigure 3.6 shows the points in the unit hypercube for the case of 5 points with edges=1.\n\n\n\n\n\n\n\n\nFigure 3.6: 2D Latin Hypercube Sampling (5 Points, Edges=1)\n\n\n\n\n\n\n\n\n3.3.3 Space-filling Designs: Maximin Plans\nA widely adopted measure for assessing the uniformity, or ‘space-fillingness’, of a sampling plan is the maximin metric, initially proposed by (john90a?). This criterion can be formally defined as follows.\nConsider a sampling plan \\(X\\). Let \\(d_1, d_2, \\ldots, d_m\\) represent the unique distances between all possible pairs of points within \\(X\\), arranged in ascending order. Furthermore, let \\(J_1, J_2, \\ldots, J_m\\) be defined such that \\(J_j\\) denotes the count of point pairs in \\(X\\) separated by the distance \\(d_j\\).\n\nDefinition 3.4 (Maximin plan) A sampling plan \\(X\\) is considered a maximin plan if, among all candidate plans, it maximizes the smallest inter-point distance \\(d_1\\). Among plans that satisfy this condition, it further minimizes \\(J_1\\), the number of pairs separated by this minimum distance.\n\nWhile this definition is broadly applicable to any collection of sampling plans, our focus is narrowed to Latin hypercube designs to preserve their desirable stratification properties. However, even within this restricted class, Definition 3.4 may identify multiple equivalent maximin designs. To address this, a more comprehensive ‘tie-breaker’ definition, as proposed by (morr95a?), is employed:\n\nDefinition 3.5 (Maximin plan with tie-breaker) A sampling plan \\(X\\) is designated as the maximin plan if it sequentially optimizes the following conditions: it maximizes \\(d_1\\); among those, it minimizes \\(J_1\\); among those, it maximizes \\(d_2\\); among those, it minimizes \\(J_2\\); and so forth, concluding with minimizing \\(J_m\\).\n\n(john90a?) established that the maximin criterion (Definition 3.4) is equivalent to the D-optimality criterion used in linear regression. However, the extended maximin criterion incorporating a tie-breaker (Definition 3.5) is often preferred due to its intuitive nature and practical utility. Given that the sampling plans under consideration make no assumptions about model structure, the latter criterion (Definition 3.5) will be employed.\nTo proceed, a precise definition of ‘distance’ within these contexts is necessary. The p-norm is the most widely adopted metric for this purpose:\n\nDefinition 3.6 (p-norm) The p-norm of a vector \\(\\vec{x} = (x_1, x_2, \\ldots, x_k)\\) is defined as:\n\\[\nd_p(\\vec{x}^{(i_1)}, \\vec{x}^{(i_2)}) = \\left( \\sum_{j=1}^k |x_j^{(i_1)} - x_j^{(i_2)}|^p \\right)^{1/p}.\n\\tag{3.2}\\]\n\nWhen \\(p = 1\\), Equation 3.2 defines the rectangular distance, occasionally referred to as the Manhattan norm (an allusion to a grid-like city layout). Setting \\(p = 2\\) yields the Euclidean norm. The existing literature offers limited evidence to suggest the superiority of one norm over the other for evaluating sampling plans when no model structure assumptions are made. It is important to note, however, that the rectangular distance is considerably less computationally demanding. This advantage can be quite significant, particularly when evaluating large sampling plans.\nFor the computational implementation of Definition 3.5, the initial step involves constructing the vectors \\(d_1, d_2, \\ldots, d_m\\) and \\(J_1, J_2, \\ldots, J_m\\). The jd function facilitates this task.\n\n3.3.3.1 The Function jd\nThe function jd computes the distinct p-norm distances between all pairs of points in a given set and counts their occurrences. It returns two arrays: one for the distinct distances and another for their multiplicities.\n\ndef jd(X: np.ndarray, p: float = 1.0) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array of shape (n, d) representing n points\n            in d-dimensional space.\n        p (float, optional):\n            The distance norm to use.\n            p=1 uses the Manhattan (L1) norm, while p=2 uses the\n            Euclidean (L2) norm. Defaults to 1.0 (Manhattan norm).\n\n    Returns:\n        (np.ndarray, np.ndarray):\n            A tuple (J, distinct_d), where:\n            - distinct_d is a 1D float array of unique,\n            sorted distances between points.\n            - J is a 1D integer array that provides\n            the multiplicity (occurrence count)\n            of each distance in distinct_d.\n    \"\"\"\n    n = X.shape[0]\n\n    # Allocate enough space for all pairwise distances\n    # (n*(n-1))/2 pairs for an n-point set\n    pair_count = n * (n - 1) // 2\n    d = np.zeros(pair_count, dtype=float)\n\n    # Fill the distance array\n    idx = 0\n    for i in range(n - 1):\n        for j in range(i + 1, n):\n            # Compute the p-norm distance\n            d[idx] = np.linalg.norm(X[i] - X[j], ord=p)\n            idx += 1\n\n    # Find unique distances and their multiplicities\n    distinct_d = np.unique(d)\n    J = np.zeros_like(distinct_d, dtype=int)\n    for i, val in enumerate(distinct_d):\n        J[i] = np.sum(d == val)\n    return J, distinct_d\n\n\nExample 3.7 (The Function jd) Consider a small 3-point set in 2D space, with points located at (0,0), (1,1), and (2,2) as shown in Figure 3.7. The distinct distances and their occurrences can be computed using the jd function, as shown in the following code:\n\n\n\n\n\n\n\n\nFigure 3.7: 3-Point Set in 2D Space\n\n\n\n\n\n\nJ, distinct_d = jd(X, p=2.0)\nprint(\"Distinct distances (d_i):\", distinct_d)\nprint(\"Occurrences (J_i):\", J)\n\nDistinct distances (d_i): [1.41421356 2.82842712]\nOccurrences (J_i): [2 1]\n\n\n\n\n\n\n3.3.4 Memory Management\nA computationally intensive part of the calculation performed with the jd-function is the creation of the vector \\(\\vec{d}\\) containing all pairwise distances. This is particularly true for large sampling plans; for instance, a 1000-point plan requires nearly half a million distance calculations.\n\nDefinition 3.7 (Pre-allocation of Memory) Pre-allocation of memory is a programming technique where a fixed amount of memory is reserved for a data structure (like an array or vector) before it is actually filled with data. This is done to avoid the computational overhead associated with dynamic memory allocation, which involves repeatedly requesting and resizing memory as new elements are added.\n\nConsequently, pre-allocating memory for the distance vector \\(\\vec{d}\\) is essential. This necessitates a slightly less direct method for computing the indices of \\(\\vec{d}\\), rather than appending each new element, which would involve costly dynamic memory allocation.\nThe implementation of Definition 3.5 is now required. Finding the most space-filling design involves pairwise comparisons. This problem can be approached using a ‘divide and conquer’ strategy, simplifying it to the task of selecting the better of two sampling plans. The function mm(X1,X2,p) is designed for this purpose. It returns an index indicating which of the two designs is more space-filling, or 0 if they are equally space-filling, based on the \\(p\\)-norm for distance computation.\n\n3.3.4.1 The Function mm\nThe function mm compares two sampling plans based on the Morris-Mitchell criterion. It uses the jd function to compute the distances and multiplicities, constructs vectors for comparison, and determines which plan is more space-filling.\n\ndef mm(X1: np.ndarray, X2: np.ndarray, p: Optional[float] = 1.0) -&gt; int:\n    \"\"\"\n    Args:\n        X1 (np.ndarray): A 2D array representing the first sampling plan.\n        X2 (np.ndarray): A 2D array representing the second sampling plan.\n        p (float, optional): The distance metric. p=1 uses Manhattan (L1) distance,\n            while p=2 uses Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        int:\n            - 0 if both plans are identical or equally space-filling\n            - 1 if X1 is more space-filling\n            - 2 if X2 is more space-filling\n    \"\"\"\n    X1_sorted = X1[np.lexsort(np.rot90(X1))]\n    X2_sorted = X2[np.lexsort(np.rot90(X2))]\n    if np.array_equal(X1_sorted, X2_sorted):\n        return 0  # Identical sampling plans\n\n    # Compute distance multiplicities for each plan\n    J1, d1 = jd(X1, p)\n    J2, d2 = jd(X2, p)\n    m1, m2 = len(d1), len(d2)\n\n    # Construct V1 and V2: alternate distance and negative multiplicity\n    V1 = np.zeros(2 * m1)\n    V1[0::2] = d1\n    V1[1::2] = -J1\n\n    V2 = np.zeros(2 * m2)\n    V2[0::2] = d2\n    V2[1::2] = -J2\n\n    # Trim the longer vector to match the size of the shorter\n    m = min(m1, m2)\n    V1 = V1[:m]\n    V2 = V2[:m]\n\n    # Compare element-by-element:\n    # c[i] = 1 if V1[i] &gt; V2[i], 2 if V1[i] &lt; V2[i], 0 otherwise.\n    c = (V1 &gt; V2).astype(int) + 2 * (V1 &lt; V2).astype(int)\n\n    if np.sum(c) == 0:\n        # Equally space-filling\n        return 0\n    else:\n        # The first non-zero entry indicates which plan is better\n        idx = np.argmax(c != 0)\n        return c[idx]\n\n\nExample 3.8 (The Function mm) We can use the mm function to compare two sampling plans. The following code creates two 3-point sampling plans in 2D (shown in Figure 3.8) and compares them using the Morris-Mitchell criterion:\n\nX1 = np.array([[0.0, 0.0],[0.5, 0.5],[0.0, 1.0], [1.0, 1.0]])\nX2 = np.array([[0.1, 0.1],[0.4, 0.6],[0.1, 0.9], [0.9, 0.9]])\n\n\n\n\n\n\n\n\n\nFigure 3.8: Comparison of Two Sampling Plans\n\n\n\n\n\nWe can compare which plan has better space-filling (Morris-Mitchell). The output is either 0, 1, or 2 depending on which plan is more space-filling.\n\nbetter = mm(X1, X2, p=2.0)\nprint(f\"Plan {better} is more space-filling.\")\n\nPlan 1 is more space-filling.\n\n\n\n\n\n3.3.4.2 The Function mmphi\nSearching across a space of potential sampling plans can be accomplished by pairwise comparisons. An optimization algorithm could, in theory, be written with mm as the comparative objective. However, experimental evidence (morr95a?) suggests that the resulting optimization landscape can be quite deceptive, making it difficult to search reliably. This difficulty arises because the comparison process terminates upon finding the first non-zero element in the comparison array c. Consequently, the remaining values in the distance (\\(d_1, d_2, ..., d_m\\)) and multiplicity (\\(J_1, J_2, ..., J_m\\)) arrays are disregarded. These disregarded values, however, might contain potentially useful ‘slope’ information about the global landscape for the optimization process.\nTo address this, (morr95a?) defined the following scalar-valued criterion function, which is used to rank competing sampling plans. This function, while based on the logic of Definition 3.5, incorporates the complete vectors \\(d_1, d_2, ..., d_m\\) and \\(J_1, J_2, ..., J_m\\).\n\nDefinition 3.8 (Morris-Mitchell Criterion) The Morris-Mitchell criterion is defined as:\n\\[\n\\Phi_q (X) = \\left(\\sum_{j=1}^m J_j d_j^{-q}\\right)^{1/q},\n\\tag{3.3}\\]\nwhere \\(X\\) is the sampling plan, \\(d_j\\) is the distance between points, \\(J_j\\) is the multiplicity of that distance, and \\(q\\) is a user-defined exponent. The parameter \\(q\\) can be adjusted to control the influence of smaller distances on the overall metric.\n\nThe smaller the value of \\(\\Phi_q\\), the better the space-filling properties of \\(X\\) will be.\nThe function mmphi computes the Morris-Mitchell sampling plan quality criterion for a given sampling plan. It takes a 2D array of points and calculates the space-fillingness metric based on the distances between points. This can be implemented in Python as follows:\n\ndef mmphi(X: np.ndarray,\n          q: Optional[float] = 2.0,\n          p: Optional[float] = 1.0) -&gt; float:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array representing the sampling plan,\n            where each row is a point in\n            d-dimensional space (shape: (n, d)).\n        q (float, optional):\n            Exponent used in the computation of the metric.\n            Defaults to 2.0.\n        p (float, optional):\n            The distance norm to use.\n            For example, p=1 is Manhattan (L1),\n            p=2 is Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        float:\n            The space-fillingness metric Phiq. Larger values typically indicate a more\n            space-filling plan according to the Morris-Mitchell criterion.\n    \"\"\"\n    # Compute the distance multiplicities: J, and unique distances: d\n    J, d = jd(X, p)\n    # Summation of J[i] * d[i]^(-q), then raised to 1/q\n    # This follows the Morris-Mitchell definition.\n    Phiq = np.sum(J * (d ** (-q))) ** (1.0 / q)\n    return Phiq\n\n\nExample 3.9 (The Function mmphi) We can use the mmphi function to evaluate the space-filling quality of the two sampling plans from Example 3.8. The following code uses these two 3-point sampling plans in 2D and computes their quality using the Morris-Mitchell criterion:\n\n# Two simple sampling plans from above\nquality1 = mmphi(X1, q=2, p=2)\nquality2 = mmphi(X2, q=2, p=2)\nprint(f\"Quality of sampling plan X1:  {quality1}\")\nprint(f\"Quality of sampling plan X2:  {quality2}\")\n\nQuality of sampling plan X1:  2.91547594742265\nQuality of sampling plan X2:  3.917162046269215\n\n\n\nThis equation provides a more compact representation of the maximin criterion, but the selection of the \\(q\\) value is an important consideration. Larger values of \\(q\\) ensure that terms in the sum corresponding to smaller inter-point distances (the \\(d_j\\) values, which are sorted in ascending order) have a dominant influence. As a result, \\(\\Phi_q\\) will rank sampling plans in a way that closely emulates the original maximin definition (Definition 3.5). This implies that the optimization landscape might retain the challenging characteristics that the \\(\\Phi_q\\) metric, especially with smaller \\(q\\) values, is intended to alleviate. Conversely, smaller \\(q\\) values tend to produce a \\(\\Phi_q\\) landscape that, while not perfectly aligning with the original definition, is generally more conducive to optimization.\nTo illustrate the relationship between Equation 3.3 and the maximin criterion of Definition 3.5, sets of 50 random Latin hypercubes of varying sizes and dimensionalities were considered by (Forr08a?). The correlation plots from this analysis suggest that as the sampling plan size increases, a smaller \\(q\\) value is needed for the \\(\\Phi_q\\)-based ranking to closely match the ranking derived from Definition 3.5.\nRankings based on both the direct maximin comparison (mm) and the \\(\\Phi_q\\) metric (mmphi), determined using a simple bubble sort algorithm, are implemented in the Python function mmsort.\n\n\n3.3.4.3 The Function mmsort\nThe function mmsort is designed to rank multiple sampling plans based on their space-filling properties using the Morris-Mitchell criterion. It takes a 3D array of sampling plans and returns the indices of the plans sorted in ascending order of their space-filling quality.\n\ndef mmsort(X3D: np.ndarray, p: Optional[float] = 1.0) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X3D (np.ndarray):\n            A 3D NumPy array of shape (n, d, m), where m is the number of\n            sampling plans, and each plan is an (n, d) matrix of points.\n        p (float, optional):\n            The distance metric to use. p=1 for Manhattan (L1), p=2 for\n            Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        np.ndarray:\n            A 1D integer array of length m that holds the plan indices in\n            ascending order of space-filling quality. The first index in the\n            returned array corresponds to the most space-filling plan.\n    \"\"\"\n    # Number of plans (m)\n    m = X3D.shape[2]\n\n    # Create index array (1-based to match original MATLAB convention)\n    Index = np.arange(1, m + 1)\n\n    swap_flag = True\n    while swap_flag:\n        swap_flag = False\n        i = 0\n        while i &lt; m - 1:\n            # Compare plan at Index[i] vs. Index[i+1] using mm()\n            # Note: subtract 1 from each index to convert to 0-based array indexing\n            if mm(X3D[:, :, Index[i] - 1], X3D[:, :, Index[i + 1] - 1], p) == 2:\n                # Swap indices if the second plan is more space-filling\n                Index[i], Index[i + 1] = Index[i + 1], Index[i]\n                swap_flag = True\n            i += 1\n\n    return Index\n\n\nExample 3.10 (The Function mmsort) The mmsort function can be used to rank multiple sampling plans based on their space-filling properties. The following code demonstrates how to use mmsort to compare two 3-point sampling plans in 3D space:\nSuppose we have two 3-point sampling plans X1 and X1 from above. They are sorted using the Morris-Mitchell criterion with \\(p=2.0\\). For example, the output [1, 2] indicates that X1 is more space-filling than X2:\n\nX3D = np.stack([X1, X2], axis=2)\nranking = mmsort(X3D, p=2.0)\nprint(ranking)\n\n[1 2]\n\n\n\nTo determine the optimal Latin hypercube for a specific application, a recommended approach by (morr95a?) involves minimizing \\(\\Phi_q\\) for a set of \\(q\\) values (1, 2, 5, 10, 20, 50, and 100). Subsequently, the best plan from these results is selected based on the actual maximin definition. The mmsort function can be utilized for this purpose: a 3D matrix, X3D, can be constructed where each 2D slice represents the best sampling plan found for each \\(\\Phi_q\\). Applying mmsort(X3D,1) then ranks these plans according to Definition 3.5, using the rectangular distance metric. The subsequent discussion will address the methods for finding these optimized \\(\\Phi_q\\) designs.\n\n\n3.3.4.4 The Function phisort\nphisort only differs from mmsort in having \\(q\\) as an additional argument, as well as the comparison line being:\nif mmphi(X3D[:, :, Index[i] - 1], q=q, p=p) &gt;\n    mmphi(X3D[:, :, Index[i + 1] - 1], q=q, p=p):\n\ndef phisort(X3D: np.ndarray,\n            q: Optional[float] = 2.0,\n            p: Optional[float] = 1.0) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X3D (np.ndarray):\n            A 3D array of shape (n, d, m),\n            where m is the number of sampling plans.\n        q (float, optional):\n            Exponent for the mmphi metric. Defaults to 2.0.\n        p (float, optional):\n            Distance norm for mmphi.\n            p=1 is Manhattan; p=2 is Euclidean.\n            Defaults to 1.0.\n\n    Returns:\n        np.ndarray:\n            A 1D integer array of length m, giving the plan indices in ascending\n            order of mmphi. The first index in the returned array corresponds\n            to the numerically lowest mmphi value.\n    \"\"\"\n    # Number of 2D sampling plans\n    m = X3D.shape[2]\n    # Create a 1-based index array\n    Index = np.arange(1, m + 1)\n    # Bubble-sort: plan with lower mmphi() climbs toward the front\n    swap_flag = True\n    while swap_flag:\n        swap_flag = False\n        for i in range(m - 1):\n            # Retrieve mmphi values for consecutive plans\n            val_i = mmphi(X3D[:, :, Index[i] - 1], q=q, p=p)\n            val_j = mmphi(X3D[:, :, Index[i + 1] - 1], q=q, p=p)\n\n            # Swap if the left plan's mmphi is larger (i.e. 'worse')\n            if val_i &gt; val_j:\n                Index[i], Index[i + 1] = Index[i + 1], Index[i]\n                swap_flag = True\n    return Index\n\n\nExample 3.11 (The Function phisort) The phisort function can be used to rank multiple sampling plans based on the Morris-Mitchell criterion. The following code demonstrates how to use phisort to compare two 3-point sampling plans in 3D space:\n\nX1 = bestlh(n=5, k=2, population=5, iterations=10)\nX2 = bestlh(n=5, k=2, population=15, iterations=20)\nX3 = bestlh(n=5, k=2, population=25, iterations=30)\n# Map X1 and X2 so that X3D has the two sampling plans\n# in X3D[:, :, 0] and X3D[:, :, 1]\nX3D = np.array([X1, X2])\nprint(phisort(X3D))\nX3D = np.array([X3, X2])\nprint(phisort(X3D))\n\n[1 2]\n[2 1]\n\n\n\n\n\n\n3.3.5 Optimizing the Morris-Mitchell Criterion \\(\\Phi_q\\)\nOnce a criterion for assessing the quality of a Latin hypercube sampling plan has been established, a systematic method for optimizing this metric across the space of Latin hypercubes is required. This task is non-trivial; as the reader may recall from the earlier discussion on Latin squares, this search space is vast. In fact, its vastness means that for many practical applications, locating the globally optimal solution is often infeasible. Therefore, the objective becomes finding the best possible sampling plan achievable within a specific computational time budget.\nThis budget is influenced by the computational cost associated with obtaining each objective function value. Determining the optimal allocation of total computational effort—between generating the sampling plan and actually evaluating the objective function at the selected points—remains an open research question. However, it is typical for no more than approximately 5% of the total available time to be allocated to the task of generating the sampling plan itself.\n(Forr08a?) draw an analogy to the process of devising a revision timetable before an exam. While a well-structured timetable enhances the effectiveness of revision, an excessive amount of the revision time itself should not be consumed by the planning phase.\nA significant challenge in devising a sampling plan optimizer is ensuring that the search process remains confined to the space of valid Latin hypercubes. As previously discussed, the defining characteristic of a Latin hypercube \\(X\\) is that each of its columns represents a permutation of the possible levels for the corresponding variable. Consequently, the smallest modification that can be applied to a Latin hypercube—without compromising its crucial multidimensional stratification property—involves swapping two elements within any single column of \\(X\\). A Python implementation for ‘mutating’ a Latin hypercube through such an operation, generalized to accommodate random changes applied to multiple sites, is provided below:\n\n3.3.5.1 The Function perturb()\nThe function perturb randomly swaps elements in a Latin hypercube sampling plan. It takes a 2D array representing the sampling plan and performs a specified number of random element swaps, ensuring that the result remains a valid Latin hypercube.\n\ndef perturb(X: np.ndarray,\n            PertNum: Optional[int] = 1) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array (sampling plan) of shape (n, k),\n            where each row is a point\n            and each column is a dimension.\n        PertNum (int, optional):\n            The number of element swaps (perturbations)\n            to perform. Defaults to 1.\n\n    Returns:\n        np.ndarray:\n            The perturbed sampling plan,\n            identical in shape to the input, with\n            one or more random column swaps executed.\n    \"\"\"\n    # Get dimensions of the plan\n    n, k = X.shape\n    if n &lt; 2 or k &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points and 2 dimensions\")\n    for _ in range(PertNum):\n        # Pick a random column\n        col = int(np.floor(np.random.rand() * k))\n        # Pick two distinct row indices\n        el1, el2 = 0, 0\n        while el1 == el2:\n            el1 = int(np.floor(np.random.rand() * n))\n            el2 = int(np.floor(np.random.rand() * n))\n        # Swap the two selected elements in the chosen column\n        X[el1, col], X[el2, col] = X[el2, col], X[el1, col]\n    return X\n\n\nExample 3.12 (The Function perturb()) The perturb function can be used to randomly swap elements in a Latin hypercube sampling plan. The following code demonstrates how to use perturb to create a perturbed version of a 4x2 sampling plan:\n\nX_original = np.array([[1, 3],[2, 4],[3, 1],[4, 2]])\nprint(\"Original Sampling Plan:\")\nprint(X_original)\nprint(\"Perturbed Sampling Plan:\")\nX_perturbed = perturb(X_original, PertNum=1)\nprint(X_perturbed)\n\nOriginal Sampling Plan:\n[[1 3]\n [2 4]\n [3 1]\n [4 2]]\nPerturbed Sampling Plan:\n[[1 3]\n [2 1]\n [3 4]\n [4 2]]\n\n\n\n(Forr08a?) uses the term ‘mutation’, because this problem lends itself to nature-inspired computation. (morr95a?) use a simulated annealing algorithm, the detailed pseudocode of which can be found in their paper. As an alternative, a method based on evolutionary operation (EVOP) is offered by (Forr08a?).\n\n\n\n3.3.6 Evolutionary Operation\nAs introduced by (Box57a?), evolutionary operation was designed to optimize chemical processes. The current parameters of the reaction would be recorded in a box at the centre of a board, with a series of ‘offspring’ boxes along the edges containing values of the parameters slightly altered with respect to the central, ‘parent’ values. Once the reaction was completed for all of these sets of variable values and the corresponding yields recorded, the contents of the central box would be replaced with that of the setup with the highest yield and this would then become the parent of a new set of peripheral boxes.\nThis is generally viewed as a local search procedure, though this depends on the mutation step sizes, that is on the differences between the parent box and its offspring. The longer these steps, the more global is the scope of the search.\nFor the purposes of the Latin hypercube search, a variable scope strategy is applied. The process starts with a long step length (that is a relatively large number of swaps within the columns) and, as the search progresses, the current best basin of attraction is gradually approached by reducing the step length to a single change.\nIn each generation the parent is mutated (randomly, using the perturb function) a pertnum number of times. The sampling plan that yields the smallest \\(\\Phi_q\\) value (as per the Morris-Mitchell criterion, calculated usingmmphi) among all offspring and the parent is then selected; in evolutionary computation parlance this selection philosophy is referred to as elitism.\nThe EVOP based search for space-filling Latin hypercubes is thus a truly evolutionary process: the optimized sampling plan results from the nonrandom survival of random variations.\n\n\n3.3.7 Putting it all Together\nAll the pieces of the optimum Latin hypercube sampling process puzzle are now in place: the random hypercube generator as a starting point for the optimization process, the ‘spacefillingness’ metric that needs to be optimized, the optimization engine that performs this task and the comparison function that selects the best of the optima found for the various \\(q\\)’s. These pieces just need to be put into a sequence. Here is the Python embodiment of the completed puzzle. It results in a function bestlh that uses the function mmlhs to find the best Latin hypercube sampling plan for a given set of parameters.\n\n3.3.7.1 The Function mmlhs\nPerforms an evolutionary search (using perturbations) to find a Morris-Mitchell optimal Latin hypercube, starting from an initial plan X_start.\nThis function does the following:\n\nInitializes a “best” Latin hypercube (X_best) from the provided X_start.\nIteratively perturbs X_best to create offspring.\nEvaluates the space-fillingness of each offspring via the Morris-Mitchell metric (using mmphi).\nUpdates the best plan whenever a better offspring is found.\n\n\ndef mmlhs(X_start: np.ndarray,\n          population: int,\n          iterations: int,\n          q: Optional[float] = 2.0,\n          plot=False) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X_start (np.ndarray):\n            A 2D array of shape (n, k) providing the initial Latin hypercube\n            (n points in k dimensions).\n        population (int):\n            Number of offspring to create in each generation.\n        iterations (int):\n            Total number of generations to run the evolutionary search.\n        q (float, optional):\n            The exponent used by the Morris-Mitchell space-filling criterion.\n            Defaults to 2.0.\n        plot (bool, optional):\n            If True, a simple scatter plot of the first two dimensions will be\n            displayed at each iteration. Only if k &gt;= 2. Defaults to False.\n\n    Returns:\n        np.ndarray:\n            A 2D array representing the most space-filling Latin hypercube found\n            after all iterations, of the same shape as X_start.\n    \"\"\"\n    n = X_start.shape[0]\n    if n &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points\")\n    k = X_start.shape[1]\n    if k &lt; 2:\n        raise ValueError(\"Latin hypercubes are not defined for dim k &lt; 2\")\n    # Initialize best plan and its metric\n    X_best = X_start.copy()\n    Phi_best = mmphi(X_best, q=q)\n    # After 85% of iterations, reduce the mutation rate to 1\n    leveloff = int(np.floor(0.85 * iterations))\n    for it in range(1, iterations + 1):\n        # Decrease number of mutations over time\n        if it &lt; leveloff:\n            mutations = int(round(1 + (0.5 * n - 1) * (leveloff - it) / (leveloff - 1)))\n        else:\n            mutations = 1\n        X_improved = X_best.copy()\n        Phi_improved = Phi_best\n        # Create offspring, evaluate, and keep the best\n        for _ in range(population):\n            X_try = perturb(X_best.copy(), mutations)\n            Phi_try = mmphi(X_try, q=q)\n\n            if Phi_try &lt; Phi_improved:\n                X_improved = X_try\n                Phi_improved = Phi_try\n        # Update the global best if we found a better plan\n        if Phi_improved &lt; Phi_best:\n            X_best = X_improved\n            Phi_best = Phi_improved\n        # Simple visualization of the first two dimensions\n        if plot and (X_best.shape[1] &gt;= 2):\n            plt.clf()\n            plt.scatter(X_best[:, 0], X_best[:, 1], marker=\"o\")\n            plt.grid(True)\n            plt.title(f\"Iteration {it} - Current Best Plan\")\n            plt.pause(0.01)\n    return X_best\n\n\nExample 3.13 (The Function mmlhs) The mmlhs function can be used to optimize a Latin hypercube sampling plan. The following code demonstrates how to use mmlhs to optimize a 4x2 Latin hypercube starting from an initial plan:\n\n# Suppose we have an initial 4x2 plan\nX_start = np.array([[0.1, 0.3],[.1, .4],[.2, .9],[.9, .2]])\nprint(\"Initial plan:\")\nprint(X_start)\n# Search for a more space-filling plan\nX_opt = mmlhs(X_start, population=10, iterations=100, q=2)\nprint(\"Optimized plan:\")\nprint(X_opt)\n\nInitial plan:\n[[0.1 0.3]\n [0.1 0.4]\n [0.2 0.9]\n [0.9 0.2]]\nOptimized plan:\n[[0.1 0.2]\n [0.1 0.9]\n [0.2 0.4]\n [0.9 0.3]]\n\n\nFigure 3.9 shows the initial and optimized plans in 2D. The blue points represent the initial plan, while the red points represent the optimized plan.\n\n\n\n\n\n\n\n\nFigure 3.9: Comparison of the initial and optimized plans in 2D.\n\n\n\n\n\n\n\n\n3.3.7.2 The Function bestlh\nGenerates an optimized Latin hypercube by evolving the Morris-Mitchell criterion across multiple exponents (q values) and selecting the best plan.\n\ndef bestlh(n: int,\n           k: int,\n           population: int,\n           iterations: int,\n           p=1,\n           plot=False,\n           verbosity=0,\n           edges=0,\n           q_list=[1, 2, 5, 10, 20, 50, 100]) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        n (int):\n            Number of points required in the Latin hypercube.\n        k (int):\n            Number of design variables (dimensions).\n        population (int):\n            Number of offspring in each generation of the evolutionary search.\n        iterations (int):\n            Number of generations for the evolutionary search.\n        p (int, optional):\n            The distance norm to use. p=1 for Manhattan (L1), p=2 for Euclidean (L2).\n            Defaults to 1 (faster than 2).\n        plot (bool, optional):\n            If True, a scatter plot of the optimized plan in the first two dimensions\n            will be displayed. Only if k&gt;=2.  Defaults to False.\n        verbosity (int, optional):\n            Verbosity level. 0 is silent, 1 prints the best q value found. Defaults to 0.\n        edges (int, optional):\n            If 1, places centers of the extreme bins at the domain edges ([0,1]).\n            Otherwise, bins are fully contained within the domain, i.e. midpoints.\n            Defaults to 0.\n        q_list (list, optional):\n            A list of q values to optimize. Defaults to [1, 2, 5, 10, 20, 50, 100].\n            These values are used to evaluate the space-fillingness of the Latin\n            hypercube. The best plan is selected based on the lowest mmphi value.\n\n    Returns:\n        np.ndarray:\n            A 2D array of shape (n, k) representing an optimized Latin hypercube.\n    \"\"\"\n    if n &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points\")\n    if k &lt; 2:\n        raise ValueError(\"Latin hypercubes are not defined for dim k &lt; 2\")\n\n    # A list of exponents (q) to optimize\n\n    # Start with a random Latin hypercube\n    X_start = rlh(n, k, edges=edges)\n\n    # Allocate a 3D array to store the results for each q\n    # (shape: (n, k, number_of_q_values))\n    X3D = np.zeros((n, k, len(q_list)))\n\n    # Evolve the plan for each q in q_list\n    for i, q_val in enumerate(q_list):\n        if verbosity &gt; 0:\n            print(f\"Now optimizing for q={q_val}...\")\n        X3D[:, :, i] = mmlhs(X_start, population, iterations, q_val)\n\n    # Sort the set of evolved plans according to the Morris-Mitchell criterion\n    index_order = mmsort(X3D, p=p)\n\n    # index_order is a 1-based array of plan indices; the first element is the best\n    best_idx = index_order[0] - 1\n    if verbosity &gt; 0:\n        print(f\"Best lh found using q={q_list[best_idx]}...\")\n\n    # The best plan in 3D array order\n    X = X3D[:, :, best_idx]\n\n    # Plot the first two dimensions\n    if plot and (k &gt;= 2):\n        plt.scatter(X[:, 0], X[:, 1], c=\"r\", marker=\"o\")\n        plt.title(f\"Morris-Mitchell optimum plan found using q={q_list[best_idx]}\")\n        plt.xlabel(\"x_1\")\n        plt.ylabel(\"x_2\")\n        plt.grid(True)\n        plt.show()\n\n    return X\n\n\nExample 3.14 (The Function bestlh) The bestlh function can be used to generate an optimized Latin hypercube sampling plan. The following code demonstrates how to use bestlh to create a 5x2 Latin hypercube with a population of 5 and 10 iterations:\n\nXbestlh= bestlh(n=5, k=2, population=5, iterations=10)\n\nFigure 3.10 shows the best Latin hypercube sampling in 2D. The red points represent the optimized plan.\n\n\n\n\n\n\n\n\nFigure 3.10: Best Latin Hypercube Sampling\n\n\n\n\n\n\nSorting all candidate plans in ascending order is not strictly necessary - after all, only the best one is truly of interest. Nonetheless, the added computational complexity is minimal (the vector will only ever contain as many elements as there are candidate \\(q\\) values, and only an index array is sorted, not the actual repository of plans). This sorting gives the reader the opportunity to compare, if desired, how different choices of \\(q\\) influence the resulting plans.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#experimental-analysis-of-the-morris-mitchell-criterion",
    "href": "001_sampling.html#experimental-analysis-of-the-morris-mitchell-criterion",
    "title": "3  Sampling Plans",
    "section": "3.4 Experimental Analysis of the Morris-Mitchell Criterion",
    "text": "3.4 Experimental Analysis of the Morris-Mitchell Criterion\nMorris-Mitchell Criterion Experimental Analysis\n\nNumber of points: 16, Dimensions: 2\nmmphi parameters: q (exponent) = 2.0, p (distance norm) = 2.0 (1=Manhattan, 2=Euclidean)\n\n\nN_POINTS = 16\nN_DIM = 2\nRANDOM_SEED = 42\nq = 2.0\np = 2.0\n\n\n3.4.1 Evaluation of Sampling Designs\nWe generate various sampling designs and evaluate their space-filling properties using the Morris-Mitchell criterion.\n\ndesigns = {}\nif int(np.sqrt(N_POINTS))**2 == N_POINTS:\n    grid_design = Grid(k=N_DIM)\n    designs[\"Grid (4x4)\"] = grid_design.generate_grid_design(points_per_dim=int(np.sqrt(N_POINTS)))\nelse:\n    print(f\"Skipping grid design as N_POINTS={N_POINTS} is not a perfect square for a simple 2D grid.\")\n\nlhs_design = SpaceFilling(k=N_DIM, seed=42)\ndesigns[\"LHS\"] = lhs_design.generate_qms_lhs_design(n_points=N_POINTS)\n\nsobol_design = Sobol(k=N_DIM, seed=42)\ndesigns[\"Sobol\"] = sobol_design.generate_sobol_design(n_points=N_POINTS)\n\nrandom_design = Random(k=N_DIM)\ndesigns[\"Random\"] = random_design.uniform(n_points=N_POINTS)\n\npoor_design = Poor(k=N_DIM)\ndesigns[\"Collinear\"] = poor_design.generate_collinear_design(n_points=N_POINTS)\n\nclustered_design = Clustered(k=N_DIM)\ndesigns[\"Clustered (3 clusters)\"] = clustered_design.generate_clustered_design(n_points=N_POINTS, n_clusters=3, seed=42)\n\nresults = {}\n\nprint(\"Calculating Morris-Mitchell metric (smaller is better):\")\nfor name, X_design in designs.items():\n    metric_val = mmphi(X_design, q=q, p=p)\n    results[name] = metric_val\n    print(f\"  {name}: {metric_val:.4f}\")\n\nCalculating Morris-Mitchell metric (smaller is better):\n  Grid (4x4): 20.2617\n  LHS: 28.1868\n  Sobol: 28.1561\n  Random: 43.0391\n  Collinear: 87.8829\n  Clustered (3 clusters): 90.3702\n\n\n\nif N_DIM == 2:\n    num_designs = len(designs)\n    cols = 2\n    rows = int(np.ceil(num_designs / cols))\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n    axes = axes.ravel() # Flatten axes array for easy iteration\n\n    for i, (name, X_design) in enumerate(designs.items()):\n        ax = axes[i]\n        ax.scatter(X_design[:, 0], X_design[:, 1], s=50, edgecolors='k', alpha=0.7)\n        ax.set_title(f\"{name}\\nmmphi = {results[name]:.3f}\", fontsize=10)\n        ax.set_xlabel(\"X1\")\n        ax.set_ylabel(\"X2\")\n        ax.set_xlim(-0.05, 1.05)\n        ax.set_ylim(-0.05, 1.05)\n        ax.set_aspect('equal', adjustable='box')\n        ax.grid(True, linestyle='--', alpha=0.6)\n\n    # Hide any unused subplots\n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.suptitle(f\"Comparison of 2D Sampling Designs ({N_POINTS} points each)\", fontsize=14, y=1.02)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n3.4.2 Demonstrate the Impact of mmphi Parameters\nDemonstrating Impact of mmphi Parameters on ‘LHS’ Design\n\nX_lhs = designs[\"LHS\"]\n\n# 1. Default parameters (already calculated)\nprint(f\"  LHS (q={q}, p={p} Euclidean): {results['LHS']:.4f}\")\n\n# 2. Change q (main exponent, literature's p or k)\nq_high = 15.0\nmetric_lhs_q_high = mmphi(X_lhs, q=q_high, p=p)\nprint(f\"  LHS (q={q_high}, p={p} Euclidean): {metric_lhs_q_high:.4f} (Higher q penalizes small distances more)\")\n\n# 3. Change p (distance norm, literature's q or m)\np_manhattan = 1.0\nmetric_lhs_p_manhattan = mmphi(X_lhs, q=q, p=p_manhattan)\nprint(f\"  LHS (q={q}, p={p_manhattan} Manhattan): {metric_lhs_p_manhattan:.4f} (Using L1 distance)\")\n\n  LHS (q=2.0, p=2.0 Euclidean): 28.1868\n  LHS (q=15.0, p=2.0 Euclidean): 8.1573 (Higher q penalizes small distances more)\n  LHS (q=2.0, p=1.0 Manhattan): 22.0336 (Using L1 distance)\n\n\n\n\n3.4.3 Morris-Mitchell Criterion: Impact of Adding Points\nImpact of adding a point to a 2x2 grid design\n\n# Initial 2x2 Grid Design\nX_initial = np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\nmmphi_initial = mmphi(X_initial, q=q, p=p)\n\nprint(f\"Parameters: q (exponent) = {q}, p (distance) = {p} (Euclidean)\\n\")\nprint(f\"Initial 2x2 Grid Design (4 points):\")\nprint(f\"  Points:\\n{X_initial}\")\nprint(f\"  Morris-Mitchell Criterion (Phi_q): {mmphi_initial:.4f}\\n\")\n\nParameters: q (exponent) = 2.0, p (distance) = 2.0 (Euclidean)\n\nInitial 2x2 Grid Design (4 points):\n  Points:\n[[0. 0.]\n [1. 0.]\n [0. 1.]\n [1. 1.]]\n  Morris-Mitchell Criterion (Phi_q): 2.2361\n\n\n\nScenarios for adding a 5th point:\n\nscenarios = {\n    \"Scenario 1: Add to Center\": {\n        \"new_point\": np.array([[0.5, 0.5]]),\n        \"description\": \"Adding a point in the center of the grid.\"\n    },\n    \"Scenario 2: Add Close to Existing (Cluster)\": {\n        \"new_point\": np.array([[0.1, 0.1]]),\n        \"description\": \"Adding a point very close to an existing point (0,0).\"\n    },\n    \"Scenario 3: Add on Edge\": {\n        \"new_point\": np.array([[0.5, 0.0]]),\n        \"description\": \"Adding a point on an edge between (0,0) and (1,0).\"\n    }\n}\n\nresults_summary = []\naugmented_designs_for_plotting = {\"Initial Design\": X_initial}\n\nfor name, scenario_details in scenarios.items():\n    new_point = scenario_details[\"new_point\"]\n    X_augmented = np.vstack((X_initial, new_point))\n    augmented_designs_for_plotting[name] = X_augmented\n    \n    mmphi_augmented = mmphi(X_augmented, q=q, p=p)\n    change = mmphi_augmented - mmphi_initial\n    \n    print(f\"{name}:\")\n    print(f\"  Description: {scenario_details['description']}\")\n    print(f\"  New Point Added: {new_point}\")\n    # print(f\"  Augmented Design (5 points):\\n{X_augmented}\") # Optional: print full matrix\n    print(f\"  Morris-Mitchell Criterion (Phi_q): {mmphi_augmented:.4f}\")\n    print(f\"  Change from Initial Phi_q: {change:+.4f}\\n\")\n    \n    results_summary.append({\n        \"Scenario\": name,\n        \"Initial Phi_q\": mmphi_initial,\n        \"Augmented Phi_q\": mmphi_augmented,\n        \"Change\": change\n    })\n\nScenario 1: Add to Center:\n  Description: Adding a point in the center of the grid.\n  New Point Added: [[0.5 0.5]]\n  Morris-Mitchell Criterion (Phi_q): 3.6056\n  Change from Initial Phi_q: +1.3695\n\nScenario 2: Add Close to Existing (Cluster):\n  Description: Adding a point very close to an existing point (0,0).\n  New Point Added: [[0.1 0.1]]\n  Morris-Mitchell Criterion (Phi_q): 7.6195\n  Change from Initial Phi_q: +5.3834\n\nScenario 3: Add on Edge:\n  Description: Adding a point on an edge between (0,0) and (1,0).\n  New Point Added: [[0.5 0. ]]\n  Morris-Mitchell Criterion (Phi_q): 3.8210\n  Change from Initial Phi_q: +1.5849\n\n\n\n\nnum_designs = len(augmented_designs_for_plotting)\ncols = 2\nrows = int(np.ceil(num_designs / cols))\n\nfig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\naxes = axes.ravel() \n\nplot_idx = 0\n# Plot initial design first\nax = axes[plot_idx]\nax.scatter(X_initial[:, 0], X_initial[:, 1], s=100, edgecolors='k', alpha=0.7, label=\"Original Points\")\nax.set_title(f\"Initial Design\\nPhi_q = {mmphi_initial:.3f}\", fontsize=10)\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.set_xlim(-0.1, 1.1)\nax.set_ylim(-0.1, 1.1)\nax.set_aspect('equal', adjustable='box')\nax.grid(True, linestyle='--', alpha=0.6)\nax.legend(fontsize='small')\nplot_idx +=1\n\n# Plot augmented designs\nfor name, X_design in augmented_designs_for_plotting.items():\n    if name == \"Initial Design\":\n        continue # Already plotted\n\n    ax = axes[plot_idx]\n    # Highlight original vs new point\n    original_points = X_design[:-1, :]\n    new_point = X_design[-1, :].reshape(1,2)\n    \n    ax.scatter(original_points[:, 0], original_points[:, 1], s=100, edgecolors='k', alpha=0.7, label=\"Original Points\")\n    ax.scatter(new_point[:, 0], new_point[:, 1], s=150, color='red', edgecolors='k', marker='X', label=\"Added Point\")\n    \n    current_phi_q = next(item['Augmented Phi_q'] for item in results_summary if item[\"Scenario\"] == name)\n    ax.set_title(f\"{name}\\nPhi_q = {current_phi_q:.3f}\", fontsize=10)\n    ax.set_xlabel(\"X1\")\n    ax.set_ylabel(\"X2\")\n    ax.set_xlim(-0.1, 1.1)\n    ax.set_ylim(-0.1, 1.1)\n    ax.set_aspect('equal', adjustable='box')\n    ax.grid(True, linestyle='--', alpha=0.6)\n    ax.legend(fontsize='small')\n    plot_idx +=1\n    \n# Hide any unused subplots\nfor j in range(plot_idx, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\nplt.suptitle(f\"Impact of Adding a Point to a 2x2 Grid Design (q={q}, p={p})\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\nSummary Table (Conceptual):\n\n\n\n\n\n\n\n\n\nScenario\nInitial Phi_q\nAugmented Phi_q\nChange\n\n\n\n\nBaseline (2x2 Grid)\n2.236\n—\n—\n\n\nScenario 1: Add to Center\n2.236\n3.606\n+1.369\n\n\nScenario 2: Add Close to Existing (Cluster)\n2.236\n7.619\n+5.383\n\n\nScenario 3: Add on Edge\n2.236\n3.821\n+1.585",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#a-sample-size-invariant-version-of-the-morris-mitchell-criterion",
    "href": "001_sampling.html#a-sample-size-invariant-version-of-the-morris-mitchell-criterion",
    "title": "3  Sampling Plans",
    "section": "3.5 A Sample-Size Invariant Version of the Morris-Mitchell Criterion",
    "text": "3.5 A Sample-Size Invariant Version of the Morris-Mitchell Criterion\n\n3.5.1 Comparison of mmphi() and mmphi_intensive()\nThe Morris-Mitchell criterion is a widely used metric for evaluating the space-filling properties of Latin hypercube sampling designs. However, it is sensitive to the number of points in the design, which can lead to misleading comparisons between designs with different sample sizes. To address this issue, a sample-size invariant version of the Morris-Mitchell criterion has been proposed. It is avaiable in the spotpython package as mmphi_intensive(), see [SOURCE].\nThe functions mmphi() and mmphi_intensive() both calculate a Morris-Mitchell criterion, but they differ in their normalization, which makes mmphi_intensive() invariant to the sample size.\nLet \\(X\\) be a sampling plan with \\(n\\) points \\(\\{x_1, x_2, \\dots, x_n\\}\\) in a \\(k\\)-dimensional space. Let \\(d_{ij} = \\|x_i - x_j\\|_p\\) be the \\(p\\)-norm distance between points \\(x_i\\) and \\(x_j\\). Let \\(J_l\\) be the multiplicity of the \\(l\\)-th unique distance \\(d_l\\) among all pairs of points in \\(X\\). Let \\(m\\) be the total number of unique distances.\n1. mmphi() (Morris-Mitchell Criterion \\(\\Phi_q\\))\nThe mmphi() function, as defined in the context and implemented in sampling.py, calculates the Morris-Mitchell criterion \\(\\Phi_q\\) as:\n\\[\n\\Phi_q(X) = \\left( \\sum_{l=1}^{m} J_l d_l^{-q} \\right)^{1/q},\n\\] where:\n\n\\(J_l\\) is the number of pairs of points separated by the unique distance \\(d_l\\).\n\\(d_l\\) are the unique pairwise distances.\n\\(q\\) is a user-defined exponent (typically \\(q &gt; 0\\)).\n\nThis formulation is directly based on the sum of inverse powers of distances. The value of \\(\\Phi_q\\) is generally dependent on the number of points \\(n\\) in the design \\(X\\), as the sum \\(\\sum J_l d_l^{-q}\\) will typically increase with more points (and thus more pairs).\n2. mmphi_intensive() (Intensive Morris-Mitchell Criterion)\nThe mmphi_intensive() function, as implemented in sampling.py calculates a sample-size invariant version of the Morris-Mitchell criterion, which will be referred to as \\(\\Phi_q^{I}\\). The formula is:\n\\[\n\\Phi_q^{I}(X) = \\left( \\frac{1}{M} \\sum_{l=1}^{m} J_l d_l^{-q} \\right)^{1/q}\n\\]\nwhere:\n\n\\(M = \\binom{n}{2} = \\frac{n(n-1)}{2}\\) is the total number of unique pairs of points in the design \\(X\\).\nThe other terms \\(J_l\\), \\(d_l\\), \\(q\\) are the same as in mmphi().\n\nThe key mathematical difference is the normalization factor \\(\\frac{1}{M}\\) inside the parentheses before the outer exponent \\(1/q\\) is applied.\n\nmmphi(): Calculates \\(\\left( \\text{SumTerm} \\right)^{1/q}\\), where SumTerm = \\(\\sum J_l d_l^{-q}\\).\nmmphi_intensive(): Calculates \\(\\left( \\frac{\\text{SumTerm}}{M} \\right)^{1/q}\\).\n\nBy dividing the sum \\(\\sum J_l d_l^{-q}\\) by \\(M\\) (the total number of pairs), mmphi_intensive() effectively calculates an average contribution per pair to the \\(-q\\)-th power of distance, before taking the \\(q\\)-th root. This normalization makes the criterion less dependent on the absolute number of points \\(n\\) and allows for more meaningful comparisons of space-fillingness between designs of different sizes. A smaller value indicates a better (more space-filling) design for both criteria.\n\n\n3.5.2 Plotting the Two Morris-Mitchell Criteria for Different Sample Sizes\nFigure 3.11 shows the comparison of the two Morris-Mitchell criteria for different sample sizes using the plot_mmphi_vs_n_lhs function. The red line represents the standard Morris-Mitchell criterion, while the blue line represents the sample-size invariant version. Note the difference in the y-axis scales, which highlights how the sample-size invariant version remains consistent across varying sample sizes.\n\ndef plot_mmphi_vs_n_lhs(k_dim: int, \n                        seed: int, \n                        n_min: int = 10, \n                        n_max: int = 100, \n                        n_step: int = 5,\n                        q_phi: float = 2.0, \n                        p_phi: float = 2.0):\n    \"\"\"\n    Generates LHS designs for varying n, calculates mmphi and mmphi_intensive,\n    and plots them against the number of samples (n).\n\n    Args:\n        k_dim (int): Number of dimensions for the LHS design.\n        seed (int): Random seed for reproducibility.\n        n_min (int): Minimum number of samples.\n        n_max (int): Maximum number of samples.\n        n_step (int): Step size for increasing n.\n        q_phi (float): Exponent q for the Morris-Mitchell criteria.\n        p_phi (float): Distance norm p for the Morris-Mitchell criteria.\n    \"\"\"\n    n_values = list(range(n_min, n_max + 1, n_step))\n    if not n_values:\n        print(\"Warning: n_values list is empty. Check n_min, n_max, and n_step.\")\n        return\n    mmphi_results = []\n    mmphi_intensive_results = []\n    lhs_generator = SpaceFilling(k=k_dim, seed=seed)\n    print(f\"Calculating for n from {n_min} to {n_max} with step {n_step}...\")\n    for n_points in n_values:\n        if n_points &lt; 2 : # mmphi requires at least 2 points to calculate distances\n            print(f\"Skipping n={n_points} as it's less than 2.\")\n            mmphi_results.append(np.nan)\n            mmphi_intensive_results.append(np.nan)\n            continue\n        try:\n            X_design = lhs_generator.generate_qms_lhs_design(n_points=n_points)\n            phi = mmphi(X_design, q=q_phi, p=p_phi)\n            phi_intensive, _, _ = mmphi_intensive(X_design, q=q_phi, p=p_phi)\n            mmphi_results.append(phi)\n            mmphi_intensive_results.append(phi_intensive)\n        except Exception as e:\n            print(f\"Error calculating for n={n_points}: {e}\")\n            mmphi_results.append(np.nan)\n            mmphi_intensive_results.append(np.nan)\n\n    fig, ax1 = plt.subplots(figsize=(9, 6))\n\n    color = 'tab:red'\n    ax1.set_xlabel('Number of Samples (n)')\n    ax1.set_ylabel('mmphi (Phiq)', color=color)\n    ax1.plot(n_values, mmphi_results, color=color, marker='o', linestyle='-', label='mmphi (Phiq)')\n    ax1.tick_params(axis='y', labelcolor=color)\n    ax1.grid(True, linestyle='--', alpha=0.7)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n    color = 'tab:blue'\n    ax2.set_ylabel('mmphi_intensive (PhiqI)', color=color)  # we already handled the x-label with ax1\n    ax2.plot(n_values, mmphi_intensive_results, color=color, marker='x', linestyle='--', label='mmphi_intensive (PhiqI)')\n    ax2.tick_params(axis='y', labelcolor=color)\n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    plt.title(f'Morris-Mitchell Criteria vs. Number of Samples (n)\\nLHS (k={k_dim}, q={q_phi}, p={p_phi})')\n    # Add legends\n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines + lines2, labels + labels2, loc='best')\n    plt.show()\n\n\nN_DIM = 2\nRANDOM_SEED = 42\nplot_mmphi_vs_n_lhs(k_dim=N_DIM, seed=RANDOM_SEED, n_min=10, n_max=100, n_step=5)\n\nCalculating for n from 10 to 100 with step 5...\n\n\n\n\n\n\n\n\nFigure 3.11: Comparison of the two Morris-Mitchell Criteria for Different Sample Sizes",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#jupyter-notebook",
    "href": "001_sampling.html#jupyter-notebook",
    "title": "3  Sampling Plans",
    "section": "3.6 Jupyter Notebook",
    "text": "3.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html",
    "href": "006_constructing_surrogate.html",
    "title": "4  Constructing a Surrogate",
    "section": "",
    "text": "4.1 Stage One: Preparing the Data and Choosing a Modelling Approach\nThis black box could take the form of either a physical or computer experiment, for example, a finite element code, which calculates the maximum stress (\\(\\sigma\\)) for given product dimensions (\\(\\vec{x}\\)).\nThe first step is the identification, through a small number of observations, of the inputs that have a significant impact on \\(f\\); that is the determination of the shortest design variable vector \\(\\vec{x} = \\{x_1, x_2, \\ldots, x_k\\}^T\\) that, by sweeping the ranges of all of its variables, can still elicit most of the behavior the black box is capable of. The ranges of the various design variables also have to be established at this stage.\nThe second step is to recruit \\(n\\) of these \\(k\\)-vectors into a list \\[\nX = \\{ \\vec{x}^{(1)},\\vec{x}^{(2)}, \\ldots, \\vec{x}^{(n)} \\}^T,\n\\] where each \\(\\vec{x}^{(i)}\\) is a \\(k\\)-vector. The corresponding responses are collected in a vector such that this represents the design space as thoroughly as possible.\nIn the surrogate modeling process, the number of samples \\(n\\) is often limited, as it is constrained by the computational cost (money and/or time) associated with obtaining each observation.\nIt is advisable to scale \\(\\vec{x}\\) at this stage into the unit cube \\([0, 1]^k\\), a step that can simplify the subsequent mathematics and prevent multidimensional scaling issues.\nWe now focus on the attempt to learn \\(f\\) through data pairs \\[\n\\{ (\\vec{x}^{(1)}, y^{(1)}), (\\vec{x}^{(2)}, y^{(2)}), \\ldots, (\\vec{x}^{(n)}, y^{(n)}) \\}.\n\\]\nThis supervised learning process essentially involves searching across the space of possible functions \\(\\hat{f}\\) that would replicate observations of \\(f\\). This space of functions is infinite. Any number of hypersurfaces could be drawn to pass through or near the known observations, accounting for experimental error. However, most of these would generalize poorly; they would be practically useless at predicting responses at new sites, which is the ultimate goal.\nThere are countless other configurations, perhaps less contrived, that still generalize poorly. This suggests a need for systematic means to filter out nonsensical predictors. In our approach, we embed the structure of \\(f\\) into the model selection algorithm and search over its parameters to fine-tune the approximation to observations. For instance, consider one of the simplest models, \\[\nf(x, \\vec{w}) = \\vec{w}^T\\vec{x} + v.\n\\tag{4.1}\\] Learning \\(f\\) with this model implies that its structure—a hyperplane—is predetermined, and the fitting process involves finding the \\(k + 1\\) parameters (the slope vector \\(\\vec{w}\\) and the intercept \\(v\\)) that best fit the data. This will be accomplished in Stage Two.\nComplicating this further is the noise present in observed responses (we assume design vectors \\(\\vec{x}\\) are not corrupted). Here, we focus on learning from such data, which sometimes risks overfitting.\nIn the surrogate modeling process, the second stage as described in Section 4.2, addresses this issue of complexity control by estimating the parameters of the fixed structure model. However, foresight is necessary even at the model type selection stage.\nModel selection often involves physics-based considerations, where the modeling technique is chosen based on expected underlying responses.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#stage-one-preparing-the-data-and-choosing-a-modelling-approach",
    "href": "006_constructing_surrogate.html#stage-one-preparing-the-data-and-choosing-a-modelling-approach",
    "title": "4  Constructing a Surrogate",
    "section": "",
    "text": "Example 4.1 (The Needle(s) in the Haystack Function) An extreme example is the ‘needle(s) in the haystack’ function:\n\\[\nf(x) = \\begin{cases}\ny^{(1)}, & \\text{if } x = \\vec{x}^{(1)} \\\\\ny^{(2)}, & \\text{if } x = \\vec{x}^{(2)} \\\\\n\\vdots & \\\\\ny^{(n)}, & \\text{if } x = \\vec{x}^{(n)} \\\\\n0, & \\text{otherwise.}\n\\end{cases}\n\\]\nWhile this predictor reproduces all training data, it seems counter-intuitive and unsettling to predict 0 everywhere else for most engineering functions. Although there is a small chance that the function genuinely resembles the equation above and we sampled exactly where the needles are, it is highly unlikely.\n\n\n\n\nDefinition 4.3 (Overfitting) Overfitting occurs when the model becomes too flexible and captures not only the underlying trend but also the noise in the data.\n\n\n\n\nExample 4.2 (Model Selection) Modeling stress in an elastically deformed solid due to small strains may justify using a simple linear approximation. Without insights into the physics, and if one fails to account for the simplicity of the data, a more complex and excessively flexible model may be incorrectly chosen. Although parameter estimation might still adjust the approximation to become linear, an opportunity to develop a simpler and robust model may be lost.\n\nSimple linear (or polynomial) models, despite their lack of flexibility, have advantages like applicability in further symbolic computations.\nConversely, if we incorrectly assume a quadratic process when multiple peaks and troughs exist, the parameter estimation stage will not compensate for an unsuitable model choice. A quadratic model is too rigid to fit a multimodal function, regardless of parameter adjustments.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#sec-stage-two",
    "href": "006_constructing_surrogate.html#sec-stage-two",
    "title": "4  Constructing a Surrogate",
    "section": "4.2 Stage Two: Parameter Estimation and Training",
    "text": "4.2 Stage Two: Parameter Estimation and Training\nAssuming that Stage One helped identify the \\(k\\) critical design variables, acquire the learning data set, and select a generic model structure \\(f(\\vec{x}, \\vec{w})\\), the task now is to estimate parameters \\(\\vec{w}\\) to ensure the model fits the data optimally. Among several estimation criteria, we will discuss two methods here.\n\nDefinition 4.4 (Maximum Likelihood Estimation) Given a set of parameters \\(\\vec{w}\\), the model \\(f(\\vec{x}, \\vec{w})\\) allows computation of the probability of the data set \\[\n\\{(\\vec{x}^{(1)}, y^{(1)} \\pm \\epsilon), (\\vec{x}^{(2)}, y^{(2)} \\pm \\epsilon), \\ldots, (\\vec{x}^{(n)}, y^{(n)} \\pm \\epsilon)\\}\n\\] resulting from \\(f\\) (where \\(\\epsilon\\) is a small error margin around each data point).\n\n\n\n\n\n\n\nNoteMaximum Likelihood Estimation\n\n\n\n?sec-max-likelihood presents a more detailed discussion of the maximum likelihood estimation (MLE) method.\n\n\nTaking ?eq-likelihood-mvn and assuming errors \\(\\epsilon\\) are independently and normally distributed with standard deviation \\(\\sigma\\), the probability of the data set is given by:\n\\[\nP = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp \\left[ -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} \\left( y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w}) \\right)^2 \\epsilon \\right].\n\\]\nIntuitively, this is equivalent to the likelihood of the parameters given the data. Accepting this intuitive relationship as a mathematical one aids in model parameter estimation. This is achieved by maximizing the likelihood or, more conveniently, minimizing the negative of its natural logarithm:\n\\[\n\\min_{\\vec{w}} \\sum_{i=1}^{n} \\frac{[y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w})]^2}{2\\sigma^2} + \\frac{n}{2} \\ln \\epsilon .\n\\tag{4.2}\\]\nIf we assume \\(\\sigma\\) and \\(\\epsilon\\) are constants, Equation 4.2 simplifies to the well-known least squares criterion:\n\\[\n\\min_{\\vec{w}} \\sum_{i=1}^{n} [y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w})]^2 .\n\\]\nCross-validation is another method used to estimate model performance.\n\nDefinition 4.5 (Cross-Validation) Cross-validation splits the data randomly into \\(q\\) roughly equal subsets, and then cyclically removing each subset and fitting the model to the remaining \\(q - 1\\) subsets. A loss function \\(L\\) is then computed to measure the error between the predictor and the withheld subset for each iteration, with contributions summed over all \\(q\\) iterations. More formally, if a mapping \\(\\theta: \\{1, \\ldots, n\\} \\to \\{1, \\ldots, q\\}\\) describes the allocation of the \\(n\\) training points to one of the \\(q\\) subsets and \\(f^{(-\\theta(i))}(\\vec{x})\\) is the predicted value by removing the subset \\(\\theta(i)\\) (i.e., the subset where observation \\(i\\) belongs), the cross-validation measure, used as an estimate of prediction error, is:\n\\[\nCV = \\frac{1}{n} \\sum_{i=1}^{n} L(y^{(i)}, f^{(-\\theta(i))}(\\vec{x}^{(i)})) .\n\\tag{4.3}\\]\n\nIntroducing the squared error as the loss function and considering our generic model \\(f\\) still dependent on undetermined parameters, we write Equation 4.3 as:\n\\[\nCV = \\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)} - f^{(-\\theta(i))}(\\vec{x}^{(i)})]^2 .\n\\tag{4.4}\\]\nThe extent to which Equation 4.4 is an unbiased estimator of true risk depends on \\(q\\). It is shown that if \\(q = n\\), the leave-one-out cross-validation (LOOCV) measure is almost unbiased. However, LOOCV can have high variance because subsets are very similar. (Hast17a?)) suggest using compromise values like \\(q = 5\\) or \\(q = 10\\). Using fewer subsets also reduces the computational cost of the cross-validation process, see also (arlot2010?) and (Koha95a?).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#stage-three-model-testing",
    "href": "006_constructing_surrogate.html#stage-three-model-testing",
    "title": "4  Constructing a Surrogate",
    "section": "4.3 Stage Three: Model Testing",
    "text": "4.3 Stage Three: Model Testing\nIf there is a sufficient amount of observational data, a random subset should be set aside initially for model testing. (Hast17a?) recommend setting aside approximately \\(0.25n\\) of \\(\\vec{x} \\rightarrow y\\) pairs for testing purposes. These observations must remain untouched during Stages One and Two, as their sole purpose is to evaluate the testing error—the difference between true and approximated function values at the test sites—once the model has been built. Interestingly, if the main goal is to construct an initial surrogate for seeding a global refinement criterion-based strategy (as discussed in Section 3.2 in (Forr08a?)), the model testing phase might be skipped.\nIt is noted that, ideally, parameter estimation (Stage Two) should also rely on a separate subset. However, observational data is rarely abundant enough to afford this luxury (if the function is cheap to evaluate and evaluation sites are selectable, a surrogate model might not be necessary).\nWhen data are available for model testing and the primary objective is a globally accurate model, using either a root mean square error (RMSE) metric or the correlation coefficient (\\(r^2\\)) is recommended. To test the model, a test data set of size \\(n_t\\) is used alongside predictions at the corresponding locations to calculate these metrics.\nThe RMSE is defined as follows:\n\nDefinition 4.6 (Root Mean Square Error (RMSE)) \\[\n\\text{RMSE} = \\sqrt{\\frac{1}{n_t} \\sum_{i=1}^{n_t} (y^{(i)} - \\hat{y}^{(i)})^2},\n\\]\n\nIdeally, the RMSE should be minimized, acknowledging its limitation by errors in the objective function \\(f\\) calculation. If the error level is known, like a standard deviation, the aim might be to achieve an RMSE within this value. Often, the target is an RMSE within a specific percentage of the observed data’s objective value range.\nThe squared correlation coefficient \\(r\\), see ?eq-pears-corr, between the observed \\(y\\) and predicted \\(\\hat{y}\\) values can be computed as:\n\\[\nr^2 = \\left( \\frac{\\text{cov}(y, \\hat{y})}{\\sqrt{\\text{var}(y)\\text{var}(\\hat{y})}} \\right)^2,\n\\tag{4.5}\\]\nEquation 4.5 and can be expanded as:\n\\[\nr^2 =\n\\left(\n\\frac{n_t \\sum_{i=1}^{n_t} y^{(i)} \\hat{y}^{(i)} - \\sum_{i=1}^{n_t} y^{(i)} \\sum_{i=1}^{n_t} \\hat{y}^{(i)}}{ \\sqrt{\\left( n_t \\sum_{i=1}^{n_t} (y^{(i)})^2 - \\left(\\sum_{i=1}^{n_t} y^{(i)}\\right)^2 \\right) \\left( n_t \\sum_{i=1}^{n_t} (\\hat{y}^{(i)})^2 - \\left(\\sum_{i=1}^{n_t} \\hat{y}^{(i)}\\right)^2 \\right)}}\n\\right)^2.\n\\]\nThe correlation coefficient \\(r^2\\) does not require scaling the data sets and only compares landscape shapes, not values. An \\(r^2 &gt; 0.8\\) typically indicates a surrogate with good predictive capability.\nThe methods outlined provide quantitative assessments of model accuracy, yet visual evaluations can also be insightful. In general, the RMSE will not reach zero but will stabilize around a low value. At this point, the surrogate model is saturated with data, and further additions do not enhance the model globally (though local improvements can occur at newly added points if using an interpolating model).\n\nExample 4.3 (The Tea and Sugar Analogy) (Forr08a?) illustrates this saturation point using a comparison with a cup of tea and sugar. The tea represents the surrogate model, and sugar represents data. Initially, the tea is unsweetened, and adding sugar increases its sweetness. Eventually, a saturation point is reached where no more sugar dissolves, and the tea cannot get any sweeter. Similarly, a more flexible model, like one with additional parameters or employing interpolation rather than regression, can increase the saturation point—akin to making a hotter cup of tea for dissolving more sugar.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#jupyter-notebook",
    "href": "006_constructing_surrogate.html#jupyter-notebook",
    "title": "4  Constructing a Surrogate",
    "section": "4.4 Jupyter Notebook",
    "text": "4.4 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html",
    "href": "005_num_rsm.html",
    "title": "5  Response Surface Methods",
    "section": "",
    "text": "5.1 What is RSM?\nThis part deals with numerical implementations of optimization methods. The goal is to understand the implementation of optimization methods and to solve real-world problems numerically and efficiently. We will focus on the implementation of surrogate models, because they are the most efficient way to solve real-world problems.\nStarting point is the well-established response surface methodology (RSM). It will be extended to the design and analysis of computer experiments (DACE). The DACE methodology is a modern extension of the response surface methodology. It is based on the use of surrogate models, which are used to replace the real-world problem with a simpler problem. The simpler problem is then solved numerically. The solution of the simpler problem is then used to solve the real-world problem.\nResponse Surface Methods (RSM) refer to a collection of statistical and mathematical tools that are valuable for developing, improving, and optimizing processes. The overarching theme of RSM involves studying how input variables that control a product or process can potentially influence a response that measures performance or quality characteristics.\nThe advantages of RSM include a rich literature, well-established methods often used in manufacturing, the importance of careful experimental design combined with a well-understood model, and the potential to add significant value to scientific inquiry, process refinement, optimization, and more. However, there are also drawbacks to RSM, such as the use of simple and crude surrogates, the hands-on nature of the methods, and the limitation of local methods.\nRSM is related to various fields, including Design of Experiments (DoE), quality management, reliability, and productivity. Its applications are widespread in industry and manufacturing, focusing on designing, developing, and formulating new products and improving existing ones, as well as from laboratory research. RSM is commonly applied in domains such as materials science, manufacturing, applied chemistry, climate science, and many others.\nAn example of RSM involves studying the relationship between a response variable, such as yield (\\(y\\)) in a chemical process, and two process variables: reaction time (\\(\\xi_1\\)) and reaction temperature (\\(\\xi_2\\)). The provided code illustrates this scenario, following a variation of the so-called “banana function.”\nIn the context of visualization, RSM offers the choice between 3D plots and contour plots. In a 3D plot, the independent variables \\(\\xi_1\\) and \\(\\xi_2\\) are represented, with \\(y\\) as the dependent variable.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef fun_rosen(x1, x2):\n    b = 10\n    return (x1-1)**2 + b*(x2-x1**2)**2\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx = np.arange(-2.0, 2.0, 0.05)\ny = np.arange(-1.0, 3.0, 0.05)\nX, Y = np.meshgrid(x, y)\nzs = np.array(fun_rosen(np.ravel(X), np.ravel(Y)))\nZ = zs.reshape(X.shape)\n\nax.plot_surface(X, Y, Z)\n\nax.set_xlabel('X1')\nax.set_ylabel('X2')\nax.set_zlabel('Y')\n\nplt.show()\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-1.0, 3.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_rosen(X1, X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y , 50)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title(\"Rosenbrock's Banana Function\")\n\nText(0.5, 1.0, \"Rosenbrock's Banana Function\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#sec-rsm-intro",
    "href": "005_num_rsm.html#sec-rsm-intro",
    "title": "5  Response Surface Methods",
    "section": "",
    "text": "contour plot example:\n\n\\(x_1\\) and \\(x_2\\) are the independent variables\n\\(y\\) is the dependent variable\n\n\n\n\nVisual inspection: yield is optimized near \\((\\xi_1. \\xi_2)\\)\n\n\n5.1.1 Visualization: Problems in Practice\n\nTrue response surface is unknown in practice\nWhen yield evaluation is not as simple as a toy banana function, but a process requiring care to monitor, reconfigure and run, it’s far too expensive to observe over a dense grid\nAnd, measuring yield may be a noisy/inexact process\nThat’s where stats (RSM) comes in\n\n\n\n5.1.2 RSM: Strategies\n\nRSMs consist of experimental strategies for\nexploring the space of the process (i.e., independent/input) variables (above \\(\\xi_1\\) and \\(\\xi2)\\)\nempirical statistical modeling targeted toward development of an appropriate approximating relationship between the response (yield) and process variables local to a study region of interest\noptimization methods for sequential refinement in search of the levels or values of process variables that produce desirable responses (e.g., that maximize yield or explain variation)\nRSM used for fitting an Empirical Model\nTrue response surface driven by an unknown physical mechanism\nObservations corrupted by noise\nHelpful: fit an empirical model to output collected under different process configurations\nConsider response \\(Y\\) that depends on controllable input variables \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\)\nRSM: Equations of the Empirical Model\n\n\\(Y=f(\\xi_1, \\xi_2, \\ldots, \\xi_m) + \\epsilon\\)\n\\(\\mathbb{E}\\{Y\\} = \\eta = f(\\xi1_1, \\xi_2, \\ldots, \\xi_m)\\)\n\\(\\epsilon\\) is treated as zero mean idiosyncratic noise possibly representing\n\ninherent variation, or\nthe effect of other systems or\nvariables not under our purview at this time\n\n\n\n\n\n5.1.3 RSM: Noise in the Empirical Model\n\nTypical simplifying assumption: \\(\\epsilon \\sim N(0,\\sigma^2)\\)\nWe seek estimates for \\(f\\) and \\(\\sigma^2\\) from noisy observations \\(Y\\) at inputs \\(\\xi\\)\n\n\n\n5.1.4 RSM: Natural and Coded Variables\n\nInputs \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\) called natural variables:\n\nexpressed in natural units of measurement, e.g., degrees Celsius, pounds per square inch (psi), etc.\n\nTransformed to coded variables \\(x_1, x_2, \\ldots, x_m\\):\n\nto mitigate hassles and confusion that can arise when working with a multitude of scales of measurement\n\nTypical Transformations offering dimensionless inputs \\(x_1, x_2, \\ldots, x_m\\)\n\nin the unit cube, or\nscaled to have a mean of zero and standard deviation of one, are common choices.\n\nEmpirical model becomes \\(\\eta = f(x_1, x_2, \\ldots, x_m)\\)\n\n\n\n5.1.5 RSM Low-order Polynomials\n\nLow-order polynomial make the following simplifying Assumptions\n\nLearning about \\(f\\) is lots easier if we make some simplifying approximations\nAppealing to Taylor’s theorem, a low-order polynomial in a small, localized region of the input (\\(x\\)) space is one way forward\nClassical RSM:\n\ndisciplined application of local analysis and\nsequential refinement of locality through conservative extrapolation\n\nInherently a hands-on process",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#first-order-models-main-effects-model",
    "href": "005_num_rsm.html#first-order-models-main-effects-model",
    "title": "5  Response Surface Methods",
    "section": "5.2 First-Order Models (Main Effects Model)",
    "text": "5.2 First-Order Models (Main Effects Model)\n\nFirst-order model (sometimes called main effects model) useful in parts of the input space where it’s believed that there’s little curvature in \\(f\\): \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\]\nFor example: \\[\\eta = 50 + 8 x_1 + 3x_2\\]\nIn practice, such a surface would be obtained by fitting a model to the outcome of a designed experiment\nFirst-Order Model in python Evaluated on a Grid\nEvaluate model on a grid in a double-unit square centered at the origin\nCoded units are chosen arbitrarily, although one can imagine deploying this approximating function nearby \\(x^{(0)} = (0,0)\\)\n\n\ndef fun_1(x1,x2):\n    return 50 + 8*x1 + 3*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-1.0, 1.0, delta)\nx2 = np.arange(-1.0, 1.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_1(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model: $50 + 8x_1 + 3x_2$')\n\nText(0.5, 1.0, 'First Order Model: $50 + 8x_1 + 3x_2$')\n\n\n\n\n\n\n\n\n\n\n5.2.1 First-Order Model Properties\n\nFirst-order model in 2d traces out a plane in \\(y \\times (x_1, x_2)\\) space\nOnly be appropriate for the most trivial of response surfaces, even when applied in a highly localized part of the input space\nAdding curvature is key to most applications:\n\nFirst-order model with interactions induces limited degree of curvature via different rates of change of \\(y\\) as \\(x_1\\) is varied for fixed \\(x_2\\), and vice versa: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_{12} \\]\n\nFor example \\(\\eta = 50+8x_1+3x_2-4x_1x_2\\)\n\n\n\n5.2.2 First-order Model with Interactions in python\n\nCode below facilitates evaluations for pairs \\((x_1, x_2)\\)\nResponses may be observed over a mesh in the same double-unit square\n\n\ndef fun_11(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_11(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model with Interactions')\n\nText(0.5, 1.0, 'First Order Model with Interactions')\n\n\n\n\n\n\n\n\n\n\n\n5.2.3 Observations: First-Order Model with Interactions\n\nMean response \\(\\eta\\) is increasing marginally in both \\(x_1\\) and \\(x_2\\), or conditional on a fixed value of the other until \\(x_1\\) is 0.75\nRate of increase slows as both coordinates grow simultaneously since the coefficient in front of the interaction term \\(x_1 x_2\\) is negative\nCompared to the first-order model (without interactions): surface is far more useful locally\nLeast squares regressions often flag up significant interactions when fit to data collected on a design far from local optima",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#second-order-models",
    "href": "005_num_rsm.html#second-order-models",
    "title": "5  Response Surface Methods",
    "section": "5.3 Second-Order Models",
    "text": "5.3 Second-Order Models\n\nSecond-order model may be appropriate near local optima where \\(f\\) would have substantial curvature: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2  + \\beta_{11}x_1^2 + \\beta_{22}x^2 + \\beta_{12} x_1 x_2\\]\nFor example \\[\\eta = 50 + 8 x_1 + 3x_2 - 7x_1^2 - 3 x_2^2 - 4x_1x_2\\]\nImplementation of the Second-Order Model as fun_2().\n\n\ndef fun_2(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 7 * x1**2 - 3*x2**2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_2(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\nText(0.5, 1.0, 'Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\n\n\n\n\n\n\n\n\n\n5.3.1 Second-Order Models: Properties\n\nNot all second-order models would have a single stationary point (in RSM jargon called “a simple maximum”)\nIn “yield maximizing” setting we’re presuming response surface is concave down from a global viewpoint\n\neven though local dynamics may be more nuanced\n\nExact criteria depend upon the eigenvalues of a certain matrix built from those coefficients\nBox and Draper (2007) provide a diagram categorizing all of the kinds of second-order surfaces in RSM analysis, where finding local maxima is the goal\n\n\n\n5.3.2 Example: Stationary Ridge\n\nExample set of coefficients describing what’s called a stationary ridge is provided by the code below\n\n\ndef fun_ridge(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Example of a stationary ridge')\n\nText(0.5, 1.0, 'Example of a stationary ridge')\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 Observations: Second-Order Model (Ridge)\n\nRidge: a whole line of stationary points corresponding to maxima\nSituation means that the practitioner has some flexibility when it comes to optimizing:\n\ncan choose the precise setting of \\((x_1, x_2)\\) either arbitrarily or (more commonly) by consulting some tertiary criteria\n\n\n\n\n5.3.4 Example: Rising Ridge\n\nAn example of a rising ridge is implemented by the code below.\n\n\ndef fun_ridge_rise(x1, x2):\n     return 80 - 4*x1 + 12*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge_rise(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n5.3.5 Summary: Rising Ridge\n\nThe stationary point is remote to the study region\nCcontinuum of (local) stationary points along any line going through the 2d space, excepting one that lies directly on the ridge\nAlthough estimated response will increase while moving along the axis of symmetry toward its stationary point, this situation indicates\n\neither a poor fit by the approximating second-order function, or\nthat the study region is not yet precisely in the vicinity of a local optima—often both.\n\n\n\n\n5.3.6 Falling Ridge\n\nInversion of a rising ridge is a falling ridge\nSimilarly indicating one is far from local optima, except that the response decreases as you move toward the stationary point\nFinding a falling ridge system can be a back-to-the-drawing-board affair.\n\n\n\n5.3.7 Saddle Point\n\nFinally, we can get what’s called a saddle or minimax system.\n\n\ndef fun_saddle(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 2*x2**2 - 12*x1*x2 \n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_saddle(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n5.3.8 Interpretation: Saddle Points\n\nLikely further data collection, and/or outside expertise, is needed before determining a course of action in this situation\n\n\n\n5.3.9 Summary: Ridge Analysis\n\nFinding a simple maximum, or stationary ridge, represents ideals in the spectrum of second-order approximating functions\nBut getting there can be a bit of a slog\nUsing models fitted from data means uncertainty due to noise, and therefore uncertainty in the type of fitted second-order model\nA ridge analysis attempts to offer a principled approach to navigating uncertainties when one is seeking local maxima\nThe two-dimensional setting exemplified above is convenient for visualization, but rare in practice\nComplications compound when studying the effect of more than two process variables",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-rsm-models",
    "href": "005_num_rsm.html#general-rsm-models",
    "title": "5  Response Surface Methods",
    "section": "5.4 General RSM Models",
    "text": "5.4 General RSM Models\n\nGeneral first-order model on \\(m\\) process variables \\(x_1, x_2, \\cdots, x_m\\) is \\[\\eta = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_m x_m\\]\nGeneral second-order model on \\(m\\) process variables \\[\n\\eta= \\beta_0 + \\sum_{j=1}^m + \\sum_{j=1}^m x_j^2 + \\sum_{j=2}^m \\sum_{k=1}^j \\beta_{kj}x_k x_j.\n\\]\n\n\n5.4.1 Ordinary Least Squares\n\nInference from data is carried out by ordinary least squares (OLS)\nFor an excellent review including R examples, see Sheather (2009)\nOLS and maximum likelihood estimators (MLEs) are in the typical Gaussian linear modeling setup basically equivalent",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-linear-regression",
    "href": "005_num_rsm.html#general-linear-regression",
    "title": "5  Response Surface Methods",
    "section": "5.5 General Linear Regression",
    "text": "5.5 General Linear Regression\nWe are considering a model, which can be written in the form\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\) is an \\((n \\times 1)\\) vector of observations (responses), \\(X\\) is an \\((n \\times p)\\) matrix of known form, \\(\\beta\\) is a \\((1 \\times p)\\) vector of unknown parameters, and \\(\\epsilon\\) is an \\((n \\times 1)\\) vector of errors. Furthermore, \\(E(\\epsilon) = 0\\), \\(Var(\\epsilon) = \\sigma^2 I\\) and the \\(\\epsilon_i\\) are uncorrelated.\nUsing the normal equations \\[\n(X'X)b = X'Y,\n\\]\nthe solution is given by\n\\[\nb = (X'X)^{-1}X'Y.\n\\]\n\nExample 5.1 (Linear Regression)  \n\nimport numpy as np\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\nprint(np.round(X, 2))\ny = np.sin(X)\nprint(np.round(y, 2))\n# fit an OLS model to the data, predict the response based on the 1ßß x values\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X, y)\ny_pred = model.predict(x)\n# visualize the data and the fitted model\nimport matplotlib.pyplot as plt\nplt.scatter(X, y, color='black')\nplt.plot(x, y_pred, color='blue', linewidth=1)\n# add the ground truth (sine function) in orange\nplt.plot(x, np.sin(x), color='orange', linewidth=1)\nplt.show()\n\n[[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\n[[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#designs",
    "href": "005_num_rsm.html#designs",
    "title": "5  Response Surface Methods",
    "section": "5.6 Designs",
    "text": "5.6 Designs\n\nImportant: Organize the data collection phase of a response surface study carefully\nDesign: choice of \\(x\\)’s where we plan to observe \\(y\\)’s, for the purpose of approximating \\(f\\)\nAnalyses and designs need to be carefully matched\nWhen using a first-order model, some designs are preferred over others\nWhen using a second-order model to capture curvature, a different sort of design is appropriate\nDesign choices often contain features enabling modeling assumptions to be challenged\n\ne.g., to check if initial impressions are supported by the data ultimately collected\n\n\n\n5.6.1 Different Designs\n\nScreening desings: determine which variables matter so that subsequent experiments may be smaller and/or more focused\nThen there are designs tailored to the form of model (first- or second-order, say) in the screened variables\nAnd then there are more designs still",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-experimentation",
    "href": "005_num_rsm.html#rsm-experimentation",
    "title": "5  Response Surface Methods",
    "section": "5.7 RSM Experimentation",
    "text": "5.7 RSM Experimentation\n\n5.7.1 First Step\n\nRSM-based experimentation begins with a first-order model, possibly with interactions\nPresumption: current process operating far from optimal conditions\nCollect data and apply method of steepest ascent (gradient) on fitted surfaces to move to the optimum\n\n\n\n5.7.2 Second Step\n\nEventually, if all goes well after several such carefully iterated refinements, second-order models are used on appropriate designs in order to zero-in on ideal operating conditions\nCareful analysis of the fitted surface:\n\nRidge analysis with further refinement using gradients of, and\nstandard errors associated with, the fitted surfaces, and so on\n\n\n\n\n5.7.3 Third Step\n\nOnce the practitioner is satisfied with the full arc of\n\ndesign(s),\nfit(s), and\ndecision(s):\n\nA small experiment called confirmation test may be performed to check if the predicted optimal settings are realizable in practice",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-review-and-general-considerations",
    "href": "005_num_rsm.html#rsm-review-and-general-considerations",
    "title": "5  Response Surface Methods",
    "section": "5.8 RSM: Review and General Considerations",
    "text": "5.8 RSM: Review and General Considerations\n\nFirst Glimpse, RSM seems sensible, and pretty straightforward as quantitative statistics-based analysis goes\nBut: RSM can get complicated, especially when input dimensions are not very low\nDesign considerations are particularly nuanced, since the goal is to obtain reliable estimates of main effects, interaction, and curvature while minimizing sampling effort/expense\nRSM Downside: Inefficiency\n\nDespite intuitive appeal, several RSM downsides become apparent upon reflection\nProblems in practice\nStepwise nature of sequential decision making is inefficient:\n\nNot obvious how to re-use or update analysis from earlier phases, or couple with data from other sources/related experiments\n\n\nRSM Downside: Locality\n\nIn addition to being local in experiment-time (stepwise approach), it’s local in experiment-space\nBalance between\n\nexploration (maybe we’re barking up the wrong tree) and\nexploitation (let’s make things a little better) is modest at best\n\n\nRSM Downside: Expert Knowledge\n\nInterjection of expert knowledge is limited to hunches about relevant variables (i.e., the screening phase), where to initialize search, how to design the experiments\nYet at the same time classical RSMs rely heavily on constant examination throughout stages of modeling and design and on the instincts of seasoned practitioners\n\nRSM Downside: Replicability\n\nParallel analyses, conducted according to the same best intentions, rarely lead to the same designs, model fits and so on\nSometimes that means they lead to different conclusions, which can be cause for concern\n\n\n\n5.8.1 Historical Considerations about RSM\n\nIn spite of those criticisms, however, there was historically little impetus to revise the status quo\nClassical RSM was comfortable in its skin, consistently led to improvements or compelling evidence that none can reasonably be expected\nBut then in the late 20th century came an explosive expansion in computational capability, and with it a means of addressing many of those downsides\n\n\n\n5.8.2 Status Quo\n\nNowadays, field experiments and statistical models, designs and optimizations are coupled with with mathematical models\nSimple equations are not regarded as sufficient to describe real-world systems anymore\nPhysicists figured that out fifty years ago; industrial engineers followed, biologists, social scientists, climate scientists and weather forecasters, etc.\nSystems of equations are required, solved over meshes (e.g., finite elements), or stochastically interacting agents\nGoals for those simulation experiments are as diverse as their underlying dynamics\nOptimization of systems is common, e.g., to identify worst-case scenarios\n\n\n\n5.8.3 The Role of Statistics\n\nSolving systems of equations, or interacting agents, requires computing\nStatistics involved at various stages:\n\nchoosing the mathematical model\nsolving by stochastic simulation (Monte Carlo)\ndesigning the computer experiment\nsmoothing over idiosyncrasies or noise\nfinding optimal conditions, or\ncalibrating mathematical/computer models to data from field experiments\n\n\n\n\n5.8.4 New RSM is needed: DACE\n\nClassical RSMs are not well-suited to any of those tasks, because\n\nthey lack the fidelity required to model these data\ntheir intended application is too local\nthey’re also too hands-on.\n\nOnce computers are involved, a natural inclination is to automate—to remove humans from the loop and set the computer running on the analysis in order to maximize computing throughput, or minimize idle time\nDesign and Analysis of Computer Experiments as a modern extension of RSM\nExperimentation is changing due to advances in machine learning\nGaussian process (GP) regression is the canonical surrogate model\nOrigins in geostatistics (gold mining)\nWide applicability in contexts where prediction is king\nMachine learners exposed GPs as powerful predictors for all sorts of tasks:\nfrom regression to classification,\nactive learning/sequential design,\nreinforcement learning and optimization,\nlatent variable modeling, and so on",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#exercises",
    "href": "005_num_rsm.html#exercises",
    "title": "5  Response Surface Methods",
    "section": "5.9 Exercises",
    "text": "5.9 Exercises\n\nGenerate 3d Plots for the Contour Plots in this notebook.\nWrite a plot_3d function, that takes the objective function fun as an argument.\n\n\nIt should provide the following interface: plot_3d(fun).\n\n\nWrite a plot_contour function, that takes the objective function fun as an argument:\n\n\nIt should provide the following interface: plot_contour(fun).\n\n\nConsider further arguments that might be useful for both function, e.g., ranges, size, etc.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#jupyter-notebook",
    "href": "005_num_rsm.html#jupyter-notebook",
    "title": "5  Response Surface Methods",
    "section": "5.10 Jupyter Notebook",
    "text": "5.10 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html",
    "href": "006_num_poly.html",
    "title": "6  Polynomial Models",
    "section": "",
    "text": "6.1 Fitting a Polynomial\nWe will consider one-variable cases, i.e., \\(k=1\\), first.\nLet us consider the scalar-valued function \\(f: \\mathbb{R} \\to \\mathbb{R}\\) observed according to the sampling plan \\(X = \\{x^{(1)}, x^{(2)} \\dots, x^{(n)}\\}^T\\), yielding the responses \\(\\vec{y} = \\{y^{(1)}, y^{(2)}, \\dots, y^{(n)}\\}^T\\).\nA polynomial approximation of \\(f\\) of order \\(m\\) can be written as:\n\\[\n\\hat{f}(x, m, \\vec{w}) = \\sum_{i=0}^m w_i x^i.\n\\]\nIn the spirit of the earlier discussion of maximum likelihood parameter estimation, we seek to estimate \\(w = {w_0, w_1, \\dots, w_m}^T\\) through a least squares solution of:\n\\[\n\\Phi \\vec{w} = \\vec{y}\n\\] where \\(\\Phi\\) is the Vandermonde matrix:\n\\[\n\\Phi =\n\\begin{bmatrix}\n1 & x_1 & x_1^2 & \\dots & x_1^m \\\\\n1 & x_2 & x_2^2 & \\dots & x_2^m \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_n & x_n^2 & \\dots & x_n^m\n\\end{bmatrix}.\n\\]\nThe maximum likelihood estimate of \\(w\\) is given by:\n\\[\n\\vec{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T y,\n\\]\nwhere \\(\\Phi^+ = (\\Phi^T \\Phi)^{-1} \\Phi^T\\) is the Moore-Penrose pseudo-inverse of \\(\\Phi\\) (see Section 9.3).\nThe polynomial approximation of order \\(m\\) is essentially a truncated Taylor series expansion. While higher values of \\(m\\) yield more accurate approximations, they risk overfitting the noise in the data.\nTo prevent this, we estimate \\(m\\) using cross-validation. This involves minimizing the cross-validation error over a discrete set of possible orders \\(m\\) (e.g., \\(m \\in {1, 2, \\dots, 15}\\)).\nFor each \\(m\\), the data is split into \\(q\\) subsets. The model is trained on \\(q-1\\) subsets, and the error is computed on the left-out subset. This process is repeated for all subsets, and the cross-validation error is summed. The order \\(m\\) with the smallest cross-validation error is chosen.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#polynomial-fitting-in-python",
    "href": "006_num_poly.html#polynomial-fitting-in-python",
    "title": "6  Polynomial Models",
    "section": "6.2 Polynomial Fitting in Python",
    "text": "6.2 Polynomial Fitting in Python\n\n6.2.1 Fitting the Polynomial\n\nfrom sklearn.model_selection import KFold\ndef polynomial_fit(X, Y, max_order=15, q=5):\n    \"\"\"\n    Fits a one-variable polynomial to one-dimensional data using cross-validation.\n\n    Args:\n        X (array-like): Training data vector (independent variable).\n        Y (array-like): Training data vector (dependent variable).\n        max_order (int): Maximum polynomial order to consider. Default is 15.\n        q (int): Number of cross-validation folds. Default is 5.\n\n    Returns:\n        best_order (int): The optimal polynomial order.\n        coeff (array): Coefficients of the best-fit polynomial.\n        mnstd (tuple): Normalization parameters (mean, std) for X.\n    \"\"\"\n    X = np.array(X)\n    Y = np.array(Y)\n    n = len(X)\n    # Normalize X\n    mnstd = (np.mean(X), np.std(X))\n    X_norm = (X - mnstd[0]) / mnstd[1]\n    # Cross-validation setup\n    kf = KFold(n_splits=q, shuffle=True, random_state=42)\n    cross_val_errors = np.zeros(max_order)\n    for order in range(1, max_order + 1):\n        fold_errors = []\n        for train_idx, val_idx in kf.split(X_norm):\n            X_train, X_val = X_norm[train_idx], X_norm[val_idx]\n            Y_train, Y_val = Y[train_idx], Y[val_idx]\n            # Fit polynomial\n            coeff = np.polyfit(X_train, Y_train, order)\n            # Predict on validation set\n            Y_pred = np.polyval(coeff, X_val)\n            # Compute mean squared error\n            mse = np.mean((Y_val - Y_pred) ** 2)\n            fold_errors.append(mse)\n        cross_val_errors[order - 1] = np.mean(fold_errors)\n    # Find the best order\n    best_order = np.argmin(cross_val_errors) + 1\n    # Fit the best polynomial on the entire dataset\n    best_coeff = np.polyfit(X_norm, Y, best_order)\n    return best_order, best_coeff, mnstd\n\n\n\n6.2.2 Explaining the \\(k\\)-fold Cross-Validation\nThe line\nkf = KFold(n_splits=q, shuffle=True, random_state=42)\ninitializes a \\(k\\)-Fold cross-validator object from the sklearn.model_selection library. The n_splits parameter specifies the number of folds. The data will be divided into q parts. In each iteration of the cross-validation, one part will be used as the validation set, and the remaining q-1 parts will be used as the training set.\nThe kf.split method takes the dataset X_norm as input and yields pairs of index arrays for each fold: * train_idx: In each iteration, train_idx is an array containing the indices of the data points that belong to the training set for that specific fold. * val_idx: Similarly, val_idx is an array containing the indices of the data points that belong to the validation (or test) set for that specific fold.\nThe loop will run q times (the number of splits). In each iteration, a different fold serves as the validation set, while the other q-1 folds form the training set.\nHere’s a Python example to demonstrate the values of train_idx and val_idx:\n\n# Sample data (e.g., X_norm)\nX_norm = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\nprint(f\"Original data indices: {np.arange(len(X_norm))}\\n\")\n# Number of splits (folds)\nq = 3 # Let's use 3 folds for this example\n# Initialize KFold\nkf = KFold(n_splits=q, shuffle=True, random_state=42)\n# Iterate through the splits and print the indices\nfold_number = 1\nfor train_idx, val_idx in kf.split(X_norm):\n    print(f\"--- Fold {fold_number} ---\")\n    print(f\"Train indices: {train_idx}\")\n    print(f\"Validation indices: {val_idx}\")\n    print(f\"Training data for this fold: {X_norm[train_idx]}\")\n    print(f\"Validation data for this fold: {X_norm[val_idx]}\\n\")\n    fold_number += 1\n\nOriginal data indices: [0 1 2 3 4 5 6 7 8 9]\n\n--- Fold 1 ---\nTrain indices: [2 3 4 6 7 9]\nValidation indices: [0 1 5 8]\nTraining data for this fold: [0.3 0.4 0.5 0.7 0.8 1. ]\nValidation data for this fold: [0.1 0.2 0.6 0.9]\n\n--- Fold 2 ---\nTrain indices: [0 1 3 4 5 6 8]\nValidation indices: [2 7 9]\nTraining data for this fold: [0.1 0.2 0.4 0.5 0.6 0.7 0.9]\nValidation data for this fold: [0.3 0.8 1. ]\n\n--- Fold 3 ---\nTrain indices: [0 1 2 5 7 8 9]\nValidation indices: [3 4 6]\nTraining data for this fold: [0.1 0.2 0.3 0.6 0.8 0.9 1. ]\nValidation data for this fold: [0.4 0.5 0.7]\n\n\n\n\n\n6.2.3 Making Predictions\nTo make predictions, we can use the coefficients. The data is standardized around its mean in the polynomial function, which is why the vector mnstd is required. The coefficient vector is computed based on the normalized data, and this must be taken into account if further analytical calculations are performed on the fitted model.\nThe polynomial approximation of \\(C_D\\) is:\n\\[\nC_D(x) = w_8 x^8 + w_7 x^7 + \\dots + w_1 x + w_0,\n\\]\nwhere \\(x\\) is normalized as:\n\\[\n\\bar{x} = \\frac{x - \\mu(X)}{\\sigma(X)}\n\\]\n\ndef predict_polynomial_fit(X, coeff, mnstd):\n    \"\"\"\n    Generates predictions for the polynomial fit.\n\n    Args:\n        X (array-like): Original independent variable data.\n        coeff (array): Coefficients of the best-fit polynomial.\n        mnstd (tuple): Normalization parameters (mean, std) for X.\n\n    Returns:\n        tuple: De-normalized predicted X values and corresponding Y predictions.\n    \"\"\"\n    # Normalize X\n    X_norm = (X - mnstd[0]) / mnstd[1]\n\n    # Generate predictions\n    X_pred = np.linspace(min(X_norm), max(X_norm), 100)\n    Y_pred = np.polyval(coeff, X_pred)\n\n    # De-normalize X for plotting\n    X_pred_original = X_pred * mnstd[1] + mnstd[0]\n\n    return X_pred_original, Y_pred\n\n\n\n6.2.4 Plotting the Results\n\ndef plot_polynomial_fit(X, Y, X_pred_original, Y_pred, best_order, y_true=None):\n    \"\"\"\n    Visualizes the polynomial fit.\n\n    Args:\n        X (array-like): Original independent variable data.\n        Y (array-like): Original dependent variable data.\n        X_pred_original (array): De-normalized predicted X values.\n        Y_pred (array): Predicted Y values.\n        y_true (array): True Y values.\n        best_order (int): The optimal polynomial order.\n    \"\"\"\n    plt.scatter(X, Y, label=\"Training Data\", color=\"grey\", marker=\"o\")\n    plt.plot(X_pred_original, Y_pred, label=f\"Order {best_order} Polynomial\", color=\"red\")\n    if y_true is not None:\n        plt.plot(X, y_true, label=\"True Function\", color=\"blue\", linestyle=\"--\")\n    plt.title(f\"Polynomial Fit (Order {best_order})\")\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.legend()\n    plt.show()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#example-one-aerofoil-drag",
    "href": "006_num_poly.html#example-one-aerofoil-drag",
    "title": "6  Polynomial Models",
    "section": "6.3 Example One: Aerofoil Drag",
    "text": "6.3 Example One: Aerofoil Drag\nThe circles in Figure 6.1 represent 101 drag coefficient values obtained through a numerical simulation by iterating each member of a family of aerofoils towards a target lift value (see the Appendix, Section A.3 in (Forr08a?)). The members of the family have different shapes, as determined by the sampling plan:\n\\[\nX = {x_1, x_2, \\dots, x_{101}}\n\\]\nThe responses are:\n\\[\nC_D = \\{C_{D}^{(1)}, C_{D}^{(2)}, \\dots, C_{D}^{(101)}\\}\n\\]\nThese responses are corrupted by “noise,” which are deviations of the systematic variety caused by small changes in the computational mesh from one design to the next.\nThe original data is measured in natural units, i.e., from \\(-0.3\\) untion to \\(0.1\\) unit. The data is normalized to the range of \\(0\\) to \\(1\\) for the computation with the aerofoilcd function. The data is then fitted with a polynomial of order \\(m\\). To obtain the best polynomial through this data, the following Python code can be used:\n\nfrom spotpython.surrogate.functions.forr08a import aerofoilcd\nimport numpy as np\nimport matplotlib.pyplot as plt\nX = np.linspace(-0.3, 0.1, 101)\n# normalize the data so that it will be in the range of 0 to 1\na = np.min(X)\nb = np.max(X)\nX_cod = (X - a) / (b - a)\ny = aerofoilcd(X_cod)\nbest_order, best_coeff, mnstd = polynomial_fit(X, y)\nX_pred_original, Y_pred = predict_polynomial_fit(X, best_coeff, mnstd)\n\n\nplot_polynomial_fit(X, y, X_pred_original, Y_pred, best_order)\n\n\n\n\n\n\n\nFigure 6.1: Aerofoil drag data\n\n\n\n\n\nFigure 6.1 shows an eighth-order polynomial fitted through the aerofoil drag data. The order was selected via cross-validation, and the coefficients were determined through likelihood maximization. Results, i.e, the best polynomial order and coefficients, are printed in the console. The coefficients are stored in the vector best_coeff, which contains the coefficients of the polynomial in descending order. The first element is the coefficient of \\(x^8\\), and the last element is the constant term. The vector mnstd, containing the mean and standard deviation of \\(X\\), is:\n\nprint(f\"Best polynomial order: {best_order}\\n\")\nprint(f\"Coefficients (starting with w0):\\n {best_coeff}\\n\")\nprint(f\"Normalization parameters (mean, std):\\n {mnstd}\\n\")\n\nBest polynomial order: 8\n\nCoefficients (starting with w0):\n [-0.00022964 -0.00014636  0.00116742  0.00052988 -0.0016912  -0.00047398\n  0.00244373  0.00270342  0.03041508]\n\nNormalization parameters (mean, std):\n (np.float64(-0.09999999999999999), np.float64(0.11661903789690602))",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#example-two-a-multimodal-test-case",
    "href": "006_num_poly.html#example-two-a-multimodal-test-case",
    "title": "6  Polynomial Models",
    "section": "6.4 Example Two: A Multimodal Test Case",
    "text": "6.4 Example Two: A Multimodal Test Case\nLet us consider the one-variable test function:\n\\[\nf(x) = (6x - 2)^2 \\sin(12x - 4).\n\\]\n\nimport numpy as np\nfrom spotpython.surrogate.functions.forr08a import onevar\nX = np.linspace(0, 1, 51)\ny_true = onevar(X)\n# initialize random seed\nnp.random.seed(42)\ny = y_true + np.random.normal(0, 1, len(X))*1.1\nbest_order, best_coeff, mnstd = polynomial_fit(X, y)\nX_pred_original, Y_pred = predict_polynomial_fit(X, best_coeff, mnstd)\n\n\nplot_polynomial_fit(X, y, X_pred_original, Y_pred, best_order, y_true=y_true)\n\n\n\n\n\n\n\nFigure 6.2: Onevar function\n\n\n\n\n\nThis function, depicted by the dotted line in Figure 6.2, has local minima of different depths, which can be deceptive to some surrogate-based optimization procedures. Here, we use it as an example of a multimodal function for polynomial fitting.\nWe generate the training data (depicted by circles in Figure 6.2) by adding normally distributed noise to the function. Figure 6.2 shows a seventh-order polynomial fitted through the noisy data. This polynomial was selected as it minimizes the cross-validation metric.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#extending-to-multivariable-polynomial-models",
    "href": "006_num_poly.html#extending-to-multivariable-polynomial-models",
    "title": "6  Polynomial Models",
    "section": "6.5 Extending to Multivariable Polynomial Models",
    "text": "6.5 Extending to Multivariable Polynomial Models\nWhile the examples above focus on the one-variable case, real-world engineering problems typically involve multiple input variables. For \\(k\\)-variable problems, polynomial approximation becomes significantly more complex but follows the same fundamental principles. For a \\(k\\)-dimensional input space, the polynomial approximation can be expressed as:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^N w_i \\phi_i(\\vec{x}),\n\\] where \\(\\phi_i(\\vec{x})\\) represents multivariate basis functions, and \\(N\\) is the total number of terms in the polynomial. Unlike the univariate case, these basis functions include all possible combinations of variables up to the selected polynomial order \\(m\\), which might result in a “basis function explosion” as the number of variables increases.\nFor a third-order polynomial (\\(m = 3\\)) with three variables (\\(k = 3\\)), the complete set of basis functions would include 20 terms:\n\\[\\begin{align}\n\\text{Constant term: } & {1} \\\\\n\\text{First-order terms: } & {x_1, x_2, x_3} \\\\\n\\text{Second-order terms: } & {x_1^2, x_2^2, x_3^2, x_1x_2, x_1x_3, x_2x_3} \\\\\n\\text{Third-order terms: } & {x_1^3, x_2^3, x_3^3, x_1^2x_2, x_1^2x_3, x_2^2x_1, x_2^2x_3, x_3^2x_1, x_3^2x_2, x_1x_2x_3}\n\\end{align}\\]\nThe total number of terms grows combinatorially as \\(N = \\binom{k+m}{m}\\), which quickly becomes prohibitive as dimensionality increases. For example, a 10-variable cubic polynomial requires \\(\\binom{13}{3} = 286\\) coefficients! This exponential growth creates three interrelated challenges:\n\nModel Selection: Determining the appropriate polynomial order \\(m\\) that balances complexity with generalization ability\nCoefficient Estimation: Computing the potentially large number of weights \\(\\vec{w}\\) while avoiding numerical instability\nTerm Selection: Identifying which specific basis functions should be included, as many may be irrelevant to the response\n\nSeveral techniques have been developed to address these challenges:\n\nRegularization methods (LASSO, ridge regression) that penalize model complexity\nStepwise regression algorithms that incrementally add or remove terms\nDimension reduction techniques that project the input space to lower dimensions\nOrthogonal polynomials that improve numerical stability for higher-order models\n\nThese limitations of polynomial models in higher dimensions motivate the exploration of more flexible surrogate modeling approaches like Radial Basis Functions and Kriging, which we’ll examine in subsequent sections.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#jupyter-notebook",
    "href": "006_num_poly.html#jupyter-notebook",
    "title": "6  Polynomial Models",
    "section": "6.6 Jupyter Notebook",
    "text": "6.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html",
    "href": "006_num_rbf.html",
    "title": "7  Radial Basis Function Models",
    "section": "",
    "text": "7.1 Radial Basis Function Models\nScientists and engineers frequently tackle complex functions by decomposing them into a “vocabulary” of simpler, well-understood basic functions. These fundamental building blocks possess properties that make them easier to analyze mathematically and implement computationally. We explored this concept earlier with multivariable polynomials, where complex behaviors were modeled using combinations of polynomial terms such as \\(1\\), \\(x_1\\), \\(x_2\\), \\(x_1^2\\), and \\(x_1 x_2\\). This approach is not limited to polynomials; it extends to various function classes, including trigonometric functions, exponential functions, and even more complex structures.\nWhile Fourier analysis—perhaps the most widely recognized example of this approach—excels at representing periodic phenomena through sine and cosine functions, the focus in (Forr08a?) is broader. They aim to approximate arbitrary smooth, continuous functions using strategically positioned basis functions. Specifically, radial basis function (RBF) models employ symmetrical basis functions centered at selected points distributed throughout the design space. These basis functions have the unique property that their output depends only on the distance from their center point.\nFirst, we give a definition of the Euclidean distance, which is the most common distance measure used in RBF models.\nThe Euclidean distance measure represents the straight-line distance between two points in Euclidean space.\nUsing the Euclidean distance, we can define the radial basis function (RBF) model.\nIn the context of RBFs, the Euclidean distance calculation determines how much influence a particular center point \\(\\vec{c}\\) has on the prediction at point \\(\\vec{x}\\).\nWe will first examine interpolating RBF models, which assume noise-free data and pass exactly through all training points. This approach provides an elegant mathematical foundation before we consider more practical scenarios where data contains measurement or process noise.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#radial-basis-function-models",
    "href": "006_num_rbf.html#radial-basis-function-models",
    "title": "7  Radial Basis Function Models",
    "section": "",
    "text": "Definition 7.1 (Euclidean Distance) The Euclidean distance between two points in a \\(k\\)-dimensional space is defined as:\n\\[\n\\|\\vec{x} - \\vec{c}\\| = \\sqrt{\\sum_{i=1}^{k} (x_i - c_i)^2},\n\\tag{7.1}\\]\nwhere:\n\n\\(\\vec{x} = (x_1, x_2, \\ldots, x_d)\\) is the first point,\n\\(\\vec{c} = (c_1, c_2, \\ldots, c_d)\\) is the second point, and\n\\(k\\) is the number of dimensions.\n\n\n\n\n\nDefinition 7.2 (Radial Basis Function (RBF)) Mathematically, a radial basis function \\(\\psi\\) can be expressed as:\n\\[\n\\psi(\\vec{x}) = \\psi(\\|\\vec{x} - \\vec{c}\\|),\n\\tag{7.2}\\] where \\(\\vec{x}\\) is the input vector, \\(\\vec{c}\\) is the center of the function, and \\(\\|\\vec{x} - \\vec{c}\\|\\) denotes the Euclidean distance between \\(\\vec{x}\\) and \\(\\vec{c}\\).\n\n\n\n\n7.1.1 Fitting Noise-Free Data\nLet us consider the scalar valued function \\(f\\) observed without error, according to the sampling plan \\(X = \\{\\vec{x}^{(1)}, \\vec{x}^{(2)}, \\ldots, \\vec{x}^{(n)}\\}^T\\), yielding the responses \\(\\vec{y} = \\{y^{(1)}, y^{(2)}, \\ldots, y^{(n)}\\}^T\\).\nFor a given set of \\(n_c\\) centers \\(\\vec{c}^{(i)}\\), we would like to express the RBF model as a linear combination of the basis functions centered at these points. The goal is to find the weights \\(\\vec{w}\\) that minimize the error between the predicted and observed values. Thus, we seek a radial basis function approximation to \\(f\\) of the fixed form:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n_c} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||),\n\\tag{7.3}\\] where\n\n\\(w_i\\) are the weights of the \\(n_c\\) basis functions,\n\\(\\vec{c}^{(i)}\\) are the \\(n_c\\) centres of the basis functions, and\n\\(\\psi\\) is a radial basis function.\n\nThe notation \\(||\\cdot||\\) denotes the Euclidean distance between two points in the design space as defined in Equation 7.1.\n\n7.1.1.1 Selecting Basis Functions: From Fixed to Parametric Forms\nWhen implementing a radial basis function model, we initially have one undetermined parameter per basis function: the weight applied to each function’s output. This simple parameterization remains true when we select from several standard fixed-form basis functions, such as:\n\nLinear (\\(\\psi(r) = r\\)): The simplest form, providing a response proportional to distance\nCubic (\\(\\psi(r) = r^3\\)): Offers stronger emphasis on points farther from the center\nThin plate spline (\\(\\psi(r) = r^2 \\ln r\\)): Models the physical bending of a thin sheet, providing excellent smoothness properties\n\nWhile these fixed basis functions are computationally efficient, they offer limited flexibility in how they generalize across the design space. For more adaptive modeling power, we can employ parametric basis functions that introduce additional tunable parameters:\n\nGaussian (\\(\\psi(r) = e^{-r^2/(2\\sigma^2)}\\)): Produces bell-shaped curves with \\(\\sigma\\) controlling the width of influence\nMultiquadric (\\(\\psi(r) = (r^2 + \\sigma^2)^{1/2}\\)): Provides broader coverage with less localized effects\nInverse multiquadric (\\(\\psi(r) = (r^2 + \\sigma^2)^{-1/2}\\)): Offers sharp peaks near centers with asymptotic behavior\n\nThe parameter \\(\\sigma\\) in these functions serves as a shape parameter that controls how rapidly the function’s influence decays with distance. This added flexibility enables significantly better generalization, particularly when modeling complex responses, though at the cost of a more involved parameter estimation process requiring optimization of both weights and shape parameters.\n\nExample 7.1 (Gaussian RBF) Using the general definition of a radial basis function (Equation 7.2), we can express the Gaussian RBF as: \\[\n\\psi(\\vec{x}) = \\exp\\left(-\\frac{\\|\\vec{x} - \\vec{c}\\|^2}{2\\sigma^2}\\right)  = \\exp\\left(-\\frac{\\sum_{j=1}^{k} (x_j - c_j)^2}{2\\sigma^2}\\right)\n\\tag{7.4}\\] where:\n\n\\(\\vec{x}\\) is the input vector,\n\\(\\vec{c}\\) is the center vector,\n\\(\\|\\vec{x} - \\vec{c}\\|\\) is the Euclidean distance between the input and center, and\n\\(\\sigma\\) is the width parameter that controls how quickly the function’s response diminishes with distance from the center.\n\nThe Gaussian RBF produces a bell-shaped response that reaches its maximum value of 1 when \\(\\vec{x} = \\vec{c}\\) and asymptotically approaches zero as the distance increases. The parameter \\(\\sigma\\) determines how “localized” the response is—smaller values create a narrower peak with faster decay, while larger values produce a broader, more gradual response across the input space. Figure 7.1 shows the Gaussian RBF for different values of \\(\\sigma\\) in an one-dimensional space. The center of the RBF is set at 0, and the width parameter \\(\\sigma\\) varies to illustrate how it affects the shape of the function.\n\ndef gaussian_rbf(x, center, sigma):\n    \"\"\"\n    Compute the Gaussian Radial Basis Function.\n\n    Args:\n        x (ndarray): Input points\n        center (float): Center of the RBF\n        sigma (float): Width parameter\n\n    Returns:\n        ndarray: RBF values\n    \"\"\"\n    return np.exp(-((x - center)**2) / (2 * sigma**2))\n\n\n\n\n\n\n\n\n\nFigure 7.1: Gaussian RBF\n\n\n\n\n\nThe sum of Gaussian RBFs can be visualized by summing the individual Gaussian RBFs centered at different points as shown in Figure 7.2. The following code snippet demonstrates how to create this plot showing the sum of three Gaussian RBFs with different centers and a common width parameter \\(\\sigma\\).\n\n\n\n\n\n\n\n\nFigure 7.2: Sum of Gaussian RBFs\n\n\n\n\n\n\n\n\n7.1.1.2 The Interpolation Condition: Elegant Solutions Through Linear Systems\nA remarkable property of radial basis function models is that regardless of which basis functions we choose—parametric or fixed—determining the weights \\(\\vec{w}\\) remains straightforward through interpolation. The core principle is elegantly simple: we require our model to exactly reproduce the observed data points:\n\\[\n\\hat{f}(\\vec{x}^{(i)}) = y^{(i)}, \\quad i = 1, 2, \\ldots, n.\n\\tag{7.5}\\]\nThis constraint produces one of the most powerful aspects of RBF modeling: while the system in Equation 7.5 is linear with respect to the weights \\(\\vec{w}\\), the resulting predictor \\(\\hat{f}\\) can capture highly nonlinear relationships in the data. The RBF approach transforms a complex nonlinear modeling problem into a solvable linear algebra problem.\nFor a unique solution to exist, we require that the number of basis functions equals the number of data points (\\(n_c = n\\)). The standard practice, which greatly simplifies implementation, is to center each basis function at a training data point, setting \\(\\vec{c}^{(i)} = \\vec{x}^{(i)}\\) for all \\(i = 1, 2, \\ldots, n\\). This choice allows us to express the interpolation condition as a compact matrix equation:\n\\[\n\\Psi \\vec{w} = \\vec{y}.\n\\]\nHere, \\(\\Psi\\) represents the Gram matrix (also called the design matrix or kernel matrix), whose elements measure the similarity between data points:\n\\[\n\\Psi_{i,j} = \\psi(||\\vec{x}^{(i)} - \\vec{x}^{(j)}||), \\quad i, j = 1, 2, \\ldots, n.\n\\]\nThe solution for the weight vector becomes:\n\\[\n\\vec{w} = \\Psi^{-1} \\vec{y}.\n\\]\nThis matrix inversion step is the computational core of the RBF model fitting process, and the numerical properties of this operation depend critically on the chosen basis function. Different basis functions produce Gram matrices with distinct conditioning properties, directly affecting both computational stability and the model’s generalization capabilities.\n\n\n\n7.1.2 Numerical Stability Through Positive Definite Matrices\nA significant advantage of Gaussian and inverse multiquadric basis functions lies in their mathematical guarantees. (vapn98a?) demonstrated that these functions always produce symmetric positive definite Gram matrices when using strictly positive definite kernels (see Section 9.4), which is a critical property for numerical reliability. Unlike other basis functions that may lead to ill-conditioned systems, these functions ensure the existence of unique, stable solutions.\nThis positive definiteness enables the use of Cholesky factorization, which offers substantial computational advantages over standard matrix inversion techniques. The Cholesky approach reduces the computational cost (reducing from \\(O(n^3)\\) to roughly \\(O(n^3/3)\\)) while significantly improving numerical stability when handling the inevitable rounding errors in floating-point arithmetic. This robustness to numerical issues explains why Gaussian and inverse multiquadric basis functions remain the preferred choice in many practical RBF implementations.\nFurthermore, the positive definiteness guarantee provides theoretical assurances about the model’s interpolation properties—ensuring that the RBF interpolant exists and is unique for any distinct set of centers. This mathematical foundation gives practitioners confidence in the method’s reliability, particularly for complex engineering applications where model stability is paramount.\nThe computational advantage stems from how a symmetric positive definite matrix \\(\\Psi\\) can be efficiently decomposed into the product of an upper triangular matrix \\(U\\) and its transpose:\n\\[\n\\Psi = U^T U.\n\\]\nThis decomposition transforms the system \\[\n\\Psi \\vec{w} = \\vec{y}\n\\] into \\[\nU^T U \\vec{w} = \\vec{y},\n\\] which can be solved through two simpler triangular systems:\n\nFirst solve \\(U^T \\vec{v} = \\vec{y}\\) for the intermediate vector \\(\\vec{v}\\)\nThen solve \\(U \\vec{w} = \\vec{v}\\) for the desired weights \\(\\vec{w}\\)\n\nIn Python implementations, this process is elegantly handled using NumPy’s or SciPy’s Cholesky decomposition functions, followed by specialized solvers that exploit the triangular structure:\nfrom scipy.linalg import cholesky, cho_solve\n# Compute the Cholesky factorization\nL = cholesky(Psi, lower=True)  # L is the lower triangular factor\nweights = cho_solve((L, True), y)  # Efficient solver for (L L^T)w = y\n\n\n7.1.3 Ill-Conditioning\nAn important numerical consideration in RBF modeling is that points positioned extremely close to each other in the input space \\(X\\) can lead to severe ill-conditioning of the Gram matrix (micc86a?). This ill-conditioning manifests as nearly linearly dependent rows and columns in \\(\\Psi\\), potentially causing the Cholesky factorization to fail.\nWhile this problem rarely arises with initial space-filling experimental designs (such as Latin Hypercube or quasi-random sequences), it frequently emerges during sequential optimization processes that adaptively add infill points in promising regions. As these clusters of points concentrate in areas of high interest, the condition number of the Gram matrix deteriorates, jeopardizing numerical stability.\nSeveral mitigation strategies exist: regularization through ridge-like penalties (modifying the standard RBF interpolation problem by adding a penalty term to the diagonal of the Gram matrix. This creates a literal “ridge” along the diagonal of the matrix), removing nearly coincident points, clustering, or applying more sophisticated approaches. One theoretically elegant solution involves augmenting non-conditionally positive definite basis functions with polynomial terms (kean05a?). This technique not only improves conditioning but also ensures polynomial reproduction properties, enhancing the approximation quality for certain function classes while maintaining numerical stability.\nBeyond determining \\(\\vec{w}\\), there is, of course, the additional task of estimating any other parameters introduced via the basis functions. A typical example is the \\(\\sigma\\) of the Gaussian basis function, usually taken to be the same for all basis functions, though a different one can be selected for each centre, as is customary in the case of the Kriging basis function, to be discussed shortly (once again, we trade additional parameter estimation complexity versus increased flexibility and, hopefully, better generalization).\n\n\n7.1.4 Parameter Optimization: A Two-Level Approach\nWhen building RBF models, we face two distinct parameter estimation challenges:\n\nDetermining the weights (\\(\\vec{w}\\)): These parameters ensure our model precisely reproduces the training data. For any fixed basis function configuration, we can calculate these weights directly through linear algebra as shown earlier.\nOptimizing shape parameters (like \\(\\sigma\\) in Gaussian RBF): These parameters control how the model generalizes to new, unseen data. Unlike weights, there’s no direct formula to find their optimal values.\n\nTo address this dual challenge, we employ a nested optimization strategy (inner and outer levels):\n\n7.1.4.1 Inner Level (\\(\\vec{w}\\))\nFor each candidate value of shape parameters (e.g., \\(\\sigma\\)), we determine the corresponding optimal weights \\(\\vec{w}\\) by solving the linear system. The estim_weights() method implements the inner level optimization by calculating the optimal weights \\(\\vec{w}\\) for a given shape parameter (\\(\\sigma\\)):\ndef estim_weights(self):\n    # [...]\n    \n    # Construct the Phi (Psi) matrix\n    self.Phi = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i+1):\n            self.Phi[i, j] = self.basis(d[i, j], self.sigma)\n            self.Phi[j, i] = self.Phi[i, j]\n    \n    # Calculate weights using appropriate method\n    if self.code == 4 or self.code == 6:\n        # Use Cholesky factorization for Gaussian or inverse multiquadric\n        try:\n            L = cholesky(self.Phi, lower=True)\n            self.weights = cho_solve((L, True), self.y)\n            self.success = True\n        except np.linalg.LinAlgError:\n            # Error handling...\n    else:\n        # Use direct solve for other basis functions\n        try:\n            self.weights = np.linalg.solve(self.Phi, self.y)\n            self.success = True\n        except np.linalg.LinAlgError:\n            # Error handling...\n    \n    return self\nThis method:\n\nCreates the Gram matrix (Phi) based on distances between points\nSolves the linear system \\(\\Psi\\vec{w} = \\vec{y}\\) for weights\nUses appropriate numerical methods based on the basis function type (Cholesky factorization or direct solve)\n\n\n\n7.1.4.2 Outer Level (\\(\\sigma\\))\nWe use cross-validation to evaluate how well the model generalizes with different shape parameter values. The outer level optimization is implemented within the fit() method, where cross-validation is used to evaluate different \\(\\sigma\\) values:\ndef fit(self):\n    if self.code &lt; 4:\n        # Fixed basis function, only w needs estimating\n        self.estim_weights()\n    else:\n        # Basis function requires a sigma, estimate first using cross-validation\n        # [...]\n        \n        # Generate candidate sigma values\n        sigmas = np.logspace(-2, 2, 30)\n        \n        # Setup cross-validation (determine number of folds)\n        # [...]\n        \n        cross_val = np.zeros(len(sigmas))\n        \n        # For each candidate sigma value\n        for sig_index, sigma in enumerate(sigmas):\n            print(f\"Computing cross-validation metric for Sigma={sigma:.4f}...\")\n            \n            # Perform k-fold cross-validation\n            for j in range(len(from_idx)):\n                # Create and fit model on training subset\n                temp_model = Rbf(\n                    X=X_orig[xs_temp],\n                    y=y_orig[xs_temp],\n                    code=self.code\n                )\n                temp_model.sigma = sigma\n                \n                # Call inner level optimization\n                temp_model.estim_weights()\n                \n                # Evaluate on held-out data\n                # [...]\n            \n        # Select best sigma based on cross-validation performance\n        min_cv_index = np.argmin(cross_val)\n        best_sig = sigmas[min_cv_index]\n        \n        # Use the best sigma for final model\n        self.sigma = best_sig\n        self.estim_weights()  # Call inner level again with optimal sigma\nThe outer level:\n\nGenerates a range of candidate \\(\\sigma\\) values\nFor each \\(\\sigma\\), performs k-fold cross-validation:\n\nCreates models on subsets of the data\nCalls the inner level method (estim_weights()) to determine weights\nEvaluates prediction quality on held-out data\n\nSelects the \\(\\sigma\\) that minimizes cross-validation error\nPerforms a final call to the inner level method with the optimal \\(\\sigma\\)\n\nThis two-level approach is particularly critical for parametric basis functions (Gaussian, multiquadric, etc.), where the wrong choice of shape parameter could lead to either overfitting (too much flexibility) or underfitting (too rigid). Cross-validation provides an unbiased estimate of how well different parameter choices will perform on new data, helping us balance the trade-off between fitting the training data perfectly and generalizing well.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#sec-rbf-python",
    "href": "006_num_rbf.html#sec-rbf-python",
    "title": "7  Radial Basis Function Models",
    "section": "7.2 Python Implementation of the RBF Model",
    "text": "7.2 Python Implementation of the RBF Model\nSection 7.2 shows a Python implementation of this parameter estimation process (based on a cross-validation routine), which will represent the surrogate, once its parameters have been estimated. The model building process is very simple.\nInstead of using a dictionary for bookkeeping, we implement a Python class Rbf that encapsulates all the necessary data and functionality. The class stores the sampling plan \\(X\\) as the X attribute and the corresponding \\(n\\)-vector of responses \\(y\\) as the y attribute. The code attribute specifies the type of basis function to be used. After fitting the model, the class will also contain the estimated parameter values \\(\\vec{w}\\) and, if a parametric basis function is used, \\(\\sigma\\). These are stored in the weights and sigma attributes respectively.\nFinally, a note on prediction error estimation. We have already indicated that the guarantee of a positive definite \\(\\Psi\\) is one of the advantages of Gaussian radial basis functions. They also possess another desirable feature: it is relatively easy to estimate their prediction error at any \\(\\vec{x}\\) in the design space. Additionally, the expectation function of the improvement in minimum (or maximum) function value with respect to the minimum (or maximum) known so far can also be calculated quite easily, both of these features being very useful when the optimization of \\(f\\) is the goal of the surrogate modelling process.\n\n7.2.1 The Rbf Class\nThe Rbf class implements the Radial Basis Function model. It encapsulates all the data and methods needed for fitting the model and making predictions.\n\nimport numpy as np\nfrom scipy.linalg import cholesky, cho_solve\nimport numpy.random as rnd\n\nclass Rbf:\n    \"\"\"Radial Basis Function model implementation.\n    \n    Attributes:\n        X (ndarray): The sampling plan (input points).\n        y (ndarray): The response vector.\n        code (int): Type of basis function to use.\n        weights (ndarray, optional): The weights vector (set after fitting).\n        sigma (float, optional): Parameter for parametric basis functions.\n        Phi (ndarray, optional): The Gram matrix (set during fitting).\n        success (bool, optional): Flag indicating successful fitting.\n    \"\"\"\n    \n    def __init__(self, X=None, y=None, code=3):\n        \"\"\"Initialize the RBF model.\n        \n        Args:\n            X (ndarray, optional):\n                The sampling plan.\n            y (ndarray, optional):\n                The response vector.\n            code (int, optional):\n                Type of basis function.\n                Default is 3 (thin plate spline).\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.code = code\n        self.weights = None\n        self.sigma = None\n        self.Phi = None\n        self.success = None\n    \n    def basis(self, r, sigma=None):\n        \"\"\"Compute the value of the basis function.\n        \n        Args:\n            r (float): Radius (distance)\n            sigma (float, optional): Parameter for parametric basis functions\n            \n        Returns:\n            float: Value of the basis function\n        \"\"\"\n        # Use instance sigma if not provided\n        if sigma is None and hasattr(self, 'sigma'):\n            sigma = self.sigma\n            \n        if self.code == 1:\n            # Linear function\n            return r\n        elif self.code == 2:\n            # Cubic\n            return r**3\n        elif self.code == 3:\n            # Thin plate spline\n            if r &lt; 1e-200:\n                return 0\n            else:\n                return r**2 * np.log(r)\n        elif self.code == 4:\n            # Gaussian\n            return np.exp(-(r**2)/(2*sigma**2))\n        elif self.code == 5:\n            # Multi-quadric\n            return (r**2 + sigma**2)**0.5\n        elif self.code == 6:\n            # Inverse Multi-Quadric\n            return (r**2 + sigma**2)**(-0.5)\n        else:\n            raise ValueError(\"Invalid basis function code\")\n    \n    def estim_weights(self):\n        \"\"\"Estimates the basis function weights if sigma is known or not required.\n        \n        Returns:\n            self: The updated model instance\n        \"\"\"\n        # Check if sigma is required but not provided\n        if self.code &gt; 3 and self.sigma is None:\n            raise ValueError(\"The basis function requires a sigma parameter\")\n        \n        # Number of points\n        n = len(self.y)\n        \n        # Build distance matrix\n        d = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i+1):\n                d[i, j] = np.linalg.norm(self.X[i] - self.X[j])\n                d[j, i] = d[i, j]\n        \n        # Construct the Phi (Psi) matrix\n        self.Phi = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i+1):\n                self.Phi[i, j] = self.basis(d[i, j], self.sigma)\n                self.Phi[j, i] = self.Phi[i, j]\n        \n        # Calculate weights using appropriate method\n        if self.code == 4 or self.code == 6:\n            # Use Cholesky factorization for Gaussian or inverse multiquadric\n            try:\n                L = cholesky(self.Phi, lower=True)\n                self.weights = cho_solve((L, True), self.y)\n                self.success = True\n            except np.linalg.LinAlgError:\n                print(\"Cholesky factorization failed.\")\n                print(\"Two points may be too close together.\")\n                self.weights = None\n                self.success = False\n        else:\n            # Use direct solve for other basis functions\n            try:\n                self.weights = np.linalg.solve(self.Phi, self.y)\n                self.success = True\n            except np.linalg.LinAlgError:\n                self.weights = None\n                self.success = False\n        \n        return self\n    \n    def fit(self):\n        \"\"\"Estimates the parameters of the Radial Basis Function model.\n        \n        Returns:\n            self: The updated model instance\n        \"\"\"\n        if self.code &lt; 4:\n            # Fixed basis function, only w needs estimating\n            self.estim_weights()\n        else:\n            # Basis function also requires a sigma, estimate first\n            # Save original model data\n            X_orig = self.X.copy()\n            y_orig = self.y.copy()\n            \n            # Direct search between 10^-2 and 10^2\n            sigmas = np.logspace(-2, 2, 30)\n            \n            # Number of cross-validation subsets\n            if len(self.X) &lt; 6:\n                q = 2\n            elif len(self.X) &lt; 15:\n                q = 3\n            elif len(self.X) &lt; 50:\n                q = 5\n            else:\n                q = 10\n            \n            # Number of sample points\n            n = len(self.X)\n            \n            # X split into q randomly selected subsets\n            xs = rnd.permutation(n)\n            full_xs = xs.copy()\n            \n            # The beginnings of the subsets...\n            from_idx = np.arange(0, n, n//q)\n            if from_idx[-1] &gt;= n:\n                from_idx = from_idx[:-1]\n            \n            # ...and their ends\n            to_idx = np.zeros_like(from_idx)\n            for i in range(len(from_idx) - 1):\n                to_idx[i] = from_idx[i+1] - 1\n            to_idx[-1] = n - 1\n            \n            cross_val = np.zeros(len(sigmas))\n            \n            # Cycling through the possible values of Sigma\n            for sig_index, sigma in enumerate(sigmas):\n                print(f\"Computing cross-validation metric for Sigma={sigma:.4f}...\")\n                \n                cross_val[sig_index] = 0\n                \n                # Model fitting to subsets of the data\n                for j in range(len(from_idx)):\n                    removed = xs[from_idx[j]:to_idx[j]+1]\n                    xs_temp = np.delete(xs, np.arange(from_idx[j], to_idx[j]+1))\n                    \n                    # Create a temporary model for CV\n                    temp_model = Rbf(\n                        X=X_orig[xs_temp],\n                        y=y_orig[xs_temp],\n                        code=self.code\n                    )\n                    temp_model.sigma = sigma\n                    \n                    # Sigma and subset chosen, now estimate w\n                    temp_model.estim_weights()\n                    \n                    if temp_model.weights is None:\n                        cross_val[sig_index] = 1e20\n                        xs = full_xs.copy()\n                        break\n                    \n                    # Compute vector of predictions at the removed sites\n                    pr = np.zeros(len(removed))\n                    for jj, idx in enumerate(removed):\n                        pr[jj] = temp_model.predict(X_orig[idx])\n                    \n                    # Calculate cross-validation error\n                    cross_val[sig_index] += np.sum((y_orig[removed] - pr)**2) / len(removed)\n                    \n                    xs = full_xs.copy()\n                \n                # Now attempt Cholesky on the full set, in case the subsets could\n                # be fitted correctly, but the complete X could not\n                temp_model = Rbf(\n                    X=X_orig,\n                    y=y_orig,\n                    code=self.code\n                )\n                temp_model.sigma = sigma\n                temp_model.estim_weights()\n                \n                if temp_model.weights is None:\n                    cross_val[sig_index] = 1e20\n                    print(\"Failed to fit complete sample data.\")\n            \n            # Find the best sigma\n            min_cv_index = np.argmin(cross_val)\n            best_sig = sigmas[min_cv_index]\n            \n            # Set the best sigma and recompute weights\n            print(f\"Selected sigma={best_sig:.4f}\")\n            self.sigma = best_sig\n            self.estim_weights()\n        \n        return self\n    \n    def predict(self, x):\n        \"\"\"Calculates the value of the Radial Basis Function surrogate model at x.\n        \n        Args:\n            x (ndarray): Point at which to make prediction\n            \n        Returns:\n            float: Predicted value\n        \"\"\"\n        # Calculate distances to all sample points\n        d = np.zeros(len(self.X))\n        for k in range(len(self.X)):\n            d[k] = np.linalg.norm(x - self.X[k])\n        \n        # Calculate basis function values\n        phi = np.zeros(len(self.X))\n        for k in range(len(self.X)):\n            phi[k] = self.basis(d[k], self.sigma)\n        \n        # Calculate prediction\n        y = np.dot(phi, self.weights)\n        return y",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#rbf-example-the-one-dimensional-sin-function",
    "href": "006_num_rbf.html#rbf-example-the-one-dimensional-sin-function",
    "title": "7  Radial Basis Function Models",
    "section": "7.3 RBF Example: The One-Dimensional sin Function",
    "text": "7.3 RBF Example: The One-Dimensional sin Function\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import cholesky, cho_solve\n\n# Define the data points for fitting\nx_centers = np.array([np.pi/2, np.pi, 3*np.pi/2]).reshape(-1, 1)  # Centers for RBFs\ny_values = np.sin(x_centers.flatten())  # Sine values at these points\n\n# Create and fit the RBF model\nrbf_model = Rbf(X=x_centers, y=y_values, code=4)  # Code 4 is Gaussian RBF\nrbf_model.sigma = 1.0  # Set sigma parameter directly\nrbf_model.estim_weights()  # Calculate optimal weights\n\n# Print the weights\nprint(\"RBF model weights:\", rbf_model.weights)\n\n# Create a grid for visualization\nx_grid = np.linspace(0, 2*np.pi, 1000).reshape(-1, 1)\ny_true = np.sin(x_grid.flatten())  # True sine function\n\n# Generate predictions using the RBF model\ny_pred = np.zeros(len(x_grid))\nfor i in range(len(x_grid)):\n    y_pred[i] = rbf_model.predict(x_grid[i])\n\n# Calculate individual basis functions for visualization\nbasis_funcs = np.zeros((len(x_grid), len(x_centers)))\nfor i in range(len(x_grid)):\n    for j in range(len(x_centers)):\n        # Calculate distance\n        distance = np.linalg.norm(x_grid[i] - x_centers[j])\n        # Compute basis function value scaled by its weight\n        basis_funcs[i, j] = rbf_model.basis(distance, rbf_model.sigma) * rbf_model.weights[j]\n\n# Plot the results\nplt.figure(figsize=(6, 4))\n\n# Plot the true sine function\nplt.plot(x_grid, y_true, 'k-', label='True sine function', linewidth=2)\n\n# Plot individual basis functions\nfor i in range(len(x_centers)):\n    plt.plot(x_grid, basis_funcs[:, i], '--', \n             label=f'Basis function at x={x_centers[i][0]:.2f}')\n\n# Plot the RBF fit (sum of basis functions)\nplt.plot(x_grid, y_pred, 'r-', label='RBF fit', linewidth=2)\n\n# Plot the sample points\nplt.scatter(x_centers, y_values, color='blue', s=100, label='Sample points')\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n\nplt.title('RBF Approximation of Sine Function')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nRBF model weights: [ 1.00724398e+00  2.32104414e-16 -1.00724398e+00]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#rbf-example-the-two-diemnsional-dome-function",
    "href": "006_num_rbf.html#rbf-example-the-two-diemnsional-dome-function",
    "title": "7  Radial Basis Function Models",
    "section": "7.4 RBF Example: The Two-Diemnsional dome Function",
    "text": "7.4 RBF Example: The Two-Diemnsional dome Function\nThe dome function is an example of a test function that can be used to evaluate the performance of the Radial Basis Function model. It is a simple mathematical function defined over a two-dimensional space.\n\ndef dome(x) -&gt; float:\n  \"\"\"\n  Dome test function.\n  \n  Args:\n      x (ndarray): Input vector (1D array of length 2)\n  \n  Returns:\n      float: Function value\n  \n  Examples:\n      dome(np.array([0.5, 0.5]))\n  \"\"\"\n  return np.sum(1 - (2*x - 1)**2) / len(x)\n\nThe following code demonstrates how to use the Radial Basis Function model to approximate a function. It generates a Latin Hypercube sample, computes the objective function values, estimates the model parameters, and plots the results.\n\ndef generate_rbf_data(n_samples=10, grid_points=41):\n    \"\"\"\n    Generates data for RBF visualization.\n\n    Args:\n        n_samples (int): Number of samples for the RBF model\n        grid_points (int): Number of grid points for prediction\n\n    Returns:\n        tuple: (rbf_model, X, Y, Z, Z_0) - Model and grid data for plotting\n    \"\"\"\n    from spotpython.utils.sampling import bestlh as best_lh\n    # Generate sampling plan\n    X_samples = best_lh(n_samples, 2, population=10, iterations=100)\n    # Compute objective function values\n    y_samples = np.zeros(len(X_samples))\n    for i in range(len(X_samples)):\n        y_samples[i] = dome(X_samples[i])\n    # Create and fit RBF model\n    rbf_model = Rbf(X=X_samples, y=y_samples, code=3)  # Thin plate spline\n    rbf_model.fit()\n    # Generate grid for prediction\n    x = np.linspace(0, 1, grid_points)\n    y = np.linspace(0, 1, grid_points)\n    X, Y = np.meshgrid(x, y)\n    Z_0 = np.zeros_like(X)\n    Z = np.zeros_like(X)\n    \n    # Evaluate model at grid points\n    for i in range(len(x)):\n        for j in range(len(y)):\n            Z_0[j, i] = dome(np.array([x[i], y[j]]))\n            Z[j, i] = rbf_model.predict(np.array([x[i], y[j]]))\n    \n    return rbf_model, X, Y, Z, Z_0\n\ndef plot_rbf_results(rbf_model, X, Y, Z, Z_0=None, n_contours=10):\n    \"\"\"\n    Plots RBF approximation results.\n\n    Args:\n        rbf_model (Rbf): Fitted RBF model\n        X (ndarray): Grid X-coordinates\n        Y (ndarray): Grid Y-coordinates\n        Z (ndarray): RBF model predictions\n        Z_0 (ndarray, optional): True function values for comparison\n        n_contours (int): Number of contour levels to plot\n    \"\"\"\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 8))\n    \n    # Plot the contour\n    contour = plt.contour(X, Y, Z, n_contours)\n\n    if Z_0 is not None:\n        contour_0 = plt.contour(X, Y, Z_0, n_contours, colors='k', linestyles='dashed')\n    \n    # Plot the sample points\n    plt.scatter(rbf_model.X[:, 0], rbf_model.X[:, 1], \n                c='r', marker='o', s=50)\n    \n    plt.title('RBF Approximation (Thin Plate Spline)')\n    plt.xlabel('x1')\n    plt.ylabel('x2')\n    plt.colorbar(label='f(x1, x2)')\n    plt.show()\n\nFigure 7.3 shows the contour plots of the underlying function \\(f(x_1, x_2) = 0.5[-(2x_1-1)^2-(2x_2-1)^2]\\) and its thin plate spline radial basis function approximation, along with the 10 points of a Morris-Mitchell optimal Latin hypercube sampling plan (obtained via best_lh()).\n\nrbf_model, X, Y, Z, Z_0 = generate_rbf_data(n_samples=10, grid_points=41)\nplot_rbf_results(rbf_model, X, Y, Z, Z_0)\n\n\n\n\n\n\n\nFigure 7.3: RBF Approximation.\n\n\n\n\n\n\n7.4.1 The Connection Between RBF Models and Neural Networks\nRadial basis function models share a profound architectural similarity with artificial neural networks, specifically with what’s known as RBF networks. This connection provides valuable intuition about how RBF models function. A radial basis function model can be viewed as a specialized neural network with the following structure:\n\nInput Layer: Receives the feature vector \\(\\vec{x}\\)\nHidden Layer: Contains neurons (basis functions) that compute radial distances\nOutput Layer: Produces a weighted sum of the hidden unit activations\n\nUnlike traditional neural networks that use dot products followed by nonlinear activation functions, RBF networks measure the distance between inputs and learned center points. This distance is then transformed by the radial basis function.\nMathematically, the equivalence between RBF models and RBF networks can be expressed as follows:\nThe RBF model equation:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n_c} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||)\n\\]\ndirectly maps to the following neural network components:\n\n\\(\\vec{x}\\): Input vector\n\\(\\vec{c}^{(i)}\\): Center vectors for each hidden neuron\n\\(\\psi(\\cdot)\\): Activation function (Gaussian, inverse multiquadric, etc.)\n\\(w_i\\): Output weights\n\\(\\hat{f}(\\vec{x})\\): Network output\n\n\nExample 7.2 (Comparison of RBF Networks and Traditional Neural Networks) Consider approximating a simple 1D function \\(f(x) = \\sin(2\\pi x)\\) over the interval \\([0,1]\\):\nThe neral network approach would use multiple layers with neurons computing \\(\\sigma(w \\cdot x + b)\\). It would require a large number of neurons and layers to capture the sine wave’s complexity. The network would learn both weights and biases, making it less interpretable.\nThe RBF network approach, on the other hand, places basis functions at strategic points (e.g., 5 evenly spaced centers). Each neuron computes \\(\\psi(||x - c_i||)\\) (e.g., using Gaussian RBF). The output layer combines these values with learned weights. If we place Gaussian RBFs with \\(\\sigma=0.15\\) at \\({0.1, 0.3, 0.5, 0.7, 0.9}\\), each neuron responds strongly when the input is close to its center and weakly otherwise. The network can then learn weights that, when multiplied by these response patterns and summed, closely approximate the sine function.\nThis locality property gives RBF networks a notable advantage: they offer more interpretable internal representations and often require fewer neurons for certain types of function approximation compared to traditional multilayer perceptrons.\nThe key insight is that while standard neural networks create complex decision boundaries through compositions of hyperplanes, RBF networks directly model functions using a set of overlapping “bumps” positioned strategically in the input space.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#radial-basis-function-models-for-noisy-data",
    "href": "006_num_rbf.html#radial-basis-function-models-for-noisy-data",
    "title": "7  Radial Basis Function Models",
    "section": "7.5 Radial Basis Function Models for Noisy Data",
    "text": "7.5 Radial Basis Function Models for Noisy Data\nWhen the responses \\(\\vec{y} = {y^{(1)}, y^{(2)}, \\ldots, y^{(n)}}^T\\) contain measurement or simulation noise, the standard RBF interpolation approach can lead to overfitting—the model captures both the underlying function and the random noise. This compromises generalization performance on new data points. Two principal strategies address this challenge:\n\n7.5.1 Ridge Regularization Approach\nThe most straightforward solution involves introducing regularization through the parameter \\(\\lambda\\) (pogg90a?). This is implemented by adding \\(\\lambda\\) to the diagonal elements of the Gram matrix, creating a “ridge” that improves numerical stability. Mathematically, the weights are determined by:\n\\[\n\\vec{w} = (\\Psi + \\lambda I)^{-1} \\vec{y},\n\\]\nwhere \\(I\\) is an \\(n \\times n\\) identity matrix. This regularized solution balances two competing objectives:\n\nfitting the training data accurately versus\nkeeping the magnitude of weights controlled to prevent overfitting.\n\nTheoretically, optimal performance is achieved when \\(\\lambda\\) equals the variance of the noise in the response data \\(\\vec{y}\\) (kean05a?). Since this information is rarely available in practice, \\(\\lambda\\) is typically estimated through cross-validation alongside other model parameters.\n\n\n7.5.2 Reduced Basis Approach\nAn alternative strategy involves reducing \\(m\\), the number of basis functions. This might result in a non-square \\(\\Psi\\) matrix. With a non-square \\(\\Psi\\) matrix, the weights are found through least squares minimization:\n\\[\n\\vec{w} = (\\Psi^T\\Psi)^{-1}\\Psi^T\\vec{y}\n\\]\nThis approach introduces an important design decision: which subset of points should serve as basis function centers? Several selection strategies exist:\n\nClustering methods that identify representative points\nGreedy algorithms that sequentially select influential centers\nSupport vector regression techniques (discussed elsewhere in the literature)\n\nAdditional parameters such as the width parameter \\(\\sigma\\) in Gaussian bases can be optimized through cross-validation to minimize generalization error estimates.\nThe ridge regularization and reduced basis approaches can be combined, allowing for a flexible modeling framework, though at the cost of a more complex parameter estimation process. This hybrid approach often yields superior results for highly noisy datasets or when the underlying function has varying complexity across the input space.\nThe broader challenge of building accurate models from noisy observations is examined comprehensively in the context of Kriging models, which provide a statistical framework for explicitly modeling both the underlying function and the noise process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#jupyter-notebook",
    "href": "006_num_rbf.html#jupyter-notebook",
    "title": "7  Radial Basis Function Models",
    "section": "7.6 Jupyter Notebook",
    "text": "7.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html",
    "href": "006_num_gp.html",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "8.1 From Gaussian RBF to Kriging Basis Functions\nKriging can be explained using the concept of radial basis functions (RBFs), which were introduced in Chapter 7. An RBF is a real-valued function whose value depends only on the distance from a certain point, called the center, usually in a multidimensional space. The basis function is a function of the distance between the point \\(\\vec{x}\\) and the center \\(\\vec{x}^{(i)}\\). Other names for basis functions are kernel or covariance functions.\nKriging uses a specialized basis function that offers greater flexibility than standard RBFs. Examining Equation 8.1, we can observe how Kriging builds upon and extends the Gaussian basis concept. The key enhancements of Kriging over Gaussian RBF can be summarized as follows:\nThese enhancements make Kriging particularly well-suited for engineering problems where variables may operate at different scales or exhibit varying degrees of smoothness across dimensions. For now, we will only consider Kriging interpolation. We will cover Kriging regression later.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#from-gaussian-rbf-to-kriging-basis-functions",
    "href": "006_num_gp.html#from-gaussian-rbf-to-kriging-basis-functions",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "Definition 8.1 (The Kriging Basis Functions) Kriging (also known as Gaussian Process Regression) uses \\(k\\)-dimensional basis functions of the form \\[\n\\psi^{(i)}(\\vec{x}) =\n\\psi(\\vec{x}^{(i)}, \\vec{x}) = \\exp \\left( - \\sum_{j=1}^k \\theta_j | x_{j}^{(i)} - x_{j} | ^{p_j} \\right),\n\\tag{8.1}\\] where \\(\\vec{x}\\) and \\(\\vec{x}^{(i)}\\) denote the \\(k\\)-dim vector \\(\\vec{x}= (x_1, \\ldots, x_k)^T\\) and \\(\\vec{x}^{(i)}= (x_1^{(i)}, \\ldots, x_k^{(i)})^T\\), respectively.\n\\(\\Box\\)\n\n\n\nDimension-specific width parameters: While a Gaussian RBF uses a single width parameter \\(1/\\sigma^2\\), Kriging employs a vector \\(\\vec{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_k)^T\\). This allows the model to automatically adjust its sensitivity to each input dimension, effectively performing automatic feature relevance determination.\nFlexible smoothness control: The Gaussian RBF fixes the exponent at 2, producing uniformly smooth functions. In contrast, Kriging’s dimension-specific exponents \\(\\vec{p} = (p_1, p_2, \\ldots, p_k)^T\\) (typically with \\(p_j \\in [1, 2]\\)) enable precise control over smoothness properties in each dimension.\nUnifying framework: When all exponents are set to \\(p_j = 2\\) and all width parameters are equal (\\(\\theta_j = 1/\\sigma^2\\) for all \\(j\\)), the Kriging basis function reduces exactly to the Gaussian RBF. This makes Gaussian RBF a special case within the more general Kriging framework.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#building-the-kriging-model",
    "href": "006_num_gp.html#building-the-kriging-model",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.2 Building the Kriging Model",
    "text": "8.2 Building the Kriging Model\nConsider sample data \\(X\\) and \\(\\vec{y}\\) from \\(n\\) locations that are available in matrix form: \\(X\\) is a \\((n \\times k)\\) matrix, where \\(k\\) denotes the problem dimension and \\(\\vec{y}\\) is a \\((n\\times 1)\\) vector. We want to find an expression for a predicted values at a new point \\(\\vec{x}\\), denoted as \\(\\hat{y}\\).\nWe start with an abstract, not really intuitive concept: The observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process, which will be denoted as \\[\n\\begin{pmatrix}\nY(\\vec{x}^{(1)})\\\\\n\\vdots\\\\\nY(\\vec{x}^{(n)})\\\\\n\\end{pmatrix}.\n\\tag{8.2}\\]\nThe set of random vectors from Equation 8.2 (also referred to as a random field) has a mean of \\(\\vec{1} \\mu\\), which is a \\((n\\times 1)\\) vector. The random vectors are correlated with each other using the basis function expression from Equation 8.1: \\[\n\\text{cor} \\left(Y(\\vec{x}^{(i)}),Y(\\vec{x}^{(l)}) \\right) = \\exp\\left(- \\sum_{j=1}^k \\theta_j |x_j^{(i)} - x_j^{(l)} |^{p_j}\\right).\n\\tag{8.3}\\] Using Equation 8.3, we can compute the \\((n \\times n)\\) correlation matrix \\(\\Psi\\) of the observed sample data as shown in Equation 8.4,\n\\[\n\\Psi = \\begin{pmatrix}\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x}^{(1)})\n\\right) & \\ldots &\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x}^{(n)})\n\\right)\\\\\n\\vdots  & \\vdots &  \\vdots\\\\\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x}^{(1)})\n\\right)&\n\\ldots &\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x}^{(n)})\n\\right)\n\\end{pmatrix},\n\\tag{8.4}\\]\nand a covariance matrix as shown in Equation 8.5,\n\\[\n\\text{Cov}(Y, Y ) = \\sigma^2\\Psi.\n\\tag{8.5}\\]\nThis assumed correlation between the sample data reflects our expectation that an engineering function will behave in a certain way and it will be smoothly and continuous.\n\nRemark 8.1 (Note on Stochastic Processes). See ?sec-random-samples-gp for a more detailed discussion on realizations of stochastic processes.\n\\(\\Box\\)\n\nWe now have a set of \\(n\\) random variables (\\(\\mathbf{Y}\\)) that are correlated with each other as described in the \\((n \\times n)\\) correlation matrix \\(\\Psi\\), see Equation 8.4. The correlations depend on the absolute distances in dimension \\(j\\) between the \\(i\\)-th and the \\(l\\)-th sample point \\(|x_j^{(i)} - x_j^{(l)}|\\) and the corresponding parameters \\(p_j\\) and \\(\\theta_j\\) for dimension \\(j\\). The correlation is intuitive, because when\n\ntwo points move close together, then \\(|x_j^{(i)} - x_j| \\to 0\\) and \\(\\exp \\left(-|x_j^{(i)} - x_j|^{p_j} \\right) \\to 1\\) (these points show very close correlation and \\(Y(x_j^{(i)}) = Y(x_j)\\)).\ntwo points move far apart, then \\(|x_j^{(i)} - x_j| \\to \\infty\\) and \\(\\exp \\left(-|x_j^{(i)} - x_j|^{p_j} \\right) \\to 0\\) (these points show very low correlation).\n\n\nExample 8.1 (Correlations for different \\(p_j\\)) Three different correlations are shown in Figure 8.1: \\(p_j= 0.1, 1, 2\\). The smoothness parameter \\(p_j\\) affects the correlation:\n\nWith \\(p_j=0.1\\), there is basicaly no immediate correlation between the points and there is a near discontinuity between the points \\(Y(\\vec{x}_j^{(i)})\\) and \\(Y(\\vec{x}_j)\\).\nWith \\(p_j=2\\), the correlation is more smooth and we have a continuous gradient through \\(x_j^{(i)} - x_j\\).\n\nReducing \\(p_j\\) increases the rate at which the correlation initially drops with distance. This is shown in Figure 8.1.\n\n\n\n\n\n\n\n\nFigure 8.1: Correlations with varying \\(p\\). \\(\\theta\\) set to 1.\n\n\n\n\n\n\\(\\Box\\)\n\n\nExample 8.2 (Correlations for different \\(\\theta\\)) Figure 8.2 visualizes the correlation between two points \\(Y(\\vec{x}_j^{(i)})\\) and \\(Y(\\vec{x}_j)\\) for different values of \\(\\theta\\). The parameter \\(\\theta\\) can be seen as a width parameter:\n\nlow \\(\\theta_j\\) means that all points will have a high correlation, with \\(Y(x_j)\\) being similar across the sample.\nhigh \\(\\theta_j\\) means that there is a significant difference between the \\(Y(x_j)\\)’s.\n\\(\\theta_j\\) is a measure of how active the function we are approximating is.\nHigh \\(\\theta_j\\) indicate important parameters, see Figure 8.2.\n\n\n\n\n\n\n\n\n\nFigure 8.2: Correlations with varying \\(\\theta\\). \\(p\\) set to 2.\n\n\n\n\n\n\\(\\Box\\)\n\nConsidering the activity parameter \\(\\theta\\) is useful in high-dimensional problems where it is difficult to visualize the design landscape and the effect of the variable is unknown. By examining the elements of the vector \\(\\vec{\\theta}\\), we can identify the most important variables and focus on them. This is a crucial step in the optimization process, as it allows us to reduce the dimensionality of the problem and focus on the most important variables.\n\nExample 8.3 (The Correlation Matrix (Detailed Computation)) Let \\(n=4\\) and \\(k=3\\). The sample plan is represented by the following matrix \\(X\\): \\[\nX = \\begin{pmatrix} x_{11} & x_{12} & x_{13}\\\\\nx_{21} & x_{22} & x_{23}\\\\\nx_{31} & x_{32} & x_{33}\\\\\nx_{41} & x_{42} & x_{43}\\\\\n\\end{pmatrix}\n\\]\nTo compute the elements of the matrix \\(\\Psi\\), the following \\(k\\) (one for each of the \\(k\\) dimensions) \\((n,n)\\)-matrices have to be computed:\n\nFor \\(k=1\\), i.e., the first column of \\(X\\): \\[\nD_1 = \\begin{pmatrix} x_{11} - x_{11} & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  x_{21} - x_{11} & x_{21} - x_{21} & x_{21} -x_{31} & x_{21} - x_{41} \\\\ x_{31} - x_{11} & x_{31} - x_{21} & x_{31} -x_{31} & x_{31} - x_{41} \\\\ x_{41} - x_{11} & x_{41} - x_{21} & x_{41} -x_{31} & x_{41} - x_{41} \\\\\n\\end{pmatrix}\n\\]\nFor \\(k=2\\), i.e., the second column of \\(X\\): \\[\nD_2 = \\begin{pmatrix} x_{12} - x_{12} & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  x_{22} - x_{12} & x_{22} - x_{22} & x_{22} -x_{32} & x_{22} - x_{42} \\\\ x_{32} - x_{12} & x_{32} - x_{22} & x_{32} -x_{32} & x_{32} - x_{42} \\\\ x_{42} - x_{12} & x_{42} - x_{22} & x_{42} -x_{32} & x_{42} - x_{42} \\\\\n\\end{pmatrix}\n\\]\nFor \\(k=3\\), i.e., the third column of \\(X\\): \\[\nD_3 = \\begin{pmatrix} x_{13} - x_{13} & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  x_{23} - x_{13} & x_{23} - x_{23} & x_{23} -x_{33} & x_{23} - x_{43} \\\\ x_{33} - x_{13} & x_{33} - x_{23} & x_{33} -x_{33} & x_{33} - x_{43} \\\\ x_{43} - x_{13} & x_{43} - x_{23} & x_{43} -x_{33} & x_{43} - x_{43} \\\\\\end{pmatrix}\n\\]\n\nSince the matrices are symmetric and the main diagonals are zero, it is sufficient to compute the following matrices: \\[\nD_1 = \\begin{pmatrix} 0 & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  0 &  0 & x_{21} -x_{31} & x_{21} - x_{41} \\\\ 0 & 0 & 0 & x_{31} - x_{41} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\] \\[\nD_2 = \\begin{pmatrix} 0 & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  0 & 0 & x_{22} -x_{32} & x_{22} - x_{42} \\\\ 0 & 0 & 0 & x_{32} - x_{42} \\\\ 0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\n\\[\nD_3 = \\begin{pmatrix} 0 & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  0 & 0 & x_{23} -x_{33} & x_{23} - x_{43} \\\\ 0 & 0 & 0 & x_{33} - x_{43} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nWe will consider \\(p_l=2\\). The differences will be squared and multiplied by \\(\\theta_i\\), i.e.:\n\\[\nD_1 = \\theta_1 \\begin{pmatrix} 0 & (x_{11} - x_{21})^2 & (x_{11} -x_{31})^2 & (x_{11} - x_{41})^2 \\\\  0 &  0 & (x_{21} -x_{31})^2 & (x_{21} - x_{41})^2 \\\\ 0 & 0 & 0 & (x_{31} - x_{41})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_2 = \\theta_2 \\begin{pmatrix} 0 & (x_{12} - x_{22})^2 & (x_{12} -x_{32})^2 & (x_{12} - x_{42})^2 \\\\  0 & 0 & (x_{22} -x_{32})^2 & (x_{22} - x_{42})^2 \\\\ 0 & 0 & 0 & (x_{32} - x_{42})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_3 = \\theta_3 \\begin{pmatrix} 0 & (x_{13} - x_{23})^2 & (x_{13} -x_{33})^2 & (x_{13} - x_{43})^2 \\\\  0 & 0 & (x_{23} -x_{33})^2 & (x_{23} - x_{43})^2 \\\\ 0 & 0 & 0 & (x_{33} - x_{43})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nThe sum of the three matrices \\(D=D_1+ D_2 + D_3\\) will be calculated next:\n\\[\n\\begin{pmatrix} 0 &\n\\theta_1  (x_{11} - x_{21})^2 + \\theta_2 (x_{12} - x_{22})^2 + \\theta_3  (x_{13} - x_{23})^2  &\n\\theta_1 (x_{11} -x_{31})^2 + \\theta_2  (x_{12} -x_{32})^2 + \\theta_3  (x_{13} -x_{33})^2 &\n\\theta_1  (x_{11} - x_{41})^2 + \\theta_2  (x_{12} - x_{42})^2 + \\theta_3 (x_{13} - x_{43})^2\n\\\\  0 &  0 &\n\\theta_1  (x_{21} -x_{31})^2 + \\theta_2 (x_{22} -x_{32})^2 + \\theta_3  (x_{23} -x_{33})^2 &\n\\theta_1  x_{21} - x_{41})^2 + \\theta_2  (x_{22} - x_{42})^2 + \\theta_3 (x_{23} - x_{43})^2\n\\\\ 0 & 0 & 0 &\n\\theta_1 (x_{31} - x_{41})^2 + \\theta_2 (x_{32} - x_{42})^2 + \\theta_3 (x_{33} - x_{43})^2\n\\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nFinally, \\[ \\Psi = \\exp(-D)\\] is computed.\nNext, we will demonstrate how this computation can be implemented in Python. We will consider four points in three dimensions and compute the correlation matrix \\(\\Psi\\) using the basis function from Equation 8.1. These points are placed at the origin, at the unit vectors, and at the points \\((100, 100, 100)\\) and \\((101, 100, 100)\\). So, they form two clusters: one at the origin and one at \\((100, 100, 100)\\).\n\ntheta = np.array([1,2,3])\nX = np.array([ [1,0,0], [0,1,0], [100, 100, 100], [101, 100, 100]])\nX\n\narray([[  1,   0,   0],\n       [  0,   1,   0],\n       [100, 100, 100],\n       [101, 100, 100]])\n\n\n\ndef build_Psi(X, theta):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)  \n\n\nPsi = build_Psi(X, theta)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\n\n\n\n\n\n\n\n\nFigure 8.3: Correlation matrix \\(\\Psi\\).\n\n\n\n\n\n\\(\\Box\\)\n\n\nExample 8.4 (Example: The Correlation Matrix (Using Existing Functions)) The same result as computed in Example 8.3 can be obtained with existing python functions, e.g., from the package scipy.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    return exp(- squareform(pdist(X,\n                            metric='sqeuclidean',\n                            out=None,\n                            w=theta))) +  multiply(eye(X.shape[0]),\n                                                   eps)\n\nPsi = build_Psi(X, theta, eps=.0)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\nThe condition number of the correlation matrix \\(\\Psi\\) is a measure of how well the matrix can be inverted. A high condition number indicates that the matrix is close to singular, which can lead to numerical instability in computations involving the inverse of the matrix, see Section 9.2.\n\nnp.linalg.cond(Psi)\n\nnp.float64(2.163953413738652)\n\n\n\\(\\Box\\)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#mle-to-estimate-theta-and-p",
    "href": "006_num_gp.html#mle-to-estimate-theta-and-p",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.3 MLE to estimate \\(\\theta\\) and \\(p\\)",
    "text": "8.3 MLE to estimate \\(\\theta\\) and \\(p\\)\n\n8.3.1 The Log-Likelihood\nUntil now, the observed data \\(\\vec{y}\\) was not used. We know what the correlations mean, but how do we estimate the values of \\(\\theta_j\\) and where does our observed data \\(y\\) come in? To estimate the values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\), they are chosen to maximize the likelihood of \\(\\vec{y}\\), \\[\nL = L\\left(Y(\\vec{x}^{(1)}), \\ldots, Y(\\vec{x}^{(n)}) | \\mu, \\sigma \\right) = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp\\left[ - \\frac{\\sum_{i=1}^n(Y(\\vec{x}^{(i)})-\\mu)^2}{2 \\sigma^2}\\right],\n\\tag{8.6}\\] where \\(\\mu\\) is the mean of the observed data \\(\\vec{y}\\) and \\(\\sigma\\) is the standard deviation of the errors \\(\\epsilon\\), which can be expressed in terms of the sample data \\[\nL = \\frac{1}{(2\\pi \\sigma^2)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left[ - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}\\right].\n\\tag{8.7}\\]\n\nRemark 8.2. The transition from Equation 8.6 to Equation 8.7 reflects a shift from assuming independent errors in the observed data to explicitly modeling the correlation structure between the observed responses, which is a key aspect of the stochastic process framework used in methods like Kriging. It can be explained as follows:\n\nInitial Likelihood Expression (assuming independent errors): Equation 8.6 is an expression for the likelihood of the data set, which is based on the assumption that the errors \\(\\epsilon\\) are independently randomly distributed according to a normal distribution with standard deviation \\(\\sigma\\). This form is characteristic of the likelihood of \\(n\\) independent observations \\(Y(\\vec{x}^{(i)})\\), each following a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nUsing Vector Notation. The sum in the exponent, i.e., \\[\n\\sum_{i=1}^n(Y(\\vec{x}^{(i)})-\\mu)^2\n\\] is equivalent to \\[\n(\\vec{y} - \\vec{1}\\mu)^T (\\vec{y} - \\vec{1}\\mu),\n\\] assuming \\(Y(\\vec{x}^{(i)}) = y^{(i)}\\) and using vector notation for \\(\\vec{y}\\) and \\(\\vec{1}\\mu\\).\nAssuming Independent Observations: Equation 8.6 assumes that the observations are independent, which means that the covariance between any two observations \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is zero for \\(i \\neq l\\). In this case, the covariance matrix of the observations would be a diagonal matrix with \\(\\sigma^2\\) along the diagonal (i.e., \\(\\sigma^2 I\\)), where \\(I\\) is the identity matrix.\nStochastic Process and Correlation: In the context of Kriging, the observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process or random field. This means the random variables \\(Y(\\vec{x}^{(i)})\\) at different locations \\(\\vec{x}^{(i)}\\) are not independent, but they correlated with each other. This correlation is described by an \\((n \\times n)\\) correlation matrix \\(\\Psi\\), which is used instead of \\(\\sigma^2 I\\). The strength of the correlation between two points \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) depends on the distance between them and model parameters \\(\\theta_j\\) and \\(p_j\\).\nMultivariate Normal Distribution: When random variables are correlated, their joint probability distribution is generally described by a multivariate distribution. Assuming the stochastic process follows a Gaussian process, the joint distribution of the observed responses \\(\\vec{y}\\) is a multivariate normal distribution. A multivariate normal distribution for a vector \\(\\vec{Y}\\) with mean vector \\(\\vec{\\mu}\\) and covariance matrix \\(\\Sigma\\) has a probability density function given by: \\[\np(\\vec{y}) = \\frac{1}{\\sqrt{(2\\pi)^n |\\Sigma|}} \\exp\\left[ -\\frac{1}{2}(\\vec{y} - \\vec{\\mu})^T \\Sigma^{-1}(\\vec{y} - \\vec{\\mu}) \\right].\n\\]\nConnecting the Expressions: In the stochastic process framework, the following holds:\n\nThe mean vector of the observed data \\(\\vec{y}\\) is \\(\\vec{1}\\mu\\).\nThe covariance matrix \\(\\Sigma\\) is constructed by considering both the variance \\(\\sigma^2\\) and the correlations \\(\\Psi\\).\nThe covariance between \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is \\(\\sigma^2 \\text{cor}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)}))\\).\nTherefore, the covariance matrix is \\(\\Sigma = \\sigma^2 \\vec{\\Psi}\\).\nSubstituting \\(\\vec{\\mu} = \\vec{1}\\mu\\) and \\(\\Sigma = \\sigma^2 \\vec{\\Psi}\\) into the multivariate normal PDF formula, we get: \\[\n\\Sigma^{-1} = (\\sigma^2 \\vec{\\Psi})^{-1} = \\frac{1}{\\sigma^2} \\vec{\\Psi}^{-1}\n\\] and \\[\n|\\Sigma| = |\\sigma^2 \\vec{\\Psi}| = (\\sigma^2)^n |\\vec{\\Psi}|.\n\\] The PDF becomes: \\[\np(\\vec{y}) = \\frac{1}{\\sqrt{(2\\pi)^n (\\sigma^2)^n |\\vec{\\Psi}|}} \\exp\\left[ -\\frac{1}{2}(\\vec{y} - \\vec{1}\\mu)^T \\left(\\frac{1}{\\sigma^2} \\vec{\\Psi}^{-1}\\right)(\\vec{y} - \\vec{1}\\mu) \\right]\n\\] and simplifies to: \\[\np(\\vec{y}) = \\frac{1}{(2\\pi \\sigma^2)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left[ -\\frac{1}{2\\sigma^2}(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) \\right].\n\\] This is the likelihood of the sample data \\(\\vec{y}\\) given the parameters \\(\\mu\\), \\(\\sigma\\), and the correlation structure defined by the parameters within \\(\\vec{\\Psi}\\) (i.e., \\(\\vec{\\theta}\\) and \\(\\vec{p}\\)).\n\n\nIn summary, the Equation 8.6 represents the likelihood under a simplified assumption of independent errors, whereas Equation 8.7 is the likelihood derived from the assumption that the observed data comes from a multivariate normal distribution where observations are correlated according to the matrix \\(\\vec{\\Psi}\\). Equation 8.7, using the sample data vector \\(\\vec{y}\\) and the correlation matrix \\(\\vec{\\Psi}\\), properly accounts for the dependencies between data points inherent in the stochastic process model. Maximizing this likelihood is how the correlation parameters \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are estimated in Kriging.\n\\(\\Box\\)\n\nEquation 8.7 can be formulated as the log-likelihood: \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi \\sigma) - \\frac{1}{2} \\ln |\\vec{\\Psi}| - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}.\n\\tag{8.8}\\]\n\n\n8.3.2 Differentiation with Respect to \\(\\mu\\)\nLooking at the log-likelihood function, only the last term depends on \\(\\mu\\):\n\\[\n\\frac{1}{2 \\sigma^2} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nTo differentiate this with respect to the scalar \\(\\mu\\), we can use matrix calculus rules.\nLet \\(\\mathbf{v} = \\vec{y} - \\vec{1}\\mu\\). \\(\\vec{y}\\) is a constant vector with respect to \\(\\mu\\), and \\(\\vec{1}\\mu\\) is a vector whose derivative with respect to the scalar \\(\\mu\\) is \\(\\vec{1}\\). So, \\(\\frac{\\partial \\mathbf{v}}{\\partial \\mu} = -\\vec{1}\\).\nThe term is in the form \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\), where \\(\\mathbf{A} = \\vec{\\Psi}^{-1}\\) is a symmetric matrix. The derivative of \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to \\(\\mathbf{v}\\) is \\(2 \\mathbf{A} \\mathbf{v}\\) as explained in Remark 8.3.\n\nRemark 8.3 (Derivative of a Quadratic Form). Consider the derivative of \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to \\(\\mathbf{v}\\):\n\nThe derivative of a scalar function \\(f(\\mathbf{v})\\) with respect to a vector \\(\\mathbf{v}\\) is a vector (the gradient).\nFor a quadratic form \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\), where \\(\\mathbf{A}\\) is a matrix and \\(\\mathbf{v}\\) is a vector, the general formula for the derivative with respect to \\(\\mathbf{v}\\) is \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}\\). (This is a standard result in matrix calculus and explained in Equation 9.1).\nSince \\(\\mathbf{A} = \\vec{\\Psi}^{-1}\\) is a symmetric matrix, its transpose \\(\\mathbf{A}^T\\) is equal to \\(\\mathbf{A}\\).\nSubstituting \\(\\mathbf{A}^T = \\mathbf{A}\\) into the general derivative formula, we get \\(\\mathbf{A} \\mathbf{v} + \\mathbf{A} \\mathbf{v} = 2 \\mathbf{A} \\mathbf{v}\\).\n\n\\(\\Box\\)\n\nUsing the chain rule for differentiation with respect to the scalar \\(\\mu\\): \\[ \\frac{\\partial}{\\partial \\mu} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = 2 \\left(\\frac{\\partial \\mathbf{v}}{\\partial \\mu}\\right)^T \\mathbf{A} \\mathbf{v} \\] Substituting \\(\\frac{\\partial \\mathbf{v}}{\\partial \\mu} = -\\vec{1}\\) and \\(\\mathbf{v} = \\vec{y} - \\vec{1}\\mu\\): \\[\n\\frac{\\partial}{\\partial \\mu} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 2 (-\\vec{1})^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = -2 \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nNow, differentiate the full log-likelihood term depending on \\(\\mu\\):\n\\[\n\\frac{\\partial}{\\partial \\mu} \\left( - \\frac{1}{2 \\sigma^2} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) \\right) = - \\frac{1}{2 \\sigma^2} \\left( -2 \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) \\right) = \\frac{1}{\\sigma^2} \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nSetting this to zero for maximization gives:\n\\[\n\\frac{1}{\\sigma^2} \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 0.\n\\]\nRearranging gives: \\[\n\\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 0.\n\\]\nSolving for \\(\\mu\\) gives: \\[\n\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y} = \\mu \\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}.\n\\]\n\n\n8.3.3 Differentiation with Respect to \\(\\sigma\\)\nLet \\(\\nu = \\sigma^2\\) for simpler differentiation notation. The log-likelihood becomes: \\[\n\\ln(L) = C_1 - \\frac{n}{2} \\ln(\\nu) - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\nu},\n\\] where \\(C_1 = - \\frac{n}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln |\\vec{\\Psi}|\\) is a constant with respect to \\(\\nu = \\sigma^2\\).\nWe differentiate with respect to \\(\\nu\\): \\[\n\\frac{\\partial \\ln(L)}{\\partial \\nu} = \\frac{\\partial}{\\partial \\nu} \\left( -\\frac{n}{2} \\ln(\\nu) \\right) + \\frac{\\partial}{\\partial \\nu} \\left( - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\nu} \\right).\n\\]\nThe first term’s derivative is straightforward: \\[\n\\frac{\\partial}{\\partial \\nu} \\left( -\\frac{n}{2} \\ln(\\nu) \\right) = -\\frac{n}{2} \\cdot \\frac{1}{\\nu} = -\\frac{n}{2\\sigma^2}.\n\\]\nFor the second term, let \\(C_2 = (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)\\). This term is constant with respect to \\(\\sigma^2\\). The derivative is:\n\\[\n\\frac{\\partial}{\\partial \\nu} \\left( - \\frac{C_2}{2\\nu} \\right) = - \\frac{C_2}{2} \\frac{\\partial}{\\partial \\nu} (\\nu^{-1}) = - \\frac{C_2}{2} (-\\nu^{-2}) = \\frac{C_2}{2\\nu^2} = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2}.\n\\]\nCombining the derivatives, the gradient of the log-likelihood with respect to \\(\\sigma^2\\) is: \\[\n\\frac{\\partial \\ln(L)}{\\partial \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2}.\n\\]\nSetting this to zero for maximization gives: \\[\n-\\frac{n}{2\\sigma^2} + \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2} = 0.\n\\]\n\n\n8.3.4 Results of the Optimizations\nOptimization of the log-likelihood by taking derivatives with respect to \\(\\mu\\) and \\(\\sigma\\) results in \\[\n\\hat{\\mu} = \\frac{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y}^T}{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}^T}\n\\tag{8.9}\\] and \\[\n\\hat{\\sigma}^2 = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{n}.\n\\tag{8.10}\\]\n\n\n8.3.5 The Concentrated Log-Likelihood Function\nCombining the equations, i.e., substituting Equation 8.9 and Equation 8.10 into Equation 8.8 leads to the concentrated log-likelihood function: \\[\n\\ln(L) \\approx - \\frac{n}{2} \\ln(\\hat{\\sigma}) - \\frac{1}{2} \\ln |\\vec{\\Psi}|.\n\\tag{8.11}\\]\n\nRemark 8.4 (The Concentrated Log-Likelihood). \n\nThe first term in Equation 8.11 requires information about the measured point (observations) \\(y_i\\).\nTo maximize \\(\\ln(L)\\), optimal values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are determined numerically, because the function (Equation 8.11) is not differentiable.\n\n\\(\\Box\\)\n\n\n\n8.3.6 Optimizing the Parameters \\(\\vec{\\theta}\\) and \\(\\vec{p}\\)\nThe concentrated log-likelihood function is very quick to compute. We do not need a statistical model, because we are only interested in the maximum likelihood estimate (MLE) of \\(\\theta\\) and \\(p\\). Optimizers such as Nelder-Mead, Conjugate Gradient, or Simulated Annealing can be used to determine optimal values for \\(\\theta\\) and \\(p\\). After the optimization, the correlation matrix \\(\\Psi\\) is build with the optimized \\(\\theta\\) and \\(p\\) values. This is best (most likely) Kriging model for the given data \\(y\\).\nObserving Figure 8.2, there’s significant change between \\(\\theta = 0.1\\) and \\(\\theta = 1\\), just as there is between \\(\\theta = 1\\) and \\(\\theta = 10\\). Hence, it is sensible to search for \\(\\theta\\) on a logarithmic scale. Suitable search bounds typically range from \\(10^{-3}\\) to \\(10^2\\), although this is not a stringent requirement. Importantly, the scaling of the observed data does not affect the values of \\(\\hat{\\theta}\\), but the scaling of the design space does. Therefore, it is advisable to consistently scale variable ranges between zero and one to ensure consistency in the degree of activity \\(\\hat{\\theta}_j\\) represents across different problems.\n\n\n8.3.7 Correlation and Covariance Matrices Revisited\nThe covariance matrix \\(\\Sigma\\) is constructed by considering both the variance \\(\\sigma^2\\) and the correlation matrix \\(\\Psi\\). They are related as follows:\n\nCovariance vs. Correlation: Covariance is a measure of the joint variability of two random variables, while correlation is a standardized measure of this relationship, ranging from -1 to 1. The relationship between covariance and correlation for two random variables \\(X\\) and \\(Y\\) is given by \\(\\text{cor}(X, Y) = \\text{cov}(X, Y) / (\\sigma_X \\sigma_Y)\\), where \\(\\sigma_X\\) and \\(\\sigma_Y\\) are their standard deviations.\nThe Covariance Matrix \\(\\Sigma\\): The covariance matrix \\(\\Sigma\\) (or \\(\\text{Cov}(Y, Y)\\) for the vector \\(\\vec{Y}\\)) captures the pairwise covariances between all elements of the vector of observed responses.\nConnecting \\(\\sigma^2\\) and \\(\\Psi\\) to \\(\\Sigma\\): In the Kriging framework described, the variance of each observation is often assumed to be constant, \\(\\sigma^2\\). The covariance between any two observations \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is given by \\(\\sigma^2\\) multiplied by their correlation. That is, \\[\n\\text{cov}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)})) = \\sigma^2 \\text{cor}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)})).\n\\] This relationship holds for all pairs of points. When expressed in matrix form, the covariance matrix \\(\\Sigma\\) is the product of the variance \\(\\sigma^2\\) (a scalar) and the correlation matrix \\(\\Psi\\): \\[\n\\Sigma = \\sigma^2 \\Psi.\n\\]\n\nIn essence, the correlation matrix \\(\\Psi\\) defines the structure or shape of the dependencies between the data points based on their locations. The parameter \\(\\sigma^2\\) acts as a scaling factor that converts these unitless correlation values (which are between -1 and 1) into actual covariance values with units of variance, setting the overall level of variability in the system.\nSo, \\(\\sigma^2\\) tells us about the general spread or variability of the underlying process, while \\(\\Psi\\) tells you how that variability is distributed and how strongly points are related to each other based on their positions. Together, they completely define the covariance structure of your observed data in the multivariate normal distribution used in Kriging.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#implementing-an-mle-of-the-model-parameters",
    "href": "006_num_gp.html#implementing-an-mle-of-the-model-parameters",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.4 Implementing an MLE of the Model Parameters",
    "text": "8.4 Implementing an MLE of the Model Parameters\nThe matrix algebra necessary for calculating the likelihood is the most computationally intensive aspect of the Kriging process. It is crucial to ensure that the code implementation is as efficient as possible.\nGiven that \\(\\Psi\\) (our correlation matrix) is symmetric, only half of the matrix needs to be computed before adding it to its transpose. When calculating the log-likelihood, several matrix inversions are required. The fastest approach is to conduct one Cholesky factorization and then apply backward and forward substitution for each inverse.\nThe Cholesky factorization is applicable only to positive-definite matrices, which \\(\\Psi\\) generally is. However, if \\(\\Psi\\) becomes nearly singular, such as when the \\(\\vec{x}^{(i)}\\)’s are densely packed, the Cholesky factorization might fail. In these cases, one could employ an LU-decomposition, though the result might be unreliable. When \\(\\Psi\\) is near singular, the best course of action is to either use regression techniques or, as we do here, assign a poor likelihood value to parameters generating the near singular matrix, thus diverting the MLE search towards better-conditioned \\(\\Psi\\) matrices.\nWhen working with correlation matrices, increasing the values on the main diagonal of a matrix will increase the absolute value of its determinant. A critical numerical consideration in calculating the concentrated log-likelihood is that for poorly conditioned matrices, \\(\\det(\\Psi)\\) approaches zero, leading to potential numerical instability. To address this issue, it is advisable to calculate \\(\\ln(\\lvert\\Psi\\rvert)\\) in Equation 8.11 using twice the sum of the logarithms of the diagonal elements of the Cholesky factorization. This approach provides a more numerically stable method for computing the log-determinant, as the Cholesky decomposition \\(\\Psi = L L^T\\) allows us to express \\(\\ln(\\lvert\\Psi\\rvert) = 2\\sum_{i=1}^{n} \\ln(L_{ii})\\), avoiding the direct computation of potentially very small determinant values.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-prediction",
    "href": "006_num_gp.html#kriging-prediction",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.5 Kriging Prediction",
    "text": "8.5 Kriging Prediction\nWe will use the Kriging correlation \\(\\Psi\\) to predict new values based on the observed data. The presentation follows the approach described in (Forr08a?) and (bart21i?).\nMain idea for prediction is that the new \\(Y(\\vec{x})\\) should be consistent with the old sample data \\(X\\). For a new prediction \\(\\hat{y}\\) at \\(\\vec{x}\\), the value of \\(\\hat{y}\\) is chosen so that it maximizes the likelihood of the sample data \\(X\\) and the prediction, given the (optimized) correlation parameter \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) from above. The observed data \\(\\vec{y}\\) is augmented with the new prediction \\(\\hat{y}\\) which results in the augmented vector \\(\\vec{\\tilde{y}} = ( \\vec{y}^T, \\hat{y})^T\\). A vector of correlations between the observed data and the new prediction is defined as\n\\[ \\vec{\\psi} = \\begin{pmatrix}\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x})\n\\right) \\\\\n\\vdots  \\\\\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x})\n\\right)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\vec{\\psi}^{(1)}\\\\\n\\vdots\\\\\n\\vec{\\psi}^{(n)}\n\\end{pmatrix}.\n\\]\n\nDefinition 8.2 (The Augmented Correlation Matrix) The augmented correlation matrix is constructed as \\[ \\tilde{\\vec{\\Psi}} =\n\\begin{pmatrix}\n\\vec{\\Psi} & \\vec{\\psi} \\\\\n\\vec{\\psi}^T & 1\n\\end{pmatrix}.\n\\]\n\\(\\Box\\)\n\nThe log-likelihood of the augmented data is \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\hat{\\sigma}^2) - \\frac{1}{2} \\ln |\\vec{\\hat{\\Psi}}| -  \\frac{(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})^T \\vec{\\tilde{\\Psi}}^{-1}(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})}{2 \\hat{\\sigma}^2},\n\\tag{8.12}\\]\nwhere \\(\\vec{1}\\) is a vector of ones and \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}^2\\) are the MLEs from Equation 8.9 and Equation 8.10. Only the last term in Equation 8.12 depends on \\(\\hat{y}\\), so we need only consider this term in the maximization. Details can be found in (Forr08a?). Finally, the MLE for \\(\\hat{y}\\) can be calculated as \\[\n\\hat{y}(\\vec{x}) = \\hat{\\mu} + \\vec{\\psi}^T \\vec{\\tilde{\\Psi}}^{-1} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\tag{8.13}\\]\nEquation 8.13 reveals two important properties of the Kriging predictor:\n\nBasis functions: The basis function impacts the vector \\(\\vec{\\psi}\\), which contains the \\(n\\) correlations between the new point \\(\\vec{x}\\) and the observed locations. Values from the \\(n\\) basis functions are added to a mean base term \\(\\mu\\) with weightings \\[\n\\vec{w} = \\vec{\\tilde{\\Psi}}^{(-1)} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\]\nInterpolation: The predictions interpolate the sample data. When calculating the prediction at the \\(i\\)th sample point, \\(\\vec{x}^{(i)}\\), the \\(i\\)th column of \\(\\vec{\\Psi}^{-1}\\) is \\(\\vec{\\psi}\\), and \\(\\vec{\\psi}  \\vec{\\Psi}^{-1}\\) is the \\(i\\)th unit vector. Hence,\n\n\\[\n\\hat{y}(\\vec{x}^{(i)}) = y^{(i)}.\n\\]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-example-sinusoid-function",
    "href": "006_num_gp.html#kriging-example-sinusoid-function",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.6 Kriging Example: Sinusoid Function",
    "text": "8.6 Kriging Example: Sinusoid Function\nToy example in 1d where the response is a simple sinusoid measured at eight equally spaced \\(x\\)-locations in the span of a single period of oscillation.\n\n8.6.1 Calculating the Correlation Matrix \\(\\Psi\\)\nThe correlation matrix \\(\\Psi\\) is based on the pairwise squared distances between the input locations. Here we will use \\(n=8\\) sample locations and \\(\\theta\\) is set to 1.0.\n\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\nprint(np.round(X, 2))\n\n[[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\n\n\nEvaluate at sample points\n\ny = np.sin(X)\nprint(np.round(y, 2))\n\n[[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]\n\n\nWe have the data points shown in Table 8.1.\n\n\n\nTable 8.1: Data points for the sinusoid function\n\n\n\n\n\n\\(x\\)\n\\(y\\)\n\n\n\n\n0.0\n0.0\n\n\n0.79\n0.71\n\n\n1.57\n1.0\n\n\n2.36\n0.71\n\n\n3.14\n0.0\n\n\n3.93\n-0.71\n\n\n4.71\n-1.0\n\n\n5.5\n-0.71\n\n\n\n\n\n\nThe data points are visualized in Figure 8.4.\n\nplt.plot(X, y, \"bo\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\nFigure 8.4: Sin(x) evaluated at 8 points.\n\n\n\n\n\n\n\n8.6.2 Computing the \\(\\Psi\\) Matrix\nWe will use the build_Psi function from Example 8.4 to compute the correlation matrix \\(\\Psi\\). \\(\\theta\\) should be an array of one value, because we are only working in one dimension (\\(k=1\\)).\n\ntheta = np.array([1.0])\nPsi = build_Psi(X, theta)\nprint(np.round(Psi, 2))\n\n[[1.   0.54 0.08 0.   0.   0.   0.   0.  ]\n [0.54 1.   0.54 0.08 0.   0.   0.   0.  ]\n [0.08 0.54 1.   0.54 0.08 0.   0.   0.  ]\n [0.   0.08 0.54 1.   0.54 0.08 0.   0.  ]\n [0.   0.   0.08 0.54 1.   0.54 0.08 0.  ]\n [0.   0.   0.   0.08 0.54 1.   0.54 0.08]\n [0.   0.   0.   0.   0.08 0.54 1.   0.54]\n [0.   0.   0.   0.   0.   0.08 0.54 1.  ]]\n\n\nFigure 8.5 visualizes the \\((8, 8)\\) correlation matrix \\(\\Psi\\).\n\n\n\n\n\n\n\n\nFigure 8.5: Correlation matrix \\(\\Psi\\) for the sinusoid function.\n\n\n\n\n\n\n\n8.6.3 Selecting the New Locations\nWe would like to predict at \\(m = 100\\) new locations (or testign locations) in the interval \\([0, 2\\pi]\\). The new locations are stored in the variable x.\n\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\n\n\n\n8.6.4 Computing the \\(\\psi\\) Vector\nDistances between testing locations \\(x\\) and training data locations \\(X\\).\n\ndef build_psi(X, x, theta, eps=sqrt(spacing(1))):\n    n = X.shape[0]\n    k = X.shape[1]\n    m = x.shape[0]\n    psi = zeros((n, m))\n    theta = theta * ones(k)\n    D = zeros((n, m))\n    D = cdist(x.reshape(-1, k),\n              X.reshape(-1, k),\n              metric='sqeuclidean',\n              out=None,\n              w=theta)    \n    psi = exp(-D)\n    # return psi transpose to be consistent with the literature\n    print(f\"Dimensions of psi: {psi.T.shape}\")\n    return(psi.T)\n\npsi = build_psi(X, x, theta)\n\nDimensions of psi: (8, 100)\n\n\nFigure 8.6 visualizes the \\((8, 100)\\) prediction matrix \\(\\psi\\).\n\n\n\n\n\n\n\n\nFigure 8.6: Visualization of the predition matrix \\(\\psi\\)\n\n\n\n\n\n\n\n8.6.5 Predicting at New Locations\nComputation of the predictive equations.\n\nU = cholesky(Psi).T\none = np.ones(n).reshape(-1,1)\nmu = (one.T.dot(solve(U, solve(U.T, y)))) / one.T.dot(solve(U, solve(U.T, one)))\nf = mu * ones(m).reshape(-1,1) + psi.T.dot(solve(U, solve(U.T, y - one * mu)))\nprint(f\"Dimensions of f: {f.shape}\")\n\nDimensions of f: (100, 1)\n\n\nTo compute \\(f\\), Equation 8.13 is used.\n\n\n8.6.6 Visualization\n\nplt.plot(x, f, color = \"orange\", label=\"Fitted\")\nplt.plot(x, np.sin(x), color = \"grey\", label=\"Original\")\nplt.plot(X, y, \"bo\", label=\"Measurements\")\nplt.title(\"Kriging prediction of sin(x) with {} points.\\n theta: {}\".format(n, theta[0]))\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n8.6.7 The Complete Python Code for the Example\nHere is the self-contained Python code for direct use in a notebook:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import (array, zeros, power, ones, exp, multiply, eye, linspace, spacing, sqrt, arange, append, ravel)\nfrom numpy.linalg import cholesky, solve\nfrom scipy.spatial.distance import squareform, pdist, cdist\n\n# --- 1. Kriging Basis Functions (Defining the Correlation) ---\n# The core of Kriging uses a specialized basis function for correlation:\n# psi(x^(i), x) = exp(- sum_{j=1}^k theta_j |x_j^(i) - x_j|^p_j)\n# For this 1D example (k=1), and with p_j=2 (squared Euclidean distance implicit from pdist usage)\n# and theta_j = theta (a single value), it simplifies.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    \"\"\"\n    Computes the correlation matrix Psi based on pairwise squared Euclidean distances\n    between input locations, scaled by theta.\n    Adds a small epsilon to the diagonal for numerical stability (nugget effect).\n    \"\"\"\n    # Calculate pairwise squared Euclidean distances (D) between points in X\n    D = squareform(pdist(X, metric='sqeuclidean', out=None, w=theta))\n    # Compute Psi = exp(-D)\n    Psi = exp(-D)\n    # Add a small value to the diagonal for numerical stability (nugget)\n    # This is often done in Kriging implementations, though a regression method\n    # with a 'nugget' parameter (Lambda) is explicitly mentioned for noisy data later.\n    # The source code snippet for build_Psi explicitly includes `multiply(eye(X.shape), eps)`.\n    # FIX: Use X.shape to get the number of rows for the identity matrix\n    Psi += multiply(eye(X.shape[0]), eps) # Corrected line\n    return Psi\n\ndef build_psi(X_train, x_predict, theta):\n    \"\"\"\n    Computes the correlation vector (or matrix) psi between new prediction locations\n    and training data locations.\n    \"\"\"\n    # Calculate pairwise squared Euclidean distances (D) between prediction points (x_predict)\n    # and training points (X_train).\n    # `cdist` computes distances between each pair of the two collections of inputs.\n    D = cdist(x_predict, X_train, metric='sqeuclidean', out=None, w=theta)\n    # Compute psi = exp(-D)\n    psi = exp(-D)\n    return psi.T # Return transpose to be consistent with literature (n x m or n x 1)\n\n# --- 2. Data Points for the Sinusoid Function Example ---\n# The example uses a 1D sinusoid measured at eight equally spaced x-locations [153, Table 9.1].\nn = 8 # Number of sample locations\nX_train = np.linspace(0, 2 * np.pi, n, endpoint=False).reshape(-1, 1) # Generate x-locations\ny_train = np.sin(X_train) # Corresponding y-values (sine of x)\n\nprint(\"--- Training Data (X_train, y_train) ---\")\nprint(\"x values:\\n\", np.round(X_train, 2))\nprint(\"y values:\\n\", np.round(y_train, 2))\nprint(\"-\" * 40)\n\n# Visualize the data points\nplt.figure(figsize=(8, 5))\nplt.plot(X_train, y_train, \"bo\", label=f\"Measurements ({n} points)\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.xlabel(\"x\")\nplt.ylabel(\"sin(x)\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# --- 3. Calculating the Correlation Matrix (Psi) ---\n# Psi is based on pairwise squared distances between input locations.\n# theta is set to 1.0 for this 1D example.\ntheta = np.array([1.0])\nPsi = build_Psi(X_train, theta)\n\nprint(\"\\n--- Computed Correlation Matrix (Psi) ---\")\nprint(\"Dimensions of Psi:\", Psi.shape) # Should be (8, 8)\nprint(\"First 5x5 block of Psi:\\n\", np.round(Psi[:5,:5], 2))\nprint(\"-\" * 40)\n\n# --- 4. Selecting New Locations (for Prediction) ---\n# We want to predict at m = 100 new locations in the interval [0, 2*pi].\nm = 100 # Number of new locations\nx_predict = np.linspace(0, 2 * np.pi, m, endpoint=True).reshape(-1, 1)\n\nprint(\"\\n--- New Locations for Prediction (x_predict) ---\")\nprint(f\"Number of prediction points: {m}\")\nprint(\"First 5 prediction points:\\n\", np.round(x_predict[:5], 2).flatten())\nprint(\"-\" * 40)\n\n# --- 5. Computing the psi Vector ---\n# This vector contains correlations between each of the n observed data points\n# and each of the m new prediction locations.\npsi = build_psi(X_train, x_predict, theta)\n\nprint(\"\\n--- Computed Prediction Correlation Matrix (psi) ---\")\nprint(\"Dimensions of psi:\", psi.shape) # Should be (8, 100)\nprint(\"First 5x5 block of psi:\\n\", np.round(psi[:5,:5], 2))\nprint(\"-\" * 40)\n\n# --- 6. Predicting at New Locations (Kriging Prediction) ---\n# The Maximum Likelihood Estimate (MLE) for y_hat is calculated using the formula:\n# y_hat(x) = mu_hat + psi.T @ Psi_inv @ (y - 1 * mu_hat) [p. 2 of previous response, and 263]\n# Matrix inversion is efficiently performed using Cholesky factorization.\n\n# Step 6a: Cholesky decomposition of Psi\nU = cholesky(Psi).T # Note: `cholesky` in numpy returns lower triangular L, we need U (upper) so transpose L.\n\n# Step 6b: Calculate mu_hat (estimated mean)\n# mu_hat = (one.T @ Psi_inv @ y) / (one.T @ Psi_inv @ one) [p. 2 of previous response]\none = np.ones(n).reshape(-1, 1) # Vector of ones\nmu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one)))\nmu_hat = mu_hat.item() # Extract scalar value\n\nprint(\"\\n--- Kriging Prediction Calculation ---\")\nprint(f\"Estimated mean (mu_hat): {np.round(mu_hat, 4)}\")\n\n# Step 6c: Calculate predictions f (y_hat) at new locations\n# f = mu_hat * ones(m) + psi.T @ Psi_inv @ (y - one * mu_hat)\nf_predict = mu_hat * np.ones(m).reshape(-1, 1) + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat))\n\nprint(f\"Dimensions of predicted values (f_predict): {f_predict.shape}\") # Should be (100, 1)\nprint(\"First 5 predicted f values:\\n\", np.round(f_predict[:5], 2).flatten())\nprint(\"-\" * 40)\n\n# --- 7. Visualization ---\n# Plot the original sinusoid function, the measured points, and the Kriging predictions.\n\nplt.figure(figsize=(10, 6))\nplt.plot(x_predict, f_predict, color=\"orange\", label=\"Kriging Prediction\")\nplt.plot(x_predict, np.sin(x_predict), color=\"grey\", linestyle='--', label=\"True Sinusoid Function\")\nplt.plot(X_train, y_train, \"bo\", markersize=8, label=\"Measurements\")\nplt.title(f\"Kriging prediction of sin(x) with {n} points. (theta: {theta})\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.show()\n\n--- Training Data (X_train, y_train) ---\nx values:\n [[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\ny values:\n [[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]\n----------------------------------------\n\n\n\n\n\n\n\n\n\n\n--- Computed Correlation Matrix (Psi) ---\nDimensions of Psi: (8, 8)\nFirst 5x5 block of Psi:\n [[1.   0.54 0.08 0.   0.  ]\n [0.54 1.   0.54 0.08 0.  ]\n [0.08 0.54 1.   0.54 0.08]\n [0.   0.08 0.54 1.   0.54]\n [0.   0.   0.08 0.54 1.  ]]\n----------------------------------------\n\n--- New Locations for Prediction (x_predict) ---\nNumber of prediction points: 100\nFirst 5 prediction points:\n [0.   0.06 0.13 0.19 0.25]\n----------------------------------------\n\n--- Computed Prediction Correlation Matrix (psi) ---\nDimensions of psi: (8, 100)\nFirst 5x5 block of psi:\n [[1.   1.   0.98 0.96 0.94]\n [0.54 0.59 0.65 0.7  0.75]\n [0.08 0.1  0.12 0.15 0.18]\n [0.   0.01 0.01 0.01 0.01]\n [0.   0.   0.   0.   0.  ]]\n----------------------------------------\n\n--- Kriging Prediction Calculation ---\nEstimated mean (mu_hat): -0.0499\nDimensions of predicted values (f_predict): (100, 1)\nFirst 5 predicted f values:\n [0.   0.05 0.1  0.15 0.21]\n----------------------------------------",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#jupyter-notebook",
    "href": "006_num_gp.html#jupyter-notebook",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.7 Jupyter Notebook",
    "text": "8.7 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_matrices.html",
    "href": "006_matrices.html",
    "title": "9  Matrices",
    "section": "",
    "text": "9.1 Derivatives of Quadratic Forms\nWe present a step-by-step derivation of the general formula \\[\n\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}.\n\\tag{9.1}\\]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-derivative-quadratic-form",
    "href": "006_matrices.html#sec-derivative-quadratic-form",
    "title": "9  Matrices",
    "section": "",
    "text": "Define the components. Let \\(\\mathbf{v}\\) be a vector of size \\(n \\times 1\\), and let \\(\\mathbf{A}\\) be a matrix of size \\(n \\times n\\).\nWrite out the quadratic form in summation notation. The product \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) is a scalar. It can be expanded and be rewritten as a double summation: \\[\n\\mathbf{v}^T \\mathbf{A} \\mathbf{v} = \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j.\n\\]\nCalculate the partial derivative with respect to a component \\(v_k\\): The derivative of the scalar \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to the vector \\(\\mathbf{v}\\) is the gradient vector, whose \\(k\\)-th component is \\(\\frac{\\partial}{\\partial v_k} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v})\\). We need to find \\(\\frac{\\partial}{\\partial v_k} \\left( \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j \\right)\\). Consider the terms in the summation that involve \\(v_k\\). A term \\(v_i a_{ij} v_j\\) involves \\(v_k\\) if \\(i=k\\) or \\(j=k\\) (or both).\n\nTerms where \\(i=k\\): \\(v_k a_{kj} v_j\\). The derivative with respect to \\(v_k\\) is \\(a_{kj} v_j\\).\nTerms where \\(j=k\\): \\(v_i a_{ik} v_k\\). The derivative with respect to \\(v_k\\) is \\(v_i a_{ik}\\).\nThe term where \\(i=k\\) and \\(j=k\\): \\(v_k a_{kk} v_k = a_{kk} v_k^2\\). Its derivative with respect to \\(v_k\\) is \\(2 a_{kk} v_k\\). Notice this term is included in both cases above when \\(i=k\\) and \\(j=k\\). When \\(i=k\\), the term is \\(v_k a_{kk} v_k\\), derivative is \\(a_{kk} v_k\\). When \\(j=k\\), the term is \\(v_k a_{kk} v_k\\), derivative is \\(v_k a_{kk}\\). Summing these two gives \\(2 a_{kk} v_k\\).\n\nLet’s differentiate the sum \\(\\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j\\) with respect to \\(v_k\\): \\[\n\\frac{\\partial}{\\partial v_k} \\left( \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j \\right) = \\sum_{i=1}^n \\sum_{j=1}^n \\frac{\\partial}{\\partial v_k} (v_i a_{ij} v_j).\n\\]\nThe partial derivative \\(\\frac{\\partial}{\\partial v_k} (v_i a_{ij} v_j)\\) is non-zero only if \\(i=k\\) or \\(j=k\\).\n\nIf \\(i=k\\) and \\(j \\ne k\\): \\(\\frac{\\partial}{\\partial v_k} (v_k a_{kj} v_j) = a_{kj} v_j\\).\nIf \\(i \\ne k\\) and \\(j = k\\): \\(\\frac{\\partial}{\\partial v_k} (v_i a_{ik} v_k) = v_i a_{ik}\\).\nIf \\(i=k\\) and \\(j=k\\): \\(\\frac{\\partial}{\\partial v_k} (v_k a_{kk} v_k) = \\frac{\\partial}{\\partial v_k} (a_{kk} v_k^2) = 2 a_{kk} v_k\\).\n\nSo, the partial derivative is the sum of derivatives of all terms involving \\(v_k\\): \\(\\frac{\\partial}{\\partial v_k} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\sum_{j \\ne k} (a_{kj} v_j) + \\sum_{i \\ne k} (v_i a_{ik}) + (2 a_{kk} v_k)\\).\nWe can rewrite this by including the \\(i=k, j=k\\) term back into the summations: \\(\\sum_{j \\ne k} (a_{kj} v_j) + a_{kk} v_k + \\sum_{i \\ne k} (v_i a_{ik}) + v_k a_{kk}\\) (since \\(v_k a_{kk} = a_{kk} v_k\\)) \\(= \\sum_{j=1}^n a_{kj} v_j + \\sum_{i=1}^n v_i a_{ik}\\).\nConvert back to matrix/vector notation: The first summation \\(\\sum_{j=1}^n a_{kj} v_j\\) is the \\(k\\)-th component of the matrix-vector product \\(\\mathbf{A} \\mathbf{v}\\).The second summation \\(\\sum_{i=1}^n v_i a_{ik}\\) can be written as \\(\\sum_{i=1}^n a_{ik} v_i\\). Recall that the element in the \\(k\\)-th row and \\(i\\)-th column of the transpose matrix \\(\\mathbf{A}^T\\) is \\((A^T)_{ki} = a_{ik}\\). So, \\(\\sum_{i=1}^n a_{ik} v_i = \\sum_{i=1}^n (A^T)_{ki} v_i\\), which is the \\(k\\)-th component of the matrix-vector product \\(\\mathbf{A}^T \\mathbf{v}\\).\nAssemble the gradient vector: The \\(k\\)-th component of the gradient \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v})\\) is \\((\\mathbf{A} \\mathbf{v})_k + (\\mathbf{A}^T \\mathbf{v})_k\\). Since this holds for all \\(k = 1, \\dots, n\\), the gradient vector is the sum of the two vectors \\(\\mathbf{A} \\mathbf{v}\\) and \\(\\mathbf{A}^T \\mathbf{v}\\). Therefore, the general formula for the derivative is \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-conditon-number",
    "href": "006_matrices.html#sec-conditon-number",
    "title": "9  Matrices",
    "section": "9.2 The Condition Number",
    "text": "9.2 The Condition Number\nA small value, eps, can be passed to the function build_Psi to improve the condition number. For example, eps=sqrt(spacing(1)) can be used. The numpy function spacing() returns the distance between a number and its nearest adjacent number.\nThe condition number of a matrix is a measure of its sensitivity to small changes in its elements. It is used to estimate how much the output of a function will change if the input is slightly altered.\nA matrix with a low condition number is well-conditioned, which means its behavior is relatively stable, while a matrix with a high condition number is ill-conditioned, meaning its behavior is unstable with respect to numerical precision.\n\nimport numpy as np\n\n# Define a well-conditioned matrix (low condition number)\nA = np.array([[1, 0.1], [0.1, 1]])\nprint(\"Condition number of A: \", np.linalg.cond(A))\n\n# Define an ill-conditioned matrix (high condition number)\nB = np.array([[1, 0.99999999], [0.99999999, 1]])\nprint(\"Condition number of B: \", np.linalg.cond(B))\n\nCondition number of A:  1.2222222222222225\nCondition number of B:  200000000.57495335",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-matrix-pseudoinverse",
    "href": "006_matrices.html#sec-matrix-pseudoinverse",
    "title": "9  Matrices",
    "section": "9.3 The Moore-Penrose Pseudoinverse",
    "text": "9.3 The Moore-Penrose Pseudoinverse\n\n9.3.1 Definitions\nThe Moore-Penrose pseudoinverse is a generalization of the inverse matrix for non-square or singular matrices. It is computed as\n\\[\nA^+ = (A^* A)^{-1} A^*,\n\\] where \\(A^*\\) is the conjugate transpose of \\(A\\).\nIt satisfies the following properties:\n\n\\(AA^+A = A\\)\n\\(A^+AA^+ = A^+\\)\n\\((AA^+)^* = AA^+\\).\n\\((A^+A)^* = A^+A\\)\n\\(A^+ = (A^*)^+\\)\n\\(A^+ = A^T\\) if \\(A\\) is a square matrix and \\(A\\) is invertible.\n\nThe pseudoinverse can be computed using Singular Value Decomposition (SVD).\n\n\n9.3.2 Implementation in Python\n\nimport numpy as np\nfrom numpy.linalg import pinv\nA = np.array([[1, 2], [3, 4], [5, 6]])\nprint(f\"Matrix A:\\n {A}\")\nA_pseudo_inv = pinv(A)\nprint(f\"Moore-Penrose Pseudoinverse:\\n {A_pseudo_inv}\")\n\nMatrix A:\n [[1 2]\n [3 4]\n [5 6]]\nMoore-Penrose Pseudoinverse:\n [[-1.33333333 -0.33333333  0.66666667]\n [ 1.08333333  0.33333333 -0.41666667]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-strictly-positive-definite",
    "href": "006_matrices.html#sec-strictly-positive-definite",
    "title": "9  Matrices",
    "section": "9.4 Strictly Positive Definite Kernels",
    "text": "9.4 Strictly Positive Definite Kernels\n\n9.4.1 Definition\n\nDefinition 9.1 (Strictly Positive Definite Kernel) A kernel function \\(k(x,y)\\) is called strictly positive definite if for any finite collection of distinct points \\({x_1, x_2, \\ldots, x_n}\\) in the input space and any non-zero vector of coefficients \\(\\alpha = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_n)\\), the following inequality holds:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_i \\alpha_j k(x_i, x_j) &gt; 0.\n\\tag{9.2}\\]\n\nIn contrast, a kernel function \\(k(x,y)\\) is called positive definite (but not strictly) if the “\\(&gt;\\)” sign is replaced by “\\(\\geq\\)” in the above inequality.\n\n\n9.4.2 Connection to Positive Definite Matrices\nThe connection between strictly positive definite kernels and positive definite matrices lies in the Gram matrix construction:\n\nWhen we evaluate a kernel function \\(k(x,y)\\) at all pairs of data points in our sample, we construct the Gram matrix \\(K\\) where \\(K_{ij} = k(x_i, x_j)\\).\nIf the kernel function \\(k\\) is strictly positive definite, then for any set of distinct points, the resulting Gram matrix will be symmetric positive definite.\n\nA symmetric matrix is positive definite if and only if for any non-zero vector \\(\\alpha\\), the quadratic form \\(\\alpha^T K \\alpha &gt; 0\\), which directly corresponds to the kernel definition above.\n\n\n9.4.3 Connection to RBF Models\nFor RBF models, the kernel function is the radial basis function itself: \\[\nk(x,y) = \\psi(||x-y||).\n\\]\nThe Gaussian RBF kernel \\(\\psi(r) = e^{-r^2/(2\\sigma^2)}\\) is strictly positive definite in \\(\\mathbb{R}^n\\) for any dimension \\(n\\). The inverse multiquadric kernel \\(\\psi(r) = (r^2 + \\sigma^2)^{-1/2}\\) is also strictly positive definite in any dimension.\nThis mathematical property guarantees that the interpolation problem has a unique solution (the weight vector \\(\\vec{w}\\) is uniquely determined). The linear system \\(\\Psi \\vec{w} = \\vec{y}\\) can be solved reliably using Cholesky decomposition. The RBF interpolant exists and is unique for any distinct set of centers.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#cholesky-decomposition-and-positive-definite-matrices",
    "href": "006_matrices.html#cholesky-decomposition-and-positive-definite-matrices",
    "title": "9  Matrices",
    "section": "9.5 Cholesky Decomposition and Positive Definite Matrices",
    "text": "9.5 Cholesky Decomposition and Positive Definite Matrices\nWe consider the definiteness of a matrix, before discussing the Cholesky decomposition.\n\nDefinition 9.2 (Positive Definite Matrix) A symmetric matrix \\(A\\) is positive definite if all its eigenvalues are positive.\n\n\nExample 9.1 (Positive Definite Matrix) Given a symmetric matrix \\(A = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\), the eigenvalues of \\(A\\) are \\(\\lambda_1 = 13\\) and \\(\\lambda_2 = 5\\). Since both eigenvalues are positive, the matrix \\(A\\) is positive definite.\n\n\nDefinition 9.3 (Negative Definite, Positive Semidefinite, and Negative Semidefinite Matrices) Similarily, a symmetric matrix \\(A\\) is negative definite if all its eigenvalues are negative. It is positive semidefinite if all its eigenvalues are non-negative, and negative semidefinite if all its eigenvalues are non-positive.\n\nThe covariance matrix must be positive definite for a multivariate normal distribution for a couple of reasons:\n\nSemidefinite vs Definite: A covariance matrix is always symmetric and positive semidefinite. However, for a multivariate normal distribution, it must be positive definite, not just semidefinite. This is because a positive semidefinite matrix can have zero eigenvalues, which would imply that some dimensions in the distribution have zero variance, collapsing the distribution in those dimensions. A positive definite matrix has all positive eigenvalues, ensuring that the distribution has positive variance in all dimensions.\nInvertibility: The multivariate normal distribution’s probability density function involves the inverse of the covariance matrix. If the covariance matrix is not positive definite, it may not be invertible, and the density function would be undefined.\n\nIn summary, the covariance matrix being positive definite ensures that the multivariate normal distribution is well-defined and has positive variance in all dimensions.\nThe definiteness of a matrix can be checked by examining the eigenvalues of the matrix. If all eigenvalues are positive, the matrix is positive definite.\n\nimport numpy as np\n\ndef is_positive_definite(matrix):\n    return np.all(np.linalg.eigvals(matrix) &gt; 0)\n\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_positive_definite(matrix))  # Outputs: True\n\nTrue\n\n\nHowever, a more efficient way to check the definiteness of a matrix is through the Cholesky decomposition.\n\nDefinition 9.4 (Cholesky Decomposition) For a given symmetric positive-definite matrix \\(A \\in \\mathbb{R}^{n \\times n}\\), there exists a unique lower triangular matrix \\(L \\in \\mathbb{R}^{n \\times n}\\) with positive diagonal elements such that:\n\\[\nA = L L^T.\n\\]\nHere, \\(L^T\\) denotes the transpose of \\(L\\).\n\n\nExample 9.2 (Cholesky decomposition using numpy) linalg.cholesky computes the Cholesky decomposition of a matrix, i.e., it computes a lower triangular matrix \\(L\\) such that \\(LL^T = A\\). If the matrix is not positive definite, an error (LinAlgError) is raised.\n\nimport numpy as np\n\n# Define a Hermitian, positive-definite matrix\nA = np.array([[9, 4], [4, 9]]) \n\n# Compute the Cholesky decomposition\nL = np.linalg.cholesky(A)\n\nprint(\"L = \\n\", L)\nprint(\"L*LT = \\n\", np.dot(L, L.T))\n\nL = \n [[3.         0.        ]\n [1.33333333 2.68741925]]\nL*LT = \n [[9. 4.]\n [4. 9.]]\n\n\n\n\nExample 9.3 (Cholesky Decomposition) Given a symmetric positive-definite matrix \\(A = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\), the Cholesky decomposition computes the lower triangular matrix \\(L\\) such that \\(A = L L^T\\). The matrix \\(L\\) is computed as: \\[\nL = \\begin{pmatrix} 3 & 0 \\\\ 4/3 & 2 \\end{pmatrix},\n\\] so that \\[\nL L^T = \\begin{pmatrix} 3 & 0 \\\\ 4/3 & \\sqrt{65}/3 \\end{pmatrix} \\begin{pmatrix} 3 & 4/3 \\\\ 0 & \\sqrt{65}/3 \\end{pmatrix} = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix} = A.\n\\]\n\nAn efficient implementation of the definiteness-check based on Cholesky is already available in the numpy library. It provides the np.linalg.cholesky function to compute the Cholesky decomposition of a matrix. This more efficient numpy-approach can be used as follows:\n\nimport numpy as np\n\ndef is_pd(K):\n    try:\n        np.linalg.cholesky(K)\n        return True\n    except np.linalg.linalg.LinAlgError as err:\n        if 'Matrix is not positive definite' in err.message:\n            return False\n        else:\n            raise\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_pd(matrix))  # Outputs: True\n\nTrue\n\n\n\n9.5.1 Example of Cholesky Decomposition\nWe consider dimension \\(k=1\\) and \\(n=2\\) sample points. The sample points are located at \\(x_1=1\\) and \\(x_2=5\\). The response values are \\(y_1=2\\) and \\(y_2=10\\). The correlation parameter is \\(\\theta=1\\) and \\(p\\) is set to \\(1\\). Using Equation 8.1, we can compute the correlation matrix \\(\\Psi\\):\n\\[\n\\Psi = \\begin{pmatrix}\n1 & e^{-1}\\\\\ne^{-1} & 1\n\\end{pmatrix}.\n\\]\nTo determine MLE as in Equation 8.13, we need to compute \\(\\Psi^{-1}\\):\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nCholesky-decomposition of \\(\\Psi\\) is recommended to compute \\(\\Psi^{-1}\\). Cholesky decomposition is a decomposition of a positive definite symmetric matrix into the product of a lower triangular matrix \\(L\\), a diagonal matrix \\(D\\) and the transpose of \\(L\\), which is denoted as \\(L^T\\). Consider the following example:\n\\[\nLDL^T=\n\\begin{pmatrix}\n1 & 0 \\\\\nl_{21} & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nd_{11} & 0 \\\\\n0 & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}=\n\\]\n\\[\n\\begin{pmatrix}\nd_{11} & 0 \\\\\nd_{11} l_{21} & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nd_{11} & d_{11} l_{21} \\\\\nd_{11} l_{21} & d_{11} l_{21}^2 + d_{22}\n\\end{pmatrix}.\n\\tag{9.3}\\]\nUsing Equation 9.3, we can compute the Cholesky decomposition of \\(\\Psi\\):\n\n\\(d_{11} = 1\\),\n\\(l_{21}d_{11} = e^{-1} \\Rightarrow l_{21} = e^{-1}\\), and\n\\(d_{11} l_{21}^2 + d_{22} = 1 \\Rightarrow d_{22} = 1 - e^{-2}\\).\n\nThe Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & 1\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 1 - e^{-2}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & 1\\\\\n\\end{pmatrix}\n= LDL^T\\]\nSome programs use \\(U\\) instead of \\(L\\). The Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = LDL^T = U^TDU.\n\\]\nUsing \\[\n\\sqrt{D} =\\begin{pmatrix}\n1 & 0\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix},\n\\] we can write the Cholesky decomposition of \\(\\Psi\\) without a diagonal matrix \\(D\\) as \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n= U^TU.\n\\]\n\n\n9.5.2 Inverse Matrix Using Cholesky Decomposition\nTo compute the inverse of a matrix using the Cholesky decomposition, you can follow these steps:\n\nDecompose the matrix \\(A\\) into \\(L\\) and \\(L^T\\), where \\(L\\) is a lower triangular matrix and \\(L^T\\) is the transpose of \\(L\\).\nCompute \\(L^{-1}\\), the inverse of \\(L\\).\nThe inverse of \\(A\\) is then \\((L^{-1})^T  L^-1\\).\n\nPlease note that this method only applies to symmetric, positive-definite matrices.\nThe inverse of the matrix \\(\\Psi\\) from above is:\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nHere’s an example of how to compute the inverse of a matrix using Cholesky decomposition in Python:\n\nimport numpy as np\nfrom scipy.linalg import cholesky, inv\nE = np.exp(1)\n\n# Psi is a symmetric, positive-definite matrix \nPsi = np.array([[1, 1/E], [1/E, 1]])\nL = cholesky(Psi, lower=True)\nL_inv = inv(L)\n# The inverse of A is (L^-1)^T * L^-1\nPsi_inv = np.dot(L_inv.T, L_inv)\n\nprint(\"Psi:\\n\", Psi)\nprint(\"Psi Inverse:\\n\", Psi_inv)\n\nPsi:\n [[1.         0.36787944]\n [0.36787944 1.        ]]\nPsi Inverse:\n [[ 1.15651764 -0.42545906]\n [-0.42545906  1.15651764]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#nyström-approximation",
    "href": "006_matrices.html#nyström-approximation",
    "title": "9  Matrices",
    "section": "9.6 Nyström Approximation",
    "text": "9.6 Nyström Approximation\n\n9.6.1 What’s the Big Idea?\nImagine you have a huge, detailed map of a country. Working with the full, high-resolution map is slow and takes up a lot of computer memory. The Nyström method is like creating a smaller-scale summary map by only looking at a few key, representative locations.\nIn machine learning, we often work with a kernel matrix (or Gram matrix), which tells us how similar every pair of data points is to each other. For very large datasets, this matrix can become massive, making it computationally expensive to store and process.\nThe Nyström method provides an efficient way to create a low-rank approximation of this large kernel matrix. In simple terms, it finds a “simpler” version of the matrix that captures its most important properties without needing to compute or store the whole thing.\n\n\n\n9.6.2 How Does It Work?\nThe core idea is to select a small, random subset of the columns of the full kernel matrix and use them to reconstruct the entire matrix. Let’s say our full kernel matrix is \\(K\\).\n\nSample: Randomly select \\(l\\) columns from the \\(n\\) total columns of \\(K\\). Let \\(C\\) be the \\(n \\times l\\) matrix of these sampled columns.\nIntersect: Take the rows of \\(C\\) corresponding to the sampled column indices to form the \\(l \\times l\\) matrix \\(W\\).\nApproximate: Using \\(C\\) and \\(W\\), calculate the Nyström approximation \\(\\tilde{K}\\) of \\(K\\): \\[\n\\tilde{K} \\approx C W^{+} C^T\n\\] where \\(W^{+}\\) is the pseudoinverse of \\(W\\).\n\n\n\n\n9.6.3 Example\nSuppose we have 4 data points and the full kernel matrix \\(K\\) is: \\[\nK = \\begin{pmatrix}\n9 & 6 & 3 & 1 \\\\\n6 & 4 & 2 & 0.5 \\\\\n3 & 2 & 1 & 0.25 \\\\\n1 & 0.5 & 0.25 & 0.1\n\\end{pmatrix}\n\\]\nLet’s approximate it by sampling 2 columns (\\(l=2\\)):\n\nSample: Pick the 1st and 3rd columns: \\[\nC = \\begin{pmatrix}\n9 & 3 \\\\\n6 & 2 \\\\\n3 & 1 \\\\\n1 & 0.25\n\\end{pmatrix}\n\\]\nIntersect: Take the 1st and 3rd rows from \\(C\\) to form \\(W\\): \\[\nW = \\begin{pmatrix}\n9 & 3 \\\\\n3 & 1\n\\end{pmatrix}\n\\]\nApproximate: Suppose the pseudoinverse of \\(W\\) is: \\[\nW^{+} = \\begin{pmatrix}\n0.09 & -0.27 \\\\\n-0.27 & 0.81\n\\end{pmatrix}\n\\] Then, \\[\n\\tilde{K} = C W^{+} C^T = \\begin{pmatrix}\n9 & 6 & 3 & 0.675 \\\\\n6 & 4 & 2 & 0.45 \\\\\n3 & 2 & 1 & 0.225 \\\\\n0.675 & 0.45 & 0.225 & 0.05\n\\end{pmatrix}\n\\]\n\n\\(\\tilde{K}\\) is a good approximation of the original \\(K\\), especially in the top-left portion.\n\n\n\n9.6.4 Why Is This Useful?\n\nSpeed: The Nyström method is much faster than computing the full kernel matrix. The complexity is roughly \\(O(l^2 n)\\) instead of \\(O(n^2 d)\\) (where \\(d\\) is the number of features).\nScalability: It allows kernel methods (like SVM or Kernel PCA) to be used on much larger datasets.\nFeature Mapping: The method can be used to project new data points into the same feature space for prediction tasks.\n\nThe quality of the approximation depends on the columns you sample. Uniform random sampling is common and often effective, but more advanced techniques exist to select more informative columns.\n\n\n9.6.5 Applying the Nyström Approximation: How Nyström Approximation Helps Kriging\nKriging can significantly benefit from the Nyström approximation, especially when dealing with large datasets. Kriging is a spatial interpolation method used to estimate values at unmeasured locations based on observed points. It relies on a covariance matrix (often denoted as K) that describes the spatial correlation between all observed data points.\nThe Problem with Standard Kriging:\nThe main computational challenge in Kriging is solving for the weights needed for prediction, which requires inverting the covariance matrix K. For n data points, K is an n x n matrix, and inverting it has computational complexity \\(O(n^3)\\). This becomes impractical for large datasets.\nThe Nyström Solution:\nSince the covariance matrix in Kriging is a type of kernel matrix, we can use the Nyström method to create a low-rank approximation, \\(\\tilde{K}\\). Instead of inverting the full matrix, we use the Woodbury matrix identity on the Nyström approximation, allowing us to efficiently compute \\(\\tilde{K}^{-1}\\) without forming the full matrix. This reduces computational complexity to roughly \\(O(l^2 n)\\), where l is the number of sampled columns.\nIn summary, Nyström makes Kriging feasible for large-scale problems by replacing expensive matrix inversion with a faster, memory-efficient approximation.\n\n\n\n9.6.6 Example: Predicting Temperature with Nyström-Kriging\nSuppose we have temperature readings from 100 weather stations (n=100) and want to predict the temperature at a new location.\nData:\n\nObserved Locations (X): 100 coordinate pairs\nObserved Temperatures (y): 100 values\nPrediction Location (x*): Coordinates of the new location\n\n\n9.6.6.1 Step 1: Nyström Approximation of the Covariance Matrix\n\nSample Representative Points: Randomly select l=10 stations as landmarks.\nCompute C and W:\n\nC: Covariance between all 100 stations and the 10 landmarks (100x10 matrix)\nW: Covariance among the 10 landmarks (10x10 matrix)\n\n\nNyström approximation: \\(\\tilde{K} = C W^{+} C^T\\)\n\n\n9.6.6.2 Step 2: Modeling and Prediction\nStandard Kriging prediction: \\[\ny(x^*) = \\mathbf{k}^{*T} \\mathbf{K}^{-1} \\mathbf{y}\n\\] where \\(\\mathbf{k}^{*T}\\) is the covariance vector between the prediction location and all observed locations.\nNyström-Kriging prediction: \\[\ny(x^*) \\approx \\mathbf{k}^{*T} (\\text{fast\\_approx\\_inverse}(\\mathbf{C}, \\mathbf{W})) \\mathbf{y}\n\\]\nPrediction Steps:\n\nCalculate \\(\\mathbf{k}^{*T}\\): Covariance between new location and all stations.\nApproximate the inverse term using the Woodbury identity with C and W.\nMake the prediction: Take the dot product of \\(\\mathbf{k}^{*T}\\) and the weights vector.\n\nThis yields an accurate prediction efficiently, enabling rapid mapping for large regions.\n\n\n\n9.6.7 Details: Woodbury Matrix Identity for Avoiding the Big Inversion\nFirst, what is the Woodbury matrix identity? It’s a mathematical rule that tells you how to find the inverse of a matrix that’s been modified slightly. Its most useful form is for a “low-rank update”:\n\\[\n(A + UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1}VA^{-1}\n\\]\nThis looks complicated, but the core idea is simple:\n\nIf you have a matrix \\(A\\) that is easy to invert (like a diagonal matrix).\nAnd you add a low-rank matrix to it (the \\(UCV\\) part, where \\(C\\) is small).\nYou can find the new inverse without directly inverting the big \\((A + UCV)\\) matrix. Instead, you only need to invert the much smaller matrix in the middle of the formula: \\((C^{-1} + VA^{-1}U)\\).\n\nHow does this apply to the Nyström approximation?\nIn many machine learning and Kriging applications, we don’t just need the kernel matrix \\(\\tilde{K}\\), but a “regularized” version, \\((\\lambda I + \\tilde{K})\\), where \\(\\lambda I\\) is a diagonal matrix that helps prevent overfitting. We need to find the inverse of this:\n\\[\n(\\lambda I + \\tilde{K})^{-1}\n\\]\nSubstituting the Nyström formula \\(\\tilde{K} = C W^{+} C^T\\), we get:\n\\[\n(\\lambda I + C W^{+} C^T)^{-1}\n\\]\nThis expression fits the Woodbury identity perfectly!\n\n\\(A = \\lambda I\\) (very easy to invert: \\(A^{-1} = \\frac{1}{\\lambda}I\\))\n\\(U = C\\) (our \\(n \\times l\\) matrix)\n\\(C\\) (middle matrix) \\(= W^{+}\\) (our small \\(l \\times l\\) matrix)\n\\(V = C^T\\) (our \\(l \\times n\\) matrix)\n\nBy plugging these into the Woodbury formula, we get an expression for the inverse that only requires inverting a small \\(l \\times l\\) matrix. This means we never have to build the full \\(n \\times n\\) matrix \\(\\tilde{K}\\) or invert it directly. This is the source of the massive speed-up.\n\n\n\n9.6.8 The Example: Step-by-Step\nLet’s reuse our 4-point example and show both the slow way and the fast Woodbury way.\nRecall our matrices:\n\n\\(C = \\begin{pmatrix} 9 & 3 \\\\ 6 & 2 \\\\ 3 & 1 \\\\ 1 & 0.25 \\end{pmatrix}\\)\n\\(W^{+} = \\begin{pmatrix} 0.09 & -0.27 \\\\ -0.27 & 0.81 \\end{pmatrix}\\)\nLet’s use a regularization value \\(\\lambda = 0.1\\).\n\n\n9.6.8.1 Method 1: The Slow Way (Forming the full matrix)\n\nConstruct \\(\\tilde{K}\\): First, we explicitly calculate the full \\(4 \\times 4\\) Nyström approximation \\(\\tilde{K} = C W^{+} C^T\\).\n\\[\n\\tilde{K} = \\begin{pmatrix}\n9 & 6 & 3 & 0.675 \\\\\n6 & 4 & 2 & 0.45 \\\\\n3 & 2 & 1 & 0.225 \\\\\n0.675 & 0.45 & 0.225 & 0.05\n\\end{pmatrix}\n\\]\nAdd the regularization: Now we compute \\((\\lambda I + \\tilde{K})\\).\n\\[\n(\\lambda I + \\tilde{K}) = \\begin{pmatrix}\n9.1 & 6 & 3 & 0.675 \\\\\n6 & 4.1 & 2 & 0.45 \\\\\n3 & 2 & 1.1 & 0.225 \\\\\n0.675 & 0.45 & 0.225 & 0.15\n\\end{pmatrix}\n\\]\nInvert the \\(4 \\times 4\\) matrix: This is the expensive step. The result is:\n\\[\n(\\lambda I + \\tilde{K})^{-1} \\approx\n\\begin{pmatrix}\n9.85 & -14.78 & -0.07 & 0.27 \\\\\n-14.78 & 22.22 & 0.09 & -0.41 \\\\\n-0.07 & 0.09 & 0.91 & -0.03 \\\\\n0.27 & -0.41 & -0.03 & 6.67\n\\end{pmatrix}\n\\]\n\nThis works for our tiny \\(4 \\times 4\\) example, but it would be computationally infeasible if \\(n\\) was 10,000.\n\n\n9.6.8.2 Method 2: The Fast Way (Using Woodbury Identity)\nWe use the Woodbury formula to get the same result without ever creating a \\(4 \\times 4\\) matrix. The formula simplifies to:\n\\[\n(\\lambda I + \\tilde{K})^{-1} = \\frac{1}{\\lambda}I - \\frac{1}{\\lambda^2} C \\left(W + \\frac{1}{\\lambda}C^T C\\right)^{-1} C^T\n\\]\n\nCompute the small \\(2 \\times 2\\) pieces:\n\n\\(C^T C = \\begin{pmatrix} 127 & 42.25 \\\\ 42.25 & 14.0625 \\end{pmatrix}\\)\n\\(W = \\begin{pmatrix} 9 & 3 \\\\ 3 & 1 \\end{pmatrix}\\)\nThe matrix to invert is \\(W + \\frac{1}{0.1}C^T C = W + 10 \\cdot (C^T C)\\), which is: \\[\n\\begin{pmatrix} 9 & 3 \\\\ 3 & 1 \\end{pmatrix} +\n\\begin{pmatrix} 1270 & 422.5 \\\\ 422.5 & 140.625 \\end{pmatrix} =\n\\begin{pmatrix} 1279 & 425.5 \\\\ 425.5 & 141.625 \\end{pmatrix}\n\\]\n\nInvert the small \\(2 \\times 2\\) matrix: This is the only inversion we need, and it’s extremely fast.\n\\[\n(W + \\frac{1}{\\lambda}C^T C)^{-1} \\approx\n\\begin{pmatrix}\n0.22 & -0.66 \\\\\n-0.66 & 1.99\n\\end{pmatrix}\n\\]\nCombine the results: Now we plug this small inverse back into the full formula. The rest is just matrix multiplication, no more inversions.\n\nFirst, calculate the middle term: \\(M = \\frac{1}{\\lambda^2} C (\\dots)^{-1} C^T\\). This will result in a \\(4 \\times 4\\) matrix.\nThen, calculate the final result: \\(\\frac{1}{\\lambda}I - M\\).\n\n\nAfter performing these multiplications, you will get the exact same \\(4 \\times 4\\) inverse matrix as in the slow method.\nThe crucial difference is that the most expensive operation—the matrix inversion—was performed on a tiny \\(2 \\times 2\\) matrix instead of a \\(4 \\times 4\\) one. For a large-scale problem, this is the difference between a calculation that takes seconds and one that could take hours or even be impossible.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#extending-spotpythons-kriging-surrogate-with-nyström-approximation-for-enhanced-scalability",
    "href": "006_matrices.html#extending-spotpythons-kriging-surrogate-with-nyström-approximation-for-enhanced-scalability",
    "title": "9  Matrices",
    "section": "9.7 Extending spotpython’s Kriging Surrogate with Nyström Approximation for Enhanced Scalability",
    "text": "9.7 Extending spotpython’s Kriging Surrogate with Nyström Approximation for Enhanced Scalability\n\n9.7.1 Introduction: Overcoming the Scalability Challenge in Kriging for Sequential Optimization\nThe Sequential Parameter Optimization Toolbox (spotpython) is a framework for hyperparameter tuning and black-box optimization based on Sequential Model-Based Optimization (SMBO). At the core of SMBO lies a surrogate model that approximates the true, expensive objective. Kriging (Gaussian Process regression) is a premier choice because it provides both predictions and a principled measure of uncertainty. This uncertainty enables a balance between exploration and exploitation. In each SMBO iteration, the Kriging model is updated with new evaluations, refining its approximation and proposing the next points.\nStandard Kriging requires constructing and inverting an \\(n \\times n\\) covariance matrix, where \\(n\\) is the number of data points. Matrix inversion scales as \\(O(n^3)\\). During SMBO, \\(n\\) can reach hundreds or thousands; refitting the surrogate each iteration becomes prohibitively expensive. This cubic scaling is the key obstacle to applying Kriging at larger scales.\nWe integrate the Nyström method into the spotpython Kriging class. The Nyström method yields a low-rank approximation of a symmetric positive semidefinite (SPSD) kernel matrix by selecting \\(l \\ll n\\) “landmark” points. It approximates the full \\(n \\times n\\) covariance while requiring inversion of only an \\(l \\times l\\) matrix, reducing fitting cost from \\(O(n^3)\\) to \\(O(n\\,l^2)\\). This makes Kriging viable even when the number of function evaluations is large.\n\n\n9.7.2 Report Objectives and Structure\n\nReview theoretical foundations of Kriging and Nyström approximation\nPresent documented Python code updates for Kriging (as in kriging.py)\nExplain changes to __init__, fit, and predict\nShow how mixed variable types are preserved via build_Psi and build_psi_vec\nProvide practical usage guidance and a formal complexity analysis",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#theoretical-foundations-the-nyströmkriging-framework",
    "href": "006_matrices.html#theoretical-foundations-the-nyströmkriging-framework",
    "title": "9  Matrices",
    "section": "9.8 Theoretical Foundations: The Nyström–Kriging Framework",
    "text": "9.8 Theoretical Foundations: The Nyström–Kriging Framework\n\n9.8.1 A Primer on Kriging (Gaussian Process Regression)\nKriging models \\(f(x)\\) as a Gaussian Process with mean function \\(m(\\cdot)\\) and covariance (kernel) \\(k(\\cdot,\\cdot)\\). For training inputs \\(X = \\{x_1,\\dots,x_n\\}\\) and observations \\(y = \\{y_1,\\dots,y_n\\}\\): \\[\ny \\sim \\mathcal{N}\\!\\big(m(X),\\, K(X,X) + \\sigma_n^2 I\\big)\n\\] For a new point \\(x_\\ast\\): \\[\n\\mu(x_\\ast) = k(x_\\ast, X)\\,[K(X,X) + \\sigma_n^2 I]^{-1} y\n\\] \\[\n\\sigma^2(x_\\ast) = k(x_\\ast, x_\\ast) - k(x_\\ast, X)\\,[K(X,X) + \\sigma_n^2 I]^{-1} k(X, x_\\ast)\n\\] The challenge is inverting the \\(n \\times n\\) matrix \\(K(X,X) + \\sigma_n^2 I\\).\n\n\n9.8.2 The Nyström Method for Low-Rank Kernel Approximation\nSelect \\(l\\) landmark points \\(X_m \\subset X\\). Let: - \\(C = K_{nm} = K(X, X_m) \\in \\mathbb{R}^{n \\times l}\\) - \\(W = K_{mm} = K(X_m, X_m) \\in \\mathbb{R}^{l \\times l}\\) Then the Nyström approximation is: \\[\n\\tilde{K}_{nn} = C\\,W^{+}\\,C^\\top = K_{nm}\\,K_{mm}^{+}\\,K_{mn}\n\\] where \\(W^{+}\\) is the pseudoinverse of \\(W\\). The approximation has rank \\(\\le l\\).\n\n\n9.8.3 Justification for Landmark Selection\nUniform sampling without replacement is an effective and inexpensive strategy for selecting landmarks across varied datasets and kernels.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#implementation-a-scalable-kriging-class-for-spotpython",
    "href": "006_matrices.html#implementation-a-scalable-kriging-class-for-spotpython",
    "title": "9  Matrices",
    "section": "9.9 Implementation: A Scalable Kriging Class for spotpython",
    "text": "9.9 Implementation: A Scalable Kriging Class for spotpython\n\n9.9.1 Updated kriging.py with Nyström Approximation (excerpt)\n\"\"\"\nKriging surrogate with optional Nyström approximation.\n\"\"\"\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom scipy.linalg import cholesky, cho_solve, solve_triangular\n\nclass Kriging:\n    def __init__(self, fun_control, n_theta=None, theta=None, p=2.0,\n                 corr=\"squared_exponential\", isotropic=False,\n                 approximation=\"None\", n_landmarks=100):\n        self.fun_control = fun_control\n        self.dim = self.fun_control[\"lower\"].shape\n        self.p = p\n        self.corr = corr\n        self.isotropic = isotropic\n        self.approximation = approximation\n        self.n_landmarks = n_landmarks\n        self.factor_mask = self.fun_control[\"var_type\"] == \"factor\"\n        self.ordered_mask = ~self.factor_mask\n        self.n_theta = 1 if isotropic else (n_theta or self.dim)\n        self.theta = np.full(self.n_theta, 0.1) if theta is None else theta\n        self.X_, self.y_, self.L_, self.alpha_ = None, None, None, None\n        self.landmarks_, self.W_cho_, self.nystrom_alpha_ = None, None, None\n\n    def fit(self, X, y):\n        self.X_, self.y_ = X, y\n        n_samples = X.shape[0]\n        if self.approximation.lower() == \"nystroem\" and n_samples &gt; self.n_landmarks:\n            return self._fit_nystrom(X, y)\n        return self._fit_standard(X, y)\n\n    def _fit_standard(self, X, y):\n        Psi = self.build_Psi(X, X)\n        Psi[np.diag_indices_from(Psi)] += 1e-8\n        try:\n            self.L_ = cholesky(Psi, lower=True)\n            self.alpha_ = cho_solve((self.L_, True), y)\n        except np.linalg.LinAlgError:\n            self.L_ = None\n            self.alpha_ = np.linalg.pinv(Psi) @ y\n\n    def _fit_nystrom(self, X, y):\n        n_samples = X.shape[0]\n        idx = np.random.choice(n_samples, self.n_landmarks, replace=False)\n        self.landmarks_ = X[idx, :]\n        W = self.build_Psi(self.landmarks_, self.landmarks_) + 1e-8 * np.eye(self.n_landmarks)\n        C = self.build_Psi(X, self.landmarks_)\n        try:\n            self.W_cho_ = cholesky(W, lower=True)\n            self.nystrom_alpha_ = cho_solve((self.W_cho_, True), C.T @ y)\n        except np.linalg.LinAlgError:\n            self.W_cho_ = None\n            self._fit_standard(X, y)\n\n    def predict(self, X_star):\n        if self.approximation.lower() == \"nystroem\" and self.landmarks_ is not None:\n            return self._predict_nystrom(X_star)\n        return self._predict_standard(X_star)\n\n    def _predict_standard(self, X_star):\n        psi = self.build_Psi(X_star, self.X_)\n        y_pred = psi @ self.alpha_\n        if self.L_ is not None:\n            v = solve_triangular(self.L_, psi.T, lower=True)\n            y_mse = 1.0 - np.sum(v**2, axis=0)\n        else:\n            Psi = self.build_Psi(self.X_, self.X_) + 1e-8 * np.eye(self.X_.shape[0])\n            pi_Psi = np.linalg.pinv(Psi)\n            y_mse = 1.0 - np.sum((psi @ pi_Psi) * psi, axis=1)\n        y_mse[y_mse &lt; 0] = 0\n        return y_pred, y_mse.reshape(-1, 1)\n\n    def _predict_nystrom(self, X_star):\n        psi_star_m = self.build_Psi(X_star, self.landmarks_)\n        y_pred = psi_star_m @ self.nystrom_alpha_\n        if self.W_cho_ is not None:\n            v = cho_solve((self.W_cho_, True), psi_star_m.T)\n            quad = np.sum(psi_star_m * v.T, axis=1)\n            y_mse = 1.0 - quad\n        else:\n            y_mse = np.ones(X_star.shape[0])\n        y_mse[y_mse &lt; 0] = 0\n        return y_pred, y_mse.reshape(-1, 1)\n\n    def build_Psi(self, X1, X2):\n        n1 = X1.shape[0]\n        Psi = np.zeros((n1, X2.shape[0]))\n        for i in range(n1):\n            Psi[i, :] = self.build_psi_vec(X1[i, :], X2)\n        return Psi\n\n    def build_psi_vec(self, x, X_):\n        theta10 = np.full(self.dim, 10**self.theta) if self.isotropic else 10**self.theta\n        D = np.zeros(X_.shape[0])\n        if self.ordered_mask.any():\n            Xo = X_[:, self.ordered_mask]\n            xo = x[self.ordered_mask]\n            D += cdist(xo.reshape(1, -1), Xo, metric=\"sqeuclidean\",\n                       w=theta10[self.ordered_mask]).ravel()\n        if self.factor_mask.any():\n            Xf = X_[:, self.factor_mask]\n            xf = x[self.factor_mask]\n            D += cdist(xf.reshape(1, -1), Xf, metric=\"hamming\",\n                       w=theta10[self.factor_mask]).ravel() * self.factor_mask.sum()\n        return np.exp(-D) if self.corr == \"squared_exponential\" else np.exp(-(D**self.p))",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#implementation-details",
    "href": "006_matrices.html#implementation-details",
    "title": "9  Matrices",
    "section": "9.10 Implementation Details",
    "text": "9.10 Implementation Details\n\n9.10.1 Architectural Enhancements to init\n\nNew argument approximation=\"None\" for backward-compatible selection between exact Kriging and Nyström\nNew argument n_landmarks (default 100) controls the number of inducing points when using Nyström\nState attributes for both exact and Nyström paths are maintained separately\n\n\n\n9.10.2 The fit() Method: A Dual-Pathway Approach\n\nDispatcher selecting exact or Nyström pathway\nThe Nyström fit Pathway (_fit_nystrom):\n\nLandmark selection via uniform sampling without replacement\nCore matrices:\n\n\\(W = K_{mm}\\) (landmark-landmark)\n\\(C = K_{nm}\\) (data-landmark)\n\nCholesky factorization of \\(W\\) (with jitter) for stability\nPre-computation: \\(\\alpha_{nys} = W^{-1} C^T y\\) via cho_solve\n\nThe Standard fit Pathway (_fit_standard):\n\nFull \\(\\Psi\\) construction, Cholesky decomposition, and solve for \\(\\alpha\\)\nFallback to pseudoinverse if Cholesky fails\n\n\n\n\n9.10.3 The predict() Method: Conditional Prediction Logic\n\nRoutes to Nyström or standard prediction path based on fitted model state\nThe Nyström predict Pathway (_predict_nystrom):\n\nCross-covariance \\(\\psi\\) between test points and landmarks\nMean: \\(\\psi \\cdot \\alpha_{nys}\\)\nVariance: uses cho_solve with \\(W\\) Cholesky; non-negative clipping\n\nThe Standard predict Pathway (_predict_standard):\n\nCross-covariance with all training points\nMean from \\(\\alpha\\); variance via triangular solves or pseudoinverse fallback\n\n\n\n\n9.10.4 Critical Detail: Preserving Mixed Variable Type Functionality\nThe Significance of build_psi_vec:\n\nMixed spaces: continuous (ordered) and categorical (factor) variables\nDistances:\n\nWeighted squared Euclidean for ordered variables\nWeighted Hamming for factors\n\nAnisotropic kernel via per-dimension length-scales \\(\\theta\\)\nNyström path reuses build_Psi → build_psi_vec, preserving mixed-type handling\n\n\n\n9.10.5 Seamless Integration into the Nyström Workflow\nAll covariance computations (\\(W\\), \\(C\\), predictive cross-covariance) use build_Psi, ensuring identical handling for mixed variable types in both standard and Nyström modes.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#jupyter-notebook",
    "href": "006_matrices.html#jupyter-notebook",
    "title": "9  Matrices",
    "section": "9.11 Jupyter Notebook",
    "text": "9.11 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_infill.html",
    "href": "006_infill.html",
    "title": "10  Infill Criteria",
    "section": "",
    "text": "10.1 Balancing Exploitation and Exploration\nIn the context of computer experiments and surrogate modeling, a sampling plan refers to the set of input values, often denoted as \\(X\\), at which a computer code is evaluated. The primary objective of a sampling plan is to efficiently explore the input space to understand the behavior of the computer code and to construct a surrogate model that accurately represents that behavior. Historically, Response Surface Methodology (RSM) provided methods for designing such plans, often based on rectangular grids or factorial designs. More recently, Design and Analysis of Computer Experiments (DACE) has emerged as a more flexible and powerful approach for this purpose.\nA surrogate model, or \\(\\hat{f}\\), is built to approximate the expensive response of a black-box function \\(f(x)\\). Since evaluating \\(f\\) is costly, only a sparse set of samples is used to construct \\(\\hat{f}\\), which can then provide inexpensive predictions for any point in the design space. However, as a surrogate model is inherently an approximation of the true function, its accuracy and predictive capabilities can be significantly improved by incorporating new data points, known as infill points. Infill points are strategically chosen to either reduce uncertainty, improve predictions in specific regions of interest, or enhance the model’s ability to identify optima or trends.\nThe process of updating a surrogate model with infill points is iterative. It typically involves:\nA crucial aspect of selecting infill points is navigating the inherent trade-off between exploitation and exploration.\n(Forr08a?) emphasizes that effective infill criteria are designed to combine both exploitation and exploration.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#balancing-exploitation-and-exploration",
    "href": "006_infill.html#balancing-exploitation-and-exploration",
    "title": "10  Infill Criteria",
    "section": "",
    "text": "Definition 10.1 (Exploitation) Exploitation refers to sampling near predicted optima to refine the solution. This strategy aims to rapidly converge on a good solution by focusing computational effort where the surrogate model suggests the best values might lie.\n\n\nDefinition 10.2 (Exploration) Exploration involves sampling in regions of high uncertainty to improve the global accuracy of the model. This approach ensures that the model is well-informed across the entire design space, preventing it from getting stuck in local optima.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#expected-improvement-ei",
    "href": "006_infill.html#expected-improvement-ei",
    "title": "10  Infill Criteria",
    "section": "10.2 Expected Improvement (EI)",
    "text": "10.2 Expected Improvement (EI)\nExpected Improvement (EI) is one of the most influential and widely-used infill criteria. Formalized by (Jones1998?) and building upon the work of (mockus1978toward?), EI provides a mathematically elegant framework that naturally balances exploitation and exploration. Rather than simply picking the point with the best predicted value (pure exploitation) or the point with the highest uncertainty (pure exploration), EI asks a more nuanced question: “How much improvement over the current best solution can we expect to gain by evaluating the true function at a new point \\(x\\)?”.\nThe Expected Improvement, \\(EI(x)\\), can be calculated using the following formula:\n\\[\nEI(x) = \\sigma(x) \\left[ Z \\Phi(Z) + \\phi(Z) \\right]\n\\] where:\n\n\\(\\mu(x)\\) (or \\(\\hat{y}(x)\\)) is the Kriging prediction (mean of the stochastic process) at a new, unobserved point \\(x\\).\n\\(\\sigma(x)\\) (or \\(\\hat{s}(x)\\)) is the estimated standard deviation (square root of the variance \\(\\hat{s}^2(x)\\)) of the prediction at point \\(x\\).\n\\(f_{best}\\) (or \\(y_{min}\\)) is the best (minimum, for minimization problems) observed function value found so far.\n\\(Z = \\frac{f_{best} - \\mu(x)}{\\sigma(x)}\\) is the standardized improvement.\n\\(\\Phi(Z)\\) is the cumulative distribution function (CDF) of the standard normal distribution.\n\\(\\phi(Z)\\) is the probability density function (PDF) of the standard normal distribution.\n\nIf \\(\\sigma(x) = 0\\) (meaning there is no uncertainty at point \\(x\\), typically because it’s an already sampled point), then \\(EI(x) = 0\\), reflecting the intuition that no further improvement can be expected at a known point. A maximization of Expected Improvement as an infill criterion will eventually lead to the global optimum.\nThe elegance of the EI formula lies in its combination of two distinct terms:\n\nExploitation Term: \\((f_{best} - \\mu(x)) \\Phi(Z)\\). This part of the formula contributes more when the predicted value \\(\\mu(x)\\) is significantly lower (better) than the current best observed value \\(f_{best}\\). It is weighted by the probability \\(\\Phi(Z)\\) that the true function value at \\(x\\) will indeed be an improvement over \\(f_{best}\\).\nExploration Term: \\(\\sigma(x) \\phi(Z)\\). This term becomes larger when there is high uncertainty (\\(\\sigma(x)\\) is large) in the model’s prediction at \\(x\\). It accounts for the potential of discovering unexpectedly good values in areas that have not been thoroughly explored, even if the current mean prediction there is not the absolute best.\n\nExpected Improvement offers several significant practical benefits:\n\nAutomatic Balance: It inherently balances exploitation and exploration without requiring any manual adjustment of weights or parameters.\nScale Invariance: EI is relatively insensitive to the scaling of the objective function, making it robust across various problem types.\nTheoretical Foundation: It is underpinned by a strong theoretical basis derived from decision theory and information theory.\nEfficient Optimization: The smooth and differentiable nature of the EI function allows for efficient optimization using gradient-based algorithms to find the next infill point.\nProven Performance: EI has demonstrated consistent and strong performance in numerous real-world applications across various domains.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#expected-improvement-in-the-hyperparameter-tuning-cookbook-python-implementation",
    "href": "006_infill.html#expected-improvement-in-the-hyperparameter-tuning-cookbook-python-implementation",
    "title": "10  Infill Criteria",
    "section": "10.3 Expected Improvement in the Hyperparameter Tuning Cookbook (Python Implementation)",
    "text": "10.3 Expected Improvement in the Hyperparameter Tuning Cookbook (Python Implementation)\nWithin the context of the Hyperparameter Tuning Cookbook, Expected Improvement serves a critical role in Sequential Model-Based Optimization. It systematically guides the selection of which hyperparameter configurations to evaluate next, facilitating the efficient utilization of computational resources. By intelligently balancing the need to exploit promising regions and explore uncertain areas, EI helps identify optimal hyperparameters with a reduced number of expensive model training runs. This provides a principled and automated method for navigating complex hyperparameter spaces without extensive manual intervention.\nWhile the foundational concepts in (Forr08a?) are often illustrated with MATLAB code, the Hyperparameter Tuning Cookbook emphasizes and provides implementations in Python. The spotpython package, consistent with the Cookbook’s approach, provides a Python implementation of Expected Improvement within its Kriging class. For minimization problems, spotpython typically calculates and returns the negative Expected Improvement, aligning with standard optimization algorithm conventions. Furthermore, to enhance numerical stability and mitigate issues when EI values are very small, spotpython often works with a logarithmic transformation of EI and incorporates a small epsilon value.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#jupyter-notebook",
    "href": "006_infill.html#jupyter-notebook",
    "title": "10  Infill Criteria",
    "section": "10.4 Jupyter Notebook",
    "text": "10.4 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "reproducibility.html",
    "href": "reproducibility.html",
    "title": "11  Reproducibility in SpotOptim",
    "section": "",
    "text": "11.1 Introduction\nSpotOptim provides full support for reproducible optimization runs through the seed parameter. This is essential for:\nWhen you specify a seed, SpotOptim guarantees that running the same optimization multiple times will produce identical results. Without a seed, each run explores the search space differently, which can be useful for robustness testing.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#introduction",
    "href": "reproducibility.html#introduction",
    "title": "11  Reproducibility in SpotOptim",
    "section": "",
    "text": "Scientific research: Ensuring experiments can be replicated\nDebugging: Reproducing specific optimization behaviors\nBenchmarking: Fair comparison between different configurations\nProduction: Consistent results in deployed applications",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#basic-usage",
    "href": "reproducibility.html#basic-usage",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.2 Basic Usage",
    "text": "11.2 Basic Usage\n\n11.2.1 Making Optimization Reproducible\nTo ensure reproducible results, simply specify the seed parameter when creating the optimizer:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    \"\"\"Simple sphere function: f(x) = sum(x^2)\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Reproducible optimization\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    seed=42,  # This ensures reproducibility\n    verbose=True\n)\n\nresult = optimizer.optimize()\nprint(f\"Best solution: {result.x}\")\nprint(f\"Best value: {result.fun}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 5.542803\nIteration 1: New best f(x) = 0.001607\nIteration 2: f(x) = 0.007183\nIteration 3: f(x) = 0.009504\nIteration 4: New best f(x) = 0.000000\nIteration 5: f(x) = 0.000003\nIteration 6: f(x) = 0.000002\nIteration 7: f(x) = 0.000001\nIteration 8: f(x) = 0.000001\nIteration 9: f(x) = 0.000002\nIteration 10: f(x) = 0.000000\nIteration 11: f(x) = 0.000001\nIteration 12: f(x) = 0.000003\nIteration 13: f(x) = 0.000000\nIteration 14: f(x) = 0.000000\nIteration 15: f(x) = 0.000001\nBest solution: [-0.0003343  -0.00013835]\nBest value: 1.3089731064068852e-07\n\n\nKey Point: Running this code multiple times (even on different days or machines) will always produce the same result.\n\n\n11.2.2 Running Independent Experiments\nIf you don’t specify a seed, each optimization run will explore the search space differently:\n\n# Non-reproducible: different results each time\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15\n    # No seed specified\n)\n\nresult = optimizer.optimize()\n# Results will vary between runs\n\nThis is useful when you want to: - Explore different regions of the search space - Test the robustness of your results - Run multiple independent optimization attempts",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#practical-examples",
    "href": "reproducibility.html#practical-examples",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.3 Practical Examples",
    "text": "11.3 Practical Examples\n\n11.3.1 Example 1: Comparing Different Configurations\nWhen comparing different optimizer settings, use the same seed for fair comparison:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\n# Configuration 1: More initial points\nopt1 = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=50,\n    n_initial=20,\n    seed=42  # Same seed for fair comparison\n)\nresult1 = opt1.optimize()\n\n# Configuration 2: Fewer initial points, more iterations\nopt2 = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=50,\n    n_initial=10,\n    seed=42  # Same seed\n)\nresult2 = opt2.optimize()\n\nprint(f\"Config 1 (more initial): {result1.fun:.6f}\")\nprint(f\"Config 2 (fewer initial): {result2.fun:.6f}\")\n\nConfig 1 (more initial): 0.036226\nConfig 2 (fewer initial): 0.015384\n\n\n\n\n11.3.2 Example 2: Reproducible Research Experiment\nFor scientific papers or reports, always use a fixed seed and document it:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rastrigin(X):\n    \"\"\"Rastrigin function (multimodal)\"\"\"\n    A = 10\n    n = X.shape[1]\n    return A * n + np.sum(X**2 - A * np.cos(2 * np.pi * X), axis=1)\n\n# Documented seed for reproducibility\nRANDOM_SEED = 12345\n\noptimizer = SpotOptim(\n    fun=rastrigin,\n    bounds=[(-5.12, 5.12), (-5.12, 5.12), (-5.12, 5.12)],\n    max_iter=100,\n    n_initial=30,\n    seed=RANDOM_SEED,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nExperiment Results (seed={RANDOM_SEED}):\")\nprint(f\"Best solution: {result.x}\")\nprint(f\"Best value: {result.fun}\")\nprint(f\"Iterations: {result.nit}\")\nprint(f\"Function evaluations: {result.nfev}\")\n\n# These results can now be cited in a paper\n\nTensorBoard logging disabled\nInitial best: f(x) = 20.392774\nIteration 1: f(x) = 21.363476\nIteration 2: f(x) = 47.301823\nIteration 3: f(x) = 54.722105\nIteration 4: f(x) = 26.938125\nIteration 5: f(x) = 47.976435\nIteration 6: New best f(x) = 11.815352\nIteration 7: f(x) = 42.986117\nIteration 8: f(x) = 18.405281\nIteration 9: New best f(x) = 9.416725\nIteration 10: New best f(x) = 8.466069\nIteration 11: f(x) = 30.100210\nIteration 12: New best f(x) = 2.903089\nIteration 13: f(x) = 14.397238\nIteration 14: f(x) = 6.076849\nIteration 15: f(x) = 3.075001\nIteration 16: f(x) = 8.238939\nIteration 17: f(x) = 32.184621\nIteration 18: f(x) = 24.864179\nIteration 19: f(x) = 47.118258\nIteration 20: f(x) = 39.419666\nIteration 21: f(x) = 53.085310\nIteration 22: f(x) = 9.975504\nIteration 23: f(x) = 35.001393\nIteration 24: f(x) = 38.805263\nIteration 25: f(x) = 53.761437\nIteration 26: f(x) = 22.263620\nIteration 27: f(x) = 36.329232\nIteration 28: f(x) = 43.768628\nIteration 29: f(x) = 48.136701\nIteration 30: f(x) = 33.012990\nIteration 31: f(x) = 39.630292\nIteration 32: f(x) = 56.076800\nIteration 33: f(x) = 56.395240\nIteration 34: f(x) = 38.348341\nIteration 35: f(x) = 49.557146\nIteration 36: f(x) = 59.083493\nIteration 37: f(x) = 30.011270\nIteration 38: f(x) = 41.465815\nIteration 39: f(x) = 27.727924\nIteration 40: f(x) = 42.088395\nIteration 41: f(x) = 28.204654\nIteration 42: f(x) = 18.178644\nIteration 43: f(x) = 35.087961\nIteration 44: f(x) = 57.612698\nIteration 45: f(x) = 38.620443\nIteration 46: f(x) = 54.041182\nIteration 47: f(x) = 28.335777\nIteration 48: f(x) = 31.404859\nIteration 49: f(x) = 68.751895\nIteration 50: f(x) = 62.442382\nIteration 51: f(x) = 53.043276\nIteration 52: f(x) = 49.678065\nIteration 53: f(x) = 51.523703\nIteration 54: f(x) = 45.533620\nIteration 55: New best f(x) = 2.181277\nIteration 56: New best f(x) = 1.996482\nIteration 57: f(x) = 51.513483\nIteration 58: f(x) = 43.295834\nIteration 59: f(x) = 3.690653\nIteration 60: f(x) = 33.624017\nIteration 61: f(x) = 37.625215\nIteration 62: f(x) = 67.144123\nIteration 63: f(x) = 25.844100\nIteration 64: f(x) = 54.673898\nIteration 65: f(x) = 11.388202\nIteration 66: f(x) = 39.385158\nIteration 67: f(x) = 4.226770\nIteration 68: f(x) = 67.022923\nIteration 69: f(x) = 28.240244\nIteration 70: f(x) = 36.207929\n\nExperiment Results (seed=12345):\nBest solution: [ 0.99166413 -0.99787425 -0.0037072 ]\nBest value: 1.9964821694753638\nIterations: 70\nFunction evaluations: 100\n\n\n\n\n11.3.3 Example 3: Multiple Independent Runs\nTo test robustness, run the same optimization with different seeds:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef ackley(X):\n    \"\"\"Ackley function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\n# Run 5 independent optimizations\nresults = []\nseeds = [42, 123, 456, 789, 1011]\n\nfor seed in seeds:\n    optimizer = SpotOptim(\n        fun=ackley,\n        bounds=[(-5, 5), (-5, 5)],\n        max_iter=40,\n        n_initial=20,\n        seed=seed,\n        verbose=False\n    )\n    result = optimizer.optimize()\n    results.append(result.fun)\n    print(f\"Run with seed {seed:4d}: f(x) = {result.fun:.6f}\")\n\n# Analyze robustness\nprint(f\"\\nBest result: {min(results):.6f}\")\nprint(f\"Worst result: {max(results):.6f}\")\nprint(f\"Mean: {np.mean(results):.6f}\")\nprint(f\"Std dev: {np.std(results):.6f}\")\n\nRun with seed   42: f(x) = 0.145422\nRun with seed  123: f(x) = 0.023381\nRun with seed  456: f(x) = 0.022664\nRun with seed  789: f(x) = 0.035378\nRun with seed 1011: f(x) = 0.115351\n\nBest result: 0.022664\nWorst result: 0.145422\nMean: 0.068439\nStd dev: 0.051664\n\n\n\n\n11.3.4 Example 4: Reproducible Initial Design\nThe seed ensures that even the initial design points are reproducible:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef simple_quadratic(X):\n    return np.sum((X - 1)**2, axis=1)\n\n# Create two optimizers with same seed\nopt1 = SpotOptim(\n    fun=simple_quadratic,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=25,\n    n_initial=10,\n    seed=999\n)\n\nopt2 = SpotOptim(\n    fun=simple_quadratic,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=25,\n    n_initial=10,\n    seed=999  # Same seed\n)\n\n# Run both optimizations\nresult1 = opt1.optimize()\nresult2 = opt2.optimize()\n\n# Verify identical results\nprint(\"Initial design points are identical:\", \n      np.allclose(opt1.X_[:10], opt2.X_[:10]))\nprint(\"All evaluated points are identical:\", \n      np.allclose(opt1.X_, opt2.X_))\nprint(\"All function values are identical:\", \n      np.allclose(opt1.y_, opt2.y_))\nprint(\"Best solutions are identical:\", \n      np.allclose(result1.x, result2.x))\n\nInitial design points are identical: True\nAll evaluated points are identical: True\nAll function values are identical: True\nBest solutions are identical: True\n\n\n\n\n11.3.5 Example 5: Custom Initial Design with Seed\nEven when providing a custom initial design, the seed ensures reproducible subsequent iterations:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef beale(X):\n    \"\"\"Beale function\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    term1 = (1.5 - x + x * y)**2\n    term2 = (2.25 - x + x * y**2)**2\n    term3 = (2.625 - x + x * y**3)**2\n    return term1 + term2 + term3\n\n# Custom initial design (e.g., from previous knowledge)\nX_start = np.array([\n    [0.0, 0.0],\n    [1.0, 1.0],\n    [2.0, 2.0],\n    [-1.0, -1.0]\n])\n\n# Run twice with same seed and initial design\nopt1 = SpotOptim(\n    fun=beale,\n    bounds=[(-4.5, 4.5), (-4.5, 4.5)],\n    max_iter=30,\n    n_initial=10,\n    seed=777\n)\nresult1 = opt1.optimize(X0=X_start)\n\nopt2 = SpotOptim(\n    fun=beale,\n    bounds=[(-4.5, 4.5), (-4.5, 4.5)],\n    max_iter=30,\n    n_initial=10,\n    seed=777  # Same seed\n)\nresult2 = opt2.optimize(X0=X_start)\n\nprint(\"Results are identical:\", np.allclose(result1.x, result2.x))\nprint(f\"Best value: {result1.fun:.6f}\")\n\nResults are identical: True\nBest value: 1.024940",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#advanced-topics",
    "href": "reproducibility.html#advanced-topics",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.4 Advanced Topics",
    "text": "11.4 Advanced Topics\n\n11.4.1 Seed and Noisy Functions\nWhen optimizing noisy functions with repeated evaluations, the seed ensures reproducible noise:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_sphere(X):\n    \"\"\"Sphere function with Gaussian noise\"\"\"\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=40,\n    n_initial=20,\n    repeats_initial=3,  # 3 evaluations per point\n    repeats_surrogate=2,\n    seed=42  # Ensures same noise pattern\n)\n\nresult = optimizer.optimize()\nprint(f\"Best mean value: {optimizer.min_mean_y:.6f}\")\nprint(f\"Variance at best: {optimizer.min_var_y:.6f}\")\n\nBest mean value: 0.141195\nVariance at best: 0.001682\n\n\nImportant: With the same seed, even the noise will be identical across runs!\n\n\n11.4.2 Different Seeds for Different Exploration\nUse different seeds to explore different regions systematically:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef griewank(X):\n    \"\"\"Griewank function\"\"\"\n    sum_sq = np.sum(X**2 / 4000, axis=1)\n    prod_cos = np.prod(np.cos(X / np.sqrt(np.arange(1, X.shape[1] + 1))), axis=1)\n    return sum_sq - prod_cos + 1\n\n# Systematic exploration with different seeds\nbest_overall = float('inf')\nbest_seed = None\n\nfor seed in range(10, 20):  # Seeds 10-19\n    optimizer = SpotOptim(\n        fun=griewank,\n        bounds=[(-600, 600), (-600, 600)],\n        max_iter=50,\n        n_initial=25,\n        seed=seed\n    )\n    result = optimizer.optimize()\n    \n    if result.fun &lt; best_overall:\n        best_overall = result.fun\n        best_seed = seed\n    \n    print(f\"Seed {seed}: f(x) = {result.fun:.6f}\")\n\nprint(f\"\\nBest result with seed {best_seed}: {best_overall:.6f}\")\n\nSeed 10: f(x) = 0.796656\nSeed 11: f(x) = 0.042354\nSeed 12: f(x) = 1.156801\nSeed 13: f(x) = 0.720165\nSeed 14: f(x) = 1.193134\nSeed 15: f(x) = 1.617529\nSeed 16: f(x) = 0.345078\nSeed 17: f(x) = 0.677278\nSeed 18: f(x) = 1.458146\nSeed 19: f(x) = 1.349480\n\nBest result with seed 11: 0.042354",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#best-practices",
    "href": "reproducibility.html#best-practices",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.5 Best Practices",
    "text": "11.5 Best Practices\n\n11.5.1 1. Always Use Seeds for Production Code\n# Good: Reproducible\noptimizer = SpotOptim(fun=objective, bounds=bounds, seed=42)\n\n# Risky: Non-reproducible\noptimizer = SpotOptim(fun=objective, bounds=bounds)\n\n\n11.5.2 2. Document Your Seeds\n# Configuration for experiment reported in Section 4.2\nEXPERIMENT_SEED = 2024\nMAX_ITERATIONS = 100\n\noptimizer = SpotOptim(\n    fun=my_objective,\n    bounds=my_bounds,\n    max_iter=MAX_ITERATIONS,\n    seed=EXPERIMENT_SEED\n)\n\n\n11.5.3 3. Use Different Seeds for Different Experiments\n# Different experiments should use different seeds\nBASELINE_SEED = 100\nEXPERIMENT_A_SEED = 200\nEXPERIMENT_B_SEED = 300\n\n\n11.5.4 4. Test Robustness Across Multiple Seeds\n# Run same optimization with multiple seeds\nfor seed in [42, 123, 456, 789, 1011]:\n    optimizer = SpotOptim(fun=objective, bounds=bounds, seed=seed)\n    result = optimizer.optimize()\n    # Analyze results",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#what-the-seed-controls",
    "href": "reproducibility.html#what-the-seed-controls",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.6 What the Seed Controls",
    "text": "11.6 What the Seed Controls\nThe seed parameter ensures reproducibility by controlling:\n\nInitial Design Generation: Latin Hypercube Sampling produces the same initial points\nSurrogate Model: Gaussian Process random initialization is identical\nAcquisition Optimization: Differential evolution explores the same candidates\nRandom Sampling: Any random exploration uses the same random numbers\n\nThis guarantees that the entire optimization pipeline is deterministic and reproducible.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#common-questions",
    "href": "reproducibility.html#common-questions",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.7 Common Questions",
    "text": "11.7 Common Questions\nQ: Can I use seed=0?\nA: Yes, any integer (including 0) is a valid seed.\nQ: Will different Python versions give the same results?\nA: Generally yes, but minor numerical differences may occur due to underlying library changes. Use the same environment for exact reproducibility.\nQ: Does the seed affect the objective function?\nA: No, the seed only affects SpotOptim’s internal random processes. If your objective function has its own randomness, you’ll need to control that separately.\nQ: How do I choose a good seed value?\nA: Any integer works. Common choices are 42, 123, or dates (e.g., 20241112). What matters is consistency, not the specific value.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#summary",
    "href": "reproducibility.html#summary",
    "title": "11  Reproducibility in SpotOptim",
    "section": "11.8 Summary",
    "text": "11.8 Summary\n\nUse seed parameter for reproducible optimization\nSame seed → identical results (every time)\nNo seed → different results (random exploration)\n\nEssential for research, debugging, and production\nDocument your seeds for transparency\nTest robustness with multiple different seeds",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html",
    "href": "acquisition_failure.html",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "",
    "text": "12.1 What is Acquisition Failure?\nSpotOptim provides sophisticated fallback strategies for handling acquisition function failures during optimization. This ensures robust optimization even when the surrogate model struggles to suggest new points.\nDuring surrogate-based optimization, the acquisition function suggests new points to evaluate. However, sometimes the suggested point is too close to existing points (within tolerance_x distance), which would provide little new information. When this happens, SpotOptim uses a fallback strategy to propose an alternative point.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#fallback-strategies",
    "href": "acquisition_failure.html#fallback-strategies",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.2 Fallback Strategies",
    "text": "12.2 Fallback Strategies\nSpotOptim supports two fallback strategies, controlled by the acquisition_failure_strategy parameter:\n\n12.2.1 1. Random Space-Filling Design (Default)\nStrategy name: \"random\"\nThis strategy uses Latin Hypercube Sampling (LHS) to generate a new space-filling point. LHS ensures good coverage of the search space by dividing each dimension into equal-probability intervals.\nWhen to use:\n\nGeneral-purpose optimization\nWhen you want simplicity and good space-filling properties\nDefault choice for most problems\n\nExample:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=10,\n    acquisition_failure_strategy=\"random\",  # Default\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\n\n12.2.2 2. Morris-Mitchell Minimizing Point\nStrategy name: \"mm\"\nThis strategy finds a point that maximizes the minimum distance to all existing points. It evaluates 100 candidate points and selects the one with the largest minimum distance to the already-evaluated points, providing excellent space-filling properties.\nWhen to use:\n\nWhen you want to ensure maximum exploration\nFor problems where avoiding clustering of points is critical\nWhen the search space has been heavily sampled in some regions\n\nExample:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef rosenbrock(X):\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=100,\n    n_initial=20,\n    acquisition_failure_strategy=\"mm\",  # Morris-Mitchell\n    verbose=True\n)\n\nresult = optimizer.optimize()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#how-it-works",
    "href": "acquisition_failure.html#how-it-works",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.3 How It Works",
    "text": "12.3 How It Works\nThe acquisition failure handling is integrated into the optimization process:\n\nAcquisition optimization: SpotOptim uses differential evolution to optimize the acquisition function\nDistance check: The proposed point is checked against existing points using tolerance_x\nFallback activation: If the point is too close, _handle_acquisition_failure() is called\nStrategy execution: The configured fallback strategy generates a new point\nEvaluation: The fallback point is evaluated and added to the dataset",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#comparison-of-strategies",
    "href": "acquisition_failure.html#comparison-of-strategies",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.4 Comparison of Strategies",
    "text": "12.4 Comparison of Strategies\n\n\n\nAspect\nRandom (LHS)\nMorris-Mitchell\n\n\n\n\nComputation\nVery fast\nModerate (100 candidates)\n\n\nSpace-filling\nGood\nExcellent\n\n\nExploration\nBalanced\nMaximum distance\n\n\nClustering avoidance\nGood\nBest\n\n\nRecommended for\nGeneral use\nHeavily sampled spaces",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#complete-example-comparing-strategies",
    "href": "acquisition_failure.html#complete-example-comparing-strategies",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.5 Complete Example: Comparing Strategies",
    "text": "12.5 Complete Example: Comparing Strategies\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef ackley(X):\n    \"\"\"Ackley function - multimodal test function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\n# Test with random strategy\nprint(\"=\" * 60)\nprint(\"Testing with Random Space-Filling Strategy\")\nprint(\"=\" * 60)\n\nopt_random = SpotOptim(\n    fun=ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    acquisition_failure_strategy=\"random\",\n    tolerance_x=0.1,  # Relatively large tolerance to trigger failures\n    seed=42,\n    verbose=True\n)\n\nresult_random = opt_random.optimize()\n\nprint(f\"\\nRandom Strategy Results:\")\nprint(f\"  Best value: {result_random.fun:.6f}\")\nprint(f\"  Best point: {result_random.x}\")\nprint(f\"  Total evaluations: {result_random.nfev}\")\n\n# Test with Morris-Mitchell strategy\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Testing with Morris-Mitchell Strategy\")\nprint(\"=\" * 60)\n\nopt_mm = SpotOptim(\n    fun=ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    acquisition_failure_strategy=\"mm\",\n    tolerance_x=0.1,  # Same tolerance\n    seed=42,\n    verbose=True\n)\n\nresult_mm = opt_mm.optimize()\n\nprint(f\"\\nMorris-Mitchell Strategy Results:\")\nprint(f\"  Best value: {result_mm.fun:.6f}\")\nprint(f\"  Best point: {result_mm.x}\")\nprint(f\"  Total evaluations: {result_mm.nfev}\")\n\n# Compare\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Comparison\")\nprint(\"=\" * 60)\nprint(f\"Random strategy:        {result_random.fun:.6f}\")\nprint(f\"Morris-Mitchell strategy: {result_mm.fun:.6f}\")\nif result_random.fun &lt; result_mm.fun:\n    print(\"→ Random strategy found better solution\")\nelse:\n    print(\"→ Morris-Mitchell strategy found better solution\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#advanced-usage-setting-tolerance",
    "href": "acquisition_failure.html#advanced-usage-setting-tolerance",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.6 Advanced Usage: Setting Tolerance",
    "text": "12.6 Advanced Usage: Setting Tolerance\nThe tolerance_x parameter controls when the fallback strategy is triggered. A larger tolerance means points need to be farther apart, triggering the fallback more often:\n# Strict tolerance (smaller value) - fewer fallbacks\noptimizer_strict = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    tolerance_x=1e-6,  # Very small - almost never triggers fallback\n    acquisition_failure_strategy=\"mm\"\n)\n\n# Relaxed tolerance (larger value) - more fallbacks\noptimizer_relaxed = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    tolerance_x=0.5,  # Larger - triggers fallback more often\n    acquisition_failure_strategy=\"mm\"\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#best-practices",
    "href": "acquisition_failure.html#best-practices",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.7 Best Practices",
    "text": "12.7 Best Practices\n\n12.7.1 1. Use Random for Most Problems\nThe random strategy (default) is sufficient for most optimization problems:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    acquisition_failure_strategy=\"random\"  # Good default choice\n)\n\n\n12.7.2 2. Use Morris-Mitchell for Intensive Sampling\nWhen you have a large budget and want maximum exploration:\noptimizer = SpotOptim(\n    fun=expensive_objective,\n    bounds=bounds,\n    max_iter=200,  # Large budget\n    acquisition_failure_strategy=\"mm\"  # Maximize space coverage\n)\n\n\n12.7.3 3. Monitor Fallback Activations\nEnable verbose mode to see when fallbacks are triggered:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    acquisition_failure_strategy=\"mm\",\n    verbose=True  # Shows fallback messages\n)\n\n\n12.7.4 4. Adjust Tolerance Based on Problem Scale\nFor problems with small search spaces, use smaller tolerance:\n# Small search space\noptimizer_small = SpotOptim(\n    fun=objective,\n    bounds=[(-1, 1), (-1, 1)],\n    tolerance_x=0.01,  # Small tolerance for small space\n    acquisition_failure_strategy=\"random\"\n)\n\n# Large search space\noptimizer_large = SpotOptim(\n    fun=objective,\n    bounds=[(-100, 100), (-100, 100)],\n    tolerance_x=1.0,  # Larger tolerance for large space\n    acquisition_failure_strategy=\"mm\"\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#technical-details",
    "href": "acquisition_failure.html#technical-details",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.8 Technical Details",
    "text": "12.8 Technical Details\n\n12.8.1 Morris-Mitchell Implementation\nThe Morris-Mitchell strategy:\n\nGenerates 100 candidate points using Latin Hypercube Sampling\nFor each candidate, calculates the minimum distance to all existing points\nSelects the candidate with the maximum minimum distance\n\nThis ensures the new point is as far as possible from the densest region of evaluated points.\n\n\n12.8.2 Random Strategy Implementation\nThe random strategy:\n\nGenerates a single point using Latin Hypercube Sampling\nEnsures the point is within bounds\nApplies variable type repairs (rounding for int/factor variables)\n\nThis is computationally efficient while maintaining good space-filling properties.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#summary",
    "href": "acquisition_failure.html#summary",
    "title": "12  Acquisition Failure Handling in SpotOptim",
    "section": "12.9 Summary",
    "text": "12.9 Summary\n\nDefault strategy (\"random\"): Fast, good space-filling, suitable for most problems\nMorris-Mitchell (\"mm\"): Better space-filling, maximizes minimum distance, ideal for intensive sampling\nTrigger: Activated when acquisition-proposed point is too close to existing points (within tolerance_x)\nControl: Set via acquisition_failure_strategy parameter\nMonitoring: Enable verbose=True to see when fallbacks occur\n\nChoose the strategy that best matches your optimization goals: - Use \"random\" for general-purpose optimization - Use \"mm\" when you want maximum exploration and have a generous function evaluation budget",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html",
    "href": "diabetes_dataset.html",
    "title": "13  Diabetes Dataset Utilities",
    "section": "",
    "text": "13.1 Overview\nSpotOptim provides convenient utilities for working with the sklearn diabetes dataset, including PyTorch Dataset and DataLoader implementations. These utilities simplify data loading, preprocessing, and model training for regression tasks.\nThe diabetes dataset contains 10 baseline variables (age, sex, body mass index, average blood pressure, and six blood serum measurements) for 442 diabetes patients. The target is a quantitative measure of disease progression one year after baseline.\nModule: spotoptim.data.diabetes\nKey Components:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#overview",
    "href": "diabetes_dataset.html#overview",
    "title": "13  Diabetes Dataset Utilities",
    "section": "",
    "text": "DiabetesDataset: PyTorch Dataset class\nget_diabetes_dataloaders(): Convenience function for complete data pipeline",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#quick-start",
    "href": "diabetes_dataset.html#quick-start",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.2 Quick Start",
    "text": "13.2 Quick Start\n\n13.2.1 Basic Usage\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Load data with default settings\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders()\n\n# Iterate through batches\nfor batch_X, batch_y in train_loader:\n    print(f\"Batch features: {batch_X.shape}\")  # (32, 10)\n    print(f\"Batch targets: {batch_y.shape}\")   # (32, 1)\n    break\n\n\n13.2.2 Training a Model\nimport torch\nimport torch.nn as nn\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n# Load data\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.2,\n    batch_size=32,\n    scale_features=True,\n    random_state=42\n)\n\n# Create model\nmodel = LinearRegressor(\n    input_dim=10,\n    output_dim=1,\n    l1=64,\n    num_hidden_layers=2,\n    activation=\"ReLU\"\n)\n\n# Setup training\ncriterion = nn.MSELoss()\noptimizer = model.get_optimizer(\"Adam\", lr=0.01)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    for batch_X, batch_y in train_loader:\n        # Forward pass\n        predictions = model(batch_X)\n        loss = criterion(predictions, batch_y)\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    \n    avg_train_loss = train_loss / len(train_loader)\n    \n    if (epoch + 1) % 20 == 0:\n        print(f\"Epoch {epoch+1}/{num_epochs}: Loss = {avg_train_loss:.4f}\")\n\n# Evaluation\nmodel.eval()\ntest_loss = 0.0\n\nwith torch.no_grad():\n    for batch_X, batch_y in test_loader:\n        predictions = model(batch_X)\n        loss = criterion(predictions, batch_y)\n        test_loss += loss.item()\n\navg_test_loss = test_loss / len(test_loader)\nprint(f\"Test MSE: {avg_test_loss:.4f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#function-reference",
    "href": "diabetes_dataset.html#function-reference",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.3 Function Reference",
    "text": "13.3 Function Reference\n\n13.3.1 get_diabetes_dataloaders()\nLoads the sklearn diabetes dataset and returns configured PyTorch DataLoaders.\nSignature:\nget_diabetes_dataloaders(\n    test_size=0.2,\n    batch_size=32,\n    shuffle_train=True,\n    shuffle_test=False,\n    random_state=42,\n    scale_features=True,\n    num_workers=0,\n    pin_memory=False\n)\nParameters:\n\n\n\n\n\n\n\n\n\nParameter\nType\nDefault\nDescription\n\n\n\n\ntest_size\nfloat\n0.2\nProportion of dataset for testing (0.0 to 1.0)\n\n\nbatch_size\nint\n32\nNumber of samples per batch\n\n\nshuffle_train\nbool\nTrue\nWhether to shuffle training data\n\n\nshuffle_test\nbool\nFalse\nWhether to shuffle test data\n\n\nrandom_state\nint\n42\nRandom seed for train/test split\n\n\nscale_features\nbool\nTrue\nWhether to standardize features\n\n\nnum_workers\nint\n0\nNumber of subprocesses for data loading\n\n\npin_memory\nbool\nFalse\nWhether to pin memory (useful for GPU)\n\n\n\nReturns:\n\ntrain_loader (DataLoader): Training data loader\ntest_loader (DataLoader): Test data loader\nscaler (StandardScaler or None): Fitted scaler if scale_features=True, else None\n\nExample:\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Custom configuration\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.3,\n    batch_size=64,\n    shuffle_train=True,\n    scale_features=True,\n    random_state=123\n)\n\nprint(f\"Training batches: {len(train_loader)}\")\nprint(f\"Test batches: {len(test_loader)}\")\nprint(f\"Scaler mean: {scaler.mean_[:3]}\")  # First 3 features",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#diabetesdataset-class",
    "href": "diabetes_dataset.html#diabetesdataset-class",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.4 DiabetesDataset Class",
    "text": "13.4 DiabetesDataset Class\nPyTorch Dataset implementation for the diabetes dataset.\nSignature:\nDiabetesDataset(X, y, transform=None, target_transform=None)\nParameters:\n\nX (np.ndarray): Feature matrix of shape (n_samples, n_features)\ny (np.ndarray): Target values of shape (n_samples,) or (n_samples, 1)\ntransform (callable, optional): Transform to apply to features\ntarget_transform (callable, optional): Transform to apply to targets\n\nAttributes:\n\nX (torch.Tensor): Feature tensor (n_samples, n_features)\ny (torch.Tensor): Target tensor (n_samples, 1)\nn_features (int): Number of features (10 for diabetes)\nn_samples (int): Number of samples\n\nMethods:\n\n__len__(): Returns number of samples\n__getitem__(idx): Returns tuple (features, target) for given index\n\n\n13.4.1 Manual Dataset Creation\nfrom spotoptim.data import DiabetesDataset\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import DataLoader\n\n# Load raw data\ndiabetes = load_diabetes()\nX, y = diabetes.data, diabetes.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Scale features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create datasets\ntrain_dataset = DiabetesDataset(X_train, y_train)\ntest_dataset = DiabetesDataset(X_test, y_test)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Inspect dataset\nprint(f\"Dataset size: {len(train_dataset)}\")\nprint(f\"Features shape: {train_dataset.X.shape}\")\nprint(f\"Targets shape: {train_dataset.y.shape}\")\n\n# Get a sample\nfeatures, target = train_dataset[0]\nprint(f\"Sample features: {features.shape}\")  # (10,)\nprint(f\"Sample target: {target.shape}\")      # (1,)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#advanced-usage",
    "href": "diabetes_dataset.html#advanced-usage",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.5 Advanced Usage",
    "text": "13.5 Advanced Usage\n\n13.5.1 Custom Transforms\nfrom spotoptim.data import DiabetesDataset\nfrom sklearn.datasets import load_diabetes\nimport torch\n\n# Define custom transforms\ndef add_noise(x):\n    \"\"\"Add Gaussian noise to features.\"\"\"\n    return x + torch.randn_like(x) * 0.01\n\ndef log_transform(y):\n    \"\"\"Apply log transform to target.\"\"\"\n    return torch.log1p(y)\n\n# Load data\ndiabetes = load_diabetes()\nX, y = diabetes.data, diabetes.target\n\n# Create dataset with transforms\ndataset = DiabetesDataset(\n    X, y,\n    transform=add_noise,\n    target_transform=log_transform\n)\n\n# Transforms are applied when accessing items\nfeatures, target = dataset[0]\n\n\n13.5.2 Different Train/Test Splits\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# 70/30 split\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.3,\n    random_state=42\n)\nprint(f\"Training samples: {len(train_loader.dataset)}\")  # ~310\nprint(f\"Test samples: {len(test_loader.dataset)}\")       # ~132\n\n# 90/10 split\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.1,\n    random_state=42\n)\nprint(f\"Training samples: {len(train_loader.dataset)}\")  # ~398\nprint(f\"Test samples: {len(test_loader.dataset)}\")       # ~44\n\n\n13.5.3 Without Feature Scaling\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Load without scaling (useful for tree-based models)\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=False\n)\n\nprint(f\"Scaler: {scaler}\")  # None\n\n# Data is in original scale\nfor batch_X, batch_y in train_loader:\n    print(f\"Mean: {batch_X.mean(dim=0)[:3]}\")  # Non-zero values\n    break\n\n\n13.5.4 Larger Batch Sizes\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Larger batches for faster training (if memory allows)\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=128\n)\nprint(f\"Batches per epoch: {len(train_loader)}\")  # Fewer batches\n\n# Smaller batches for more gradient updates\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=8\n)\nprint(f\"Batches per epoch: {len(train_loader)}\")  # More batches\n\n\n13.5.5 GPU Training with Pin Memory\nimport torch\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Enable pin_memory for faster GPU transfer\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=32,\n    pin_memory=True  # Set to True when using GPU\n)\n\n# Move model to GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training loop with GPU\nfor batch_X, batch_y in train_loader:\n    # Data is already pinned, faster transfer to GPU\n    batch_X = batch_X.to(device, non_blocking=True)\n    batch_y = batch_y.to(device, non_blocking=True)\n    \n    # ... training code ...",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#complete-training-example",
    "href": "diabetes_dataset.html#complete-training-example",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.6 Complete Training Example",
    "text": "13.6 Complete Training Example\nHere’s a complete example showing data loading, model training, and evaluation:\nimport torch\nimport torch.nn as nn\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\ndef train_diabetes_model():\n    \"\"\"Train a neural network on the diabetes dataset.\"\"\"\n    \n    # Load data\n    train_loader, test_loader, scaler = get_diabetes_dataloaders(\n        test_size=0.2,\n        batch_size=32,\n        scale_features=True,\n        random_state=42\n    )\n    \n    # Create model\n    model = LinearRegressor(\n        input_dim=10,\n        output_dim=1,\n        l1=128,\n        num_hidden_layers=3,\n        activation=\"ReLU\"\n    )\n    \n    # Setup training\n    criterion = nn.MSELoss()\n    optimizer = model.get_optimizer(\"Adam\", lr=0.001, weight_decay=1e-5)\n    \n    # Training configuration\n    num_epochs = 200\n    best_test_loss = float('inf')\n    \n    print(\"Starting training...\")\n    print(f\"Training samples: {len(train_loader.dataset)}\")\n    print(f\"Test samples: {len(test_loader.dataset)}\")\n    print(f\"Batches per epoch: {len(train_loader)}\")\n    print(\"-\" * 60)\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        \n        for batch_X, batch_y in train_loader:\n            # Forward pass\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        avg_train_loss = train_loss / len(train_loader)\n        \n        # Evaluation phase\n        model.eval()\n        test_loss = 0.0\n        \n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        \n        # Track best model\n        if avg_test_loss &lt; best_test_loss:\n            best_test_loss = avg_test_loss\n            # Could save model here: torch.save(model.state_dict(), 'best_model.pt')\n        \n        # Print progress\n        if (epoch + 1) % 20 == 0:\n            print(f\"Epoch {epoch+1:3d}/{num_epochs}: \"\n                  f\"Train Loss = {avg_train_loss:.4f}, \"\n                  f\"Test Loss = {avg_test_loss:.4f}\")\n    \n    print(\"-\" * 60)\n    print(f\"Training complete!\")\n    print(f\"Best test loss: {best_test_loss:.4f}\")\n    \n    return model, best_test_loss\n\n# Run training\nif __name__ == \"__main__\":\n    model, best_loss = train_diabetes_model()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#integration-with-spotoptim",
    "href": "diabetes_dataset.html#integration-with-spotoptim",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.7 Integration with SpotOptim",
    "text": "13.7 Integration with SpotOptim\nUse the diabetes dataset for hyperparameter optimization with SpotOptim:\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\ndef evaluate_model(X):\n    \"\"\"Objective function for SpotOptim.\n    \n    Args:\n        X: Array of hyperparameters [lr, l1, num_hidden_layers]\n        \n    Returns:\n        Array of validation losses\n    \"\"\"\n    results = []\n    \n    for params in X:\n        lr, l1, num_hidden_layers = params\n        lr = 10 ** lr  # Log scale for learning rate\n        l1 = int(l1)\n        num_hidden_layers = int(num_hidden_layers)\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(\n            test_size=0.2,\n            batch_size=32,\n            random_state=42\n        )\n        \n        # Create model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=num_hidden_layers,\n            activation=\"ReLU\"\n        )\n        \n        # Train briefly\n        criterion = nn.MSELoss()\n        optimizer = model.get_optimizer(\"Adam\", lr=lr)\n        \n        num_epochs = 50\n        for epoch in range(num_epochs):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n        \n        results.append(test_loss / len(test_loader))\n    \n    return np.array(results)\n\n# Optimize hyperparameters\noptimizer = SpotOptim(\n    fun=evaluate_model,\n    bounds=[\n        (-4, -2),   # log10(lr): 0.0001 to 0.01\n        (16, 128),  # l1: number of neurons\n        (0, 4)      # num_hidden_layers\n    ],\n    var_type=[\"num\", \"int\", \"int\"],\n    max_iter=30,\n    n_initial=10,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\nprint(f\"Best hyperparameters found:\")\nprint(f\"  Learning rate: {10**result.x[0]:.6f}\")\nprint(f\"  Hidden neurons (l1): {int(result.x[1])}\")\nprint(f\"  Hidden layers: {int(result.x[2])}\")\nprint(f\"  Best MSE: {result.fun:.4f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#best-practices",
    "href": "diabetes_dataset.html#best-practices",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.8 Best Practices",
    "text": "13.8 Best Practices\n\n13.8.1 1. Always Use Feature Scaling\n# Good: Features are standardized\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=True\n)\nNeural networks typically perform better with normalized inputs.\n\n\n13.8.2 2. Set Random Seeds for Reproducibility\n# Reproducible train/test splits\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    random_state=42\n)\n\n# Also set PyTorch seed\nimport torch\ntorch.manual_seed(42)\n\n\n13.8.3 3. Don’t Shuffle Test Data\n# Good: Test data in consistent order\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    shuffle_train=True,   # Shuffle training data\n    shuffle_test=False    # Don't shuffle test data\n)\nThis ensures consistent evaluation metrics across runs.\n\n\n13.8.4 4. Choose Appropriate Batch Size\n# Small dataset (442 samples) - moderate batch size works well\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=32  # Good balance for this dataset\n)\nToo large: Fewer gradient updates per epoch\nToo small: Noisy gradients, slower training\n\n\n13.8.5 5. Save the Scaler for Production\nimport pickle\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Train with scaling\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=True\n)\n\n# Save scaler for production use\nwith open('scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\n\n# Later: Load and use on new data\nwith open('scaler.pkl', 'rb') as f:\n    scaler = pickle.load(f)\n\nnew_data_scaled = scaler.transform(new_data)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#troubleshooting",
    "href": "diabetes_dataset.html#troubleshooting",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.9 Troubleshooting",
    "text": "13.9 Troubleshooting\n\n13.9.1 Issue: Out of Memory\nSolution: Reduce batch size or disable pin_memory\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=16,      # Smaller batches\n    pin_memory=False    # Disable if not using GPU\n)\n\n\n13.9.2 Issue: Different Data Ranges\nSymptom: Model not converging, loss is NaN\nSolution: Ensure feature scaling is enabled\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=True  # Must be True for neural networks\n)\n\n\n13.9.3 Issue: Non-Reproducible Results\nSolution: Set all random seeds\nimport torch\nimport numpy as np\n\n# Set all seeds\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    random_state=42,\n    shuffle_train=False  # Disable shuffle for full reproducibility\n)\n\n\n13.9.4 Issue: Slow Data Loading\nSolution: Use multiple workers (if not on Windows)\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    num_workers=4,      # Use 4 subprocesses\n    pin_memory=True     # Enable for GPU\n)\nNote: On Windows, set num_workers=0 to avoid multiprocessing issues.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#summary",
    "href": "diabetes_dataset.html#summary",
    "title": "13  Diabetes Dataset Utilities",
    "section": "13.10 Summary",
    "text": "13.10 Summary\nThe diabetes dataset utilities in SpotOptim provide:\n\nEasy data loading: One function call gets complete data pipeline\nPyTorch integration: Native Dataset and DataLoader support\nPreprocessing included: Automatic feature scaling and train/test splitting\nFlexible configuration: Control batch size, splitting, scaling, and more\nProduction ready: Save scalers and ensure reproducibility\n\nFor more examples, see: - examples/diabetes_dataset_example.py - notebooks/demos.ipynb - Test suite: tests/test_diabetes_dataset.py",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "factor_variables.html",
    "href": "factor_variables.html",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "",
    "text": "14.1 Overview\nSpotOptim supports factor variables for optimizing categorical hyperparameters, such as activation functions, optimizers, or any discrete string-based choices. Factor variables are automatically converted between string values (external interface) and integers (internal optimization), making categorical optimization seamless.\nWhat are Factor Variables?\nFactor variables allow you to specify categorical choices as tuples of strings in the bounds. SpotOptim handles the conversion:\nModule: spotoptim.SpotOptim\nKey Features:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#overview",
    "href": "factor_variables.html#overview",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "",
    "text": "String tuples in bounds → Internal integer mapping (0, 1, 2, …)\nOptimization uses integers internally for surrogate modeling\nObjective function receives strings after automatic conversion\nResults return strings (not integers)\n\n\n\n\nDefine categorical choices as string tuples: (\"ReLU\", \"Sigmoid\", \"Tanh\")\nAutomatic integer↔︎string conversion\nSeamless integration with neural network hyperparameters\nMix factor variables with numeric/integer variables",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#quick-start",
    "href": "factor_variables.html#quick-start",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.2 Quick Start",
    "text": "14.2 Quick Start\n\n14.2.1 Basic Factor Variable Usage\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective_function(X):\n    \"\"\"Objective function receives string values.\"\"\"\n    results = []\n    for params in X:\n        activation = params[0]  # This is a string!\n        print(f\"Testing activation: {activation}\")\n        \n        # Simple scoring based on activation choice (for demonstration)\n        # In real use, you would train a model and return actual performance\n        scores = {\n            \"ReLU\": 3500.0,\n            \"Sigmoid\": 4200.0,\n            \"Tanh\": 3800.0,\n            \"LeakyReLU\": 3600.0\n        }\n        score = scores.get(activation, 5000.0) + np.random.normal(0, 100)\n        results.append(score)\n    return np.array(results)  # Return numpy array\n\n# Define bounds with factor variable\noptimizer = SpotOptim(\n    fun=objective_function,\n    bounds=[(\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")],\n    var_type=[\"factor\"],\n    max_iter=20,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"\\nBest activation: {result.x[0]}\")  # Returns string, e.g., \"ReLU\"\nprint(f\"Best score: {result.fun:.4f}\")\n\n\n14.2.2 Neural Network Activation Function Optimization\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport numpy as np\n\ndef train_and_evaluate(X):\n    \"\"\"Train models with different activation functions.\"\"\"\n    results = []\n    \n    for params in X:\n        activation = params[0]  # String: \"ReLU\", \"Sigmoid\", etc.\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders()\n        \n        # Create model with the activation function\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=64,\n            num_hidden_layers=2,\n            activation=activation  # Pass string directly!\n        )\n        \n        # Train model\n        optimizer = model.get_optimizer(\"Adam\", lr=0.01)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(50):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_loss = test_loss / len(test_loader)\n        results.append(avg_loss)\n    \n    return np.array(results)  # Return numpy array\n\n# Optimize activation function choice\noptimizer = SpotOptim(\n    fun=train_and_evaluate,\n    bounds=[(\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\", \"ELU\")],\n    var_type=[\"factor\"],\n    max_iter=30\n)\n\nresult = optimizer.optimize()\nprint(f\"Best activation function: {result.x[0]}\")\nprint(f\"Best test MSE: {result.fun:.4f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#mixed-variable-types",
    "href": "factor_variables.html#mixed-variable-types",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.3 Mixed Variable Types",
    "text": "14.3 Mixed Variable Types\n\n14.3.1 Combining Factor, Integer, and Continuous Variables\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\ndef comprehensive_optimization(X):\n    \"\"\"Optimize learning rate, layer size, depth, and activation.\"\"\"\n    results = []\n    \n    for params in X:\n        log_lr = params[0]      # Continuous (log scale)\n        l1 = int(params[1])     # Integer\n        n_layers = int(params[2])  # Integer\n        activation = params[3]   # Factor (string)\n        \n        lr = 10 ** log_lr  # Convert from log scale\n        \n        print(f\"lr={lr:.6f}, l1={l1}, layers={n_layers}, activation={activation}\")\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(\n            batch_size=32,\n            random_state=42\n        )\n        \n        # Create model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=n_layers,\n            activation=activation\n        )\n        \n        # Train\n        optimizer = model.get_optimizer(\"Adam\", lr=lr)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(30):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        results.append(test_loss / len(test_loader))\n    \n    return np.array(results)\n\n# Optimize all four hyperparameters simultaneously\noptimizer = SpotOptim(\n    fun=comprehensive_optimization,\n    bounds=[\n        (-4, -2),                                    # log10(learning_rate)\n        (16, 128),                                   # l1 (neurons per layer)\n        (0, 4),                                      # num_hidden_layers\n        (\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")   # activation function\n    ],\n    var_type=[\"num\", \"int\", \"int\", \"factor\"],\n    max_iter=50\n)\n\nresult = optimizer.optimize()\n\n# Results contain original string values\nprint(\"\\nOptimization Results:\")\nprint(f\"Best learning rate: {10**result.x[0]:.6f}\")\nprint(f\"Best layer size: {int(result.x[1])}\")\nprint(f\"Best num layers: {int(result.x[2])}\")\nprint(f\"Best activation: {result.x[3]}\")  # String value!\nprint(f\"Best test MSE: {result.fun:.4f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#multiple-factor-variables",
    "href": "factor_variables.html#multiple-factor-variables",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.4 Multiple Factor Variables",
    "text": "14.4 Multiple Factor Variables\n\n14.4.1 Optimizing Both Activation and Optimizer\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport torch.nn as nn\nimport numpy as np\n\ndef optimize_activation_and_optimizer(X):\n    \"\"\"Optimize both activation function and optimizer choice.\"\"\"\n    results = []\n    \n    for params in X:\n        activation = params[0]      # Factor variable 1\n        optimizer_name = params[1]  # Factor variable 2\n        lr = 10 ** params[2]        # Continuous variable\n        \n        train_loader, test_loader, _ = get_diabetes_dataloaders()\n        \n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=64,\n            num_hidden_layers=2,\n            activation=activation\n        )\n        \n        # Use the optimizer string\n        optimizer = model.get_optimizer(optimizer_name, lr=lr)\n        criterion = nn.MSELoss()\n        \n        # Train\n        for epoch in range(30):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        results.append(test_loss / len(test_loader))\n    \n    return np.array(results)  # Return numpy array\n\n# Two factor variables + one continuous\nopt = SpotOptim(\n    fun=optimize_activation_and_optimizer,\n    bounds=[\n        (\"ReLU\", \"Tanh\", \"Sigmoid\", \"LeakyReLU\"),    # Activation\n        (\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"),         # Optimizer\n        (-4, -2)                                      # log10(lr)\n    ],\n    var_type=[\"factor\", \"factor\", \"num\"],\n    max_iter=40\n)\n\nresult = opt.optimize()\nprint(f\"Best activation: {result.x[0]}\")\nprint(f\"Best optimizer: {result.x[1]}\")\nprint(f\"Best learning rate: {10**result.x[2]:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#advanced-usage",
    "href": "factor_variables.html#advanced-usage",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.5 Advanced Usage",
    "text": "14.5 Advanced Usage\n\n14.5.1 Custom Categorical Choices\nFactor variables work with any string values, not just activation functions:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef train_model_with_config(dropout_policy, batch_norm, weight_init):\n    \"\"\"Simulate model training with different configurations.\"\"\"\n    # In real use, this would train an actual model\n    # Here we return synthetic scores for demonstration\n    base_score = 3000.0\n    \n    # Dropout impact\n    dropout_scores = {\"none\": 200, \"light\": 0, \"heavy\": 100}\n    # Batch norm impact\n    bn_scores = {\"before\": -50, \"after\": 0, \"none\": 150}\n    # Weight init impact\n    init_scores = {\"xavier\": 0, \"kaiming\": -30, \"normal\": 100}\n    \n    score = (base_score + \n             dropout_scores.get(dropout_policy, 0) + \n             bn_scores.get(batch_norm, 0) + \n             init_scores.get(weight_init, 0) +\n             np.random.normal(0, 50))\n    \n    return score\n\ndef train_with_config(X):\n    \"\"\"Objective function with various categorical choices.\"\"\"\n    results = []\n    \n    for params in X:\n        dropout_policy = params[0]  # \"none\", \"light\", \"heavy\"\n        batch_norm = params[1]       # \"before\", \"after\", \"none\"\n        weight_init = params[2]      # \"xavier\", \"kaiming\", \"normal\"\n        \n        # Use these strings to configure your model\n        score = train_model_with_config(\n            dropout_policy=dropout_policy,\n            batch_norm=batch_norm,\n            weight_init=weight_init\n        )\n        results.append(score)\n    \n    return np.array(results)  # Return numpy array\n\noptimizer = SpotOptim(\n    fun=train_with_config,\n    bounds=[\n        (\"none\", \"light\", \"heavy\"),           # Dropout policy\n        (\"before\", \"after\", \"none\"),          # Batch norm position\n        (\"xavier\", \"kaiming\", \"normal\")       # Weight initialization\n    ],\n    var_type=[\"factor\", \"factor\", \"factor\"],\n    max_iter=25,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(\"Best configuration:\")\nprint(f\"  Dropout: {result.x[0]}\")\nprint(f\"  Batch norm: {result.x[1]}\")\nprint(f\"  Weight init: {result.x[2]}\")\nprint(f\"  Score: {result.fun:.4f}\")\n\n\n14.5.2 Viewing All Evaluated Configurations\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport numpy as np\n\ndef train_and_evaluate(X):\n    \"\"\"Train models with different activation functions.\"\"\"\n    results = []\n    \n    for params in X:\n        l1 = int(params[0])         # Integer: layer size\n        activation = params[1]       # String: activation function\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders()\n        \n        # Create model with the activation function\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=2,\n            activation=activation  # Pass string directly!\n        )\n        \n        # Train model\n        optimizer = model.get_optimizer(\"Adam\", lr=0.01)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(50):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_loss = test_loss / len(test_loader)\n        results.append(avg_loss)\n    \n    return np.array(results)\n\noptimizer = SpotOptim(\n    fun=train_and_evaluate,\n    bounds=[\n        (16, 128),                                   # Layer size\n        (\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")   # Activation\n    ],\n    var_type=[\"int\", \"factor\"],  # IMPORTANT: Specify variable types!\n    max_iter=30,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Access all evaluated configurations\nprint(\"\\nAll evaluated configurations:\")\nprint(\"Layer Size | Activation | Test MSE\")\nprint(\"-\" * 42)\nfor i in range(min(10, len(result.X))):  # Show first 10\n    l1 = int(result.X[i, 0])\n    activation = result.X[i, 1]  # String value!\n    loss = result.y[i]\n    print(f\"{l1:10d} | {activation:10s} | {loss:.4f}\")\n\n# Find top 5 configurations\nsorted_indices = result.y.argsort()[:5]\nprint(\"\\nTop 5 configurations:\")\nfor idx in sorted_indices:\n    print(f\"l1={int(result.X[idx, 0]):3d}, \"\n          f\"activation={result.X[idx, 1]:10s}, \"\n          f\"MSE={result.y[idx]:.4f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#how-it-works",
    "href": "factor_variables.html#how-it-works",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.6 How It Works",
    "text": "14.6 How It Works\n\n14.6.1 Internal Mechanism\nSpotOptim handles factor variables through automatic conversion:\n\nInitialization: String tuples in bounds are detected\nbounds = [(\"ReLU\", \"Sigmoid\", \"Tanh\")]\n# Internally mapped to: {0: \"ReLU\", 1: \"Sigmoid\", 2: \"Tanh\"}\n# Bounds become: [(0, 2)]\nSampling: Initial design samples from [0, n_levels-1] and rounds to integers\n# Samples might be: [0.3, 1.8, 2.1]\n# After rounding: [0, 2, 2]\nEvaluation: Before calling objective function, integers → strings\n# [0, 2, 2] → [\"ReLU\", \"Tanh\", \"Tanh\"]\n# Objective function receives strings\nOptimization: Surrogate model works with integers [0, n_levels-1]\nResults: Final results mapped back to strings\nresult.x[0]  # Returns \"ReLU\", not 0\nresult.X     # All rows contain strings for factor variables\n\n\n\n14.6.2 Variable Type Auto-Detection\nIf you don’t specify var_type, SpotOptim automatically detects factor variables:\n# Example 1: Explicit var_type (recommended)\n# This shows the syntax - replace my_function with your actual function\n\n# optimizer = SpotOptim(\n#     fun=my_function,\n#     bounds=[(-4, -2), (\"ReLU\", \"Tanh\")],\n#     var_type=[\"num\", \"factor\"]  # Explicit\n# )\n\n# Example 2: Auto-detection (works but less explicit)\n# optimizer = SpotOptim(\n#     fun=my_function,\n#     bounds=[(-4, -2), (\"ReLU\", \"Tanh\")]\n#     # var_type automatically set to [\"float\", \"factor\"]\n# )\n\n# Here's a working example:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef demo_function(X):\n    results = []\n    for params in X:\n        lr = 10 ** params[0]  # Continuous parameter\n        activation = params[1]  # Factor parameter\n        score = 3000 + lr * 100 + {\"ReLU\": 0, \"Tanh\": 50}.get(activation, 100)\n        results.append(score + np.random.normal(0, 10))\n    return np.array(results)\n\n# With explicit var_type (recommended)\noptimizer = SpotOptim(\n    fun=demo_function,\n    bounds=[(-4, -2), (\"ReLU\", \"Tanh\")],\n    var_type=[\"num\", \"factor\"],  # Explicit is clearer\n    max_iter=10,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"Best lr: {10**result.x[0]:.6f}, Best activation: {result.x[1]}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#complete-example-full-workflow",
    "href": "factor_variables.html#complete-example-full-workflow",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.7 Complete Example: Full Workflow",
    "text": "14.7 Complete Example: Full Workflow\n\"\"\"\nComplete example: Neural network hyperparameter optimization with factor variables.\n\"\"\"\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n\ndef objective_function(X):\n    \"\"\"Train and evaluate models with given hyperparameters.\"\"\"\n    results = []\n    \n    for params in X:\n        # Extract hyperparameters\n        log_lr = params[0]\n        l1 = int(params[1])\n        num_layers = int(params[2])\n        activation = params[3]  # String!\n        \n        lr = 10 ** log_lr\n        \n        print(f\"Testing: lr={lr:.6f}, l1={l1}, layers={num_layers}, \"\n              f\"activation={activation}\")\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(\n            test_size=0.2,\n            batch_size=32,\n            random_state=42\n        )\n        \n        # Create and train model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=num_layers,\n            activation=activation\n        )\n        \n        optimizer = model.get_optimizer(\"Adam\", lr=lr)\n        criterion = nn.MSELoss()\n        \n        # Training loop\n        num_epochs = 30\n        for epoch in range(num_epochs):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluation\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results.append(avg_test_loss)\n        print(f\"  → Test MSE: {avg_test_loss:.4f}\")\n    \n    return np.array(results)\n\n\ndef main():\n    print(\"=\" * 80)\n    print(\"Neural Network Hyperparameter Optimization with Factor Variables\")\n    print(\"=\" * 80)\n    \n    # Define optimization problem\n    optimizer = SpotOptim(\n        fun=objective_function,\n        bounds=[\n            (-4, -2),                                    # log10(learning_rate)\n            (16, 128),                                   # l1 (neurons)\n            (0, 4),                                      # num_hidden_layers\n            (\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")   # activation (factor!)\n        ],\n        var_type=[\"num\", \"int\", \"int\", \"factor\"],\n        max_iter=50,\n        seed=42\n    )\n    \n    # Run optimization\n    print(\"\\nStarting optimization...\")\n    result = optimizer.optimize()\n    \n    # Display results\n    print(\"\\n\" + \"=\" * 80)\n    print(\"OPTIMIZATION RESULTS\")\n    print(\"=\" * 80)\n    print(f\"Best learning rate: {10**result.x[0]:.6f}\")\n    print(f\"Best layer size (l1): {int(result.x[1])}\")\n    print(f\"Best num hidden layers: {int(result.x[2])}\")\n    print(f\"Best activation function: {result.x[3]}\")  # String value!\n    print(f\"Best test MSE: {result.fun:.4f}\")\n    \n    # Show top 5 configurations\n    print(\"\\n\" + \"=\" * 80)\n    print(\"TOP 5 CONFIGURATIONS\")\n    print(\"=\" * 80)\n    sorted_indices = result.y.argsort()[:5]\n    print(f\"{'Rank':&lt;6} {'LR':&lt;12} {'L1':&lt;6} {'Layers':&lt;8} \"\n          f\"{'Activation':&lt;12} {'MSE':&lt;10}\")\n    print(\"-\" * 80)\n    for rank, idx in enumerate(sorted_indices, 1):\n        lr = 10 ** result.X[idx, 0]\n        l1 = int(result.X[idx, 1])\n        layers = int(result.X[idx, 2])\n        activation = result.X[idx, 3]\n        mse = result.y[idx]\n        print(f\"{rank:&lt;6} {lr:&lt;12.6f} {l1:&lt;6} {layers:&lt;8} \"\n              f\"{activation:&lt;12} {mse:&lt;10.4f}\")\n    \n    # Train final model with best configuration\n    print(\"\\n\" + \"=\" * 80)\n    print(\"TRAINING FINAL MODEL\")\n    print(\"=\" * 80)\n    \n    best_lr = 10 ** result.x[0]\n    best_l1 = int(result.x[1])\n    best_layers = int(result.x[2])\n    best_activation = result.x[3]\n    \n    print(f\"Configuration: lr={best_lr:.6f}, l1={best_l1}, \"\n          f\"layers={best_layers}, activation={best_activation}\")\n    \n    train_loader, test_loader, _ = get_diabetes_dataloaders(\n        test_size=0.2,\n        batch_size=32,\n        random_state=42\n    )\n    \n    final_model = LinearRegressor(\n        input_dim=10,\n        output_dim=1,\n        l1=best_l1,\n        num_hidden_layers=best_layers,\n        activation=best_activation\n    )\n    \n    optimizer_final = final_model.get_optimizer(\"Adam\", lr=best_lr)\n    criterion = nn.MSELoss()\n    \n    # Extended training\n    num_epochs = 100\n    print(f\"\\nTraining for {num_epochs} epochs...\")\n    for epoch in range(num_epochs):\n        final_model.train()\n        train_loss = 0.0\n        for batch_X, batch_y in train_loader:\n            predictions = final_model(batch_X)\n            loss = criterion(predictions, batch_y)\n            optimizer_final.zero_grad()\n            loss.backward()\n            optimizer_final.step()\n            train_loss += loss.item()\n        \n        if (epoch + 1) % 20 == 0:\n            avg_train_loss = train_loss / len(train_loader)\n            print(f\"Epoch {epoch+1}/{num_epochs}: Train MSE = {avg_train_loss:.4f}\")\n    \n    # Final evaluation\n    final_model.eval()\n    final_test_loss = 0.0\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            predictions = final_model(batch_X)\n            final_test_loss += criterion(predictions, batch_y).item()\n    \n    final_avg_loss = final_test_loss / len(test_loader)\n    print(f\"\\nFinal Test MSE: {final_avg_loss:.4f}\")\n    print(\"=\" * 80)\n\n\nif __name__ == \"__main__\":\n    main()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#best-practices",
    "href": "factor_variables.html#best-practices",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.8 Best Practices",
    "text": "14.8 Best Practices\n\n14.8.1 Do’s\n✅ Use descriptive string values\nbounds=[(\"xavier_uniform\", \"kaiming_normal\", \"orthogonal\")]\n✅ Explicitly specify var_type for clarity\nvar_type=[\"num\", \"int\", \"factor\"]\n✅ Access results as strings\n# Example: Accessing factor variable results as strings\n# (This assumes you've run an optimization with activation as a factor variable)\n\n# If you have a result from the previous examples:\n# best_activation = result.x[3]  # For 4-parameter optimization\n# Or for simpler cases:\n# best_activation = result.x[0]  # For single-parameter optimization\n\n# Example with inline optimization:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef quick_test(X):\n    results = []\n    for params in X:\n        activation = params[0]\n        score = {\"ReLU\": 3500, \"Tanh\": 3600}.get(activation, 4000)\n        results.append(score + np.random.normal(0, 50))\n    return np.array(results)\n\nopt = SpotOptim(\n    fun=quick_test,\n    bounds=[(\"ReLU\", \"Tanh\")],\n    var_type=[\"factor\"],\n    max_iter=10,\n    seed=42\n)\nresult = opt.optimize()\n\n# Access as string - this is the correct way\nbest_activation = result.x[0]  # String value like \"ReLU\"\nprint(f\"Best activation: {best_activation} (type: {type(best_activation).__name__})\")\n\n# You can use it directly in your model\n# model = LinearRegressor(activation=best_activation)\n✅ Mix factor variables with numeric/integer variables\nbounds=[(-4, -2), (16, 128), (\"ReLU\", \"Tanh\")]\nvar_type=[\"num\", \"int\", \"factor\"]\n\n\n14.8.2 Don’ts\n❌ Don’t use integers in factor bounds\n# Wrong: Use strings, not integers\nbounds=[(0, 1, 2)]  # Wrong!\nbounds=[(\"ReLU\", \"Sigmoid\", \"Tanh\")]  # Correct!\n❌ Don’t expect integers in objective function\ndef objective(X):\n    activation = X[0][2]\n    # activation is a string, not an integer!\n    # Don't do: if activation == 0:  # Wrong!\n    # Do: if activation == \"ReLU\":   # Correct!\n❌ Don’t manually convert factor variables\n# SpotOptim handles conversion automatically\n# Don't do manual mapping in your objective function\n❌ Don’t use empty tuples\n# Wrong: Empty tuple\nbounds=[()]\n\n# Correct: At least one string\nbounds=[(\"ReLU\",)]  # Single choice (will be treated as fixed)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#troubleshooting",
    "href": "factor_variables.html#troubleshooting",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.9 Troubleshooting",
    "text": "14.9 Troubleshooting\n\n14.9.1 Common Issues\nIssue: Objective function receives integers instead of strings\nSolution: Ensure you’re using the latest version of SpotOptim with factor variable support. Factor variables are automatically converted before calling the objective function.\n\nIssue: ValueError: could not convert string to float\nSolution: This occurs if there’s a version mismatch. Update SpotOptim to ensure the object array conversion is implemented correctly.\n\nIssue: Results show integers instead of strings\nSolution: Check that you’re accessing result.x (mapped values) instead of internal arrays. The result object automatically maps factor variables to their original strings.\n\nIssue: Single-level factor variables cause dimension reduction\nBehavior: If a factor variable has only one choice, e.g., (\"ReLU\",), SpotOptim treats it as a fixed dimension and may reduce the dimensionality. This is expected behavior.\nSolution: Use at least two choices for optimization, or remove single-choice dimensions from bounds.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#summary",
    "href": "factor_variables.html#summary",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.10 Summary",
    "text": "14.10 Summary\nFactor variables in SpotOptim enable:\n\n✅ Categorical optimization: Optimize over discrete string choices\n✅ Automatic conversion: Seamless integer↔︎string mapping\n✅ Neural network hyperparameters: Optimize activation functions, optimizers, etc.\n✅ Mixed variable types: Combine with continuous and integer variables\n✅ Clean interface: Objective functions work with strings directly\n✅ String results: Final results contain original string values\n\nFactor variables make categorical hyperparameter optimization as easy as continuous optimization!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#see-also",
    "href": "factor_variables.html#see-also",
    "title": "14  Factor Variables for Categorical Hyperparameters",
    "section": "14.11 See Also",
    "text": "14.11 See Also\n\nLinearRegressor Documentation - Neural network class supporting string-based activation functions\nDiabetes Dataset Utilities - Data loading utilities used in examples\nVariable Types - Overview of all variable types in SpotOptim\nSave and Load - Saving and loading optimization results with factor variables",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "kriging.html",
    "href": "kriging.html",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "",
    "text": "15.1 Overview\nImplementation of a Kriging (Gaussian Process) surrogate model to SpotOptim, providing an alternative to scikit-learn’s GaussianProcessRegressor.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#module-structure",
    "href": "kriging.html#module-structure",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.2 Module Structure",
    "text": "15.2 Module Structure\nsrc/spotoptim/surrogate/\n├── __init__.py          # Module exports\n├── kriging.py           # Kriging implementation (~350 lines)\n└── README.md            # Module documentation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#kriging-class-srcspotoptimsurrogatekriging.py",
    "href": "kriging.html#kriging-class-srcspotoptimsurrogatekriging.py",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.3 Kriging Class (src/spotoptim/surrogate/kriging.py)",
    "text": "15.3 Kriging Class (src/spotoptim/surrogate/kriging.py)\nKey Features:\n\nScikit-learn compatible interface (fit(), predict())\nGaussian (RBF) kernel: R = exp(-D)\nAutomatic hyperparameter optimization via maximum likelihood\nCholesky decomposition for efficient linear algebra\nPrediction with uncertainty (return_std=True)\nReproducible results via seed parameter\n\nImplementation Details:\n\nlean, well-documented code\nNo external dependencies beyond NumPy, SciPy\nSimplified from spotpython.surrogate.kriging\nFocused on core functionality needed for SpotOptim\n\nParameters:\n\nnoise: Regularization (nugget effect)\nkernel: Currently ‘gauss’ (Gaussian/RBF)\nn_theta: Number of length scale parameters\nmin_theta, max_theta: Bounds for hyperparameter optimization\nseed: Random seed for reproducibility",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#integration-with-spotoptim",
    "href": "kriging.html#integration-with-spotoptim",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.4 Integration with SpotOptim",
    "text": "15.4 Integration with SpotOptim\nNo Changes Required to SpotOptim Core!\nThe existing surrogate parameter already supports any scikit-learn compatible model:\nfrom spotoptim import SpotOptim, Kriging\n\nkriging = Kriging(seed=42)\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    surrogate=kriging,  # Just pass the Kriging instance\n    seed=42\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#documentation",
    "href": "kriging.html#documentation",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.5 Documentation",
    "text": "15.5 Documentation\nAdded Example to notebooks/demos.ipynb\n\nDemonstrates Kriging vs GP comparison\nShows custom parameter usage",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#usage-examples",
    "href": "kriging.html#usage-examples",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.6 Usage Examples",
    "text": "15.6 Usage Examples\n\n15.6.1 Basic Usage\nfrom spotoptim import SpotOptim, Kriging\n\nkriging = Kriging(noise=1e-6, seed=42)\noptimizer = SpotOptim(fun=objective, bounds=bounds, surrogate=kriging)\nresult = optimizer.optimize()\n\n\n15.6.2 Custom Parameters\nkriging = Kriging(\n    noise=1e-4,\n    min_theta=-2.0,\n    max_theta=3.0,\n    seed=123\n)\n\n\n15.6.3 Prediction with Uncertainty\nmodel = Kriging(seed=42)\nmodel.fit(X_train, y_train)\ny_pred, y_std = model.predict(X_test, return_std=True)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#technical-details",
    "href": "kriging.html#technical-details",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.7 Technical Details",
    "text": "15.7 Technical Details\n\n15.7.1 Kriging vs GaussianProcessRegressor\n\n\n\nAspect\nKriging\nGaussianProcessRegressor\n\n\n\n\nLines of code\n~350\nComplex internal implementation\n\n\nDependencies\nNumPy, SciPy\nscikit-learn + dependencies\n\n\nKernel\nGaussian (RBF)\nMultiple types (Matern, RQ, etc.)\n\n\nHyperparameter opt\nDifferential Evolution\nL-BFGS-B with restarts\n\n\nUse case\nSimplified, explicit\nProduction, flexible\n\n\n\n\n\n15.7.2 Algorithm\n\nCorrelation Matrix:\n\nCompute squared distances: D_ij = Σ_k θ_k(x_ik - x_jk)²\nApply kernel: R_ij = exp(-D_ij)\nAdd nugget: R_ii += noise\n\nMaximum Likelihood:\n\nOptimize θ via differential evolution\nMinimize: (n/2)log(σ²) + (1/2)log|R|\nConcentrated likelihood (μ profiled out)\n\nPrediction:\n\nMean: f̂(x) = μ̂ + ψ(x)ᵀR⁻¹r\nVariance: s²(x) = σ̂²[1 + λ - ψ(x)ᵀR⁻¹ψ(x)]\nUses Cholesky decomposition for efficiency\n\n\n\n\n15.7.3 Key Arguments Passed from SpotOptim\nSpotOptim passes these to the surrogate via the standard interface:\nDuring fit:\nsurrogate.fit(X, y)\n\nX: Training points (n_initial or accumulated evaluations)\ny: Function values\n\nDuring predict:\nmu = surrogate.predict(x)[0]  # For acquisition='y'\nmu, sigma = surrogate.predict(x, return_std=True)  # For acquisition='ei', 'pi'\nImplicit parameters via seed:\n\nrandom_state=seed (for GaussianProcessRegressor)\nseed=seed (for Kriging)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#benefits",
    "href": "kriging.html#benefits",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.8 Benefits",
    "text": "15.8 Benefits\n\nSelf-contained: No heavy scikit-learn dependency for surrogate\nExplicit: Clear hyperparameter bounds and optimization\nEducational: Readable implementation of Kriging/GP\nFlexible: Easy to extend with new kernels or features\nCompatible: Works seamlessly with existing SpotOptim API",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#future-enhancements",
    "href": "kriging.html#future-enhancements",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.9 Future Enhancements",
    "text": "15.9 Future Enhancements\nPotential additions:\n\nAdditional kernels (Matern, Exponential, Cubic)\nAnisotropic hyperparameters (separate θ per dimension)\nGradient-enhanced predictions\nBatch predictions for efficiency\nParallel hyperparameter optimization\nARD (Automatic Relevance Determination)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "kriging.html#conclusion",
    "href": "kriging.html#conclusion",
    "title": "15  Kriging Surrogate Integration Summary",
    "section": "15.10 Conclusion",
    "text": "15.10 Conclusion\nImplementation of a Kriging surrogate into SpotOptim with:\n\n✅ Full scikit-learn compatibility\n✅ Comprehensive test coverage (9 new tests)\n✅ Complete documentation\n✅ Example notebook\n✅ Zero breaking changes\n✅ All 25 tests passing",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging Surrogate Integration Summary</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html",
    "href": "learning_rate_mapping.html",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "",
    "text": "16.1 Overview\nSpotOptim provides a sophisticated learning rate mapping system through the map_lr() function, enabling a unified interface for learning rates across different PyTorch optimizers. This solves the challenge that different optimizers operate on vastly different learning rate scales.\nDifferent PyTorch optimizers use different default learning rates and optimal ranges:\nThis makes it difficult to compare optimizer performance fairly or optimize learning rates across different optimizers. The map_lr() function provides a unified scale where lr_unified=1.0 corresponds to each optimizer’s PyTorch default.\nModule: spotoptim.utils.mapping\nKey Features:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#overview",
    "href": "learning_rate_mapping.html#overview",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "",
    "text": "Adam: default 0.001, typical range 0.0001-0.01\nSGD: default 0.01, typical range 0.001-0.1\nRMSprop: default 0.01, typical range 0.001-0.1\n\n\n\n\n\nUnified learning rate scale across all optimizers\nFair comparison when evaluating different optimizers\nSimplified hyperparameter optimization\nBased on official PyTorch default learning rates\nSupports 13 major PyTorch optimizers",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#quick-start",
    "href": "learning_rate_mapping.html#quick-start",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.2 Quick Start",
    "text": "16.2 Quick Start\n\n16.2.1 Basic Usage\nfrom spotoptim.utils.mapping import map_lr\n\n# Get optimizer-specific learning rate from unified scale\nlr_adam = map_lr(1.0, \"Adam\")      # Returns 0.001 (Adam's default)\nlr_sgd = map_lr(1.0, \"SGD\")        # Returns 0.01 (SGD's default)\nlr_rmsprop = map_lr(1.0, \"RMSprop\")  # Returns 0.01 (RMSprop's default)\n\nprint(f\"Unified lr=1.0:\")\nprint(f\"  Adam:    {lr_adam}\")\nprint(f\"  SGD:     {lr_sgd}\")\nprint(f\"  RMSprop: {lr_rmsprop}\")\n\n\n16.2.2 Scaling Learning Rates\nfrom spotoptim.utils.mapping import map_lr\n\n# Scale all learning rates by the same factor\nunified_lr = 0.5\n\nlr_adam = map_lr(unified_lr, \"Adam\")      # 0.5 * 0.001 = 0.0005\nlr_sgd = map_lr(unified_lr, \"SGD\")        # 0.5 * 0.01 = 0.005\nlr_rmsprop = map_lr(unified_lr, \"RMSprop\")  # 0.5 * 0.01 = 0.005\n\nprint(f\"Unified lr={unified_lr}:\")\nprint(f\"  Adam:    {lr_adam}\")\nprint(f\"  SGD:     {lr_sgd}\")\nprint(f\"  RMSprop: {lr_rmsprop}\")\n\n\n16.2.3 Integration with LinearRegressor\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n# Create model with unified learning rate\nmodel = LinearRegressor(\n    input_dim=10, \n    output_dim=1, \n    l1=32, \n    num_hidden_layers=2,\n    lr=1.0  # Unified learning rate\n)\n\n# Get optimizer - automatically uses mapped learning rate\noptimizer_adam = model.get_optimizer(\"Adam\")     # Gets 1.0 * 0.001 = 0.001\noptimizer_sgd = model.get_optimizer(\"SGD\")       # Gets 1.0 * 0.01 = 0.01\n\n# Verify the actual learning rates\nprint(f\"Adam actual lr: {optimizer_adam.param_groups[0]['lr']}\")\nprint(f\"SGD actual lr: {optimizer_sgd.param_groups[0]['lr']}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#function-reference",
    "href": "learning_rate_mapping.html#function-reference",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.3 Function Reference",
    "text": "16.3 Function Reference\n\n16.3.1 map_lr(lr_unified, optimizer_name, use_default_scale=True)\nMaps a unified learning rate to an optimizer-specific learning rate.\nParameters:\n\nlr_unified (float): Unified learning rate multiplier. A value of 1.0 corresponds to the optimizer’s default learning rate. Typical range: [0.001, 100.0].\noptimizer_name (str): Name of the PyTorch optimizer. Must be one of: “Adadelta”, “Adagrad”, “Adam”, “AdamW”, “SparseAdam”, “Adamax”, “ASGD”, “LBFGS”, “NAdam”, “RAdam”, “RMSprop”, “Rprop”, “SGD”.\nuse_default_scale (bool, optional): Whether to scale by the optimizer’s default learning rate. If True (default), lr_unified is multiplied by the default lr. If False, returns lr_unified directly.\n\nReturns:\n\nfloat: The optimizer-specific learning rate.\n\nRaises:\n\nValueError: If optimizer_name is not supported.\nValueError: If lr_unified is not positive.\n\nExample:\nfrom spotoptim.utils.mapping import map_lr\n\n# Get default learning rates (unified lr = 1.0)\nlr = map_lr(1.0, \"Adam\")      # 0.001\nlr = map_lr(1.0, \"SGD\")       # 0.01\nlr = map_lr(1.0, \"RMSprop\")   # 0.01\n\n# Scale learning rates\nlr = map_lr(0.5, \"Adam\")      # 0.0005\nlr = map_lr(2.0, \"SGD\")       # 0.02\n\n# Without default scaling\nlr = map_lr(0.01, \"Adam\", use_default_scale=False)  # 0.01 (direct)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#supported-optimizers",
    "href": "learning_rate_mapping.html#supported-optimizers",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.4 Supported Optimizers",
    "text": "16.4 Supported Optimizers\nAll major PyTorch optimizers are supported with their default learning rates:\n\n\n\nOptimizer\nDefault LR\nTypical Range\nNotes\n\n\n\n\nAdam\n0.001\n0.0001-0.01\nMost popular, good default\n\n\nAdamW\n0.001\n0.0001-0.01\nAdam with weight decay\n\n\nAdamax\n0.002\n0.0001-0.01\nAdam variant with infinity norm\n\n\nNAdam\n0.002\n0.0001-0.01\nAdam with Nesterov momentum\n\n\nRAdam\n0.001\n0.0001-0.01\nRectified Adam\n\n\nSparseAdam\n0.001\n0.0001-0.01\nFor sparse gradients\n\n\nSGD\n0.01\n0.001-0.1\nClassic, needs momentum\n\n\nRMSprop\n0.01\n0.001-0.1\nGood for RNNs\n\n\nAdagrad\n0.01\n0.001-0.1\nAdaptive learning rate\n\n\nAdadelta\n1.0\n0.1-10.0\nExtension of Adagrad\n\n\nASGD\n0.01\n0.001-0.1\nAveraged SGD\n\n\nLBFGS\n1.0\n0.1-10.0\nSecond-order optimizer\n\n\nRprop\n0.01\n0.001-0.1\nResilient backpropagation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#use-cases",
    "href": "learning_rate_mapping.html#use-cases",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.5 Use Cases",
    "text": "16.5 Use Cases\n\n16.5.1 Comparing Different Optimizers\nimport torch\nimport torch.nn as nn\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Load data\ntrain_loader, test_loader, _ = get_diabetes_dataloaders(batch_size=32, random_state=42)\n\n# Test different optimizers with unified learning rate\nunified_lr = 1.0\noptimizers_to_test = [\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"]\nresults = {}\n\nfor opt_name in optimizers_to_test:\n    # Reset for fair comparison\n    torch.manual_seed(42)\n    model = LinearRegressor(input_dim=10, output_dim=1, l1=32, \n                           num_hidden_layers=2, lr=unified_lr)\n    \n    # Create optimizer with mapped learning rate\n    if opt_name == \"SGD\":\n        optimizer = model.get_optimizer(opt_name, momentum=0.9)\n    else:\n        optimizer = model.get_optimizer(opt_name)\n    \n    criterion = nn.MSELoss()\n    \n    # Train\n    model.train()\n    for epoch in range(50):\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            loss.backward()\n            optimizer.step()\n    \n    # Evaluate\n    model.eval()\n    test_loss = 0.0\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            predictions = model(batch_X)\n            test_loss += criterion(predictions, batch_y).item()\n    \n    avg_test_loss = test_loss / len(test_loader)\n    results[opt_name] = avg_test_loss\n    \n    print(f\"{opt_name:10s}: Test MSE = {avg_test_loss:.4f} \"\n          f\"(actual lr = {optimizer.param_groups[0]['lr']:.6f})\")\n\n# Find best optimizer\nbest_opt = min(results, key=results.get)\nprint(f\"\\nBest optimizer: {best_opt} with MSE = {results[best_opt]:.4f}\")\n\n\n16.5.2 Hyperparameter Optimization with SpotOptim\nfrom spotoptim import SpotOptim\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\nimport torch.nn as nn\nimport torch\nimport numpy as np\n\ndef train_and_evaluate(X):\n    \"\"\"Objective function for hyperparameter optimization.\"\"\"\n    results = []\n    \n    # Load data once\n    train_loader, test_loader, _ = get_diabetes_dataloaders(\n        batch_size=32, random_state=42\n    )\n    \n    for params in X:\n        # Extract hyperparameters\n        lr_unified = 10 ** params[0]  # Log scale\n        optimizer_name = params[1]     # Factor variable\n        l1 = int(params[2])           # Integer\n        num_layers = int(params[3])   # Integer\n        \n        # Create model with unified learning rate\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=num_layers,\n            lr=lr_unified  # Automatically mapped per optimizer\n        )\n        \n        # Get optimizer (lr already mapped internally)\n        if optimizer_name == \"SGD\":\n            optimizer = model.get_optimizer(optimizer_name, momentum=0.9)\n        else:\n            optimizer = model.get_optimizer(optimizer_name)\n        \n        criterion = nn.MSELoss()\n        \n        # Train\n        model.train()\n        for epoch in range(30):\n            for batch_X, batch_y in train_loader:\n                optimizer.zero_grad()\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results.append(avg_test_loss)\n    \n    return np.array(results)\n\n# Optimize learning rate, optimizer choice, and architecture\noptimizer = SpotOptim(\n    fun=train_and_evaluate,\n    bounds=[\n        (-4, 0),                           # log10(lr_unified): [0.0001, 1.0]\n        (\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"),  # Optimizer choice\n        (16, 128),                         # Layer size\n        (1, 3)                             # Number of hidden layers\n    ],\n    var_type=[\"num\", \"factor\", \"int\", \"int\"],\n    max_iter=30,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Display results\nprint(\"\\nOptimization Results:\")\nprint(f\"Best unified lr: {10**result.x[0]:.6f}\")\nprint(f\"Best optimizer: {result.x[1]}\")\nprint(f\"Best layer size: {int(result.x[2])}\")\nprint(f\"Best num layers: {int(result.x[3])}\")\nprint(f\"Best test MSE: {result.fun:.4f}\")\n\n# Show actual learning rate used\nfrom spotoptim.utils.mapping import map_lr\nactual_lr = map_lr(10**result.x[0], result.x[1])\nprint(f\"Actual {result.x[1]} learning rate: {actual_lr:.6f}\")\n\n\n16.5.3 Log-Scale Hyperparameter Search\nfrom spotoptim.utils.mapping import map_lr\nimport numpy as np\n\n# Common pattern: sample unified lr from log scale\nlog_lr_range = np.linspace(-4, 0, 10)  # [-4, -3.56, ..., 0]\noptimizers = [\"Adam\", \"SGD\", \"RMSprop\"]\n\nprint(\"Log-scale learning rate search:\")\nprint()\nprint(f\"{'log_lr':&lt;10} {'unified_lr':&lt;12} {'Adam':&lt;12} {'SGD':&lt;12} {'RMSprop':&lt;12}\")\nprint(\"-\" * 60)\n\nfor log_lr in log_lr_range:\n    lr_unified = 10 ** log_lr\n    lr_adam = map_lr(lr_unified, \"Adam\")\n    lr_sgd = map_lr(lr_unified, \"SGD\")\n    lr_rmsprop = map_lr(lr_unified, \"RMSprop\")\n    \n    print(f\"{log_lr:&lt;10.2f} {lr_unified:&lt;12.6f} {lr_adam:&lt;12.8f} \"\n          f\"{lr_sgd:&lt;12.8f} {lr_rmsprop:&lt;12.8f}\")\nOutput:\nlog_lr     unified_lr   Adam         SGD          RMSprop     \n------------------------------------------------------------\n-4.00      0.000100     0.00000010   0.00000100   0.00000100  \n-3.56      0.000275     0.00000028   0.00000275   0.00000275  \n-3.11      0.000759     0.00000076   0.00000759   0.00000759  \n-2.67      0.002089     0.00000209   0.00002089   0.00002089  \n-2.22      0.005754     0.00000575   0.00005754   0.00005754  \n-1.78      0.015849     0.00001585   0.00015849   0.00015849  \n-1.33      0.043652     0.00004365   0.00043652   0.00043652  \n-0.89      0.120226     0.00012023   0.00120226   0.00120226  \n-0.44      0.331131     0.00033113   0.00331131   0.00331131  \n0.00       1.000000     0.00100000   0.01000000   0.01000000  \n\n\n16.5.4 Custom Learning Rate Schedules\nimport torch\nimport torch.nn as nn\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.utils.mapping import map_lr\n\n# Create model with unified lr\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\n\n# Get initial optimizer\noptimizer = model.get_optimizer(\"Adam\")\ninitial_lr = optimizer.param_groups[0]['lr']\nprint(f\"Initial learning rate: {initial_lr}\")\n\n# Use PyTorch learning rate scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n\n# Training with scheduler\nfor epoch in range(100):\n    # ... training code ...\n    scheduler.step()\n    \n    if (epoch + 1) % 30 == 0:\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f\"Epoch {epoch+1}: lr = {current_lr:.8f}\")\n\n\n16.5.5 Direct Usage Without LinearRegressor\nimport torch\nimport torch.nn as nn\nfrom spotoptim.utils.mapping import map_lr\n\n# Define your own model\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(10, 32)\n        self.fc2 = nn.Linear(32, 1)\n    \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        return self.fc2(x)\n\nmodel = MyModel()\n\n# Use map_lr to get optimizer-specific learning rate\nunified_lr = 2.0\noptimizer_name = \"Adam\"\n\nactual_lr = map_lr(unified_lr, optimizer_name)\noptimizer = torch.optim.Adam(model.parameters(), lr=actual_lr)\n\nprint(f\"Unified lr: {unified_lr}\")\nprint(f\"Actual {optimizer_name} lr: {actual_lr}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#best-practices",
    "href": "learning_rate_mapping.html#best-practices",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.6 Best Practices",
    "text": "16.6 Best Practices\n\n16.6.1 Choosing Unified Learning Rate\nFor initial experiments:\n\nStart with lr=1.0 (gives defaults for all optimizers)\nTest with lr=0.1, lr=1.0, lr=10.0 to get a sense of scale\n\nFor hyperparameter optimization:\n\nUse log scale: sample from [-4, 0] or [-3, 1]\nConvert with lr_unified = 10 ** log_lr\nThis gives reasonable ranges for all optimizers\n\nFor fine-tuning:\n\nIf training is unstable: try smaller lr (e.g., 0.1 or 0.5)\nIf training is too slow: try larger lr (e.g., 2.0 or 5.0)\nMonitor loss curves to adjust\n\n\n\n16.6.2 Optimizer Selection Guidelines\nAdam family (Adam, AdamW, NAdam, RAdam):\n\n✅ Good default choice for most tasks\n✅ Adaptive learning rates per parameter\n✅ Works well out of the box\nUse lr=1.0 as starting point\n\nSGD:\n\n✅ Good for large datasets\n✅ Often achieves better generalization\n⚠️ Requires momentum (e.g., 0.9)\nUse lr=1.0 with momentum=0.9\n\nRMSprop:\n\n✅ Good for recurrent networks\n✅ Handles non-stationary objectives\nUse lr=1.0 as starting point\n\nOthers (Adadelta, Adagrad, etc.):\n\nSpecialized use cases\nStart with lr=1.0 and adjust\n\n\n\n16.6.3 Common Patterns\n# Pattern 1: Quick optimizer comparison\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\nfor opt in [\"Adam\", \"SGD\", \"RMSprop\"]:\n    optimizer = model.get_optimizer(opt)\n    # ... train and compare ...\n\n# Pattern 2: Hyperparameter optimization\ndef objective(X):\n    lr_unified = 10 ** X[:, 0]  # Log scale\n    optimizer_name = X[:, 1]     # Factor\n    # ... use unified lr ...\n\n# Pattern 3: Override model's lr\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\noptimizer = model.get_optimizer(\"Adam\", lr=2.0)  # Override with 2.0\n\n# Pattern 4: Direct mapping\nfrom spotoptim.utils.mapping import map_lr\nlr_actual = map_lr(unified_lr, optimizer_name)\noptimizer = torch.optim.Adam(params, lr=lr_actual)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#troubleshooting",
    "href": "learning_rate_mapping.html#troubleshooting",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.7 Troubleshooting",
    "text": "16.7 Troubleshooting\n\n16.7.1 Issue: Training is unstable (loss explodes)\nSolution: Learning rate is too high. Try:\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=0.1)  # Reduce from 1.0\n\n\n16.7.2 Issue: Training is too slow (loss decreases very slowly)\nSolution: Learning rate is too low. Try:\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=5.0)  # Increase from 1.0\n\n\n16.7.3 Issue: Different results across optimizer runs\nSolution: Set random seed for reproducibility:\nimport torch\ntorch.manual_seed(42)\n\n\n16.7.4 Issue: Want to use raw learning rate without mapping\nSolution: Use use_default_scale=False:\nfrom spotoptim.utils.mapping import map_lr\nlr = map_lr(0.001, \"Adam\", use_default_scale=False)  # Returns 0.001 directly\n\n\n16.7.5 Issue: Optimizer not supported\nSolution: Check supported optimizers:\nfrom spotoptim.utils.mapping import OPTIMIZER_DEFAULT_LR\nprint(\"Supported optimizers:\", list(OPTIMIZER_DEFAULT_LR.keys()))",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#technical-details",
    "href": "learning_rate_mapping.html#technical-details",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.8 Technical Details",
    "text": "16.8 Technical Details\n\n16.8.1 How It Works\nThe mapping is simple but effective:\nactual_lr = lr_unified * default_lr[optimizer_name]\nFor example:\n\nmap_lr(1.0, \"Adam\") → 1.0 * 0.001 = 0.001\nmap_lr(0.5, \"SGD\") → 0.5 * 0.01 = 0.005\nmap_lr(2.0, \"RMSprop\") → 2.0 * 0.01 = 0.02\n\nThis ensures that the same unified learning rate gives optimizer-specific learning rates in their typical working ranges.\n\n\n16.8.2 Design Rationale\nWhy use defaults as scaling factors?\nPyTorch’s default learning rates are carefully chosen to work well for typical use cases. By using them as scaling factors:\n\nlr=1.0 always gives sensible defaults\nScaling preserves the relative relationships between optimizers\nEach optimizer stays in its optimal range\nEasy to understand and explain\n\nComparison with spotPython’s approach:\nspotPython uses lr = lr_mult * default_lr in optimizer_handler(). Our implementation:\n\n✅ Separates mapping logic (testable, reusable)\n✅ Provides standalone function (map_lr())\n✅ Comprehensive error handling and validation\n✅ Extensive documentation and examples\n✅ Full integration with LinearRegressor\n\n\n\n16.8.3 Default Learning Rates\nAll values verified against PyTorch documentation:\nOPTIMIZER_DEFAULT_LR = {\n    \"Adadelta\": 1.0,\n    \"Adagrad\": 0.01,\n    \"Adam\": 0.001,\n    \"AdamW\": 0.001,\n    \"SparseAdam\": 0.001,\n    \"Adamax\": 0.002,\n    \"ASGD\": 0.01,\n    \"LBFGS\": 1.0,\n    \"NAdam\": 0.002,\n    \"RAdam\": 0.001,\n    \"RMSprop\": 0.01,\n    \"Rprop\": 0.01,\n    \"SGD\": 0.01,\n}",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#examples",
    "href": "learning_rate_mapping.html#examples",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.9 Examples",
    "text": "16.9 Examples\n\n16.9.1 Complete Example: Optimizer Comparison Study\n\"\"\"\nComplete example: Compare optimizers with unified learning rate interface.\n\"\"\"\nimport torch\nimport torch.nn as nn\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.utils.mapping import map_lr\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\ntorch.manual_seed(42)\n\n# Load data\ntrain_loader, test_loader, _ = get_diabetes_dataloaders(\n    batch_size=32, \n    random_state=42\n)\n\n# Test configurations\noptimizers = [\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"]\nunified_lrs = [0.5, 1.0, 2.0]\n\n# Store results\nresults = {}\n\nprint(\"Training models with different optimizers and learning rates...\")\nprint()\n\nfor unified_lr in unified_lrs:\n    results[unified_lr] = {}\n    \n    for opt_name in optimizers:\n        # Reset model for fair comparison\n        torch.manual_seed(42)\n        \n        # Create model with unified lr\n        model = LinearRegressor(\n            input_dim=10, \n            output_dim=1, \n            l1=32, \n            num_hidden_layers=2,\n            lr=unified_lr\n        )\n        \n        # Get optimizer\n        if opt_name == \"SGD\":\n            optimizer = model.get_optimizer(opt_name, momentum=0.9)\n        else:\n            optimizer = model.get_optimizer(opt_name)\n        \n        actual_lr = optimizer.param_groups[0]['lr']\n        criterion = nn.MSELoss()\n        \n        # Track training loss\n        train_losses = []\n        \n        # Train\n        model.train()\n        for epoch in range(50):\n            epoch_loss = 0.0\n            for batch_X, batch_y in train_loader:\n                optimizer.zero_grad()\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                loss.backward()\n                optimizer.step()\n                epoch_loss += loss.item()\n            \n            avg_epoch_loss = epoch_loss / len(train_loader)\n            train_losses.append(avg_epoch_loss)\n        \n        # Evaluate on test set\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results[unified_lr][opt_name] = {\n            'train_losses': train_losses,\n            'test_loss': avg_test_loss,\n            'actual_lr': actual_lr\n        }\n        \n        print(f\"Unified lr={unified_lr:.1f}, {opt_name:10s}: \"\n              f\"actual_lr={actual_lr:.6f}, test_MSE={avg_test_loss:.4f}\")\n\n# Display summary\nprint()\nprint(\"=\" * 70)\nprint(\"Summary: Best configurations\")\nprint(\"=\" * 70)\n\nfor unified_lr in unified_lrs:\n    best_opt = min(results[unified_lr].items(), \n                   key=lambda x: x[1]['test_loss'])\n    opt_name, metrics = best_opt\n    \n    print(f\"Unified lr={unified_lr:.1f}: {opt_name:10s} \"\n          f\"(test MSE={metrics['test_loss']:.4f}, \"\n          f\"actual lr={metrics['actual_lr']:.6f})\")\n\n# Find overall best\nbest_overall = None\nbest_overall_loss = float('inf')\n\nfor unified_lr in unified_lrs:\n    for opt_name, metrics in results[unified_lr].items():\n        if metrics['test_loss'] &lt; best_overall_loss:\n            best_overall_loss = metrics['test_loss']\n            best_overall = (unified_lr, opt_name, metrics['actual_lr'])\n\nprint()\nprint(f\"Overall best: unified_lr={best_overall[0]:.1f}, \"\n      f\"optimizer={best_overall[1]}, \"\n      f\"test_MSE={best_overall_loss:.4f}\")\nprint(f\"Actual learning rate used: {best_overall[2]:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#see-also",
    "href": "learning_rate_mapping.html#see-also",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.10 See Also",
    "text": "16.10 See Also\n\nLinearRegressor Documentation - Neural network class with lr parameter\nDiabetes Dataset Utilities - Data loading for examples\nHyperparameter Optimization - Using map_lr with SpotOptim\nPyTorch Optimizer Documentation - Official PyTorch reference",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#references",
    "href": "learning_rate_mapping.html#references",
    "title": "16  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "16.11 References",
    "text": "16.11 References\n\nKingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv:1412.6980.\nLoshchilov, I., & Hutter, F. (2017). Decoupled weight decay regularization. arXiv:1711.05101.\nPyTorch Team. (2023). PyTorch Optimizer Documentation. https://pytorch.org/docs/stable/optim.html",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html",
    "href": "unified_learning_rate.html",
    "title": "17  Unified Learning Rate Interface",
    "section": "",
    "text": "17.1 Overview\nThis module provides a sophisticated unified learning rate interface for PyTorch optimizers through the map_lr() function and integration with LinearRegressor.\nDifferent PyTorch optimizers operate on vastly different learning rate scales:\nThis makes it difficult to:\nThe map_lr() function solves this by providing a unified learning rate scale where lr=1.0 corresponds to each optimizer’s PyTorch default.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#overview",
    "href": "unified_learning_rate.html#overview",
    "title": "17  Unified Learning Rate Interface",
    "section": "",
    "text": "Adam typically uses lr ~ 0.0001-0.001\nSGD typically uses lr ~ 0.01-0.1\nRMSprop typically uses lr ~ 0.001-0.01\n\n\n\nCompare optimizer performance fairly\nOptimize learning rate as a hyperparameter across different optimizers\nSwitch between optimizers without retuning learning rates",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#key-features",
    "href": "unified_learning_rate.html#key-features",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.2 Key Features",
    "text": "17.2 Key Features\n\n✅ Unified Interface: Single learning rate parameter works across all optimizers\n✅ Fair Comparison: Same unified lr gives optimizer-specific optimal ranges\n✅ Hyperparameter Optimization: Optimize one learning rate for multiple optimizers\n✅ Backward Compatible: Existing code continues to work\n✅ Well-tested: 36 comprehensive tests covering all use cases\n✅ Documented: Extensive docstrings and examples",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#usage",
    "href": "unified_learning_rate.html#usage",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.3 Usage",
    "text": "17.3 Usage\n\n17.3.1 Basic Usage with LinearRegressor\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n# Create model with unified lr=1.0 (gives each optimizer its default)\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\n\n# Adam gets 0.001 (its default)\noptimizer_adam = model.get_optimizer(\"Adam\")\n\n# SGD gets 0.01 (its default)\noptimizer_sgd = model.get_optimizer(\"SGD\")\n\n# RMSprop gets 0.01 (its default)\noptimizer_rmsprop = model.get_optimizer(\"RMSprop\")\n\n\n17.3.2 Using Custom Unified Learning Rate\n# Using lr=0.5 scales all optimizers by 0.5\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=0.5)\n\noptimizer_adam = model.get_optimizer(\"Adam\")     # Gets 0.5 * 0.001 = 0.0005\noptimizer_sgd = model.get_optimizer(\"SGD\")       # Gets 0.5 * 0.01 = 0.005\n\n\n17.3.3 Direct Use of map_lr()\nfrom spotoptim.utils.mapping import map_lr\n\n# Map unified lr to optimizer-specific lr\nlr_adam = map_lr(1.0, \"Adam\")      # Returns 0.001\nlr_sgd = map_lr(1.0, \"SGD\")        # Returns 0.01\nlr_rmsprop = map_lr(1.0, \"RMSprop\")  # Returns 0.01\n\n# Scale by 2x\nlr_adam = map_lr(2.0, \"Adam\")      # Returns 0.002\nlr_sgd = map_lr(2.0, \"SGD\")        # Returns 0.02\n\n\n17.3.4 Hyperparameter Optimization\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef train_model(X):\n    results = []\n    for params in X:\n        lr_unified = 10 ** params[0]  # Log scale: [-4, 0]\n        optimizer_name = params[1]     # Factor: \"Adam\", \"SGD\", \"RMSprop\"\n        \n        # Create model with unified lr - automatically scaled per optimizer\n        model = LinearRegressor(input_dim=10, output_dim=1, lr=lr_unified)\n        optimizer = model.get_optimizer(optimizer_name)\n        \n        # Train and evaluate\n        # ... training code ...\n        results.append(test_loss)\n    return np.array(results)\n\n# Optimize unified lr across different optimizers\noptimizer = SpotOptim(\n    fun=train_model,\n    bounds=[(-4, 0), (\"Adam\", \"SGD\", \"RMSprop\")],\n    var_type=[\"num\", \"factor\"],\n    max_iter=30\n)\nresult = optimizer.optimize()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#supported-optimizers",
    "href": "unified_learning_rate.html#supported-optimizers",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.4 Supported Optimizers",
    "text": "17.4 Supported Optimizers\nAll major PyTorch optimizers are supported with their default learning rates:\n\n\n\nOptimizer\nDefault LR\nTypical Range\n\n\n\n\nAdam\n0.001\n0.0001-0.01\n\n\nAdamW\n0.001\n0.0001-0.01\n\n\nAdamax\n0.002\n0.0001-0.01\n\n\nNAdam\n0.002\n0.0001-0.01\n\n\nRAdam\n0.001\n0.0001-0.01\n\n\nSGD\n0.01\n0.001-0.1\n\n\nRMSprop\n0.01\n0.001-0.1\n\n\nAdagrad\n0.01\n0.001-0.1\n\n\nAdadelta\n1.0\n0.1-10.0\n\n\nASGD\n0.01\n0.001-0.1\n\n\nLBFGS\n1.0\n0.1-10.0\n\n\nRprop\n0.01\n0.001-0.1",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#api-reference",
    "href": "unified_learning_rate.html#api-reference",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.5 API Reference",
    "text": "17.5 API Reference\n\n17.5.1 map_lr(lr_unified, optimizer_name, use_default_scale=True)\nMaps a unified learning rate to an optimizer-specific learning rate.\nParameters:\n\nlr_unified (float): Unified learning rate multiplier. Typical range: [0.001, 100.0]\noptimizer_name (str): Name of the PyTorch optimizer\nuse_default_scale (bool): Whether to scale by optimizer’s default (default: True)\n\nReturns:\n\nfloat: The optimizer-specific learning rate\n\nExample:\nlr = map_lr(1.0, \"Adam\")  # Returns 0.001 (Adam's default)\nlr = map_lr(0.5, \"SGD\")   # Returns 0.005 (0.5 * SGD's default)\n\n\n17.5.2 LinearRegressor(..., lr=1.0)\nParameter:\n\nlr (float): Unified learning rate multiplier. Default: 1.0\n\nNew Behavior in get_optimizer():\n\nIf lr is not specified, uses self.lr\nAutomatically maps unified lr to optimizer-specific lr\nCan override model’s lr by passing lr parameter",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#design-rationale",
    "href": "unified_learning_rate.html#design-rationale",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.6 Design Rationale",
    "text": "17.6 Design Rationale\n\n17.6.1 Why Unified Learning Rates?\nThe approach is based on spotPython’s optimizer_handler() but improved:\n\nSeparation of Concerns: Mapping logic in separate, testable module\nFlexibility: Can be used independently or integrated with models\nTransparency: Clear mapping based on PyTorch defaults\nExtensibility: Easy to add new optimizers\nType Safety: Comprehensive error handling and validation\n\n\n\n17.6.2 Comparison with spotPython\n\n\n\nFeature\nspotPython\nspotoptim\n\n\n\n\nApproach\nlr_mult * default_lr\nmap_lr(lr_unified, optimizer)\n\n\nModule\noptimizer_handler()\nmap_lr() + integration\n\n\nTesting\nMinimal\n36 comprehensive tests\n\n\nDocumentation\nBasic\nExtensive with examples\n\n\nReusability\nCoupled\nStandalone function\n\n\nError Handling\nBasic\nComprehensive validation\n\n\n\n\n\n17.6.3 Log-scale Optimization\nFor hyperparameter optimization, use log-scale for unified lr:\n# Sample from log10 scale [-4, 0]\nlog_lr = -2.5  # Sampled value\nlr_unified = 10 ** log_lr  # 0.00316\n\n# Map to optimizer-specific\nlr_adam = map_lr(lr_unified, \"Adam\")  # 0.00316 * 0.001 = 0.00000316\nlr_sgd = map_lr(lr_unified, \"SGD\")    # 0.00316 * 0.01 = 0.0000316\nThis gives a reasonable search range across all optimizers.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#examples",
    "href": "unified_learning_rate.html#examples",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.7 Examples",
    "text": "17.7 Examples\nSee examples/unified_learning_rate_demo.py for comprehensive examples including: 1. Basic unified interface usage 2. Custom unified learning rates 3. Training with different optimizers 4. Direct use of map_lr() 5. Log-scale hyperparameter optimization 6. Complete hyperparameter optimization scenario",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#references",
    "href": "unified_learning_rate.html#references",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.8 References",
    "text": "17.8 References\n\nPyTorch Optimizer Documentation\nspotPython’s optimizer_handler() function (inspiration)\nHyperparameter Optimization Best Practices",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#contributing",
    "href": "unified_learning_rate.html#contributing",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.9 Contributing",
    "text": "17.9 Contributing\nWhen adding new optimizers:\n\nAdd default lr to OPTIMIZER_DEFAULT_LR dict in mapping.py\nVerify the default against PyTorch documentation\nAdd tests in test_mapping.py\nUpdate this README",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#license",
    "href": "unified_learning_rate.html#license",
    "title": "17  Unified Learning Rate Interface",
    "section": "17.10 License",
    "text": "17.10 License\nSame as spotoptim package (see main LICENSE file).",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Unified Learning Rate Interface</span>"
    ]
  },
  {
    "objectID": "multiobjective.html",
    "href": "multiobjective.html",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "",
    "text": "18.1 Overview\nSpotOptim supports multi-objective optimization functions with automatic detection and flexible scalarization strategies. This implementation follows the same approach as the Spot class from spotPython.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#what-was-implemented",
    "href": "multiobjective.html#what-was-implemented",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.2 What Was Implemented",
    "text": "18.2 What Was Implemented\n\n18.2.1 1. Core Functionality\nParameter:\n\nfun_mo2so (callable, optional): Function to convert multi-objective values to single-objective\n\nTakes array of shape (n_samples, n_objectives)\nReturns array of shape (n_samples,)\nIf None, uses first objective (default behavior)\n\n\nAttribute:\n\ny_mo (ndarray or None): Stores all multi-objective function values\n\nShape: (n_samples, n_objectives) for multi-objective problems\nNone for single-objective problems\n\n\nMethods:\n\n_get_shape(y): Get shape of objective function output\n_store_mo(y_mo): Store multi-objective values with automatic appending\n_mo2so(y_mo): Convert multi-objective to single-objective values\n\nThe method _evaluate_function(X) automatically detects multi-objective functions. It calls _mo2so() to convert multi-objective to single-objective. It also stores the original multi-objective values in y_mo. And it returns single-objective values for optimization.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#usage-examples",
    "href": "multiobjective.html#usage-examples",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.3 Usage Examples",
    "text": "18.3 Usage Examples\n\n18.3.1 Example 1: Default Behavior (Use First Objective)\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef bi_objective(X):\n    \"\"\"Two conflicting objectives.\"\"\"\n    obj1 = np.sum(X**2, axis=1)          # Minimize at origin\n    obj2 = np.sum((X - 2)**2, axis=1)    # Minimize at (2, 2)\n    return np.column_stack([obj1, obj2])\n\noptimizer = SpotOptim(\n    fun=bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\nprint(f\"Best x: {result.x}\")                    # Near [0, 0]\nprint(f\"Best f(x): {result.fun}\")               # Minimizes obj1\nprint(f\"MO values stored: {optimizer.y_mo.shape}\")  # (30, 2)\n\n\n18.3.2 Example 2: Weighted Sum Scalarization\ndef weighted_sum(y_mo):\n    \"\"\"Equal weighting of objectives.\"\"\"\n    return 0.5 * y_mo[:, 0] + 0.5 * y_mo[:, 1]\n\noptimizer = SpotOptim(\n    fun=bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    fun_mo2so=weighted_sum,  # Custom conversion\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"Compromise solution: {result.x}\")  # Near [1, 1]\n\n\n18.3.3 Example 3: Min-Max Scalarization\ndef min_max(y_mo):\n    \"\"\"Minimize the maximum objective.\"\"\"\n    return np.max(y_mo, axis=1)\n\noptimizer = SpotOptim(\n    fun=bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    fun_mo2so=min_max,\n    seed=42\n)\n\nresult = optimizer.optimize()\n# Finds solution with balanced objective values\n\n\n18.3.4 Example 4: Three or More Objectives\ndef three_objectives(X):\n    \"\"\"Three different norms.\"\"\"\n    obj1 = np.sum(X**2, axis=1)           # L2 norm\n    obj2 = np.sum(np.abs(X), axis=1)      # L1 norm\n    obj3 = np.max(np.abs(X), axis=1)      # L-infinity norm\n    return np.column_stack([obj1, obj2, obj3])\n\ndef custom_scalarization(y_mo):\n    \"\"\"Weighted combination.\"\"\"\n    return 0.4 * y_mo[:, 0] + 0.3 * y_mo[:, 1] + 0.3 * y_mo[:, 2]\n\noptimizer = SpotOptim(\n    fun=three_objectives,\n    bounds=[(-5, 5), (-5, 5), (-5, 5)],\n    max_iter=35,\n    n_initial=20,\n    fun_mo2so=custom_scalarization,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n\n18.3.5 Example 5: With Noise Handling\ndef noisy_bi_objective(X):\n    \"\"\"Noisy multi-objective function.\"\"\"\n    noise1 = np.random.normal(0, 0.05, X.shape[0])\n    noise2 = np.random.normal(0, 0.05, X.shape[0])\n    \n    obj1 = np.sum(X**2, axis=1) + noise1\n    obj2 = np.sum((X - 1)**2, axis=1) + noise2\n    return np.column_stack([obj1, obj2])\n\noptimizer = SpotOptim(\n    fun=noisy_bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=40,\n    n_initial=20,\n    repeats_initial=3,      # Handle noise\n    repeats_surrogate=2,\n    seed=42\n)\n\nresult = optimizer.optimize()\n# Works seamlessly with noise handling",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#common-scalarization-strategies",
    "href": "multiobjective.html#common-scalarization-strategies",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.4 Common Scalarization Strategies",
    "text": "18.4 Common Scalarization Strategies\n\n18.4.1 1. Weighted Sum\ndef weighted_sum(y_mo, weights=[0.5, 0.5]):\n    return sum(w * y_mo[:, i] for i, w in enumerate(weights))\nUse when: Objectives have similar scales and you want linear trade-offs\n\n\n18.4.2 2. Weighted Sum with Normalization\ndef normalized_weighted_sum(y_mo, weights=[0.5, 0.5]):\n    # Normalize each objective to [0, 1]\n    y_norm = (y_mo - y_mo.min(axis=0)) / (y_mo.max(axis=0) - y_mo.min(axis=0) + 1e-10)\n    return sum(w * y_norm[:, i] for i, w in enumerate(weights))\nUse when: Objectives have very different scales\n\n\n18.4.3 3. Min-Max (Chebyshev)\ndef min_max(y_mo):\n    return np.max(y_mo, axis=1)\nUse when: You want balanced performance across all objectives\n\n\n18.4.4 4. Target Achievement\ndef target_achievement(y_mo, targets=[0.0, 0.0]):\n    # Minimize deviation from targets\n    return np.sum((y_mo - targets)**2, axis=1)\nUse when: You have specific target values for each objective\n\n\n18.4.5 5. Product\ndef product(y_mo):\n    return np.prod(y_mo + 1e-10, axis=1)  # Add small value to avoid zero\nUse when: All objectives should be minimized together",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#integration-with-other-features",
    "href": "multiobjective.html#integration-with-other-features",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.5 Integration with Other Features",
    "text": "18.5 Integration with Other Features\nMulti-objective support works seamlessly with:\n✅ Noise Handling - Use repeats_initial and repeats_surrogate\n✅ OCBA - Use ocba_delta for intelligent re-evaluation\n✅ TensorBoard Logging - Logs converted single-objective values\n✅ Dimension Reduction - Fixed dimensions work normally\n✅ Custom Variable Names - var_name parameter supported",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#implementation-details",
    "href": "multiobjective.html#implementation-details",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.6 Implementation Details",
    "text": "18.6 Implementation Details\n\n18.6.1 Automatic Detection\nSpotOptim automatically detects multi-objective functions:\n\nIf function returns 2D array (n_samples, n_objectives), it’s multi-objective\nIf function returns 1D array (n_samples,), it’s single-objective\n\n\n\n18.6.2 Data Flow\nUser Function → y_mo (raw) → _mo2so() → y_ (single-objective)\n                    ↓\n               y_mo (stored)\n\nFunction returns multi-objective values\n_store_mo() saves them in y_mo attribute\n_mo2so() converts to single-objective using fun_mo2so or default\nSurrogate model optimizes the single-objective values\nAll original multi-objective values remain accessible in y_mo\n\n\n\n18.6.3 Backward Compatibility\n✅ Fully backward compatible:\n\nSingle-objective functions work unchanged\nfun_mo2so defaults to None\ny_mo is None for single-objective problems\nNo breaking changes to existing code",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#limitations-and-notes",
    "href": "multiobjective.html#limitations-and-notes",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.7 Limitations and Notes",
    "text": "18.7 Limitations and Notes\n\n18.7.1 What This Is\n\n✅ Scalarization approach to multi-objective optimization\n✅ Single solution found per optimization run\n✅ Different scalarizations → different Pareto solutions\n✅ Suitable for preference-based multi-objective optimization\n\n\n\n18.7.2 What This Is Not\n\n❌ Not a true multi-objective optimizer (doesn’t find Pareto front)\n❌ Doesn’t generate multiple solutions in one run\n❌ Not suitable for discovering entire Pareto front\n\n\n\n18.7.3 For True Multi-Objective Optimization\nFor finding the complete Pareto front, consider specialized tools:\n\npymoo: Comprehensive multi-objective optimization framework\nplatypus: Multi-objective optimization library\nNSGA-II, MOEA/D: Dedicated multi-objective algorithms",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#demo-script",
    "href": "multiobjective.html#demo-script",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.8 Demo Script",
    "text": "18.8 Demo Script\nRun the comprehensive demo (the demos files are located in the examples folder):\npython demo_multiobjective.py\nThis demonstrates:\n\nDefault behavior (first objective)\nWeighted sum scalarization\nMin-max scalarization\nNoisy multi-objective optimization\nThree-objective optimization",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#summary",
    "href": "multiobjective.html#summary",
    "title": "18  Multi-Objective Optimization Support in SpotOptim",
    "section": "18.9 Summary",
    "text": "18.9 Summary\nSpotOptim provides flexible multi-objective optimization support through:\n\nAutomatic detection of multi-objective functions\nCustomizable scalarization strategies via fun_mo2so\nComplete storage of multi-objective values in y_mo\nFull integration with existing features (noise, OCBA, TensorBoard, etc.)\n100% backward compatible with existing code\n\nThis implementation mirrors the approach used in spotPython’s Spot class, providing consistency across the ecosystem.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html",
    "href": "plot_surrogate.html",
    "title": "19  Surrogate Model Visualization",
    "section": "",
    "text": "19.1 Overview\nThis document describes the plot_surrogate() method added to the SpotOptim class, which provides visualization capabilities similar to the plotkd() function in the spotpython package.\nThe plot_surrogate() method creates a comprehensive 4-panel visualization of the fitted surrogate model, showing both predictions and uncertainty estimates across two selected dimensions.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#features",
    "href": "plot_surrogate.html#features",
    "title": "19  Surrogate Model Visualization",
    "section": "19.2 Features",
    "text": "19.2 Features\n\n3D Surface Plots: Visualize the surrogate’s predictions and uncertainty as 3D surfaces\nContour Plots: View 2D contours with overlaid evaluation points\nMulti-dimensional Support: Visualize any two dimensions of higher-dimensional problems\nCustomizable Appearance: Control colors, resolution, transparency, and more",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#usage",
    "href": "plot_surrogate.html#usage",
    "title": "19  Surrogate Model Visualization",
    "section": "19.3 Usage",
    "text": "19.3 Usage\n\n19.3.1 Basic Usage\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Define objective function\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\n# Run optimization\noptimizer = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)], max_iter=20)\nresult = optimizer.optimize()\n\n# Visualize the surrogate model\noptimizer.plot_surrogate(i=0, j=1, show=True)\n\n\n19.3.2 With Custom Parameters\noptimizer.plot_surrogate(\n    i=0,                          # First dimension to plot\n    j=1,                          # Second dimension to plot\n    var_name=['x1', 'x2'],        # Variable names for axes\n    add_points=True,              # Show evaluated points\n    cmap='viridis',               # Colormap\n    alpha=0.7,                    # Surface transparency\n    num=100,                      # Grid resolution\n    contour_levels=25,            # Number of contour levels\n    grid_visible=True,            # Show grid on contours\n    figsize=(12, 10),             # Figure size\n    show=True                     # Display immediately\n)\n\n\n19.3.3 Higher-Dimensional Problems\nFor problems with more than 2 dimensions, plot_surrogate() creates a 2D slice by fixing all other dimensions at their mean values:\n# 4D optimization problem\ndef sphere_4d(X):\n    return np.sum(X**2, axis=1)\n\nbounds = [(-3, 3)] * 4\noptimizer = SpotOptim(fun=sphere_4d, bounds=bounds, max_iter=20)\nresult = optimizer.optimize()\n\n# Visualize dimensions 0 and 2 (dimensions 1 and 3 fixed at mean)\noptimizer.plot_surrogate(\n    i=0, j=2,\n    var_name=['x0', 'x1', 'x2', 'x3']\n)\n\n# Visualize different dimension pair\noptimizer.plot_surrogate(i=1, j=3, var_name=['x0', 'x1', 'x2', 'x3'])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#plot-interpretation",
    "href": "plot_surrogate.html#plot-interpretation",
    "title": "19  Surrogate Model Visualization",
    "section": "19.4 Plot Interpretation",
    "text": "19.4 Plot Interpretation\nThe visualization consists of 4 panels:\n\n19.4.1 Top Left: Prediction Surface\n\nShows the surrogate model’s predicted function values as a 3D surface\nHelps understand the model’s belief about the objective function landscape\nLower values (blue in default colormap) indicate predicted minima\n\n\n\n19.4.2 Top Right: Prediction Uncertainty Surface\n\nShows the standard deviation of predictions as a 3D surface\nIndicates where the model is uncertain and might benefit from more samples\nLower values (blue) indicate high confidence, higher values (red) indicate uncertainty\n\n\n\n19.4.3 Bottom Left: Prediction Contour with Points\n\n2D contour plot of predictions\nRed dots show the actual points evaluated during optimization\nUseful for understanding the exploration-exploitation trade-off\n\n\n\n19.4.4 Bottom Right: Uncertainty Contour with Points\n\n2D contour plot of prediction uncertainty\nShows how uncertainty decreases around evaluated points\nHelps identify unexplored regions",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#parameters",
    "href": "plot_surrogate.html#parameters",
    "title": "19  Surrogate Model Visualization",
    "section": "19.5 Parameters",
    "text": "19.5 Parameters\n\n19.5.1 Dimension Selection\n\ni (int, default=0): Index of first dimension to plot\nj (int, default=1): Index of second dimension to plot\n\n\n\n19.5.2 Appearance\n\nvar_name (list of str, optional): Names for each dimension\ncmap (str, default=‘jet’): Matplotlib colormap name\nalpha (float, default=0.8): Surface transparency (0=transparent, 1=opaque)\nfigsize (tuple, default=(12, 10)): Figure size in inches (width, height)\n\n\n\n19.5.3 Grid and Resolution\n\nnum (int, default=100): Number of grid points per dimension\ncontour_levels (int, default=30): Number of contour levels\ngrid_visible (bool, default=True): Show grid lines on contour plots\n\n\n\n19.5.4 Color Scaling\n\nvmin (float, optional): Minimum value for color scale\nvmax (float, optional): Maximum value for color scale\n\n\n\n19.5.5 Display\n\nshow (bool, default=True): Display plot immediately\nadd_points (bool, default=True): Overlay evaluated points on contours",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#examples",
    "href": "plot_surrogate.html#examples",
    "title": "19  Surrogate Model Visualization",
    "section": "19.6 Examples",
    "text": "19.6 Examples\n\n19.6.1 Example 1: 2D Rosenbrock Function\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    X = np.atleast_2d(X)\n    x, y = X[:, 0], X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=30,\n    seed=42\n)\nresult = optimizer.optimize()\n\n# Visualize with custom colormap\noptimizer.plot_surrogate(\n    var_name=['x', 'y'],\n    cmap='coolwarm',\n    add_points=True\n)\n\n\n19.6.2 Example 2: Using Kriging Surrogate\nfrom spotoptim import SpotOptim, Kriging\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=Kriging(seed=42),  # Use Kriging instead of GP\n    max_iter=20\n)\nresult = optimizer.optimize()\n\n# The plotting works the same with any surrogate\noptimizer.plot_surrogate(var_name=['x1', 'x2'])\n\n\n19.6.3 Example 3: Comparing Different Dimension Pairs\n# 3D problem - visualize all dimension pairs\ndef sphere_3d(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere_3d,\n    bounds=[(-5, 5)] * 3,\n    max_iter=25\n)\nresult = optimizer.optimize()\n\n# Dimensions 0 vs 1\noptimizer.plot_surrogate(i=0, j=1, var_name=['x0', 'x1', 'x2'])\n\n# Dimensions 0 vs 2\noptimizer.plot_surrogate(i=0, j=2, var_name=['x0', 'x1', 'x2'])\n\n# Dimensions 1 vs 2\noptimizer.plot_surrogate(i=1, j=2, var_name=['x0', 'x1', 'x2'])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#tips-and-best-practices",
    "href": "plot_surrogate.html#tips-and-best-practices",
    "title": "19  Surrogate Model Visualization",
    "section": "19.7 Tips and Best Practices",
    "text": "19.7 Tips and Best Practices\n\nRun Optimization First: Always call optimize() before plot_surrogate()\nChoose Dimensions Wisely: For high-dimensional problems, plot dimensions that you suspect are most important or interactive\nAdjust Resolution: Use lower num values (e.g., 50) for faster plotting, higher values (e.g., 200) for smoother surfaces\nColor Scales: Set vmin and vmax explicitly when comparing multiple plots to ensure consistent color scales\nUncertainty Analysis: High uncertainty areas (bright colors in uncertainty plots) are good candidates for additional sampling\nExploration vs Exploitation: Red dots clustered in low-prediction areas show exploitation; spread-out dots show exploration",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#comparison-with-spotpythons-plotkd",
    "href": "plot_surrogate.html#comparison-with-spotpythons-plotkd",
    "title": "19  Surrogate Model Visualization",
    "section": "19.8 Comparison with spotpython’s plotkd()",
    "text": "19.8 Comparison with spotpython’s plotkd()\nThe plot_surrogate() method is inspired by spotpython’s plotkd() function but adapted for SpotOptim’s simplified interface:\n\n19.8.1 Similarities\n\nSame 4-panel layout (2 surfaces + 2 contours)\nVisualizes predictions and uncertainty\nSupports dimension selection and customization\n\n\n\n19.8.2 Differences\n\nIntegration: Method of SpotOptim class (no separate function needed)\nSimpler: Fewer parameters, more sensible defaults\nAutomatic: Uses optimizer’s bounds and data automatically\nType Handling: Automatically applies variable type constraints (int/float/factor)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#error-handling",
    "href": "plot_surrogate.html#error-handling",
    "title": "19  Surrogate Model Visualization",
    "section": "19.9 Error Handling",
    "text": "19.9 Error Handling\nThe method validates inputs and provides clear error messages:\n# Before optimization runs\noptimizer.plot_surrogate()  # ValueError: No optimization data available\n\n# Invalid dimension indices\noptimizer.plot_surrogate(i=5, j=1)  # ValueError: i must be less than n_dim\n\n# Same dimension twice\noptimizer.plot_surrogate(i=0, j=0)  # ValueError: i and j must be different",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#see-also",
    "href": "plot_surrogate.html#see-also",
    "title": "19  Surrogate Model Visualization",
    "section": "19.10 See Also",
    "text": "19.10 See Also\n\nnotebooks/demos.ipynb: Example 4 demonstrates plot_surrogate()\nexamples/plot_surrogate_demo.py: Standalone example script\ntests/test_plot_surrogate.py: Comprehensive test suite",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "point_selection.html",
    "href": "point_selection.html",
    "title": "20  Point Selection Implementation",
    "section": "",
    "text": "20.1 Overview\nThis feature automatically selects a subset of evaluated points for surrogate model training when the total number of points exceeds a specified threshold.\nIt is implemented as a point selection mechanism for SpotOptim that mirrors the functionality in spotpython’s Spot class.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "point_selection.html#implementation-details",
    "href": "point_selection.html#implementation-details",
    "title": "20  Point Selection Implementation",
    "section": "20.2 Implementation Details",
    "text": "20.2 Implementation Details\n\n20.2.1 Parameters\nAdded to SpotOptim.__init__:\n\nmax_surrogate_points (int, optional): Maximum number of points to use for surrogate fitting\nselection_method (str, default=‘distant’): Method for selecting points (‘distant’ or ‘best’)\n\n\n\n20.2.2 Methods\n\n_select_distant_points(X, y, k)\n\nUses K-means clustering to find k clusters\nSelects the point closest to each cluster center\nEnsures space-filling properties for surrogate training\nMimics spotpython.utils.aggregate.select_distant_points\n\n_select_best_cluster(X, y, k)\n\nUses K-means clustering to find k clusters\nComputes mean objective value for each cluster\nSelects all points from the cluster with the best (lowest) mean value\nMimics spotpython.utils.aggregate.select_best_cluster\n\n_selection_dispatcher(X, y)\n\nDispatcher method that routes to the appropriate selection function\nReturns all points if max_surrogate_points is None\nMimics spotpython.spot.spot.Spot.selection_dispatcher\n\n\nThe method _fit_surrogate(X, y) checks if X.shape[0] &gt; self.max_surrogate_points. If true, it calls _selection_dispatcher to get a subset. Then, it fits the surrogate only on the selected points. This implementation matches the logic in spotpython.spot.spot.Spot.fit_surrogate",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "point_selection.html#key-differences-from-spotpython",
    "href": "point_selection.html#key-differences-from-spotpython",
    "title": "20  Point Selection Implementation",
    "section": "20.3 Key Differences from spotpython",
    "text": "20.3 Key Differences from spotpython\nWhile the implementation follows spotpython’s design, there is a difference: spotoptim uses a simplified clustering, it uses sklearn’s KMeans directly instead of a custom implementation.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "point_selection.html#example-usage",
    "href": "point_selection.html#example-usage",
    "title": "20  Point Selection Implementation",
    "section": "20.4 Example Usage",
    "text": "20.4 Example Usage\nfrom spotoptim import SpotOptim\n\n# Without point selection (default behavior)\noptimizer1 = SpotOptim(\n    fun=expensive_function,\n    bounds=bounds,\n    max_iter=100,\n    n_initial=20\n)\n\n# With point selection using distant method\noptimizer2 = SpotOptim(\n    fun=expensive_function,\n    bounds=bounds,\n    max_iter=100,\n    n_initial=20,\n    max_surrogate_points=50,\n    selection_method='distant'\n)\n\n# With point selection using best cluster method\noptimizer3 = SpotOptim(\n    fun=expensive_function,\n    bounds=bounds,\n    max_iter=100,\n    n_initial=20,\n    max_surrogate_points=50,\n    selection_method='best'\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "point_selection.html#benefits",
    "href": "point_selection.html#benefits",
    "title": "20  Point Selection Implementation",
    "section": "20.5 Benefits",
    "text": "20.5 Benefits\n\nScalability: Enables efficient optimization with many function evaluations\nComputational efficiency: Reduces surrogate training time for large datasets\nMaintained accuracy: Careful point selection preserves model quality\nFlexibility: Two selection methods for different optimization scenarios",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "point_selection.html#comparison-with-spotpython",
    "href": "point_selection.html#comparison-with-spotpython",
    "title": "20  Point Selection Implementation",
    "section": "20.6 Comparison with spotpython",
    "text": "20.6 Comparison with spotpython\n\n\n\nFeature\nspotpython\nSpotOptim\n\n\n\n\nPoint selection via clustering\n✓\n✓\n\n\n‘distant’ method\n✓\n✓\n\n\n‘best’ method\n✓\n✓\n\n\nSelection dispatcher\n✓\n✓\n\n\nNyström approximation\n✓\n✗\n\n\nModular design\n✓ (utils.aggregate)\n✓ (class methods)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "point_selection.html#references",
    "href": "point_selection.html#references",
    "title": "20  Point Selection Implementation",
    "section": "20.7 References",
    "text": "20.7 References\n\nspotpython implementation: src/spotpython/spot/spot.py lines 1646-1778\nspotpython utilities: src/spotpython/utils/aggregate.py lines 262-336",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Point Selection Implementation</span>"
    ]
  },
  {
    "objectID": "save_load.html",
    "href": "save_load.html",
    "title": "21  Save and Load in SpotOptim",
    "section": "",
    "text": "21.1 Key Concepts\nSpotOptim provides comprehensive save and load functionality for serializing optimization configurations and results. This enables distributed workflows where experiments are defined locally, executed remotely, and analyzed back on the local machine.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#key-concepts",
    "href": "save_load.html#key-concepts",
    "title": "21  Save and Load in SpotOptim",
    "section": "",
    "text": "21.1.1 Experiments vs Results\nSpotOptim distinguishes between two types of saved data:\n\nExperiment (*_exp.pkl): Configuration only, excluding the objective function and results. Used to transfer optimization setup to remote machines.\nResult (*_res.pkl): Complete optimization state including configuration, all evaluations, and results. Used to save and analyze completed optimizations.\n\n\n\n21.1.2 What Gets Saved\n\n\n\nComponent\nExperiment\nResult\n\n\n\n\nConfiguration (bounds, parameters)\n✓\n✓\n\n\nObjective function\n✗\n✗\n\n\nEvaluations (X, y)\n✗\n✓\n\n\nBest solution\n✗\n✓\n\n\nSurrogate model\nExcluded*\n✓\n\n\nTensorBoard writer\n✗\n✗\n\n\n\n*Surrogate model is excluded from experiments and automatically recreated when loaded.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#quick-start",
    "href": "save_load.html#quick-start",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.2 Quick Start",
    "text": "21.2 Quick Start\n\n21.2.1 Basic Save and Load\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    \"\"\"Simple sphere function\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create and configure optimizer\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    seed=42\n)\n\n# Run optimization\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\n\n# Save complete results\noptimizer.save_result(prefix=\"sphere_opt\")\n# Creates: sphere_opt_res.pkl\n\n# Later: load and analyze results\nloaded_opt = SpotOptim.load_result(\"sphere_opt_res.pkl\")\nprint(f\"Loaded best value: {loaded_opt.best_y_:.6f}\")\nprint(f\"Total evaluations: {loaded_opt.counter}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#distributed-workflow",
    "href": "save_load.html#distributed-workflow",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.3 Distributed Workflow",
    "text": "21.3 Distributed Workflow\nThe save/load functionality enables a powerful workflow for distributed optimization:\n\n21.3.1 Step 1: Define Experiment Locally\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Define configuration locally (no need to run optimization yet)\noptimizer = SpotOptim(\n    bounds=[(-10, 10), (-10, 10), (-10, 10)],\n    max_iter=200,\n    n_initial=30,\n    seed=42,\n    verbose=True\n)\n\n# Save experiment configuration\noptimizer.save_experiment(prefix=\"remote_job_001\")\n# Creates: remote_job_001_exp.pkl\n\nprint(\"Experiment saved. Transfer remote_job_001_exp.pkl to remote machine.\")\n\n\n21.3.2 Step 2: Execute on Remote Machine\nfrom spotoptim import SpotOptim\nimport numpy as np\n\n# Define objective function on remote machine\ndef expensive_function(X):\n    \"\"\"Expensive simulation or computation\"\"\"\n    # Your expensive computation here\n    return np.sum(X**2, axis=1) + 0.1 * np.sum(np.sin(10 * X), axis=1)\n\n# Load experiment configuration\noptimizer = SpotOptim.load_experiment(\"remote_job_001_exp.pkl\")\nprint(\"Experiment loaded successfully\")\n\n# Attach objective function (must be done after loading)\noptimizer.fun = expensive_function\n\n# Run optimization\nresult = optimizer.optimize()\nprint(f\"Optimization complete. Best value: {result.fun:.6f}\")\n\n# Save results\noptimizer.save_result(prefix=\"remote_job_001\")\n# Creates: remote_job_001_res.pkl\n\nprint(\"Results saved. Transfer remote_job_001_res.pkl back to local machine.\")\n\n\n21.3.3 Step 3: Analyze Results Locally\nfrom spotoptim import SpotOptim\nimport matplotlib.pyplot as plt\n\n# Load results from remote execution\noptimizer = SpotOptim.load_result(\"remote_job_001_res.pkl\")\n\n# Access all optimization data\nprint(f\"Best value found: {optimizer.best_y_:.6f}\")\nprint(f\"Best point: {optimizer.best_x_}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Number of iterations: {optimizer.n_iter_}\")\n\n# Analyze convergence\nplt.figure(figsize=(10, 6))\nplt.plot(optimizer.y_, 'o-', alpha=0.6, label='Evaluations')\nplt.plot(range(len(optimizer.y_)), \n         [optimizer.y_[:i+1].min() for i in range(len(optimizer.y_))],\n         'r-', linewidth=2, label='Best so far')\nplt.xlabel('Iteration')\nplt.ylabel('Objective Value')\nplt.title('Optimization Progress')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Access all evaluated points\nprint(f\"\\nAll evaluated points shape: {optimizer.X_.shape}\")\nprint(f\"All objective values shape: {optimizer.y_.shape}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#advanced-usage",
    "href": "save_load.html#advanced-usage",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.4 Advanced Usage",
    "text": "21.4 Advanced Usage\n\n21.4.1 Custom Filenames and Paths\nimport os\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    seed=42\n)\n\n# Save with custom filename\noptimizer.save_experiment(\n    filename=\"custom_name.pkl\",\n    verbosity=1\n)\n\n# Save to specific directory\nos.makedirs(\"experiments/batch_001\", exist_ok=True)\noptimizer.save_experiment(\n    prefix=\"exp_001\",\n    path=\"experiments/batch_001\",\n    verbosity=1\n)\n# Creates: experiments/batch_001/exp_001_exp.pkl\n\n\n21.4.2 Overwrite Protection\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)], max_iter=20)\nresult = optimizer.optimize()\n\n# First save\noptimizer.save_result(prefix=\"my_result\")\n\n# Try to save again - raises FileExistsError by default\ntry:\n    optimizer.save_result(prefix=\"my_result\")\nexcept FileExistsError as e:\n    print(f\"File already exists: {e}\")\n\n# Explicitly allow overwriting\noptimizer.save_result(prefix=\"my_result\", overwrite=True)\nprint(\"File overwritten successfully\")\n\n\n21.4.3 Loading and Continuing Optimization\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Initial optimization\nopt1 = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    seed=42\n)\nresult1 = opt1.optimize()\nopt1.save_result(prefix=\"checkpoint\")\n\nprint(f\"Initial optimization: {result1.nfev} evaluations, best={result1.fun:.6f}\")\n\n# Load and continue\nopt2 = SpotOptim.load_result(\"checkpoint_res.pkl\")\nopt2.fun = objective  # Re-attach function\nopt2.max_iter = 50  # Increase budget\n\n# Continue optimization\nresult2 = opt2.optimize()\nprint(f\"After continuation: {result2.nfev} evaluations, best={result2.fun:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#working-with-noisy-functions",
    "href": "save_load.html#working-with-noisy-functions",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.5 Working with Noisy Functions",
    "text": "21.5 Working with Noisy Functions\nSave and load preserves noise statistics for reproducible analysis:\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_objective(X):\n    \"\"\"Objective with measurement noise\"\"\"\n    true_value = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, X.shape[0])\n    return true_value + noise\n\n# Optimize noisy function with repeated evaluations\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=40,\n    n_initial=15,\n    repeats_initial=3,    # Repeat initial points\n    repeats_surrogate=2,  # Repeat surrogate points\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\n# Save results (includes noise statistics)\noptimizer.save_result(prefix=\"noisy_opt\")\n\n# Load and analyze noise statistics\nloaded_opt = SpotOptim.load_result(\"noisy_opt_res.pkl\")\n\nprint(f\"Noise handling enabled: {loaded_opt.noise}\")\nprint(f\"Best mean value: {loaded_opt.best_y_:.6f}\")\n\nif loaded_opt.mean_y is not None:\n    print(f\"Mean values available: {len(loaded_opt.mean_y)}\")\n    print(f\"Variance values available: {len(loaded_opt.var_y)}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#working-with-different-variable-types",
    "href": "save_load.html#working-with-different-variable-types",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.6 Working with Different Variable Types",
    "text": "21.6 Working with Different Variable Types\nSave and load preserves variable type information:\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef mixed_objective(X):\n    \"\"\"Objective with mixed variable types\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create optimizer with mixed variable types\noptimizer = SpotOptim(\n    fun=mixed_objective,\n    bounds=[(-5, 5), (-5, 5), (-5, 5), (-5, 5)],\n    var_type=[\"num\", \"int\", \"factor\", \"num\"],\n    var_name=[\"continuous\", \"integer\", \"categorical\", \"another_cont\"],\n    max_iter=50,\n    n_initial=20,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Save results\noptimizer.save_result(prefix=\"mixed_vars\")\n\n# Load results\nloaded_opt = SpotOptim.load_result(\"mixed_vars_res.pkl\")\n\nprint(\"Variable types preserved:\")\nprint(f\"  var_type: {loaded_opt.var_type}\")\nprint(f\"  var_name: {loaded_opt.var_name}\")\n\n# Verify integer variables are still integers\nprint(f\"\\nInteger variable (dim 1) values:\")\nprint(loaded_opt.X_[:5, 1])  # Should be integers",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#best-practices",
    "href": "save_load.html#best-practices",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.7 Best Practices",
    "text": "21.7 Best Practices\n\n21.7.1 1. Always Re-attach the Objective Function\nAfter loading an experiment, you must re-attach the objective function:\n# Load experiment\noptimizer = SpotOptim.load_experiment(\"experiment_exp.pkl\")\n\n# REQUIRED: Re-attach function\noptimizer.fun = your_objective_function\n\n# Now you can optimize\nresult = optimizer.optimize()\n\n\n21.7.2 2. Use Meaningful Prefixes\nOrganize your experiments with descriptive prefixes:\n# Good practice: descriptive prefixes\noptimizer.save_experiment(prefix=\"sphere_d10_seed42\")\noptimizer.save_experiment(prefix=\"rosenbrock_n100_lhs\")\noptimizer.save_result(prefix=\"final_run_2024_11_15\")\n\n# Avoid: generic names\noptimizer.save_experiment(prefix=\"exp1\")  # Not descriptive\noptimizer.save_result(prefix=\"result\")     # Hard to track\n\n\n21.7.3 3. Save Experiments Before Remote Execution\n# Define locally\noptimizer = SpotOptim(bounds=bounds, max_iter=500, seed=42)\noptimizer.save_experiment(prefix=\"remote_job\")\n\n# Transfer file to remote machine\n# Execute remotely\n# Transfer results back\n# Analyze locally\n\n\n21.7.4 4. Version Your Experiments\nimport datetime\n\n# Add timestamp to prefix\ntimestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nprefix = f\"experiment_{timestamp}\"\n\noptimizer.save_experiment(prefix=prefix)\n# Creates: experiment_20241115_143022_exp.pkl\n\n\n21.7.5 5. Handle File Paths Robustly\nimport os\n\n# Create directory structure\nexp_dir = \"experiments/batch_001\"\nos.makedirs(exp_dir, exist_ok=True)\n\n# Save with full path\noptimizer.save_experiment(\n    prefix=\"exp_001\",\n    path=exp_dir\n)\n\n# Load with full path\nexp_file = os.path.join(exp_dir, \"exp_001_exp.pkl\")\nloaded_opt = SpotOptim.load_experiment(exp_file)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#complete-example-multi-machine-workflow",
    "href": "save_load.html#complete-example-multi-machine-workflow",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.8 Complete Example: Multi-Machine Workflow",
    "text": "21.8 Complete Example: Multi-Machine Workflow\nHere’s a complete example demonstrating the entire workflow:\n\n21.8.1 Local Machine (Setup)\n# setup_experiment.py\nimport numpy as np\nfrom spotoptim import SpotOptim\nimport os\n\n# Create experiments directory\nos.makedirs(\"experiments\", exist_ok=True)\n\n# Define multiple experiments\nexperiments = [\n    {\"seed\": 42, \"max_iter\": 100, \"prefix\": \"exp_seed42\"},\n    {\"seed\": 123, \"max_iter\": 100, \"prefix\": \"exp_seed123\"},\n    {\"seed\": 999, \"max_iter\": 100, \"prefix\": \"exp_seed999\"},\n]\n\nfor exp_config in experiments:\n    optimizer = SpotOptim(\n        bounds=[(-10, 10), (-10, 10), (-10, 10)],\n        max_iter=exp_config[\"max_iter\"],\n        n_initial=30,\n        seed=exp_config[\"seed\"],\n        verbose=False\n    )\n    \n    optimizer.save_experiment(\n        prefix=exp_config[\"prefix\"],\n        path=\"experiments\"\n    )\n    \n    print(f\"Created: experiments/{exp_config['prefix']}_exp.pkl\")\n\nprint(\"\\nAll experiments created. Transfer 'experiments' folder to remote machine.\")\n\n\n21.8.2 Remote Machine (Execution)\n# run_experiments.py\nimport numpy as np\nfrom spotoptim import SpotOptim\nimport os\nimport glob\n\ndef complex_objective(X):\n    \"\"\"Complex multimodal objective function\"\"\"\n    term1 = np.sum(X**2, axis=1)\n    term2 = 10 * np.sum(np.cos(2 * np.pi * X), axis=1)\n    term3 = 0.1 * np.sum(np.sin(5 * np.pi * X), axis=1)\n    return term1 - term2 + term3\n\n# Find all experiment files\nexp_files = glob.glob(\"experiments/*_exp.pkl\")\nprint(f\"Found {len(exp_files)} experiments to run\")\n\n# Run each experiment\nfor exp_file in exp_files:\n    print(f\"\\nProcessing: {exp_file}\")\n    \n    # Load experiment\n    optimizer = SpotOptim.load_experiment(exp_file)\n    \n    # Attach objective\n    optimizer.fun = complex_objective\n    \n    # Run optimization\n    result = optimizer.optimize()\n    print(f\"  Best value: {result.fun:.6f}\")\n    \n    # Save result (same prefix, different suffix)\n    prefix = os.path.basename(exp_file).replace(\"_exp.pkl\", \"\")\n    optimizer.save_result(\n        prefix=prefix,\n        path=\"experiments\"\n    )\n    print(f\"  Saved: experiments/{prefix}_res.pkl\")\n\nprint(\"\\nAll experiments completed. Transfer results back to local machine.\")\n\n\n21.8.3 Local Machine (Analysis)\n# analyze_results.py\nimport numpy as np\nfrom spotoptim import SpotOptim\nimport glob\nimport matplotlib.pyplot as plt\n\n# Find all result files\nresult_files = glob.glob(\"experiments/*_res.pkl\")\nprint(f\"Found {len(result_files)} results to analyze\")\n\n# Load and compare results\nresults = []\nfor res_file in result_files:\n    opt = SpotOptim.load_result(res_file)\n    results.append({\n        \"file\": res_file,\n        \"best_value\": opt.best_y_,\n        \"best_point\": opt.best_x_,\n        \"n_evals\": opt.counter,\n        \"seed\": opt.seed\n    })\n    print(f\"{res_file}: best={opt.best_y_:.6f}, evals={opt.counter}\")\n\n# Find best overall result\nbest = min(results, key=lambda x: x[\"best_value\"])\nprint(f\"\\nBest result:\")\nprint(f\"  File: {best['file']}\")\nprint(f\"  Value: {best['best_value']:.6f}\")\nprint(f\"  Point: {best['best_point']}\")\nprint(f\"  Seed: {best['seed']}\")\n\n# Plot convergence comparison\nplt.figure(figsize=(12, 6))\n\nfor res_file in result_files:\n    opt = SpotOptim.load_result(res_file)\n    seed = opt.seed\n    cummin = [opt.y_[:i+1].min() for i in range(len(opt.y_))]\n    plt.plot(cummin, label=f\"Seed {seed}\", linewidth=2, alpha=0.7)\n\nplt.xlabel(\"Iteration\", fontsize=12)\nplt.ylabel(\"Best Value Found\", fontsize=12)\nplt.title(\"Optimization Progress Comparison\", fontsize=14)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(\"experiments/convergence_comparison.png\", dpi=150)\nprint(\"\\nConvergence plot saved to: experiments/convergence_comparison.png\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#technical-details",
    "href": "save_load.html#technical-details",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.9 Technical Details",
    "text": "21.9 Technical Details\n\n21.9.1 Serialization Method\nSpotOptim uses Python’s built-in pickle module for serialization. This provides:\n\nStandard library: No additional dependencies required\nCompatibility: Works with numpy arrays, sklearn models, scipy functions\nPerformance: Efficient serialization of large datasets\n\n\n\n21.9.2 Component Reinitialization\nWhen loading experiments, certain components are automatically recreated:\n\nSurrogate model: Gaussian Process with default kernel\nLHS sampler: Latin Hypercube Sampler with original seed\n\nThis ensures loaded experiments can continue optimization without manual configuration.\n\n\n21.9.3 Excluded Components\nSome components cannot be pickled and are automatically excluded:\n\nObjective function (fun): Lambda functions and local functions cannot be reliably pickled\nTensorBoard writer (tb_writer): File handles cannot be serialized\nSurrogate model (experiments only): Recreated on load for experiments\n\n\n\n21.9.4 File Format\nFiles are saved using pickle’s highest protocol:\nwith open(filename, \"wb\") as handle:\n    pickle.dump(optimizer_state, handle, protocol=pickle.HIGHEST_PROTOCOL)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#troubleshooting",
    "href": "save_load.html#troubleshooting",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.10 Troubleshooting",
    "text": "21.10 Troubleshooting\n\n21.10.1 Issue: “AttributeError: ‘SpotOptim’ object has no attribute ‘fun’”\nCause: Objective function not re-attached after loading experiment.\nSolution: Always re-attach the function after loading:\nopt = SpotOptim.load_experiment(\"exp.pkl\")\nopt.fun = your_objective_function  # Add this line\nresult = opt.optimize()\n\n\n21.10.2 Issue: “FileNotFoundError: Experiment file not found”\nCause: Incorrect file path or file doesn’t exist.\nSolution: Check file path and ensure file exists:\nimport os\n\nfilename = \"experiment_exp.pkl\"\nif os.path.exists(filename):\n    opt = SpotOptim.load_experiment(filename)\nelse:\n    print(f\"File not found: {filename}\")\n\n\n21.10.3 Issue: “FileExistsError: File already exists”\nCause: Attempting to save over an existing file without overwrite=True.\nSolution: Either use a different prefix or enable overwriting:\n# Option 1: Use different prefix\noptimizer.save_result(prefix=\"my_result_v2\")\n\n# Option 2: Enable overwriting\noptimizer.save_result(prefix=\"my_result\", overwrite=True)\n\n\n21.10.4 Issue: Results differ after loading\nCause: Random state not preserved or function behavior changed.\nSolution: Ensure you’re using the same seed and function definition:\n# When saving\noptimizer = SpotOptim(..., seed=42)  # Use fixed seed\n\n# When loading and continuing\nloaded_opt = SpotOptim.load_result(\"result_res.pkl\")\nloaded_opt.fun = same_objective_function  # Same function definition",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#see-also",
    "href": "save_load.html#see-also",
    "title": "21  Save and Load in SpotOptim",
    "section": "21.11 See Also",
    "text": "21.11 See Also\n\nReproducibility Manual: Learn about using seeds for reproducible results\nTensorBoard Manual: Monitor optimization progress in real-time",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html",
    "href": "success_rate.html",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "",
    "text": "22.1 What is Success Rate?\nSpotOptim tracks the success rate of the optimization process, which measures how often the optimizer finds improvements over recent evaluations. This metric helps you understand whether the optimization is making progress or has stalled.\nThe success rate is a rolling metric that tracks the percentage of recent evaluations that improved upon the best value found so far. It’s calculated over a sliding window of the last 100 evaluations.\nKey Points: - A “success” occurs when a new evaluation finds a value better (smaller) than the best found so far - The rate is computed over the last 100 evaluations (window size) - Values range from 0.0 (no recent improvements) to 1.0 (all recent evaluations improved) - Helps identify when optimization is stalling and may need adjustment",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#first-example",
    "href": "success_rate.html#first-example",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.2 First Example",
    "text": "22.2 First Example\n\nStart TensorBoard to visualize success rate in real-time:\n\ntensorboard --logdir=runs\nThe execute the following code:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function - challenging optimization problem\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\n# Run optimization with periodic success rate checks\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=200,\n    n_initial=20,\n    tensorboard_log=True,\n    tensorboard_clean=True,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Analyze final success rate\nprint(f\"\\nOptimization Results:\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Final success rate: {optimizer.success_rate:.2%}\")\n\n# Interpret the result\nif optimizer.success_rate &gt; 0.5:\n    print(\"→ High success rate: Optimization is still making good progress\")\nelif optimizer.success_rate &gt; 0.2:\n    print(\"→ Medium success rate: Approaching convergence\")\nelse:\n    print(\"→ Low success rate: Optimization has likely converged\")\n\n\nOptimization Results:\nBest value: 0.000000\nTotal evaluations: 200\nFinal success rate: 4.00%\n→ Low success rate: Optimization has likely converged",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#second-example",
    "href": "success_rate.html#second-example",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.3 Second Example",
    "text": "22.3 Second Example\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    \"\"\"Simple sphere function: f(x) = sum(x^2)\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create optimizer\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5), (-5, 5)],\n    max_iter=100,\n    n_initial=20,\n    verbose=True\n)\n\n# Run optimization\nresult = optimizer.optimize()\n\n# Check success rate\nprint(f\"Final success rate: {optimizer.success_rate:.2%}\")\nprint(f\"Total evaluations: {optimizer.counter}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#accessing-success-rate",
    "href": "success_rate.html#accessing-success-rate",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.4 Accessing Success Rate",
    "text": "22.4 Accessing Success Rate\nThe success rate is stored in the success_rate attribute:\noptimizer = SpotOptim(fun=objective, bounds=bounds, max_iter=50)\nresult = optimizer.optimize()\n\n# Access success rate\ncurrent_rate = optimizer.success_rate\nprint(f\"Success rate: {current_rate:.2%}\")\n\n# Also available via getter method\nrate = optimizer._get_success_rate()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#interpreting-success-rate",
    "href": "success_rate.html#interpreting-success-rate",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.5 Interpreting Success Rate",
    "text": "22.5 Interpreting Success Rate\n\n22.5.1 High Success Rate (&gt; 0.5)\nSuccess Rate: 75%\nInterpretation: The optimizer is finding improvements frequently. This typically indicates: - The optimization is in an exploratory phase - The surrogate model is effectively guiding the search - There’s still room for improvement in the search space\nAction: Continue optimization - progress is good!\n\n\n22.5.2 Medium Success Rate (0.2 - 0.5)\nSuccess Rate: 35%\nInterpretation: The optimizer occasionally finds improvements. This suggests: - The search is becoming more refined - The optimizer is balancing exploration and exploitation - Approaching a local or global optimum\nAction: Monitor progress and consider stopping criteria.\n\n\n22.5.3 Low Success Rate (&lt; 0.2)\nSuccess Rate: 8%\nInterpretation: Few recent evaluations improve the best value. This may indicate: - The optimization has converged to a (local) optimum - The search is stuck in a plateau region - The budget may be exhausted in terms of meaningful progress\nAction: Consider stopping optimization or adjusting parameters.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#tensorboard-visualization",
    "href": "success_rate.html#tensorboard-visualization",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.6 TensorBoard Visualization",
    "text": "22.6 TensorBoard Visualization\nWhen TensorBoard logging is enabled, success rate is automatically logged and can be visualized in real-time:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=100,\n    n_initial=20,\n    tensorboard_log=True,  # Enable logging\n    verbose=True\n)\n\nresult = optimizer.optimize()\nView in TensorBoard:\ntensorboard --logdir=runs\nIn the TensorBoard interface, look for: - SCALARS tab → success_rate: Rolling success rate over iterations - Compare multiple runs side-by-side - Identify when optimization stalls",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#example-monitoring-optimization-progress",
    "href": "success_rate.html#example-monitoring-optimization-progress",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.7 Example: Monitoring Optimization Progress",
    "text": "22.7 Example: Monitoring Optimization Progress\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function - challenging optimization problem\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\n# Run optimization with periodic success rate checks\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=100,\n    n_initial=20,\n    tensorboard_log=True,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Analyze final success rate\nprint(f\"\\nOptimization Results:\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Final success rate: {optimizer.success_rate:.2%}\")\n\n# Interpret the result\nif optimizer.success_rate &gt; 0.5:\n    print(\"→ High success rate: Optimization is still making good progress\")\nelif optimizer.success_rate &gt; 0.2:\n    print(\"→ Medium success rate: Approaching convergence\")\nelse:\n    print(\"→ Low success rate: Optimization has likely converged\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#example-comparing-multiple-runs",
    "href": "success_rate.html#example-comparing-multiple-runs",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.8 Example: Comparing Multiple Runs",
    "text": "22.8 Example: Comparing Multiple Runs\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef ackley(X):\n    \"\"\"Ackley function - multimodal test function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\n# Run with different configurations\nconfigs = [\n    {\"n_initial\": 10, \"max_iter\": 50, \"name\": \"Small initial\"},\n    {\"n_initial\": 30, \"max_iter\": 50, \"name\": \"Large initial\"},\n]\n\nresults = []\nfor config in configs:\n    optimizer = SpotOptim(\n        fun=ackley,\n        bounds=[(-5, 5), (-5, 5)],\n        n_initial=config[\"n_initial\"],\n        max_iter=config[\"max_iter\"],\n        seed=42,\n        verbose=False\n    )\n    result = optimizer.optimize()\n    \n    results.append({\n        \"name\": config[\"name\"],\n        \"best_value\": result.fun,\n        \"success_rate\": optimizer.success_rate,\n        \"n_evals\": optimizer.counter\n    })\n    \n    print(f\"\\n{config['name']}:\")\n    print(f\"  Best value: {result.fun:.6f}\")\n    print(f\"  Success rate: {optimizer.success_rate:.2%}\")\n    print(f\"  Evaluations: {optimizer.counter}\")\n\n# Find best configuration\nbest = min(results, key=lambda x: x[\"best_value\"])\nprint(f\"\\nBest configuration: {best['name']}\")\nprint(f\"  Achieved: f(x) = {best['best_value']:.6f}\")\nprint(f\"  Final success rate: {best['success_rate']:.2%}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#success-rate-with-noisy-functions",
    "href": "success_rate.html#success-rate-with-noisy-functions",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.9 Success Rate with Noisy Functions",
    "text": "22.9 Success Rate with Noisy Functions\nFor noisy functions (when repeats_initial &gt; 1 or repeats_surrogate &gt; 1), the success rate tracks improvements in the raw y values, not the aggregated means:\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_sphere(X):\n    \"\"\"Sphere function with Gaussian noise\"\"\"\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.5, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    repeats_initial=3,    # 3 evaluations per initial point\n    repeats_surrogate=2,  # 2 evaluations per new point\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nNoisy Optimization Results:\")\nprint(f\"Best raw value: {optimizer.min_y:.6f}\")\nprint(f\"Best mean value: {optimizer.min_mean_y:.6f}\")\nprint(f\"Success rate: {optimizer.success_rate:.2%}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Unique design points: {optimizer.mean_X.shape[0]}\")\nNote: With noisy functions, the success rate may be lower because: - Noise can mask true improvements - Multiple evaluations of the same point contribute to the window - Focus on the mean values (min_mean_y) for better assessment",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#advanced-custom-window-size",
    "href": "success_rate.html#advanced-custom-window-size",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.10 Advanced: Custom Window Size",
    "text": "22.10 Advanced: Custom Window Size\nThe success rate is calculated over a window of 100 evaluations by default. This is controlled by the window_size attribute:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=10\n)\n\n# Check default window size\nprint(f\"Window size: {optimizer.window_size}\")  # 100\n\n# The window size is set during initialization\n# To use a different window, you would need to modify it\n# before running optimization (not typically recommended)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#best-practices",
    "href": "success_rate.html#best-practices",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.11 Best Practices",
    "text": "22.11 Best Practices\n\n22.11.1 1. Monitor During Long Runs\nFor expensive optimization runs, periodically check success rate:\n# Could be implemented with callbacks in future versions\n# For now, success rate is updated automatically and logged to TensorBoard\n\n\n22.11.2 2. Combine with TensorBoard\nAlways enable TensorBoard logging for visual monitoring:\noptimizer = SpotOptim(\n    fun=expensive_function,\n    bounds=bounds,\n    max_iter=1000,\n    tensorboard_log=True,  # Track success_rate visually\n    tensorboard_path=\"runs/long_optimization\"\n)\n\n\n22.11.3 3. Use as Stopping Criterion\nConsider stopping when success rate drops very low:\n# Manual stopping check (conceptual)\nif optimizer.success_rate &lt; 0.05 and optimizer.counter &gt; 50:\n    print(\"Success rate very low - optimization has likely converged\")\n\n\n22.11.4 4. Compare Different Strategies\nUse success rate to compare optimization strategies:\nstrategies = [\"ei\", \"pi\", \"y\"]  # Different acquisition functions\nfor acq in strategies:\n    opt = SpotOptim(fun=obj, bounds=bnds, acquisition=acq, max_iter=50)\n    result = opt.optimize()\n    print(f\"{acq}: success_rate={opt.success_rate:.2%}, best={result.fun:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#technical-details",
    "href": "success_rate.html#technical-details",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.12 Technical Details",
    "text": "22.12 Technical Details\n\n22.12.1 How Success is Counted\nA new evaluation y_new is considered a success if:\ny_new &lt; best_y_so_far\nwhere best_y_so_far is the minimum value found in all previous evaluations.\n\n\n22.12.2 Rolling Window Calculation\nThe success rate is computed as:\nsuccess_rate = (number of successes in last 100 evals) / (window size)\n\nWindow size defaults to 100\nIf fewer than 100 evaluations have been performed, the window size is the number of evaluations\nThe window slides forward with each new evaluation\n\n\n\n22.12.3 Update Frequency\nThe success rate is updated after: 1. Initial design evaluation 2. Each iteration’s new point evaluation(s) 3. OCBA re-evaluations (if applicable)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#summary",
    "href": "success_rate.html#summary",
    "title": "22  Success Rate Tracking in SpotOptim",
    "section": "22.13 Summary",
    "text": "22.13 Summary\n\nSuccess rate measures the percentage of recent evaluations that improve the best value\nCalculated over a rolling window of the last 100 evaluations\nValues range from 0.0 to 1.0\nHigh rates (&gt;0.5) indicate active progress\nLow rates (&lt;0.2) suggest convergence\nAutomatically logged to TensorBoard when logging is enabled\nAvailable via optimizer.success_rate attribute after optimization\n\nUse success rate to: - ✓ Monitor optimization progress in real-time - ✓ Identify when to stop optimization - ✓ Compare different optimization strategies - ✓ Assess optimization difficulty for different problems",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html",
    "href": "tensorboard_clean.html",
    "title": "23  TensorBoard Log Cleaning Feature",
    "section": "",
    "text": "23.1 Summary\nAutomatic cleaning of old TensorBoard log directories with the tensorboard_clean parameter.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#usage",
    "href": "tensorboard_clean.html#usage",
    "title": "23  TensorBoard Log Cleaning Feature",
    "section": "23.2 Usage",
    "text": "23.2 Usage\n\n23.2.1 Basic Usage\nfrom spotoptim import SpotOptim\n\n# Remove old logs and create new log directory\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    tensorboard_log=True,\n    tensorboard_clean=True,  # Removes all subdirectories in 'runs'\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\n\n23.2.2 Use Cases\n\n\n\ntensorboard_log\ntensorboard_clean\nBehavior\n\n\n\n\nTrue\nTrue\nClean old logs, create new log directory\n\n\nTrue\nFalse\nPreserve old logs, create new log directory\n\n\nFalse\nTrue\nClean old logs, no new logging\n\n\nFalse\nFalse\nNo logging, no cleaning (default)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#implementation-details",
    "href": "tensorboard_clean.html#implementation-details",
    "title": "23  TensorBoard Log Cleaning Feature",
    "section": "23.3 Implementation Details",
    "text": "23.3 Implementation Details\n\n23.3.1 Cleaning Method\ndef _clean_tensorboard_logs(self) -&gt; None:\n    \"\"\"Clean old TensorBoard log directories from the runs folder.\"\"\"\n    if self.tensorboard_clean:\n        runs_dir = \"runs\"\n        if os.path.exists(runs_dir) and os.path.isdir(runs_dir):\n            # Get all subdirectories in runs\n            subdirs = [\n                os.path.join(runs_dir, d)\n                for d in os.listdir(runs_dir)\n                if os.path.isdir(os.path.join(runs_dir, d))\n            ]\n            \n            # Remove each subdirectory\n            for subdir in subdirs:\n                try:\n                    shutil.rmtree(subdir)\n                    if self.verbose:\n                        print(f\"Removed old TensorBoard logs: {subdir}\")\n                except Exception as e:\n                    if self.verbose:\n                        print(f\"Warning: Could not remove {subdir}: {e}\")\n\n\n23.3.2 Execution Flow\n\nUser creates SpotOptim instance with tensorboard_clean=True\nDuring initialization, _clean_tensorboard_logs() is called\nMethod checks if ‘runs’ directory exists\nRemoves all subdirectories (but preserves files)\nIf tensorboard_log=True, a new log directory is created\nOptimization proceeds normally",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#safety-features",
    "href": "tensorboard_clean.html#safety-features",
    "title": "23  TensorBoard Log Cleaning Feature",
    "section": "23.4 Safety Features",
    "text": "23.4 Safety Features\n\nOnly removes directories, not files in ‘runs’ folder\nHandles missing ‘runs’ directory gracefully\nError handling for permission issues\nVerbose output shows what’s being removed\nDefault is False to prevent accidental deletion",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#warning",
    "href": "tensorboard_clean.html#warning",
    "title": "23  TensorBoard Log Cleaning Feature",
    "section": "23.5 Warning",
    "text": "23.5 Warning\n⚠️ IMPORTANT: Setting tensorboard_clean=True permanently deletes all subdirectories in the ‘runs’ folder. Make sure to save important logs elsewhere before enabling this feature.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature</span>"
    ]
  },
  {
    "objectID": "tensorboard.html",
    "href": "tensorboard.html",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "",
    "text": "24.1 Quick Start\nSpotOptim supports TensorBoard logging for monitoring optimization progress in real-time.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#quick-start",
    "href": "tensorboard.html#quick-start",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "",
    "text": "24.1.1 1. Enable TensorBoard Logging\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    tensorboard_log=True,  # Enable logging\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\n\n24.1.2 2. View Logs in TensorBoard\nIn a separate terminal, run:\ntensorboard --logdir=runs\nThen open your browser to http://localhost:6006",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#cleaning-old-logs",
    "href": "tensorboard.html#cleaning-old-logs",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.2 Cleaning Old Logs",
    "text": "24.2 Cleaning Old Logs\nYou can automatically remove old TensorBoard logs before starting a new optimization:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    tensorboard_log=True,\n    tensorboard_clean=True,  # Remove old logs from 'runs' directory\n    verbose=True\n)\nWarning: This permanently deletes all subdirectories in the runs folder. Make sure to save important logs elsewhere before enabling this feature.\n\n24.2.1 Use Cases\n\nClean Start - Remove old logs and create new one:\ntensorboard_log=True, tensorboard_clean=True\nPreserve History - Keep old logs and add new one (default):\ntensorboard_log=True, tensorboard_clean=False\nJust Clean - Remove old logs without new logging:\ntensorboard_log=False, tensorboard_clean=True",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#custom-log-directory",
    "href": "tensorboard.html#custom-log-directory",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.3 Custom Log Directory",
    "text": "24.3 Custom Log Directory\nSpecify a custom path for TensorBoard logs:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    tensorboard_log=True,\n    tensorboard_path=\"my_experiments/run_001\",\n    ...\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#what-gets-logged",
    "href": "tensorboard.html#what-gets-logged",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.4 What Gets Logged",
    "text": "24.4 What Gets Logged\n\n24.4.1 Scalar Metrics\nFor Deterministic Functions:\n\ny_values/min: Best (minimum) y value found so far\ny_values/last: Most recently evaluated y value\nX_best/x0, X_best/x1, ...: Coordinates of the best point\n\nFor Noisy Functions (repeats &gt; 1):\n\ny_values/min: Best single evaluation\ny_values/mean_best: Best mean y value\ny_values/last: Most recent evaluation\ny_variance_at_best: Variance at the best mean point\nX_mean_best/x0, X_mean_best/x1, ...: Coordinates of best mean point\n\n\n\n24.4.2 Hyperparameters\nEach function evaluation is logged with:\n\nInput coordinates (x0, x1, x2, …)\nFunction value (hp_metric)\n\nThis allows you to explore the relationship between hyperparameters and objective values in the HPARAMS tab.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#examples",
    "href": "tensorboard.html#examples",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.5 Examples",
    "text": "24.5 Examples\n\n24.5.1 Basic Usage\noptimizer = SpotOptim(\n    fun=lambda X: np.sum(X**2, axis=1),\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    tensorboard_log=True,\n    verbose=True\n)\nresult = optimizer.optimize()\n\n\n24.5.2 Noisy Optimization\ndef noisy_objective(X):\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    repeats_initial=3,\n    repeats_surrogate=2,\n    tensorboard_log=True,\n    tensorboard_path=\"runs/noisy_exp\",\n    seed=42\n)\nresult = optimizer.optimize()\n\n\n24.5.3 With OCBA\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    repeats_initial=2,\n    ocba_delta=3,  # Re-evaluate 3 promising points per iteration\n    tensorboard_log=True,\n    seed=42\n)\nresult = optimizer.optimize()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#comparing-multiple-runs",
    "href": "tensorboard.html#comparing-multiple-runs",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.6 Comparing Multiple Runs",
    "text": "24.6 Comparing Multiple Runs\nRun multiple optimizations with different settings:\n# Run 1: Standard\nopt1 = SpotOptim(..., tensorboard_path=\"runs/standard\")\nopt1.optimize()\n\n# Run 2: With OCBA\nopt2 = SpotOptim(..., ocba_delta=3, tensorboard_path=\"runs/with_ocba\")\nopt2.optimize()\n\n# Run 3: More initial points\nopt3 = SpotOptim(..., n_initial=20, tensorboard_path=\"runs/more_initial\")\nopt3.optimize()\nThen view all runs together:\ntensorboard --logdir=runs",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#tensorboard-features",
    "href": "tensorboard.html#tensorboard-features",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.7 TensorBoard Features",
    "text": "24.7 TensorBoard Features\n\n24.7.1 SCALARS Tab\n\nView convergence curves\nCompare optimization progress across runs\nTrack how metrics change over iterations\n\n\n\n24.7.2 HPARAMS Tab\n\nExplore hyperparameter space\nSee which parameter combinations work best\nIdentify patterns in successful configurations\n\n\n\n24.7.3 Text Tab\n\nView configuration details\nCheck run metadata",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#tips",
    "href": "tensorboard.html#tips",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.8 Tips",
    "text": "24.8 Tips\n\nOrganize Experiments: Use descriptive tensorboard_path names:\ntensorboard_path=f\"runs/exp_{date}_{config_name}\"\nCompare Algorithms: Run multiple optimization strategies and compare:\n# Different acquisition functions\nfor acq in ['ei', 'pi', 'y']:\n    opt = SpotOptim(..., acquisition=acq, tensorboard_path=f\"runs/acq_{acq}\")\n    opt.optimize()\nClean Up Old Runs: Use tensorboard_clean=True for automatic cleanup, or manually:\nrm -rf runs/old_experiment\nPort Conflicts: If port 6006 is busy, use a different port:\ntensorboard --logdir=runs --port=6007",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#demo-scripts",
    "href": "tensorboard.html#demo-scripts",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.9 Demo Scripts",
    "text": "24.9 Demo Scripts\nRun the comprehensive TensorBoard demo:\npython demo_tensorboard.py\nThis demonstrates:\n\nDeterministic optimization (Rosenbrock function)\nNoisy optimization with repeated evaluations\nOCBA for intelligent re-evaluation\n\nRun the log cleaning demo:\npython demo_tensorboard_clean.py\nThis demonstrates:\n\nCreating multiple log directories\nPreserving old logs (default behavior)\nCleaning old logs automatically\nCleaning without creating new logs\n\nThis demonstrates:\n\nDeterministic optimization (Rosenbrock function)\nNoisy optimization with repeated evaluations\nOCBA for intelligent re-evaluation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#troubleshooting",
    "href": "tensorboard.html#troubleshooting",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.10 Troubleshooting",
    "text": "24.10 Troubleshooting\nQ: TensorBoard shows “No dashboards are active” A: Make sure you’ve run an optimization with tensorboard_log=True first.\nQ: Can’t see my latest run A: Refresh TensorBoard (click the reload button in the upper right).\nQ: How do I stop TensorBoard? A: Press Ctrl+C in the terminal where TensorBoard is running.\nQ: Logs taking up too much space? A: Use tensorboard_clean=True to automatically remove old logs, or manually delete old run directories.\nQ: How do I remove all old logs at once? A: Set tensorboard_clean=True when creating your optimizer. This will remove all subdirectories in the runs folder.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#related-parameters",
    "href": "tensorboard.html#related-parameters",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.11 Related Parameters",
    "text": "24.11 Related Parameters\n\ntensorboard_log (bool): Enable/disable logging (default: False)\ntensorboard_path (str): Custom log directory (default: auto-generated with timestamp)\ntensorboard_clean (bool): Remove old logs from ‘runs’ directory before starting (default: False)\nverbose (bool): Print progress to console (default: False)\nvar_name (list): Custom names for variables (used in TensorBoard labels)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#performance-notes",
    "href": "tensorboard.html#performance-notes",
    "title": "24  TensorBoard Logging in SpotOptim",
    "section": "24.12 Performance Notes",
    "text": "24.12 Performance Notes\nTensorBoard logging has minimal overhead:\n\n&lt; 1% slowdown for typical optimizations\nEvent files are efficiently buffered and written\nWriter is properly closed after optimization completes",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html",
    "href": "var_type.html",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "",
    "text": "25.1 Overview\nThis document describes the var_type implementation in SpotOptim, which allows users to specify different data types for optimization variables.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#supported-variable-types",
    "href": "var_type.html#supported-variable-types",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.2 Supported Variable Types",
    "text": "25.2 Supported Variable Types\nSpotOptim supports three main data types:\n\n25.2.1 1. ‘float’\n\nPurpose: Continuous optimization with Python floats\nBehavior: No rounding applied, values remain continuous\nUse case: Standard continuous optimization variables\nExample: Temperature (23.5°C), Distance (1.234m)\n\n\n\n25.2.2 2. ‘int’\n\nPurpose: Discrete integer optimization\nBehavior: Float values are automatically rounded to integers\nUse case: Count variables, discrete parameters\nExample: Number of layers (5), Population size (100)\n\n\n\n25.2.3 3. ‘factor’\n\nPurpose: Unordered categorical data\nBehavior: Internally mapped to integer values (0, 1, 2, …)\nUse case: Categorical choices like colors, algorithms, modes\nExample: Color (“red”→0, “green”→1, “blue”→2)\nNote: The actual string-to-int mapping is external to SpotOptim; the optimizer works with the integer representation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#implementation-details",
    "href": "var_type.html#implementation-details",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.3 Implementation Details",
    "text": "25.3 Implementation Details\n\n25.3.1 Where var_type is Used\nThe var_type parameter is properly propagated throughout the optimization process:\n\nInitialization (__init__):\n\nStored as self.var_type\nDefault: [\"float\"] * n_dim if not specified\n\nInitial Design Generation (_generate_initial_design):\n\nApplies type constraints via _repair_non_numeric()\nEnsures initial points respect variable types\n\nNew Point Suggestion (_suggest_next_point):\n\nApplies type constraints to acquisition function optimization results\nEnsures suggested points respect variable types\n\nUser-Provided Initial Design (optimize):\n\nApplies type constraints to X0 if provided\nEnsures consistency regardless of input source\n\nMesh Grid Generation (_generate_mesh_grid):\n\nUsed for plotting, respects variable types\nEnsures visualization shows correct discrete/continuous behavior\n\n\n\n\n25.3.2 Core Method: _repair_non_numeric()\nThis method enforces variable type constraints:\ndef _repair_non_numeric(self, X: np.ndarray, var_type: List[str]) -&gt; np.ndarray:\n    \"\"\"Round non-continuous values to integers.\"\"\"\n    mask = np.isin(var_type, [\"float\"], invert=True)\n    X[:, mask] = np.around(X[:, mask])\n    return X\nLogic:\n\nVariables with type 'float': No change (continuous)\nVariables with type 'int' or 'factor': Rounded to integers",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#usage-examples",
    "href": "var_type.html#usage-examples",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.4 Usage Examples",
    "text": "25.4 Usage Examples",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#example-usage",
    "href": "var_type.html#example-usage",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.5 5. Example Usage",
    "text": "25.5 5. Example Usage\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Example 1: All float variables (default)\nopt1 = SpotOptim(\n    fun=lambda x: np.sum(x**2),\n    lower=np.array([0, 0, 0]),\n    upper=np.array([10, 10, 10])\n    # var_type defaults to [\"float\", \"float\", \"float\"]\n)\n\n25.5.1 Example 2: Pure Integer Optimization\ndef discrete_func(X):\n    return np.sum(np.round(X)**2, axis=1)\n\nbounds = [(-5, 5), (-5, 5)]\nvar_type = [\"int\", \"int\"]\n\nopt = SpotOptim(\n    fun=discrete_func,\n    bounds=bounds,\n    var_type=var_type,\n    max_iter=20,\n    seed=42\n)\n\nresult = opt.optimize()\n# result.x will have integer values like [1.0, -2.0]\n\n\n25.5.2 Example 3: Categorical (Factor) Variables\ndef categorical_func(X):\n    # Assume X[:, 0] represents 3 categories: 0, 1, 2\n    # Category 0 is best\n    return (X[:, 0]**2) + (X[:, 1]**2)\n\nbounds = [(0, 2), (0, 3)]  # 3 and 4 categories respectively\nvar_type = [\"factor\", \"factor\"]\n\nopt = SpotOptim(\n    fun=categorical_func,\n    bounds=bounds,\n    var_type=var_type,\n    max_iter=20,\n    seed=42\n)\n\nresult = opt.optimize()\n# result.x will be integers like [0.0, 1.0] representing categories\n\n\n25.5.3 Example 4: Mixed Variable Types\ndef mixed_func(X):\n    # X[:, 0]: continuous temperature\n    # X[:, 1]: discrete number of iterations\n    # X[:, 2]: categorical algorithm choice (0, 1, 2)\n    return X[:, 0]**2 + X[:, 1]**2 + X[:, 2]**2\n\nbounds = [(-5, 5), (1, 100), (0, 2)]\nvar_type = [\"float\", \"int\", \"factor\"]\n\nopt = SpotOptim(\n    fun=mixed_func,\n    bounds=bounds,\n    var_type=var_type,\n    max_iter=20,\n    seed=42\n)\n\nresult = opt.optimize()\n# result.x[0]: continuous float like 0.123\n# result.x[1]: integer like 5.0\n# result.x[2]: integer category like 0.0",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#key-findings",
    "href": "var_type.html#key-findings",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.6 Key Findings",
    "text": "25.6 Key Findings\n\nType Persistence: Variable types are correctly maintained throughout the entire optimization process, from initial design through all iterations.\nAutomatic Enforcement: The _repair_non_numeric() method is called at all critical points, ensuring type constraints are never violated.\nThree Explicit Types: Only 'float', 'int', and 'factor' are supported. The legacy 'num' type has been removed for clarity.\nUser-Provided Data: Type constraints are applied even to user-provided initial designs, ensuring consistency.\nPlotting Compatibility: The plotting functionality respects variable types, ensuring correct visualization of discrete vs. continuous variables.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#recommendations",
    "href": "var_type.html#recommendations",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.7 Recommendations",
    "text": "25.7 Recommendations\n\nAlways specify var_type explicitly for clarity, especially in mixed-type problems\nUse appropriate bounds for factor variables (e.g., (0, n_categories-1))\nExternal mapping for string categories: Maintain your own mapping dictionary outside SpotOptim (e.g., {\"red\": 0, \"green\": 1, \"blue\": 2})\nValidation: The current implementation doesn’t validate var_type length matches bounds length - users should ensure this manually",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  },
  {
    "objectID": "var_type.html#future-enhancements-optional",
    "href": "var_type.html#future-enhancements-optional",
    "title": "25  Variable Type (var_type) Implementation",
    "section": "25.8 Future Enhancements (Optional)",
    "text": "25.8 Future Enhancements (Optional)\nPotential improvements that could be added:\n\nValidation: Add validation in __init__ to check len(var_type) == len(bounds)\nString Categories: Add built-in support for automatic string-to-int mapping\nOrdered Categories: Support ordered categorical variables (ordinal data)\nType Checking: Validate that var_type values are one of the allowed strings\nBounds Checking: Warn if factor bounds are not integer ranges",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variable Type (var_type) Implementation</span>"
    ]
  }
]