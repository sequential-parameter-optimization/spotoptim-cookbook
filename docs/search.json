[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sequential Parameter Optimization Cookbook",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "002_awwe.html",
    "href": "002_awwe.html",
    "title": "1  Aircraft Wing Weight Example",
    "section": "",
    "text": "1.1 AWWE Equation\n\\[ W = 0.036 S_W^{0.758} \\times W_{fw}^{0.0035} \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times  q^{0.006}  \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49}\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-equation",
    "href": "002_awwe.html#awwe-equation",
    "title": "1  Aircraft Wing Weight Example",
    "section": "",
    "text": "Example from Forrester, Sóbester, and Keane (2008)\nUnderstand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters:",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "href": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.2 AWWE Parameters and Equations (Part 1)",
    "text": "1.2 AWWE Parameters and Equations (Part 1)\n\n\n\nTable 1.1: Aircraft Wing Weight Parameters\n\n\n\n\n\n\n\n\n\n\n\n\nSymbol\nParameter\nBaseline\nMinimum\nMaximum\n\n\n\n\n\\(S_W\\)\nWing area (\\(ft^2\\))\n174\n150\n200\n\n\n\\(W_{fw}\\)\nWeight of fuel in wing (lb)\n252\n220\n300\n\n\n\\(A\\)\nAspect ratio\n7.52\n6\n10\n\n\n\\(\\Lambda\\)\nQuarter-chord sweep (deg)\n0\n-10\n10\n\n\n\\(q\\)\nDynamic pressure at cruise (\\(lb/ft^2\\))\n34\n16\n45\n\n\n\\(\\lambda\\)\nTaper ratio\n0.672\n0.5\n1\n\n\n\\(R_{tc}\\)\nAerofoil thickness to chord ratio\n0.12\n0.08\n0.18\n\n\n\\(N_z\\)\nUltimate load factor\n3.8\n2.5\n6\n\n\n\\(W_{dg}\\)\nFlight design gross weight (lb)\n2000\n1700\n2500\n\n\n\\(W_p\\)\npaint weight (lb/ft^2)\n0.064\n0.025\n0.08\n\n\n\n\n\n\nThe study begins with a baseline Cessna C172 Skyhawk Aircraft as its reference point. It aims to investigate the impact of wing area and fuel weight on the overall weight of the aircraft. Two crucial parameters in this analysis are the aspect ratio (\\(A\\)), defined as the ratio of the wing’s length to the average chord (thickness of the airfoil), and the taper ratio (\\(\\lambda\\)), which represents the ratio of the maximum to the minimum thickness of the airfoil or the maximum to minimum chord.\nIt’s important to note that the equation used in this context is not a computer simulation but will be treated as one for the purpose of illustration. This approach involves employing a true mathematical equation, even if it’s considered unknown, as a useful tool for generating realistic settings to test the methodology. The functional form of this equation was derived by “calibrating” known physical relationships to curves obtained from existing aircraft data, as referenced in Raymer (2006). Essentially, it acts as a surrogate for actual measurements of aircraft weight.\nExamining the mathematical properties of the AWWE (Aircraft Weight With Wing Area and Fuel Weight Equation), it is evident that the response is highly nonlinear concerning its inputs. While it’s common to apply the logarithm to simplify equations with complex exponents, even when modeling the logarithm, which transforms powers into slope coefficients and products into sums, the response remains nonlinear due to the presence of trigonometric terms. Given the combination of nonlinearity and high input dimension, simple linear and quadratic response surface approximations are likely to be inadequate for this analysis.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#goals-understanding-and-optimization",
    "href": "002_awwe.html#goals-understanding-and-optimization",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.3 Goals: Understanding and Optimization",
    "text": "1.3 Goals: Understanding and Optimization\nThe primary goals of this study revolve around understanding and optimization:\n\nUnderstanding: One of the straightforward objectives is to gain a deep understanding of the input-output relationships in this context. Given the global perspective implied by this setting, it becomes evident that a more sophisticated model is almost necessary. At this stage, let’s focus on this specific scenario to establish a clear understanding.\nOptimization: Another application of this analysis could be optimization. There may be an interest in minimizing the weight of the aircraft, but it’s likely that there will be constraints in place. For example, the presence of wings with a nonzero area is essential for the aircraft to be capable of flying. In situations involving (constrained) optimization, a global perspective and, consequently, the use of flexible modeling are vital.\n\nThe provided Python code serves as a genuine computer implementation that “solves” a mathematical model. It accepts arguments encoded in the unit cube, with defaults used to represent baseline settings, as detailed in the table labeled as Table 1.1. To map values from the interval \\([a, b]\\) to the interval \\([0, 1]\\), the following formula can be employed:\n\\[\ny = f(x) = \\frac{x - a}{b - a}.\n\\tag{1.1}\\] To reverse this mapping and obtain the original values, the formula \\[\ng(y) = a + (b - a) y\n\\tag{1.2}\\] can be used. The function wingwt() expects inputs from the unit cube, which are then transformed back to their original scales using Equation 1.2. The function is defined as follows:\n\ndef wingwt(Sw=0.48, Wfw=0.4, A=0.38, L=0.5, q=0.62, l=0.344,  Rtc=0.4, Nz=0.37, Wdg=0.38):\n    # put coded inputs back on natural scale\n    Sw = Sw * (200 - 150) + 150 \n    Wfw = Wfw * (300 - 220) + 220 \n    A = A * (10 - 6) + 6 \n    L = (L * (10 - (-10)) - 10) * np.pi/180\n    q = q * (45 - 16) + 16 \n    l = l * (1 - 0.5) + 0.5  \n    Rtc = Rtc * (0.18 - 0.08) + 0.08\n    Nz = Nz * (6 - 2.5) + 2.5\n    Wdg = Wdg*(2500 - 1700) + 1700\n    # calculation on natural scale\n    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A/np.cos(L)**2)**0.6 * q**0.006 \n    W = W * l**0.04 * (100*Rtc/np.cos(L))**(-0.3) * (Nz*Wdg)**(0.49)\n    return(W)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#properties-of-the-python-solver",
    "href": "002_awwe.html#properties-of-the-python-solver",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.4 Properties of the Python “Solver”",
    "text": "1.4 Properties of the Python “Solver”\nThe compute time required by the “wingwt” solver is extremely short and can be considered trivial in terms of computational resources. The approximation error is exceptionally small, effectively approaching machine precision, which indicates the high accuracy of the solver’s results.\nTo simulate time-consuming evaluations, a deliberate delay is introduced by incorporating a sleep(3600) command, which effectively synthesizes a one-hour execution time for a particular evaluation.\nMoving on to the AWWE visualization, plotting in two dimensions is considerably simpler than dealing with nine dimensions. To aid in creating visual representations, the code provided below establishes a grid within the unit square to facilitate the generation of sliced visuals. This involves generating a “meshgrid” as outlined in the code.\n\nx = np.linspace(0, 1, 3)\ny = np.linspace(0, 1, 3)\nX, Y = np.meshgrid(x, y)\nzp = zip(np.ravel(X), np.ravel(Y))\nlist(zp)\n\n[(np.float64(0.0), np.float64(0.0)),\n (np.float64(0.5), np.float64(0.0)),\n (np.float64(1.0), np.float64(0.0)),\n (np.float64(0.0), np.float64(0.5)),\n (np.float64(0.5), np.float64(0.5)),\n (np.float64(1.0), np.float64(0.5)),\n (np.float64(0.0), np.float64(1.0)),\n (np.float64(0.5), np.float64(1.0)),\n (np.float64(1.0), np.float64(1.0))]\n\n\nThe coding used to transform inputs from natural units is largely a matter of taste, so long as it’s easy to undo for reporting back on original scales\n\n%matplotlib inline\n# plt.style.use('seaborn-white')\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 1, 100)\nX, Y = np.meshgrid(x, y)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "href": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))",
    "text": "1.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))\nWe will vary \\(N_z\\) and \\(A\\), with other inputs fixed at their baseline values.\n\nz = wingwt(A = X, Nz = Y)\nfig = plt.figure(figsize=(7., 5.))\nplt.contourf(X, Y, z, 20, cmap='jet')\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\nplt.title(\"Load factor (Nz) vs. Aspect Ratio (A)\")\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\nContour plots can be refined, e.g., by adding explicit contour lines as shown in the following figure.\n\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar()\n\n\n\n\n\n\n\n\nThe interpretation of the AWWE plot can be summarized as follows:\n\nThe figure displays the weight response as a function of two variables, \\(N_z\\) and \\(A\\), using an image-contour plot.\nThe slight curvature observed in the contours suggests an interaction between these two variables.\nNotably, the range of outputs depicted in the figure, spanning from approximately 160 to 320, nearly encompasses the entire range of outputs observed from various input settings within the full 9-dimensional input space.\nThe plot indicates that aircraft wings tend to be heavier when the aspect ratios (\\(A\\)) are high.\nThis observation aligns with the idea that wings are designed to withstand and accommodate high gravitational forces (\\(g\\)-forces, large \\(N_z\\)), and there may be a compounding effect where larger values of \\(N_z\\) contribute to increased wing weight.\nIt’s plausible that this phenomenon is related to the design considerations of fighter jets, which cannot have the efficient and lightweight glider-like wings typically found in other types of aircraft.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "href": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.6 Plot 2: Taper Ratio and Fuel Weight",
    "text": "1.6 Plot 2: Taper Ratio and Fuel Weight\n\nThe same experiment for two other inputs, e.g., taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\n\n\nz = wingwt(Wfw = X,  Nz = Y)\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"WfW\")\nplt.ylabel(\"l\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar();\n\n\n\n\n\n\n\n\n\nInterpretation of Taper Ratio (\\(l\\)) and Fuel Weight (\\(W_{fw}\\))\n\nApparently, neither input has much effect on wing weight:\n\nwith \\(\\lambda\\) having a marginally greater effect, covering less than 4 percent of the span of weights observed in the \\(A \\times N_z\\) plane\n\nThere’s no interaction evident in \\(\\lambda \\times W_{fw}\\)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#the-big-picture-combining-all-variables",
    "href": "002_awwe.html#the-big-picture-combining-all-variables",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.7 The Big Picture: Combining all Variables",
    "text": "1.7 The Big Picture: Combining all Variables\n\npl = [\"Sw\", \"Wfw\", \"A\", \"L\", \"q\", \"l\",  \"Rtc\", \"Nz\", \"Wdg\"]\n\n\nZ = []\nZlab = []\nl = len(pl)\n# lc = math.comb(l,2)\nfor i in range(l):\n    for j in range(i+1, l):\n    # for j in range(l):\n        # print(pl[i], pl[j])\n        d = {pl[i]: X, pl[j]: Y}\n        Z.append(wingwt(**d))\n        Zlab.append([pl[i],pl[j]])\n\nNow we can generate all 36 combinations, e.g., our first example is combination p = 19.\n\np = 19\nZlab[p]\n\n['A', 'Nz']\n\n\nTo help interpret outputs from experiments such as this one—to level the playing field when comparing outputs from other pairs of inputs—code below sets up a color palette that can be re-used from one experiment to the next. We use the arguments vmin=180 and vmax =360 to implement comparibility\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nLet’s plot the second example, taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\nThis is combination 11:\n\n\np = 11\nZlab[p]\n\n['Wfw', 'l']\n\n\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nUsing a global colormap indicates that these variables have minor effects on the wing weight.\nImportant factors can be detected by visual inspection\nPlotting the Big Picture: we can plot all 36 combinations in one figure.\n\n\nfig = plt.figure(figsize=(20., 20.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(6,6),  # creates 2x2 grid of axes\n                 axes_pad=0.5,  # pad between axes in inch.\n                 share_all=True,\n                 label_mode=\"all\",\n                 ) \ni = 0\nfor ax, im in zip(grid, Z):\n    # Iterating over the grid returns the Axes.\n    ax.set_xlabel(Zlab[i][0])\n    ax.set_ylabel(Zlab[i][1])\n    # ax.set_title(Zlab[i][1] + \" vs. \" + Zlab[i][0])\n    ax.contourf(X, Y, im, 30, cmap = \"jet\",  vmin = 180, vmax = 360)\n    i = i + 1\n       \nplt.show()",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-landscape",
    "href": "002_awwe.html#awwe-landscape",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.8 AWWE Landscape",
    "text": "1.8 AWWE Landscape\n\nOur Observations\n\nThe load factor \\(N_z\\), which determines the magnitude of the maximum aerodynamic load on the wing, is very active and involved in interactions with other variables.\n\n\nClassic example: the interaction of \\(N_z\\) with the aspect ratio \\(A\\) indicates a heavy wing for high aspect ratios and large \\(g\\)-forces\nThis is the reaon why highly manoeuvrable fighter jets cannot have very efficient, glider wings)\n\n\nAspect ratio \\(A\\) and airfoil thickness to chord ratio \\(R_{tc}\\) have nonlinear interactions.\nMost important variables:\n\n\nUltimate load factor \\(N_z\\), wing area \\(S_w\\), and flight design gross weight\\(W_{dg}\\).\n\n\nLittle impact: dynamic pressure \\(q\\), taper ratio \\(l\\), and quarter-chord sweep \\(L\\).\n\nExpert Knowledge\n\nAircraft designers know that the overall weight of the aircraft and the wing area must be kept to a minimum\nthe latter usually dictated by constraints such as required stall speed, landing distance, turn rate, etc.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#summary-of-the-first-experiments",
    "href": "002_awwe.html#summary-of-the-first-experiments",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.9 Summary of the First Experiments",
    "text": "1.9 Summary of the First Experiments\n\nFirst, we considered two pairs of inputs, out of 36 total pairs\nThen, the “Big Picture”:\n\nFor each pair we evaluated wingwt 10,000 times\n\nDoing the same for all pairs would require 360K evaluations:\n\nnot a reasonable number with a real computer simulation that takes any non-trivial amount of time to evaluate\nOnly 1s per evaluation: \\(&gt;100\\) hours\n\nMany solvers take minutes/hours/days to execute a single run\nAnd: three-way interactions?\nConsequence: a different strategy is needed",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#exercise",
    "href": "002_awwe.html#exercise",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.10 Exercise",
    "text": "1.10 Exercise\n\n1.10.1 Adding Paint Weight\n\nPaint weight is not considered.\nAdd Paint Weight \\(W_p\\) to formula (the updated formula is shown below) and update the functions and plots in the notebook.\n\n\\[ W = 0.036S_W^{0.758} \\times W_{fw}^{0.0035} \\times \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times q^{0.006} \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49} + S_w W_p\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#jupyter-notebook",
    "href": "002_awwe.html#jupyter-notebook",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.11 Jupyter Notebook",
    "text": "1.11 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nRaymer, Daniel P. 2006. Aircraft Design: A Conceptual Approach. AIAA.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html",
    "href": "001_surrogate.html",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "",
    "text": "2.1 Surrogates",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#surrogates",
    "href": "001_surrogate.html#surrogates",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "",
    "text": "Gathering data is expensive, and sometimes getting exactly the data you want is impossible or unethical\nSurrogate: substitute for the real thing\nIn statistics, draws from predictive equations derived from a fitted model can act as a surrogate for the data-generating mechanism\nBenefits of the surrogate approach:\n\nSurrogate could represent a cheaper way to explore relationships, and entertain “what ifs?”\nSurrogates favor faithful yet pragmatic reproduction of dynamics:\n\ninterpretation,\nestablishing causality, or\nidentification\n\nMany numerical simulators are deterministic, whereas field observations are noisy or have measurement error\n\n\n\n2.1.1 Costs of Simulation\n\nComputer simulations are generally cheaper (but not always!) than physical observation\nSome computer simulations can be just as expensive as field experimentation, but computer modeling is regarded as easier because:\n\nthe experimental apparatus is better understood\nmore aspects may be controlled.\n\n\n\n\n2.1.2 Mathematical Models and Meta-Models\n\nUse of mathematical models leveraging numerical solvers has been commonplace for some time\nMathematical models became more complex, requiring more resources to simulate/solve numerically\nPractitioners increasingly relied on meta-models built off of limited simulation campaigns\n\n\n\n2.1.3 Surrogates = Trained Meta-models\n\nData collected via expensive computer evaluations tuned flexible functional forms that could be used in lieu of further simulation to\n\nsave money or computational resources;\ncope with an inability to perform future runs (expired licenses, off-line or over-impacted supercomputers)\n\nTrained meta-models became known as surrogates\n\n\n\n2.1.4 Computer Experiments\n\nComputer experiment: design, running, and fitting meta-models.\n\nLike an ordinary statistical experiment, except the data are generated by computer codes rather than physical or field observations, or surveys\n\nSurrogate modeling is statistical modeling of computer experiments\n\n\n\n2.1.5 Limits of Mathematical Modeling\n\nMathematical biologists, economists and others had reached the limit of equilibrium-based mathematical modeling with cute closed-form solutions\nStochastic simulations replace deterministic solvers based on FEM, Navier–Stokes or Euler methods\nAgent-based simulation models are used to explore predator-prey (Lotka–Voltera) dynamics, spread of disease, management of inventory or patients in health insurance markets\nConsequence: the distinction between surrogate and statistical model is all but gone\n\n\n\n2.1.6 Why Computer Simulations are Necessary\n\nYou can’t seed a real community with Ebola and watch what happens\nIf there’s (real) field data, say on a historical epidemic, further experimentation may be almost entirely limited to the mathematical and computer modeling side\nClassical statistical methods offer little guidance\n\n\n\n2.1.7 Simulation Requirements\n\nSimulation should\n\nenable rich diagnostics to help criticize that models\nunderstanding its sensitivity to inputs and other configurations\nproviding the ability to optimize and\nrefine both automatically and with expert intervention\n\nAnd it has to do all that while remaining computationally tractable\nOne perspective is so-called response surface methods (RSMs):\na poster child from industrial statistics’ heyday, well before information technology became a dominant industry",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#applications-of-surrogate-models",
    "href": "001_surrogate.html#applications-of-surrogate-models",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "2.2 Applications of Surrogate Models",
    "text": "2.2 Applications of Surrogate Models\nThe four most common usages of surrogate models are:\n\nAugmenting Expensive Simulations: Surrogate models act as a ‘curve fit’ to approximate the results of expensive simulation codes, enabling predictions without rerunning the primary source. This provides significant speed improvements while maintaining useful accuracy.\nCalibration of Predictive Codes: Surrogates bridge the gap between simpler, faster but less accurate models and more accurate, slower models. This multi-fidelity approach allows for improved accuracy without the full computational expense.\nHandling Noisy or Missing Data: Surrogates smooth out random or systematic errors in experimental or computational data, filling gaps and revealing overall trends while filtering out extraneous details.\nData Mining and Insight Generation: Surrogates help identify functional relationships between variables and their impact on results. They enable engineers to focus on critical variables and visualize data trends effectively.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#dace-and-rsm",
    "href": "001_surrogate.html#dace-and-rsm",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "2.3 DACE and RSM",
    "text": "2.3 DACE and RSM\nMathematical models implemented in computer codes are used to circumvent the need for expensive field data collection. These models are particularly useful when dealing with highly nonlinear response surfaces, high signal-to-noise ratios (which often involve deterministic evaluations), and a global scope. As a result, a new approach is required in comparison to Response Surface Methodology (RSM), which is discussed in Section 5.1.\nWith the improvement in computing power and simulation fidelity, researchers gain higher confidence and a better understanding of the dynamics in physical, biological, and social systems. However, the expansion of configuration spaces and increasing input dimensions necessitates more extensive designs. High-performance computing (HPC) allows for thousands of runs, whereas previously only tens were possible. This shift towards larger models and training data presents new computational challenges.\nResearch questions for DACE (Design and Analysis of Computer Experiments) include how to design computer experiments that make efficient use of computation and how to meta-model computer codes to save on simulation effort. The choice of surrogate model for computer codes significantly impacts the optimal experiment design, and the preferred model-design pairs can vary depending on the specific goal.\nThe combination of computer simulation, design, and modeling with field data from similar real-world experiments introduces a new category of computer model tuning problems. The ultimate goal is to automate these processes to the greatest extent possible, allowing for the deployment of HPC with minimal human intervention.\nOne of the remaining differences between RSM and DACE lies in how they handle noise. DACE employs replication, a technique that would not be used in a deterministic setting, to separate signal from noise. Traditional RSM is best suited for situations where a substantial proportion of the variability in the data is due to noise, and where the acquisition of data values can be severely limited. Consequently, RSM is better suited for a different class of problems, aligning with its intended purposes.\nTwo very good texts on computer experiments and surrogate modeling are Santner, Williams, and Notz (2003) and Forrester, Sóbester, and Keane (2008). The former is the canonical reference in the statistics literature and the latter is perhaps more popular in engineering.\n\nExample 2.1 (Example: DACE and RSM) Imagine you are a chemical engineer tasked with optimizing a chemical process to maximize yield. You can control temperature and pressure, but repeated experiments show variability in yield due to inconsistencies in raw materials.\n\nUsing RSM: You would use RSM to design a series of experiments varying temperature and pressure. You would then fit a response surface (a mathematical model) to the data, helping you understand how changes in temperature and pressure affect yield. Using this model, you can identify optimal conditions for maximizing yield despite the noise.\nUsing DACE: If instead you use a computational model to simulate the chemical process and want to account for numerical noise or uncertainty in model parameters, you might use DACE. You would run simulations at different conditions, possibly repeating them to assess variability and build a surrogate model that accurately predicts yields, which can be optimized to find the best conditions.\n\n\n\n2.3.1 Noise Handling in RSM and DACE\nNoise in RSM: In experimental settings, noise often arises due to variability in experimental conditions, measurement errors, or other uncontrollable factors. This noise can significantly affect the response variable, \\(Y\\). Replication is a standard procedure for handling noise in RSM. In the context of computer experiments, noise might not be present in the traditional sense since simulations can be deterministic. However, variability can arise from uncertainty in input parameters or model inaccuracies. DACE predominantly utilizes advanced interpolation to construct accurate models of deterministic data, sometimes considering statistical noise modeling if needed.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#updating-a-surrogate-model",
    "href": "001_surrogate.html#updating-a-surrogate-model",
    "title": "2  Simulation and Surrogate Modeling",
    "section": "2.4 Updating a Surrogate Model",
    "text": "2.4 Updating a Surrogate Model\nA surrogate model is updated by incorporating new data points, known as infill points, into the model to improve its accuracy and predictive capabilities. This process is iterative and involves the following steps:\n\nIdentify Regions of Interest: The surrogate model is analyzed to determine areas where it is inaccurate or where further exploration is needed. This could be regions with high uncertainty or areas where the model predicts promising results (e.g., potential optima).\nSelect Infill Points: Infill points are new data points chosen based on specific criteria, such as:\nExploitation: Sampling near predicted optima to refine the solution. Exploration: Sampling in regions of high uncertainty to improve the model globally. Balanced Approach: Combining exploitation and exploration to ensure both local and global improvements.\nEvaluate the True Function: The true function (e.g., a simulation or experiment) is evaluated at the selected infill points to obtain their corresponding outputs.\nUpdate the Surrogate Model: The surrogate model is retrained or updated using the new data, including the infill points, to improve its accuracy.\nRepeat: The process is repeated until the model meets predefined accuracy criteria or the computational budget is exhausted.\n\n\nDefinition 2.1 (Infill Points) Infill points are strategically chosen new data points added to the surrogate model. They are selected to:\n\nReduce uncertainty in the model.\nImprove predictions in regions of interest.\nEnhance the model’s ability to identify optima or trends.\n\n\nThe selection of infill points is often guided by infill criteria, such as:\n\nExpected Improvement (EI): Maximizing the expected improvement over the current best solution.\nUncertainty Reduction: Sampling where the model’s predictions have high variance.\nProbability of Improvement (PI): Sampling where the probability of improving the current best solution is highest.\n\nThe iterative infill-points updating process ensures that the surrogate model becomes increasingly accurate and useful for optimization or decision-making tasks.\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer Experiments. Berlin, Heidelberg, New York: Springer.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_sampling.html",
    "href": "001_sampling.html",
    "title": "3  Sampling Plans",
    "section": "",
    "text": "3.1 Ideas and Concepts\nThe goal of a sampling plan is to efficiently explore the input space to understand the behavior of the computer code and build a surrogate model that accurately represents the code’s behavior. Traditionally, Response Surface Methodology (RSM) has been used to design sampling plans for computer experiments. These sampling plans are based on procedures that generate points by means of a rectangular grid or a factorial design.\nHowever, more recently, Design and Analysis of Computer Experiments (DACE) has emerged as a more flexible and powerful approach for designing sampling plans.\nEngineering design often requires the construction of a surrogate model \\(\\hat{f}\\) to approximate the expensive response of a black-box function \\(f\\). The function \\(f(x)\\) represents a continuous metric (e.g., quality, cost, or performance) defined over a design space \\(D \\subset \\mathbb{R}^k\\), where \\(x\\) is a \\(k\\)-dimensional vector of design variables. Since evaluating \\(f\\) is costly, only a sparse set of samples is used to construct \\(\\hat{f}\\), which can then provide inexpensive predictions for any \\(x \\in D\\).\nThe process involves:\nA sampling plan\n\\[\nX =\n\\left\\{\n  x^{(i)} \\in D | i = 1, \\ldots, n\n\\right\\}\n\\]\ndetermines the spatial arrangement of observations. While some models require a minimum number of data points \\(n\\), once this threshold is met, a surrogate model can be constructed to approximate \\(f\\) efficiently.\nA well-posed model does not always perform well because its ability to generalize depends heavily on the sampling plan used to collect data. If the sampling plan is poorly designed, the model may fail to capture critical behaviors in the design space. For example:",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#ideas-and-concepts",
    "href": "001_sampling.html#ideas-and-concepts",
    "title": "3  Sampling Plans",
    "section": "",
    "text": "Definition 3.1 (Sampling Plan) In the context of computer experiments, the term sampling plan refers to the set of input values, say \\(X\\),at which the computer code is evaluated.\n\n\n\n\n\n\nSampling discrete observations:\nUsing these samples to construct an approximation \\(\\hat{f}\\).\nEnsuring the surrogate model is well-posed, meaning it is mathematically valid and can generalize predictions effectively.\n\n\n\n\n\n\nExtreme Sampling: Measuring performance only at the extreme values of parameters may miss important behaviors in the center of the design space, leading to incomplete understanding.\nUneven Sampling: Concentrating samples in certain regions while neglecting others forces the model to extrapolate over unsampled areas, potentially resulting in inaccurate or misleading predictions. Additionally, in some cases, the data may come from external sources or be limited in scope, leaving little control over the sampling plan. This can further restrict the model’s ability to generalize effectively.\n\n\n3.1.1 The ‘Curse of Dimensionality’ and How to Avoid It\nThe “curse of dimensionality” refers to the exponential increase in computational complexity and data requirements as the number of dimensions (variables) in a problem grows. For a one-dimensional space, sampling \\(n\\) locations may suffice for accurate predictions. In high-dimensional spaces, the amount of data needed to maintain the same level of accuracy or coverage increases dramatically. For example, if a one-dimensional space requires \\(n\\) samples for a certain accuracy, a \\(k\\)-dimensional space would require \\(n^k\\) samples. This makes tasks like optimization, sampling, and modeling computationally expensive and often impractical in high-dimensional settings.\n\nExample 3.1 (Example: Curse of Dimensionality) Consider a simple example where we want to model the cost of a car tire based on its wheel diameter. If we have one variable (wheel diameter), we might need 10 simulations to get a good estimate of the cost. Now, if we add 8 more variables (e.g., tread pattern, rubber type, etc.), the number of simulations required increases to \\(10^8\\) (10 million). This is because the number of combinations of design variables grows exponentially with the number of dimensions. This means that the computational budget required to evaluate all combinations of design variables becomes infeasible. In this case, it would take 11,416 years to complete the simulations, making it impractical to explore the design space fully.\n\n\n\n3.1.2 Physical versus Computational Experiments\nPhysical experiments are prone to experimental errors from three main sources:\n\nHuman error: Mistakes made by the experimenter.\nRandom error: Measurement inaccuracies that vary unpredictably.\nSystematic error: Consistent bias due to flaws in the experimental setup.\n\nThe key distinction is repeatability: systematic errors remain constant across repetitions, while random errors vary.\nComputational experiments, on the other hand, are deterministic and free from random errors. However, they are still affected by:\n\nHuman error: Bugs in code or incorrect boundary conditions.\nSystematic error: Biases from model simplifications (e.g., inviscid flow approximations) or finite resolution (e.g., insufficient mesh resolution).\n\nThe term “noise” is used differently in physical and computational contexts. In physical experiments, it refers to random errors, while in computational experiments, it often refers to systematic errors.\nUnderstanding these differences is crucial for designing experiments and applying techniques like Gaussian process-based approximations. For physical experiments, replication mitigates random errors, but this is unnecessary for deterministic computational experiments.\n\n\n3.1.3 Designing Preliminary Experiments (Screening)\nMinimizing the number of design variables \\(x_1, x_2, \\dots, x_k\\) is crucial before modeling the objective function \\(f\\). This process, called screening, aims to reduce dimensionality without compromising the analysis. If \\(f\\) is at least once differentiable over the design domain \\(D\\), the partial derivative \\(\\frac{\\partial f}{\\partial x_i}\\) can be used to classify variables:\n\nNegligible Variables: If \\(\\frac{\\partial f}{\\partial x_i} = 0, \\, \\forall x \\in D\\), the variable \\(x_i\\) can be safely neglected.\nLinear Additive Variables: If \\(\\frac{\\partial f}{\\partial x_i} = \\text{constant} \\neq 0, \\, \\forall x \\in D\\), the effect of \\(x_i\\) is linear and additive.\nNonlinear Variables: If \\(\\frac{\\partial f}{\\partial x_i} = g(x_i), \\, \\forall x \\in D\\), where \\(g(x_i)\\) is a non-constant function, \\(f\\) is nonlinear in \\(x_i\\).\nInteractive Nonlinear Variables: If \\(\\frac{\\partial f}{\\partial x_i} = g(x_i, x_j, \\dots), /, \\forall x \\in D\\), where \\(g(x_i, x_j, \\dots)\\) is a function involving interactions with other variables, \\(f\\) is nonlinear in \\(x_i\\) and interacts with \\(x_j\\).\n\nMeasuring \\(\\frac{\\partial f}{\\partial x_i}\\) across the entire design space is often infeasible due to limited budgets. The percentage of time allocated to screening depends on the problem: If many variables are expected to be inactive, thorough screening can significantly improve model accuracy by reducing dimensionality. If most variables are believed to impact the objective, focus should shift to modeling instead. Screening is a trade-off between computational cost and model accuracy, and its effectiveness depends on the specific problem context.\n\n3.1.3.1 Estimating the Distribution of Elementary Effects\nIn order to simplify the presentation of what follows, we make, without loss of generality, the assumption that the design space \\(D = [0, 1]^k\\); that is, we normalize all variables into the unit cube. We shall adhere to this convention for the rest of the book and strongly urge the reader to do likewise when implementing any algorithms described here, as this step not only yields clearer mathematics in some cases but also safeguards against scaling issues.\nBefore proceeding with the description of the Morris algorithm, we need to define an important statistical concept. Let us restrict our design space \\(D\\) to a \\(k\\)-dimensional, \\(p\\)-level full factorial grid, that is,\n\\[\nx_i \\in \\{0, \\frac{1}{p-1}, \\frac{2}{p-1}, \\dots, 1\\}, \\quad \\text{ for } i = 1, \\dots, k.\n\\]\n\nDefinition 3.2 (Elementary Effect) For a given baseline value \\(x \\in D\\), let \\(d_i(x)\\) denote the elementary effect of \\(x_i\\), where:\n\\[\nd_i(x) = \\frac{f(x_1, \\dots, x_i + \\Delta, \\dots, x_k) - f(x_1, \\dots, x_i - \\Delta, \\dots, x_k)}{2\\Delta}, \\quad i = 1, \\dots, k,\n\\tag{3.1}\\] where \\(\\Delta\\) is the step size, which is defined as the distance between two adjacent levels in the grid. In other words, we have:\nwith \\[\\Delta = \\frac{\\xi}{p-1}, \\quad \\xi \\in \\mathbb{N}^*, \\quad \\text{and} \\quad x \\in D , \\text{ such that its components } x_i \\leq 1 - \\Delta.\n\\]\n\\(\\Delta\\) is the step size. The elementary effect \\(d_i(x)\\) measures the sensitivity of the function \\(f\\) to changes in the variable \\(x_i\\) at the point \\(x\\).\n\nMorris’s method aims to estimate the parameters of the distribution of elementary effects associated with each variable. A large measure of central tendency indicates that a variable has a significant influence on the objective function across the design space, while a large measure of spread suggests that the variable is involved in interactions or contributes to the nonlinearity of \\(f\\). In practice, the sample mean and standard deviation of a set of \\(d_i(x)\\) values, calculated in different parts of the design space, are used for this estimation.\nTo ensure efficiency, the preliminary sampling plan \\(X\\) should be designed so that each evaluation of the objective function \\(f\\) contributes to the calculation of two elementary effects, rather than just one (as would occur with a naive random spread of baseline \\(x\\) values and adding \\(\\Delta\\) to one variable). Additionally, the sampling plan should provide a specified number (e.g., \\(r\\)) of elementary effects for each variable, independently drawn with replacement. For a detailed discussion on constructing such a sampling plan, readers are encouraged to consult Morris’s original paper (Morris, 1991). Here, we focus on describing the process itself.\nThe random orientation of the sampling plan \\(B\\) can be constructed as follows:\n\nLet \\(B\\) be a \\((k+1) \\times k\\) matrix of 0s and 1s, where for each column \\(i\\), two rows differ only in their \\(i\\)-th entries.\nCompute a random orientation of \\(B\\), denoted \\(B^*\\):\n\n\\[\nB^* =\n\\left(\n1_{k+1,k} x^* + (\\Delta/2)\n\\left[\n(2B-1_{k+1,k})\nD^* +\n1_{k+1,k}\n\\right]\n\\right)\nP^*,\n\\]\nwhere:\n\n\\(D^*\\) is a \\(k\\)-dimensional diagonal matrix with diagonal elements \\(\\pm 1\\) (equal probability),\n\\(\\mathbf{1}\\) is a matrix of 1s,\n\\(x^*\\) is a randomly chosen point in the \\(p\\)-level design space (limited by \\(\\Delta\\)),\n\\(P^*\\) is a \\(k \\times k\\) random permutation matrix with one 1 per column and row.\n\nspotpython provides a Python implementation to compute \\(B^*\\), see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/effects.py.\nHere is the corresponding code:\n\ndef randorient(k, p, xi, seed=None):\n    # Initialize random number generator with the provided seed\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    else:\n        rng = np.random.default_rng()\n\n    # Step length\n    Delta = xi / (p - 1)\n\n    m = k + 1\n\n    # A truncated p-level grid in one dimension\n    xs = np.arange(0, 1 - Delta, 1 / (p - 1))\n    xsl = len(xs)\n    if xsl &lt; 1:\n        print(f\"xi = {xi}.\")\n        print(f\"p = {p}.\")\n        print(f\"Delta = {Delta}.\")\n        print(f\"p - 1 = {p - 1}.\")\n        raise ValueError(f\"The number of levels xsl is {xsl}, but it must be greater than 0.\")\n\n    # Basic sampling matrix\n    B = np.vstack((np.zeros((1, k)), np.tril(np.ones((k, k)))))\n\n    # Randomization\n\n    # Matrix with +1s and -1s on the diagonal with equal probability\n    Dstar = np.diag(2 * rng.integers(0, 2, size=k) - 1)\n\n    # Random base value\n    xstar = xs[rng.integers(0, xsl, size=k)]\n\n    # Permutation matrix\n    Pstar = np.zeros((k, k))\n    rp = rng.permutation(k)\n    for i in range(k):\n        Pstar[i, rp[i]] = 1\n\n    # A random orientation of the sampling matrix\n    Bstar = (np.ones((m, 1)) @ xstar.reshape(1, -1) +\n        (Delta / 2) * ((2 * B - np.ones((m, k))) @ Dstar +\n        np.ones((m, k)))) @ Pstar\n\n    return Bstar\n\nThe code following snippet generates a random orientation of a sampling matrix Bstar using the randorient() function. The input parameters are:\n\nk = 3: The number of design variables (dimensions).\np = 3: The number of levels in the grid for each variable.\nxi = 1: A parameter used to calculate the step size Delta.\n\nStep-size calculation is performed as follows: Delta = xi / (p - 1) = 1 / (3 - 1) = 0.5, which determines the spacing between levels in the grid.\nNext, random sampling matrix construction is computed:\n\nA truncated grid is created with levels [0, 0.5] (based on Delta).\nA basic sampling matrix B is constructed, which is a lower triangular matrix with 0s and 1s.\n\nThen, randomization is applied:\n\nDstar: A diagonal matrix with random entries of +1 or -1.\nxstar: A random starting point from the grid.\nPstar: A random permutation matrix.\n\nRandom orientation is applied to the basic sampling matrix B to create Bstar. This involves scaling, shifting, and permuting the rows and columns of B.\nThe final output is the matrix Bstar, which represents a random orientation of the sampling plan. Each row corresponds to a sampled point in the design space, and each column corresponds to a design variable.\n\nExample 3.2 (Random Orientation of the Sampling Matrix in 2-D)  \n\nk = 2\np = 3\nxi = 1\nBstar = randorient(k, p, xi, seed=123)\nprint(f\"Random orientation of the sampling matrix:\\n{Bstar}\")\n\nRandom orientation of the sampling matrix:\n[[0.5 0. ]\n [0.  0. ]\n [0.  0.5]]\n\n\nWe can visualize the random orientation of the sampling matrix in 2-D as shown in Figure 3.1.\n\nplt.figure(figsize=(6, 6))\nplt.scatter(Bstar[:, 0], Bstar[:, 1], color='blue', s=50, label='Hypercube Points')\nfor i in range(Bstar.shape[0]):\n    plt.text(Bstar[i, 0] + 0.01, Bstar[i, 1] + 0.01, str(i), fontsize=9)\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.grid()\n\n\n\n\n\n\n\nFigure 3.1: Random orientation of the sampling matrix in 2-D. The labels indicate the row index of the points.\n\n\n\n\n\n\n\nExample 3.3 (Random Orientation of the Sampling Matrix)  \n\nk = 3\np = 3\nxi = 1\nBstar = randorient(k, p, xi)\nprint(f\"Random orientation of the sampling matrix:\\n{Bstar}\")\n\nRandom orientation of the sampling matrix:\n[[0.  0.  0. ]\n [0.  0.5 0. ]\n [0.5 0.5 0. ]\n [0.5 0.5 0.5]]\n\n\n\nTo obtain \\(r\\) elementary effects for each variable, the screening plan is built from \\(r\\) random orientations:\n\\[\nX =\n\\begin{pmatrix}\nB^*_1 \\\\\nB^*_2 \\\\\n\\vdots \\\\\nB^*_r\n\\end{pmatrix}\n\\]\nThe function screeningplan() generates a screening plan by calling the randorient() function r times. It creates a list of random orientations and then concatenates them into a single array, which represents the screening plan. The screening plan implementation in Python is as follows (see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/effects.py):\n\ndef screeningplan(k, p, xi, r):\n    # Empty list to accumulate screening plan rows\n    X = []\n    for i in range(r):\n        X.append(randorient(k, p, xi))\n    # Concatenate list of arrays into a single array\n    X = np.vstack(X)\n    return X\n\nIt works like follows:\n\nThe value of the objective function \\(f\\) is computed for each row of the screening plan matrix \\(X\\). These values are stored in a column vector \\(t\\) of size \\((r * (k + 1)) \\times 1\\), where:\n\nr is the number of random orientations.\nk is the number of design variables.\n\n\nThe elementary effects are calculated using the following formula:\n\nFor each random orientation, adjacent rows of the screening plan matrix X and their corresponding function values from t are used.\nThese values are inserted into Equation 3.1 to compute elementary effects for each variable. An elementary effect measures the sensitivity of the objective function to changes in a specific variable.\n\nResults can be used for a statistical analysis. After collecting a sample of \\(r\\) elementary effects for each variable:\n\nThe sample mean (central tendency) is computed to indicate the overall influence of the variable.\nThe sample standard deviation (spread) is computed to capture variability, which may indicate interactions or nonlinearity.\n\nThe results (sample means and standard deviations) are plotted on a chart for comparison. This helps identify which variables have the most significant impact on the objective function and whether their effects are linear or involve interactions. This is implemented in the function screening_plot() in Python, which uses the helper function _screening() to calculate the elementary effects and their statistics.\n\ndef _screening(X, fun, xi, p, labels, bounds=None) -&gt; tuple:\n    \"\"\"Helper function to calculate elementary effects for a screening design.\n\n    Args:\n        X (np.ndarray): The screening plan matrix, typically structured\n            within a [0,1]^k box.\n        fun (object): The objective function to evaluate at each\n            design point in the screening plan.\n        xi (float): The elementary effect step length factor.\n        p (int): Number of discrete levels along each dimension.\n        labels (list of str): A list of variable names corresponding to\n            the design variables.\n        bounds (np.ndarray): A 2xk matrix where the first row contains\n            lower bounds and the second row contains upper bounds for\n            each variable.\n\n    Returns:\n        tuple: A tuple containing two arrays:\n            - sm: The mean of the elementary effects for each variable.\n            - ssd: The standard deviation of the elementary effects for\n            each variable.\n    \"\"\"\n    k = X.shape[1]\n    r = X.shape[0] // (k + 1)\n\n    # Scale each design point\n    t = np.zeros(X.shape[0])\n    for i in range(X.shape[0]):\n        if bounds is not None:\n            X[i, :] = bounds[0, :] + X[i, :] * (bounds[1, :] - bounds[0, :])\n        t[i] = fun(X[i, :])\n\n    # Elementary effects\n    F = np.zeros((k, r))\n    for i in range(r):\n        for j in range(i * (k + 1), i * (k + 1) + k):\n            idx = np.where(X[j, :] - X[j + 1, :] != 0)[0][0]\n            F[idx, i] = (t[j + 1] - t[j]) / (xi / (p - 1))\n\n    # Statistical measures (divide by n)\n    ssd = np.std(F, axis=1, ddof=0)\n    sm = np.mean(F, axis=1)\n    return sm, ssd\n\n\ndef screening_plot(X, fun, xi, p, labels, bounds=None, show=True) -&gt; None:\n    \"\"\"Generates a plot with elementary effect screening metrics.\n\n    This function calculates the mean and standard deviation of the\n    elementary effects for a given set of design variables and plots\n    the results.\n\n    Args:\n        X (np.ndarray):\n            The screening plan matrix, typically structured within a [0,1]^k box.\n        fun (object):\n            The objective function to evaluate at each design point in the screening plan.\n        xi (float):\n            The elementary effect step length factor.\n        p (int):\n            Number of discrete levels along each dimension.\n        labels (list of str):\n            A list of variable names corresponding to the design variables.\n        bounds (np.ndarray):\n            A 2xk matrix where the first row contains lower bounds and\n            the second row contains upper bounds for each variable.\n        show (bool):\n            If True, the plot is displayed. Defaults to True.\n\n    Returns:\n        None: The function generates a plot of the results.\n    \"\"\"\n    k = X.shape[1]\n    sm, ssd = _screening(X=X, fun=fun, xi=xi, p=p, labels=labels, bounds=bounds)\n    plt.figure()\n    for i in range(k):\n        plt.text(sm[i], ssd[i], labels[i], fontsize=10)\n    plt.axis([min(sm), 1.1 * max(sm), min(ssd), 1.1 * max(ssd)])\n    plt.xlabel(\"Sample means\")\n    plt.ylabel(\"Sample standard deviations\")\n    plt.gca().tick_params(labelsize=10)\n    plt.grid(True)\n    if show:\n        plt.show()\n\n\n\n\n3.1.4 Special Considerations When Deploying Screening Algorithms\nWhen implementing the screening algorithm described above, two specific scenarios require special attention:\n\nDuplicate Design Points: If the dimensionality \\(k\\) of the space is relatively low and you can afford a large number of elementary effects \\(r\\), we should be be aware of the increased probability of duplicate design points appearing in the sampling plan \\(X\\). *Since the responses at sample points are deterministic, there’s no value in evaluating the same point multiple times. Fortunately, this issue is relatively uncommon in practice, as screening high-dimensional spaces typically requires large numbers of elementary effects, which naturally reduces the likelihood of duplicates.\nFailed Simulations: Numerical simulation codes occasionally fail to return valid results due to meshing errors, non-convergence of partial differential equation solvers, numerical instabilities, or parameter combinations outside the stable operating range.\n\nFrom a screening perspective, this is particularly problematic because an entire random orientation \\(B^*\\) becomes compromised if even a single point within it fails to evaluate properly. Implementing error handling strategies or fallback methods to manage such cases should be considered.\nFor robust screening studies, monitoring simulation success rates and having contingency plans for failed evaluations are important aspects of the experimental design process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#analyzing-variable-importance-in-aircraft-wing-weight",
    "href": "001_sampling.html#analyzing-variable-importance-in-aircraft-wing-weight",
    "title": "3  Sampling Plans",
    "section": "3.2 Analyzing Variable Importance in Aircraft Wing Weight",
    "text": "3.2 Analyzing Variable Importance in Aircraft Wing Weight\nLet us consider the following analytical expression used as a conceptual level estimate of the weight of a light aircraft wing as discussed in Chapter 1.\n\nfun = Analytical()\nk = 10\np = 10\nxi = 1\nr = 25\nX = screeningplan(k=k, p=p, xi=xi, r=r)  # shape (r x (k+1), k)\nvalue_range = np.array([\n    [150, 220,   6, -10, 16, 0.5, 0.08, 2.5, 1700, 0.025],\n    [200, 300,  10,  10, 45, 1.0, 0.18, 6.0, 2500, 0.08 ],\n])\nlabels = [\n    \"S_W\", \"W_fw\", \"A\", \"Lambda\",\n    \"q\",   \"lambda\", \"tc\", \"N_z\",\n    \"W_dg\", \"W_p\"\n]\nscreening_plot(\n    X=X,\n    fun=fun.fun_wingwt,\n    bounds=value_range,\n    xi=xi,\n    p=p,\n    labels=labels,\n)\n\n\n\n\n\n\n\nFigure 3.2: Estimated means and standard deviations of the elementary effects for the 10 design variables of the wing weight function. Example based on Forrester, Sóbester, and Keane (2008).\n\n\n\n\n\n\n\n\n\n\n\nNoteNondeterministic Results\n\n\n\nThe code will generate a slightly different screening plan each time, as it uses random orientations of the sampling matrix \\(B\\).\n\n\nFigure 3.2 provides valuable insights into variable activity without requiring domain expertise. The screening study with \\(r = 25\\) elementary effects reveals distinct patterns in how variables affect wing weight:\n\nVariables with Minimal Impact: A clearly defined group of variables clusters around the origin - indicating their minimal impact on wing weight:\n\nPaint weight (\\(W_p\\)) - as expected, contributes little to overall wing weight\nDynamic pressure (\\(q\\)) - within our chosen range, this has limited effect (essentially representing different cruise altitudes at the same speed)\nTaper ratio (\\(\\lambda\\)) and quarter-chord sweep (\\(\\Lambda\\)) - these geometric parameters have minor influence within the narrow range (-10° to 10°) typical of light aircraft\n\nVariables with Linear Effects:\n\nWhile still close to the origin, fuel weight (\\(W_{fw}\\)) shows a slightly larger central tendency with very low standard deviation. This indicates moderate importance but minimal involvement in interactions with other variables.\n\nVariables with Nonlinear/Interactive Effects:\n\nAspect ratio (\\(A\\)) and airfoil thickness ratio (\\(R_{tc}\\)) show similar importance levels, but their high standard deviations suggest significant nonlinear behavior and interactions with other variables.\n\nDominant Variables: The most significant impacts come from:\n\nFlight design gross weight (\\(W_{dg}\\))\nWing area (\\(S_W\\))\nUltimate load factor (\\(N_z\\))\n\n\nThese variables show both large central tendency values and high standard deviations, indicating strong direct effects and complex interactions. The interaction between aspect ratio and load factor is particularly important - high values of both create extremely heavy wings, explaining why highly maneuverable fighter jets cannot use glider-like wing designs.\nWhat makes this screening approach valuable is its ability to identify critical variables without requiring engineering knowledge or expensive modeling. In real-world applications, we rarely have the luxury of creating comprehensive parameter space visualizations, which is precisely why surrogate modeling is needed. After identifying the active variables through screening, we can design a focused sampling plan for these key variables. This forms the foundation for building an accurate surrogate model of the objective function.\nWhen the objective function is particularly expensive to evaluate, we might recycle the runs performed during screening for the actual model fitting step. This is most effective when some variables prove to have no impact at all. However, since completely inactive variables are rare in practice, engineers must carefully balance the trade-off between reusing expensive simulation runs and introducing potential noise into the model.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#designing-a-sampling-plan",
    "href": "001_sampling.html#designing-a-sampling-plan",
    "title": "3  Sampling Plans",
    "section": "3.3 Designing a Sampling Plan",
    "text": "3.3 Designing a Sampling Plan\n\n3.3.1 Stratification\nA feature shared by all of the approximation models discussed in Forrester, Sóbester, and Keane (2008) is that they are more accurate in the vicinity of the points where we have evaluated the objective function. In later chapters we will delve into the laws that quantify our decaying trust in the model as we move away from a known, sampled point, but for the purposes of the present discussion we shall merely draw the intuitive conclusion that a uniform level of model accuracy throughout the design space requires a uniform spread of points. A sampling plan possessing this feature is said to be space-filling.\nThe most straightforward way of sampling a design space in a uniform fashion is by means of a rectangular grid of points. This is the full factorial sampling technique.\nHere is the simplified version of a Python function that will sample the unit hypercube at all levels in all dimensions, with the \\(k\\)-vector \\(q\\) containing the number of points required along each dimension, see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/sampling.py.\nThe variable Edges specifies whether we want the points to be equally spaced from edge to edge (Edges=1) or we want them to be in the centres of \\(n = q_1 \\times q_2 \\times \\ldots \\times q_k\\) bins filling the unit hypercube (for any other value of Edges).\n\ndef fullfactorial(q_param, Edges=1) -&gt; np.ndarray:\n    \"\"\"Generates a full factorial sampling plan in the unit cube.\n\n    Args:\n        q (list or np.ndarray):\n            A list or array containing the number of points along each dimension (k-vector).\n        Edges (int, optional):\n            Determines spacing of points. If `Edges=1`, points are equally spaced from edge to edge (default).\n            Otherwise, points will be in the centers of n = q[0]*q[1]*...*q[k-1] bins filling the unit cube.\n\n    Returns:\n        (np.ndarray): Full factorial sampling plan as an array of shape (n, k), where n is the total number of points and k is the number of dimensions.\n\n    Raises:\n        ValueError: If any dimension in `q` is less than 2.\n    \"\"\"\n    q_levels = np.array(q_param) # Use a distinct variable for original levels\n    if np.min(q_levels) &lt; 2:\n        raise ValueError(\"You must have at least two points per dimension.\")\n    \n    n = np.prod(q_levels)\n    k = len(q_levels)\n    X = np.zeros((n, k))\n    \n    # q_for_prod_calc is used for calculating repetitions, includes the phantom element.\n    # This matches the logic of the user-provided snippet where 'q' was modified.\n    q_for_prod_calc = np.append(q_levels, 1)\n\n    for j in range(k): # k is the original number of dimensions\n        # current_dim_levels is the number of levels for the current dimension j\n        # In the user's snippet, q[j] correctly refers to the original level count\n        # as j ranges from 0 to k-1, and q_for_prod_calc[j] = q_levels[j] for this range.\n        current_dim_levels = q_for_prod_calc[j] \n        \n        if Edges == 1:\n            one_d_slice = np.linspace(0, 1, int(current_dim_levels))\n        else:\n            # Corrected calculation for bin centers\n            if current_dim_levels == 1: # Should not be hit if np.min(q_levels) &gt;= 2\n                one_d_slice = np.array([0.5])\n            else:\n                one_d_slice = np.linspace(1 / (2 * current_dim_levels), \n                                          1 - 1 / (2 * current_dim_levels), \n                                          int(current_dim_levels))\n        \n        column = np.array([])\n        # The product q_for_prod_calc[j + 1 : k] correctly calculates \n        # the product of remaining original dimensions' levels.\n        num_consecutive_repeats = np.prod(q_for_prod_calc[j + 1 : k])\n        \n        # This loop structure replicates the logic from the user's snippet\n        while len(column) &lt; n:\n            for ll_idx in range(int(current_dim_levels)): # Iterate through levels of current dimension\n                val_to_repeat = one_d_slice[ll_idx]\n                column = np.append(column, np.ones(int(num_consecutive_repeats)) * val_to_repeat)\n        X[:, j] = column\n    return X\n\n\nq = [3, 2]\nX = fullfactorial(q, Edges=0)\nprint(X)\n\n[[0.16666667 0.25      ]\n [0.16666667 0.75      ]\n [0.5        0.25      ]\n [0.5        0.75      ]\n [0.83333333 0.25      ]\n [0.83333333 0.75      ]]\n\n\nFigure 3.3 shows the points in the unit hypercube for the case of 3x2 points.\n\n\n\n\n\n\n\n\nFigure 3.3: 2D Full Factorial Sampling (3x2 Points). Edges = 0\n\n\n\n\n\n\nX = fullfactorial(q, Edges=1)\nprint(X)\n\n[[0.  0. ]\n [0.  1. ]\n [0.5 0. ]\n [0.5 1. ]\n [1.  0. ]\n [1.  1. ]]\n\n\nFigure 3.4 shows the points in the unit hypercube for the case of 3x2 points with edges.\n\n\n\n\n\n\n\n\nFigure 3.4: 2D Full Factorial Sampling (3x2 Points). Edges = 1\n\n\n\n\n\nThe full factorial sampling plan method generates a uniform sampling design by creating a grid of points across all dimensions. For example, calling fullfactorial([3, 4, 5], 1) produces a three-dimensional sampling plan with 3, 4, and 5 levels along each dimension, respectively. While this approach satisfies the uniformity criterion, it has two significant limitations:\n\nRestricted Design Sizes: The method only works for designs where the total number of points \\(n\\) can be expressed as the product of the number of levels in each dimension, i.e., \\(n = q_1 \\times q_2 \\times \\cdots \\times q_k\\).\nOverlapping Projections: When the sampling points are projected onto individual axes, sets of points may overlap, reducing the effectiveness of the sampling plan. This can lead to non-uniform coverage in the projections, which may not fully represent the design space.\n\n\n\n3.3.2 Latin Squares and Random Latin Hypercubes\nTo improve the uniformity of projections for any individual variable, the range of that variable can be divided into a large number of equal-sized bins, and random subsamples of equal size can be generated within these bins. This method is called stratified random sampling. Extending this idea to all dimensions results in a stratified sampling plan, commonly implemented using Latin hypercube sampling.\n\nDefinition 3.3 (Latin Squares and Hypercubes) In the context of statistical sampling, a square grid containing sample positions is a Latin square if (and only if) there is only one sample in each row and each column. A Latin hypercube is the generalisation of this concept to an arbitrary number of dimensions, whereby each sample is the only one in each axis-aligned hyperplane containing it\n\nFor two-dimensional discrete variables, a Latin square ensures uniform projections. An \\((n \\times n)\\) Latin square is constructed by filling each row and column with a permutation of \\(\\{1, 2, \\dots, n\\}\\), ensuring each number appears only once per row and column.\n\nExample 3.4 (Latin Square) For \\(n = 4\\), a Latin square might look like this:\n2   1   3   4\n3   2   4   1\n1   4   2   3\n4   3   1   2\n\nLatin Hypercubes are the multidimensional extension of Latin squares. The design space is divided into equal-sized hypercubes (bins), and one point is placed in each bin. The placement ensures that moving along any axis from an occupied bin does not encounter another occupied bin. This guarantees uniform projections across all dimensions. To construct a Latin hypercube, the following steps are taken:\n\nRepresent the sampling plan as an \\(n \\times k\\) matrix \\(X\\), where \\(n\\) is the number of points and \\(k\\) is the number of dimensions.\nFill each column of \\(X\\) with random permutations of \\(\\{1, 2, \\dots, n\\}\\).\nNormalize the plan into the unit hypercube \\([0, 1]^k\\).\n\nThis approach ensures multidimensional stratification and uniformity in projections. Here is the code:\n\ndef rlh(n: int, k: int, edges: int = 0) -&gt; np.ndarray:\n    # Initialize array\n    X = np.zeros((n, k), dtype=float)\n\n    # Fill with random permutations\n    for i in range(k):\n        X[:, i] = np.random.permutation(n)\n\n    # Adjust normalization based on the edges flag\n    if edges == 1:\n        # [X=0..n-1] -&gt; [0..1]\n        X = X / (n - 1)\n    else:\n        # Points at true midpoints\n        # [X=0..n-1] -&gt; [0.5/n..(n-0.5)/n]\n        X = (X + 0.5) / n\n\n    return X\n\n\nExample 3.5 (Random Latin Hypercube) The following code can be used to generate a 2D Latin hypercube with 5 points and edges=0:\n\nX = rlh(n=5, k=2, edges=0)\nprint(X)\n\n[[0.7 0.9]\n [0.5 0.5]\n [0.9 0.7]\n [0.3 0.1]\n [0.1 0.3]]\n\n\nFigure 3.5 shows the points in the unit hypercube for the case of 5 points with edges=0.\n\n\n\n\n\n\n\n\nFigure 3.5: 2D Latin Hypercube Sampling (5 Points, Edges=0)\n\n\n\n\n\n\n\nExample 3.6 (Random Latin Hypercube with Edges) The following code can be used to generate a 2D Latin hypercube with 5 points and edges=1:\n\nX = rlh(n=5, k=2, edges=1)\nprint(X)\n\n[[1.   0.5 ]\n [0.25 0.25]\n [0.5  0.  ]\n [0.   1.  ]\n [0.75 0.75]]\n\n\nFigure 3.6 shows the points in the unit hypercube for the case of 5 points with edges=1.\n\n\n\n\n\n\n\n\nFigure 3.6: 2D Latin Hypercube Sampling (5 Points, Edges=1)\n\n\n\n\n\n\n\n\n3.3.3 Space-filling Designs: Maximin Plans\nA widely adopted measure for assessing the uniformity, or ‘space-fillingness’, of a sampling plan is the maximin metric, initially proposed by Johnson, Moore, and Ylvisaker (1990). This criterion can be formally defined as follows.\nConsider a sampling plan \\(X\\). Let \\(d_1, d_2, \\ldots, d_m\\) represent the unique distances between all possible pairs of points within \\(X\\), arranged in ascending order. Furthermore, let \\(J_1, J_2, \\ldots, J_m\\) be defined such that \\(J_j\\) denotes the count of point pairs in \\(X\\) separated by the distance \\(d_j\\).\n\nDefinition 3.4 (Maximin plan) A sampling plan \\(X\\) is considered a maximin plan if, among all candidate plans, it maximizes the smallest inter-point distance \\(d_1\\). Among plans that satisfy this condition, it further minimizes \\(J_1\\), the number of pairs separated by this minimum distance.\n\nWhile this definition is broadly applicable to any collection of sampling plans, our focus is narrowed to Latin hypercube designs to preserve their desirable stratification properties. However, even within this restricted class, Definition 3.4 may identify multiple equivalent maximin designs. To address this, a more comprehensive ‘tie-breaker’ definition, as proposed by Morris and Mitchell (1995), is employed:\n\nDefinition 3.5 (Maximin plan with tie-breaker) A sampling plan \\(X\\) is designated as the maximin plan if it sequentially optimizes the following conditions: it maximizes \\(d_1\\); among those, it minimizes \\(J_1\\); among those, it maximizes \\(d_2\\); among those, it minimizes \\(J_2\\); and so forth, concluding with minimizing \\(J_m\\).\n\nJohnson, Moore, and Ylvisaker (1990) established that the maximin criterion (Definition 3.4) is equivalent to the D-optimality criterion used in linear regression. However, the extended maximin criterion incorporating a tie-breaker (Definition 3.5) is often preferred due to its intuitive nature and practical utility. Given that the sampling plans under consideration make no assumptions about model structure, the latter criterion (Definition 3.5) will be employed.\nTo proceed, a precise definition of ‘distance’ within these contexts is necessary. The p-norm is the most widely adopted metric for this purpose:\n\nDefinition 3.6 (p-norm) The p-norm of a vector \\(\\vec{x} = (x_1, x_2, \\ldots, x_k)\\) is defined as:\n\\[\nd_p(\\vec{x}^{(i_1)}, \\vec{x}^{(i_2)}) = \\left( \\sum_{j=1}^k |x_j^{(i_1)} - x_j^{(i_2)}|^p \\right)^{1/p}.\n\\tag{3.2}\\]\n\nWhen \\(p = 1\\), Equation 3.2 defines the rectangular distance, occasionally referred to as the Manhattan norm (an allusion to a grid-like city layout). Setting \\(p = 2\\) yields the Euclidean norm. The existing literature offers limited evidence to suggest the superiority of one norm over the other for evaluating sampling plans when no model structure assumptions are made. It is important to note, however, that the rectangular distance is considerably less computationally demanding. This advantage can be quite significant, particularly when evaluating large sampling plans.\nFor the computational implementation of Definition 3.5, the initial step involves constructing the vectors \\(d_1, d_2, \\ldots, d_m\\) and \\(J_1, J_2, \\ldots, J_m\\). The jd function facilitates this task.\n\n3.3.3.1 The Function jd\nThe function jd computes the distinct p-norm distances between all pairs of points in a given set and counts their occurrences. It returns two arrays: one for the distinct distances and another for their multiplicities.\n\ndef jd(X: np.ndarray, p: float = 1.0) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array of shape (n, d) representing n points\n            in d-dimensional space.\n        p (float, optional):\n            The distance norm to use.\n            p=1 uses the Manhattan (L1) norm, while p=2 uses the\n            Euclidean (L2) norm. Defaults to 1.0 (Manhattan norm).\n\n    Returns:\n        (np.ndarray, np.ndarray):\n            A tuple (J, distinct_d), where:\n            - distinct_d is a 1D float array of unique,\n            sorted distances between points.\n            - J is a 1D integer array that provides\n            the multiplicity (occurrence count)\n            of each distance in distinct_d.\n    \"\"\"\n    n = X.shape[0]\n\n    # Allocate enough space for all pairwise distances\n    # (n*(n-1))/2 pairs for an n-point set\n    pair_count = n * (n - 1) // 2\n    d = np.zeros(pair_count, dtype=float)\n\n    # Fill the distance array\n    idx = 0\n    for i in range(n - 1):\n        for j in range(i + 1, n):\n            # Compute the p-norm distance\n            d[idx] = np.linalg.norm(X[i] - X[j], ord=p)\n            idx += 1\n\n    # Find unique distances and their multiplicities\n    distinct_d = np.unique(d)\n    J = np.zeros_like(distinct_d, dtype=int)\n    for i, val in enumerate(distinct_d):\n        J[i] = np.sum(d == val)\n    return J, distinct_d\n\n\nExample 3.7 (The Function jd) Consider a small 3-point set in 2D space, with points located at (0,0), (1,1), and (2,2) as shown in Figure 3.7. The distinct distances and their occurrences can be computed using the jd function, as shown in the following code:\n\n\n\n\n\n\n\n\nFigure 3.7: 3-Point Set in 2D Space\n\n\n\n\n\n\nJ, distinct_d = jd(X, p=2.0)\nprint(\"Distinct distances (d_i):\", distinct_d)\nprint(\"Occurrences (J_i):\", J)\n\nDistinct distances (d_i): [1.41421356 2.82842712]\nOccurrences (J_i): [2 1]\n\n\n\n\n\n\n3.3.4 Memory Management\nA computationally intensive part of the calculation performed with the jd-function is the creation of the vector \\(\\vec{d}\\) containing all pairwise distances. This is particularly true for large sampling plans; for instance, a 1000-point plan requires nearly half a million distance calculations.\n\nDefinition 3.7 (Pre-allocation of Memory) Pre-allocation of memory is a programming technique where a fixed amount of memory is reserved for a data structure (like an array or vector) before it is actually filled with data. This is done to avoid the computational overhead associated with dynamic memory allocation, which involves repeatedly requesting and resizing memory as new elements are added.\n\nConsequently, pre-allocating memory for the distance vector \\(\\vec{d}\\) is essential. This necessitates a slightly less direct method for computing the indices of \\(\\vec{d}\\), rather than appending each new element, which would involve costly dynamic memory allocation.\nThe implementation of Definition 3.5 is now required. Finding the most space-filling design involves pairwise comparisons. This problem can be approached using a ‘divide and conquer’ strategy, simplifying it to the task of selecting the better of two sampling plans. The function mm(X1,X2,p) is designed for this purpose. It returns an index indicating which of the two designs is more space-filling, or 0 if they are equally space-filling, based on the \\(p\\)-norm for distance computation.\n\n3.3.4.1 The Function mm\nThe function mm compares two sampling plans based on the Morris-Mitchell criterion. It uses the jd function to compute the distances and multiplicities, constructs vectors for comparison, and determines which plan is more space-filling.\n\ndef mm(X1: np.ndarray, X2: np.ndarray, p: Optional[float] = 1.0) -&gt; int:\n    \"\"\"\n    Args:\n        X1 (np.ndarray): A 2D array representing the first sampling plan.\n        X2 (np.ndarray): A 2D array representing the second sampling plan.\n        p (float, optional): The distance metric. p=1 uses Manhattan (L1) distance,\n            while p=2 uses Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        int:\n            - 0 if both plans are identical or equally space-filling\n            - 1 if X1 is more space-filling\n            - 2 if X2 is more space-filling\n    \"\"\"\n    X1_sorted = X1[np.lexsort(np.rot90(X1))]\n    X2_sorted = X2[np.lexsort(np.rot90(X2))]\n    if np.array_equal(X1_sorted, X2_sorted):\n        return 0  # Identical sampling plans\n\n    # Compute distance multiplicities for each plan\n    J1, d1 = jd(X1, p)\n    J2, d2 = jd(X2, p)\n    m1, m2 = len(d1), len(d2)\n\n    # Construct V1 and V2: alternate distance and negative multiplicity\n    V1 = np.zeros(2 * m1)\n    V1[0::2] = d1\n    V1[1::2] = -J1\n\n    V2 = np.zeros(2 * m2)\n    V2[0::2] = d2\n    V2[1::2] = -J2\n\n    # Trim the longer vector to match the size of the shorter\n    m = min(m1, m2)\n    V1 = V1[:m]\n    V2 = V2[:m]\n\n    # Compare element-by-element:\n    # c[i] = 1 if V1[i] &gt; V2[i], 2 if V1[i] &lt; V2[i], 0 otherwise.\n    c = (V1 &gt; V2).astype(int) + 2 * (V1 &lt; V2).astype(int)\n\n    if np.sum(c) == 0:\n        # Equally space-filling\n        return 0\n    else:\n        # The first non-zero entry indicates which plan is better\n        idx = np.argmax(c != 0)\n        return c[idx]\n\n\nExample 3.8 (The Function mm) We can use the mm function to compare two sampling plans. The following code creates two 3-point sampling plans in 2D (shown in Figure 3.8) and compares them using the Morris-Mitchell criterion:\n\nX1 = np.array([[0.0, 0.0],[0.5, 0.5],[0.0, 1.0], [1.0, 1.0]])\nX2 = np.array([[0.1, 0.1],[0.4, 0.6],[0.1, 0.9], [0.9, 0.9]])\n\n\n\n\n\n\n\n\n\nFigure 3.8: Comparison of Two Sampling Plans\n\n\n\n\n\nWe can compare which plan has better space-filling (Morris-Mitchell). The output is either 0, 1, or 2 depending on which plan is more space-filling.\n\nbetter = mm(X1, X2, p=2.0)\nprint(f\"Plan {better} is more space-filling.\")\n\nPlan 1 is more space-filling.\n\n\n\n\n\n3.3.4.2 The Function mmphi\nSearching across a space of potential sampling plans can be accomplished by pairwise comparisons. An optimization algorithm could, in theory, be written with mm as the comparative objective. However, experimental evidence (Morris and Mitchell 1995) suggests that the resulting optimization landscape can be quite deceptive, making it difficult to search reliably. This difficulty arises because the comparison process terminates upon finding the first non-zero element in the comparison array c. Consequently, the remaining values in the distance (\\(d_1, d_2, ..., d_m\\)) and multiplicity (\\(J_1, J_2, ..., J_m\\)) arrays are disregarded. These disregarded values, however, might contain potentially useful ‘slope’ information about the global landscape for the optimization process.\nTo address this, Morris and Mitchell (1995) defined the following scalar-valued criterion function, which is used to rank competing sampling plans. This function, while based on the logic of Definition 3.5, incorporates the complete vectors \\(d_1, d_2, ..., d_m\\) and \\(J_1, J_2, ..., J_m\\).\n\nDefinition 3.8 (Morris-Mitchell Criterion) The Morris-Mitchell criterion is defined as:\n\\[\n\\Phi_q (X) = \\left(\\sum_{j=1}^m J_j d_j^{-q}\\right)^{1/q},\n\\tag{3.3}\\]\nwhere \\(X\\) is the sampling plan, \\(d_j\\) is the distance between points, \\(J_j\\) is the multiplicity of that distance, and \\(q\\) is a user-defined exponent. The parameter \\(q\\) can be adjusted to control the influence of smaller distances on the overall metric.\n\nThe smaller the value of \\(\\Phi_q\\), the better the space-filling properties of \\(X\\) will be.\nThe function mmphi computes the Morris-Mitchell sampling plan quality criterion for a given sampling plan. It takes a 2D array of points and calculates the space-fillingness metric based on the distances between points. This can be implemented in Python as follows:\n\ndef mmphi(X: np.ndarray,\n          q: Optional[float] = 2.0,\n          p: Optional[float] = 1.0) -&gt; float:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array representing the sampling plan,\n            where each row is a point in\n            d-dimensional space (shape: (n, d)).\n        q (float, optional):\n            Exponent used in the computation of the metric.\n            Defaults to 2.0.\n        p (float, optional):\n            The distance norm to use.\n            For example, p=1 is Manhattan (L1),\n            p=2 is Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        float:\n            The space-fillingness metric Phiq. Larger values typically indicate a more\n            space-filling plan according to the Morris-Mitchell criterion.\n    \"\"\"\n    # Compute the distance multiplicities: J, and unique distances: d\n    J, d = jd(X, p)\n    # Summation of J[i] * d[i]^(-q), then raised to 1/q\n    # This follows the Morris-Mitchell definition.\n    Phiq = np.sum(J * (d ** (-q))) ** (1.0 / q)\n    return Phiq\n\n\nExample 3.9 (The Function mmphi) We can use the mmphi function to evaluate the space-filling quality of the two sampling plans from Example 3.8. The following code uses these two 3-point sampling plans in 2D and computes their quality using the Morris-Mitchell criterion:\n\n# Two simple sampling plans from above\nquality1 = mmphi(X1, q=2, p=2)\nquality2 = mmphi(X2, q=2, p=2)\nprint(f\"Quality of sampling plan X1:  {quality1}\")\nprint(f\"Quality of sampling plan X2:  {quality2}\")\n\nQuality of sampling plan X1:  2.91547594742265\nQuality of sampling plan X2:  3.917162046269215\n\n\n\nThis equation provides a more compact representation of the maximin criterion, but the selection of the \\(q\\) value is an important consideration. Larger values of \\(q\\) ensure that terms in the sum corresponding to smaller inter-point distances (the \\(d_j\\) values, which are sorted in ascending order) have a dominant influence. As a result, \\(\\Phi_q\\) will rank sampling plans in a way that closely emulates the original maximin definition (Definition 3.5). This implies that the optimization landscape might retain the challenging characteristics that the \\(\\Phi_q\\) metric, especially with smaller \\(q\\) values, is intended to alleviate. Conversely, smaller \\(q\\) values tend to produce a \\(\\Phi_q\\) landscape that, while not perfectly aligning with the original definition, is generally more conducive to optimization.\nTo illustrate the relationship between Equation 3.3 and the maximin criterion of Definition 3.5, sets of 50 random Latin hypercubes of varying sizes and dimensionalities were considered by Forrester, Sóbester, and Keane (2008). The correlation plots from this analysis suggest that as the sampling plan size increases, a smaller \\(q\\) value is needed for the \\(\\Phi_q\\)-based ranking to closely match the ranking derived from Definition 3.5.\nRankings based on both the direct maximin comparison (mm) and the \\(\\Phi_q\\) metric (mmphi), determined using a simple bubble sort algorithm, are implemented in the Python function mmsort.\n\n\n3.3.4.3 The Function mmsort\nThe function mmsort is designed to rank multiple sampling plans based on their space-filling properties using the Morris-Mitchell criterion. It takes a 3D array of sampling plans and returns the indices of the plans sorted in ascending order of their space-filling quality.\n\ndef mmsort(X3D: np.ndarray, p: Optional[float] = 1.0) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X3D (np.ndarray):\n            A 3D NumPy array of shape (n, d, m), where m is the number of\n            sampling plans, and each plan is an (n, d) matrix of points.\n        p (float, optional):\n            The distance metric to use. p=1 for Manhattan (L1), p=2 for\n            Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        np.ndarray:\n            A 1D integer array of length m that holds the plan indices in\n            ascending order of space-filling quality. The first index in the\n            returned array corresponds to the most space-filling plan.\n    \"\"\"\n    # Number of plans (m)\n    m = X3D.shape[2]\n\n    # Create index array (1-based to match original MATLAB convention)\n    Index = np.arange(1, m + 1)\n\n    swap_flag = True\n    while swap_flag:\n        swap_flag = False\n        i = 0\n        while i &lt; m - 1:\n            # Compare plan at Index[i] vs. Index[i+1] using mm()\n            # Note: subtract 1 from each index to convert to 0-based array indexing\n            if mm(X3D[:, :, Index[i] - 1], X3D[:, :, Index[i + 1] - 1], p) == 2:\n                # Swap indices if the second plan is more space-filling\n                Index[i], Index[i + 1] = Index[i + 1], Index[i]\n                swap_flag = True\n            i += 1\n\n    return Index\n\n\nExample 3.10 (The Function mmsort) The mmsort function can be used to rank multiple sampling plans based on their space-filling properties. The following code demonstrates how to use mmsort to compare two 3-point sampling plans in 3D space:\nSuppose we have two 3-point sampling plans X1 and X1 from above. They are sorted using the Morris-Mitchell criterion with \\(p=2.0\\). For example, the output [1, 2] indicates that X1 is more space-filling than X2:\n\nX3D = np.stack([X1, X2], axis=2)\nranking = mmsort(X3D, p=2.0)\nprint(ranking)\n\n[1 2]\n\n\n\nTo determine the optimal Latin hypercube for a specific application, a recommended approach by Morris and Mitchell (1995) involves minimizing \\(\\Phi_q\\) for a set of \\(q\\) values (1, 2, 5, 10, 20, 50, and 100). Subsequently, the best plan from these results is selected based on the actual maximin definition. The mmsort function can be utilized for this purpose: a 3D matrix, X3D, can be constructed where each 2D slice represents the best sampling plan found for each \\(\\Phi_q\\). Applying mmsort(X3D,1) then ranks these plans according to Definition 3.5, using the rectangular distance metric. The subsequent discussion will address the methods for finding these optimized \\(\\Phi_q\\) designs.\n\n\n3.3.4.4 The Function phisort\nphisort only differs from mmsort in having \\(q\\) as an additional argument, as well as the comparison line being:\nif mmphi(X3D[:, :, Index[i] - 1], q=q, p=p) &gt;\n    mmphi(X3D[:, :, Index[i + 1] - 1], q=q, p=p):\n\ndef phisort(X3D: np.ndarray,\n            q: Optional[float] = 2.0,\n            p: Optional[float] = 1.0) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X3D (np.ndarray):\n            A 3D array of shape (n, d, m),\n            where m is the number of sampling plans.\n        q (float, optional):\n            Exponent for the mmphi metric. Defaults to 2.0.\n        p (float, optional):\n            Distance norm for mmphi.\n            p=1 is Manhattan; p=2 is Euclidean.\n            Defaults to 1.0.\n\n    Returns:\n        np.ndarray:\n            A 1D integer array of length m, giving the plan indices in ascending\n            order of mmphi. The first index in the returned array corresponds\n            to the numerically lowest mmphi value.\n    \"\"\"\n    # Number of 2D sampling plans\n    m = X3D.shape[2]\n    # Create a 1-based index array\n    Index = np.arange(1, m + 1)\n    # Bubble-sort: plan with lower mmphi() climbs toward the front\n    swap_flag = True\n    while swap_flag:\n        swap_flag = False\n        for i in range(m - 1):\n            # Retrieve mmphi values for consecutive plans\n            val_i = mmphi(X3D[:, :, Index[i] - 1], q=q, p=p)\n            val_j = mmphi(X3D[:, :, Index[i + 1] - 1], q=q, p=p)\n\n            # Swap if the left plan's mmphi is larger (i.e. 'worse')\n            if val_i &gt; val_j:\n                Index[i], Index[i + 1] = Index[i + 1], Index[i]\n                swap_flag = True\n    return Index\n\n\nExample 3.11 (The Function phisort) The phisort function can be used to rank multiple sampling plans based on the Morris-Mitchell criterion. The following code demonstrates how to use phisort to compare two 3-point sampling plans in 3D space:\n\nX1 = bestlh(n=5, k=2, population=5, iterations=10)\nX2 = bestlh(n=5, k=2, population=15, iterations=20)\nX3 = bestlh(n=5, k=2, population=25, iterations=30)\n# Map X1 and X2 so that X3D has the two sampling plans\n# in X3D[:, :, 0] and X3D[:, :, 1]\nX3D = np.array([X1, X2])\nprint(phisort(X3D))\nX3D = np.array([X3, X2])\nprint(phisort(X3D))\n\n[2 1]\n[1 2]\n\n\n\n\n\n\n3.3.5 Optimizing the Morris-Mitchell Criterion \\(\\Phi_q\\)\nOnce a criterion for assessing the quality of a Latin hypercube sampling plan has been established, a systematic method for optimizing this metric across the space of Latin hypercubes is required. This task is non-trivial; as the reader may recall from the earlier discussion on Latin squares, this search space is vast. In fact, its vastness means that for many practical applications, locating the globally optimal solution is often infeasible. Therefore, the objective becomes finding the best possible sampling plan achievable within a specific computational time budget.\nThis budget is influenced by the computational cost associated with obtaining each objective function value. Determining the optimal allocation of total computational effort—between generating the sampling plan and actually evaluating the objective function at the selected points—remains an open research question. However, it is typical for no more than approximately 5% of the total available time to be allocated to the task of generating the sampling plan itself.\nForrester, Sóbester, and Keane (2008) draw an analogy to the process of devising a revision timetable before an exam. While a well-structured timetable enhances the effectiveness of revision, an excessive amount of the revision time itself should not be consumed by the planning phase.\nA significant challenge in devising a sampling plan optimizer is ensuring that the search process remains confined to the space of valid Latin hypercubes. As previously discussed, the defining characteristic of a Latin hypercube \\(X\\) is that each of its columns represents a permutation of the possible levels for the corresponding variable. Consequently, the smallest modification that can be applied to a Latin hypercube—without compromising its crucial multidimensional stratification property—involves swapping two elements within any single column of \\(X\\). A Python implementation for ‘mutating’ a Latin hypercube through such an operation, generalized to accommodate random changes applied to multiple sites, is provided below:\n\n3.3.5.1 The Function perturb()\nThe function perturb randomly swaps elements in a Latin hypercube sampling plan. It takes a 2D array representing the sampling plan and performs a specified number of random element swaps, ensuring that the result remains a valid Latin hypercube.\n\ndef perturb(X: np.ndarray,\n            PertNum: Optional[int] = 1) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array (sampling plan) of shape (n, k),\n            where each row is a point\n            and each column is a dimension.\n        PertNum (int, optional):\n            The number of element swaps (perturbations)\n            to perform. Defaults to 1.\n\n    Returns:\n        np.ndarray:\n            The perturbed sampling plan,\n            identical in shape to the input, with\n            one or more random column swaps executed.\n    \"\"\"\n    # Get dimensions of the plan\n    n, k = X.shape\n    if n &lt; 2 or k &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points and 2 dimensions\")\n    for _ in range(PertNum):\n        # Pick a random column\n        col = int(np.floor(np.random.rand() * k))\n        # Pick two distinct row indices\n        el1, el2 = 0, 0\n        while el1 == el2:\n            el1 = int(np.floor(np.random.rand() * n))\n            el2 = int(np.floor(np.random.rand() * n))\n        # Swap the two selected elements in the chosen column\n        X[el1, col], X[el2, col] = X[el2, col], X[el1, col]\n    return X\n\n\nExample 3.12 (The Function perturb()) The perturb function can be used to randomly swap elements in a Latin hypercube sampling plan. The following code demonstrates how to use perturb to create a perturbed version of a 4x2 sampling plan:\n\nX_original = np.array([[1, 3],[2, 4],[3, 1],[4, 2]])\nprint(\"Original Sampling Plan:\")\nprint(X_original)\nprint(\"Perturbed Sampling Plan:\")\nX_perturbed = perturb(X_original, PertNum=1)\nprint(X_perturbed)\n\nOriginal Sampling Plan:\n[[1 3]\n [2 4]\n [3 1]\n [4 2]]\nPerturbed Sampling Plan:\n[[2 3]\n [1 4]\n [3 1]\n [4 2]]\n\n\n\nForrester, Sóbester, and Keane (2008) uses the term ‘mutation’, because this problem lends itself to nature-inspired computation. Morris and Mitchell (1995) use a simulated annealing algorithm, the detailed pseudocode of which can be found in their paper. As an alternative, a method based on evolutionary operation (EVOP) is offered by Forrester, Sóbester, and Keane (2008).\n\n\n\n3.3.6 Evolutionary Operation\nAs introduced by Box (1957), evolutionary operation was designed to optimize chemical processes. The current parameters of the reaction would be recorded in a box at the centre of a board, with a series of ‘offspring’ boxes along the edges containing values of the parameters slightly altered with respect to the central, ‘parent’ values. Once the reaction was completed for all of these sets of variable values and the corresponding yields recorded, the contents of the central box would be replaced with that of the setup with the highest yield and this would then become the parent of a new set of peripheral boxes.\nThis is generally viewed as a local search procedure, though this depends on the mutation step sizes, that is on the differences between the parent box and its offspring. The longer these steps, the more global is the scope of the search.\nFor the purposes of the Latin hypercube search, a variable scope strategy is applied. The process starts with a long step length (that is a relatively large number of swaps within the columns) and, as the search progresses, the current best basin of attraction is gradually approached by reducing the step length to a single change.\nIn each generation the parent is mutated (randomly, using the perturb function) a pertnum number of times. The sampling plan that yields the smallest \\(\\Phi_q\\) value (as per the Morris-Mitchell criterion, calculated usingmmphi) among all offspring and the parent is then selected; in evolutionary computation parlance this selection philosophy is referred to as elitism.\nThe EVOP based search for space-filling Latin hypercubes is thus a truly evolutionary process: the optimized sampling plan results from the nonrandom survival of random variations.\n\n\n3.3.7 Putting it all Together\nAll the pieces of the optimum Latin hypercube sampling process puzzle are now in place: the random hypercube generator as a starting point for the optimization process, the ‘spacefillingness’ metric that needs to be optimized, the optimization engine that performs this task and the comparison function that selects the best of the optima found for the various \\(q\\)’s. These pieces just need to be put into a sequence. Here is the Python embodiment of the completed puzzle. It results in a function bestlh that uses the function mmlhs to find the best Latin hypercube sampling plan for a given set of parameters.\n\n3.3.7.1 The Function mmlhs\nPerforms an evolutionary search (using perturbations) to find a Morris-Mitchell optimal Latin hypercube, starting from an initial plan X_start.\nThis function does the following:\n\nInitializes a “best” Latin hypercube (X_best) from the provided X_start.\nIteratively perturbs X_best to create offspring.\nEvaluates the space-fillingness of each offspring via the Morris-Mitchell metric (using mmphi).\nUpdates the best plan whenever a better offspring is found.\n\n\ndef mmlhs(X_start: np.ndarray,\n          population: int,\n          iterations: int,\n          q: Optional[float] = 2.0,\n          plot=False) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X_start (np.ndarray):\n            A 2D array of shape (n, k) providing the initial Latin hypercube\n            (n points in k dimensions).\n        population (int):\n            Number of offspring to create in each generation.\n        iterations (int):\n            Total number of generations to run the evolutionary search.\n        q (float, optional):\n            The exponent used by the Morris-Mitchell space-filling criterion.\n            Defaults to 2.0.\n        plot (bool, optional):\n            If True, a simple scatter plot of the first two dimensions will be\n            displayed at each iteration. Only if k &gt;= 2. Defaults to False.\n\n    Returns:\n        np.ndarray:\n            A 2D array representing the most space-filling Latin hypercube found\n            after all iterations, of the same shape as X_start.\n    \"\"\"\n    n = X_start.shape[0]\n    if n &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points\")\n    k = X_start.shape[1]\n    if k &lt; 2:\n        raise ValueError(\"Latin hypercubes are not defined for dim k &lt; 2\")\n    # Initialize best plan and its metric\n    X_best = X_start.copy()\n    Phi_best = mmphi(X_best, q=q)\n    # After 85% of iterations, reduce the mutation rate to 1\n    leveloff = int(np.floor(0.85 * iterations))\n    for it in range(1, iterations + 1):\n        # Decrease number of mutations over time\n        if it &lt; leveloff:\n            mutations = int(round(1 + (0.5 * n - 1) * (leveloff - it) / (leveloff - 1)))\n        else:\n            mutations = 1\n        X_improved = X_best.copy()\n        Phi_improved = Phi_best\n        # Create offspring, evaluate, and keep the best\n        for _ in range(population):\n            X_try = perturb(X_best.copy(), mutations)\n            Phi_try = mmphi(X_try, q=q)\n\n            if Phi_try &lt; Phi_improved:\n                X_improved = X_try\n                Phi_improved = Phi_try\n        # Update the global best if we found a better plan\n        if Phi_improved &lt; Phi_best:\n            X_best = X_improved\n            Phi_best = Phi_improved\n        # Simple visualization of the first two dimensions\n        if plot and (X_best.shape[1] &gt;= 2):\n            plt.clf()\n            plt.scatter(X_best[:, 0], X_best[:, 1], marker=\"o\")\n            plt.grid(True)\n            plt.title(f\"Iteration {it} - Current Best Plan\")\n            plt.pause(0.01)\n    return X_best\n\n\nExample 3.13 (The Function mmlhs) The mmlhs function can be used to optimize a Latin hypercube sampling plan. The following code demonstrates how to use mmlhs to optimize a 4x2 Latin hypercube starting from an initial plan:\n\n# Suppose we have an initial 4x2 plan\nX_start = np.array([[0.1, 0.3],[.1, .4],[.2, .9],[.9, .2]])\nprint(\"Initial plan:\")\nprint(X_start)\n# Search for a more space-filling plan\nX_opt = mmlhs(X_start, population=10, iterations=100, q=2)\nprint(\"Optimized plan:\")\nprint(X_opt)\n\nInitial plan:\n[[0.1 0.3]\n [0.1 0.4]\n [0.2 0.9]\n [0.9 0.2]]\nOptimized plan:\n[[0.1 0.2]\n [0.2 0.4]\n [0.1 0.9]\n [0.9 0.3]]\n\n\nFigure 3.9 shows the initial and optimized plans in 2D. The blue points represent the initial plan, while the red points represent the optimized plan.\n\n\n\n\n\n\n\n\nFigure 3.9: Comparison of the initial and optimized plans in 2D.\n\n\n\n\n\n\n\n\n3.3.7.2 The Function bestlh\nGenerates an optimized Latin hypercube by evolving the Morris-Mitchell criterion across multiple exponents (q values) and selecting the best plan.\n\ndef bestlh(n: int,\n           k: int,\n           population: int,\n           iterations: int,\n           p=1,\n           plot=False,\n           verbosity=0,\n           edges=0,\n           q_list=[1, 2, 5, 10, 20, 50, 100]) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        n (int):\n            Number of points required in the Latin hypercube.\n        k (int):\n            Number of design variables (dimensions).\n        population (int):\n            Number of offspring in each generation of the evolutionary search.\n        iterations (int):\n            Number of generations for the evolutionary search.\n        p (int, optional):\n            The distance norm to use. p=1 for Manhattan (L1), p=2 for Euclidean (L2).\n            Defaults to 1 (faster than 2).\n        plot (bool, optional):\n            If True, a scatter plot of the optimized plan in the first two dimensions\n            will be displayed. Only if k&gt;=2.  Defaults to False.\n        verbosity (int, optional):\n            Verbosity level. 0 is silent, 1 prints the best q value found. Defaults to 0.\n        edges (int, optional):\n            If 1, places centers of the extreme bins at the domain edges ([0,1]).\n            Otherwise, bins are fully contained within the domain, i.e. midpoints.\n            Defaults to 0.\n        q_list (list, optional):\n            A list of q values to optimize. Defaults to [1, 2, 5, 10, 20, 50, 100].\n            These values are used to evaluate the space-fillingness of the Latin\n            hypercube. The best plan is selected based on the lowest mmphi value.\n\n    Returns:\n        np.ndarray:\n            A 2D array of shape (n, k) representing an optimized Latin hypercube.\n    \"\"\"\n    if n &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points\")\n    if k &lt; 2:\n        raise ValueError(\"Latin hypercubes are not defined for dim k &lt; 2\")\n\n    # A list of exponents (q) to optimize\n\n    # Start with a random Latin hypercube\n    X_start = rlh(n, k, edges=edges)\n\n    # Allocate a 3D array to store the results for each q\n    # (shape: (n, k, number_of_q_values))\n    X3D = np.zeros((n, k, len(q_list)))\n\n    # Evolve the plan for each q in q_list\n    for i, q_val in enumerate(q_list):\n        if verbosity &gt; 0:\n            print(f\"Now optimizing for q={q_val}...\")\n        X3D[:, :, i] = mmlhs(X_start, population, iterations, q_val)\n\n    # Sort the set of evolved plans according to the Morris-Mitchell criterion\n    index_order = mmsort(X3D, p=p)\n\n    # index_order is a 1-based array of plan indices; the first element is the best\n    best_idx = index_order[0] - 1\n    if verbosity &gt; 0:\n        print(f\"Best lh found using q={q_list[best_idx]}...\")\n\n    # The best plan in 3D array order\n    X = X3D[:, :, best_idx]\n\n    # Plot the first two dimensions\n    if plot and (k &gt;= 2):\n        plt.scatter(X[:, 0], X[:, 1], c=\"r\", marker=\"o\")\n        plt.title(f\"Morris-Mitchell optimum plan found using q={q_list[best_idx]}\")\n        plt.xlabel(\"x_1\")\n        plt.ylabel(\"x_2\")\n        plt.grid(True)\n        plt.show()\n\n    return X\n\n\nExample 3.14 (The Function bestlh) The bestlh function can be used to generate an optimized Latin hypercube sampling plan. The following code demonstrates how to use bestlh to create a 5x2 Latin hypercube with a population of 5 and 10 iterations:\n\nXbestlh= bestlh(n=5, k=2, population=5, iterations=10)\n\nFigure 3.10 shows the best Latin hypercube sampling in 2D. The red points represent the optimized plan.\n\n\n\n\n\n\n\n\nFigure 3.10: Best Latin Hypercube Sampling\n\n\n\n\n\n\nSorting all candidate plans in ascending order is not strictly necessary - after all, only the best one is truly of interest. Nonetheless, the added computational complexity is minimal (the vector will only ever contain as many elements as there are candidate \\(q\\) values, and only an index array is sorted, not the actual repository of plans). This sorting gives the reader the opportunity to compare, if desired, how different choices of \\(q\\) influence the resulting plans.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#experimental-analysis-of-the-morris-mitchell-criterion",
    "href": "001_sampling.html#experimental-analysis-of-the-morris-mitchell-criterion",
    "title": "3  Sampling Plans",
    "section": "3.4 Experimental Analysis of the Morris-Mitchell Criterion",
    "text": "3.4 Experimental Analysis of the Morris-Mitchell Criterion\nMorris-Mitchell Criterion Experimental Analysis\n\nNumber of points: 16, Dimensions: 2\nmmphi parameters: q (exponent) = 2.0, p (distance norm) = 2.0 (1=Manhattan, 2=Euclidean)\n\n\nN_POINTS = 16\nN_DIM = 2\nRANDOM_SEED = 42\nq = 2.0\np = 2.0\n\n\n3.4.1 Evaluation of Sampling Designs\nWe generate various sampling designs and evaluate their space-filling properties using the Morris-Mitchell criterion.\n\ndesigns = {}\nif int(np.sqrt(N_POINTS))**2 == N_POINTS:\n    grid_design = Grid(k=N_DIM)\n    designs[\"Grid (4x4)\"] = grid_design.generate_grid_design(points_per_dim=int(np.sqrt(N_POINTS)))\nelse:\n    print(f\"Skipping grid design as N_POINTS={N_POINTS} is not a perfect square for a simple 2D grid.\")\n\nlhs_design = SpaceFilling(k=N_DIM, seed=42)\ndesigns[\"LHS\"] = lhs_design.generate_qms_lhs_design(n_points=N_POINTS)\n\nsobol_design = Sobol(k=N_DIM, seed=42)\ndesigns[\"Sobol\"] = sobol_design.generate_sobol_design(n_points=N_POINTS)\n\nrandom_design = Random(k=N_DIM)\ndesigns[\"Random\"] = random_design.uniform(n_points=N_POINTS)\n\npoor_design = Poor(k=N_DIM)\ndesigns[\"Collinear\"] = poor_design.generate_collinear_design(n_points=N_POINTS)\n\nclustered_design = Clustered(k=N_DIM)\ndesigns[\"Clustered (3 clusters)\"] = clustered_design.generate_clustered_design(n_points=N_POINTS, n_clusters=3, seed=42)\n\nresults = {}\n\nprint(\"Calculating Morris-Mitchell metric (smaller is better):\")\nfor name, X_design in designs.items():\n    metric_val = mmphi(X_design, q=q, p=p)\n    results[name] = metric_val\n    print(f\"  {name}: {metric_val:.4f}\")\n\nCalculating Morris-Mitchell metric (smaller is better):\n  Grid (4x4): 20.2617\n  LHS: 28.1868\n  Sobol: 32.0350\n  Random: 48.1141\n  Collinear: 87.8829\n  Clustered (3 clusters): 90.3702\n\n\n\nif N_DIM == 2:\n    num_designs = len(designs)\n    cols = 2\n    rows = int(np.ceil(num_designs / cols))\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n    axes = axes.ravel() # Flatten axes array for easy iteration\n\n    for i, (name, X_design) in enumerate(designs.items()):\n        ax = axes[i]\n        ax.scatter(X_design[:, 0], X_design[:, 1], s=50, edgecolors='k', alpha=0.7)\n        ax.set_title(f\"{name}\\nmmphi = {results[name]:.3f}\", fontsize=10)\n        ax.set_xlabel(\"X1\")\n        ax.set_ylabel(\"X2\")\n        ax.set_xlim(-0.05, 1.05)\n        ax.set_ylim(-0.05, 1.05)\n        ax.set_aspect('equal', adjustable='box')\n        ax.grid(True, linestyle='--', alpha=0.6)\n\n    # Hide any unused subplots\n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.suptitle(f\"Comparison of 2D Sampling Designs ({N_POINTS} points each)\", fontsize=14, y=1.02)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n3.4.2 Demonstrate the Impact of mmphi Parameters\nDemonstrating Impact of mmphi Parameters on ‘LHS’ Design\n\nX_lhs = designs[\"LHS\"]\n\n# 1. Default parameters (already calculated)\nprint(f\"  LHS (q={q}, p={p} Euclidean): {results['LHS']:.4f}\")\n\n# 2. Change q (main exponent, literature's p or k)\nq_high = 15.0\nmetric_lhs_q_high = mmphi(X_lhs, q=q_high, p=p)\nprint(f\"  LHS (q={q_high}, p={p} Euclidean): {metric_lhs_q_high:.4f} (Higher q penalizes small distances more)\")\n\n# 3. Change p (distance norm, literature's q or m)\np_manhattan = 1.0\nmetric_lhs_p_manhattan = mmphi(X_lhs, q=q, p=p_manhattan)\nprint(f\"  LHS (q={q}, p={p_manhattan} Manhattan): {metric_lhs_p_manhattan:.4f} (Using L1 distance)\")\n\n  LHS (q=2.0, p=2.0 Euclidean): 28.1868\n  LHS (q=15.0, p=2.0 Euclidean): 8.1573 (Higher q penalizes small distances more)\n  LHS (q=2.0, p=1.0 Manhattan): 22.0336 (Using L1 distance)\n\n\n\n\n3.4.3 Morris-Mitchell Criterion: Impact of Adding Points\nImpact of adding a point to a 2x2 grid design\n\n# Initial 2x2 Grid Design\nX_initial = np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\nmmphi_initial = mmphi(X_initial, q=q, p=p)\n\nprint(f\"Parameters: q (exponent) = {q}, p (distance) = {p} (Euclidean)\\n\")\nprint(f\"Initial 2x2 Grid Design (4 points):\")\nprint(f\"  Points:\\n{X_initial}\")\nprint(f\"  Morris-Mitchell Criterion (Phi_q): {mmphi_initial:.4f}\\n\")\n\nParameters: q (exponent) = 2.0, p (distance) = 2.0 (Euclidean)\n\nInitial 2x2 Grid Design (4 points):\n  Points:\n[[0. 0.]\n [1. 0.]\n [0. 1.]\n [1. 1.]]\n  Morris-Mitchell Criterion (Phi_q): 2.2361\n\n\n\nScenarios for adding a 5th point:\n\nscenarios = {\n    \"Scenario 1: Add to Center\": {\n        \"new_point\": np.array([[0.5, 0.5]]),\n        \"description\": \"Adding a point in the center of the grid.\"\n    },\n    \"Scenario 2: Add Close to Existing (Cluster)\": {\n        \"new_point\": np.array([[0.1, 0.1]]),\n        \"description\": \"Adding a point very close to an existing point (0,0).\"\n    },\n    \"Scenario 3: Add on Edge\": {\n        \"new_point\": np.array([[0.5, 0.0]]),\n        \"description\": \"Adding a point on an edge between (0,0) and (1,0).\"\n    }\n}\n\nresults_summary = []\naugmented_designs_for_plotting = {\"Initial Design\": X_initial}\n\nfor name, scenario_details in scenarios.items():\n    new_point = scenario_details[\"new_point\"]\n    X_augmented = np.vstack((X_initial, new_point))\n    augmented_designs_for_plotting[name] = X_augmented\n    \n    mmphi_augmented = mmphi(X_augmented, q=q, p=p)\n    change = mmphi_augmented - mmphi_initial\n    \n    print(f\"{name}:\")\n    print(f\"  Description: {scenario_details['description']}\")\n    print(f\"  New Point Added: {new_point}\")\n    # print(f\"  Augmented Design (5 points):\\n{X_augmented}\") # Optional: print full matrix\n    print(f\"  Morris-Mitchell Criterion (Phi_q): {mmphi_augmented:.4f}\")\n    print(f\"  Change from Initial Phi_q: {change:+.4f}\\n\")\n    \n    results_summary.append({\n        \"Scenario\": name,\n        \"Initial Phi_q\": mmphi_initial,\n        \"Augmented Phi_q\": mmphi_augmented,\n        \"Change\": change\n    })\n\nScenario 1: Add to Center:\n  Description: Adding a point in the center of the grid.\n  New Point Added: [[0.5 0.5]]\n  Morris-Mitchell Criterion (Phi_q): 3.6056\n  Change from Initial Phi_q: +1.3695\n\nScenario 2: Add Close to Existing (Cluster):\n  Description: Adding a point very close to an existing point (0,0).\n  New Point Added: [[0.1 0.1]]\n  Morris-Mitchell Criterion (Phi_q): 7.6195\n  Change from Initial Phi_q: +5.3834\n\nScenario 3: Add on Edge:\n  Description: Adding a point on an edge between (0,0) and (1,0).\n  New Point Added: [[0.5 0. ]]\n  Morris-Mitchell Criterion (Phi_q): 3.8210\n  Change from Initial Phi_q: +1.5849\n\n\n\n\nnum_designs = len(augmented_designs_for_plotting)\ncols = 2\nrows = int(np.ceil(num_designs / cols))\n\nfig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\naxes = axes.ravel() \n\nplot_idx = 0\n# Plot initial design first\nax = axes[plot_idx]\nax.scatter(X_initial[:, 0], X_initial[:, 1], s=100, edgecolors='k', alpha=0.7, label=\"Original Points\")\nax.set_title(f\"Initial Design\\nPhi_q = {mmphi_initial:.3f}\", fontsize=10)\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.set_xlim(-0.1, 1.1)\nax.set_ylim(-0.1, 1.1)\nax.set_aspect('equal', adjustable='box')\nax.grid(True, linestyle='--', alpha=0.6)\nax.legend(fontsize='small')\nplot_idx +=1\n\n# Plot augmented designs\nfor name, X_design in augmented_designs_for_plotting.items():\n    if name == \"Initial Design\":\n        continue # Already plotted\n\n    ax = axes[plot_idx]\n    # Highlight original vs new point\n    original_points = X_design[:-1, :]\n    new_point = X_design[-1, :].reshape(1,2)\n    \n    ax.scatter(original_points[:, 0], original_points[:, 1], s=100, edgecolors='k', alpha=0.7, label=\"Original Points\")\n    ax.scatter(new_point[:, 0], new_point[:, 1], s=150, color='red', edgecolors='k', marker='X', label=\"Added Point\")\n    \n    current_phi_q = next(item['Augmented Phi_q'] for item in results_summary if item[\"Scenario\"] == name)\n    ax.set_title(f\"{name}\\nPhi_q = {current_phi_q:.3f}\", fontsize=10)\n    ax.set_xlabel(\"X1\")\n    ax.set_ylabel(\"X2\")\n    ax.set_xlim(-0.1, 1.1)\n    ax.set_ylim(-0.1, 1.1)\n    ax.set_aspect('equal', adjustable='box')\n    ax.grid(True, linestyle='--', alpha=0.6)\n    ax.legend(fontsize='small')\n    plot_idx +=1\n    \n# Hide any unused subplots\nfor j in range(plot_idx, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\nplt.suptitle(f\"Impact of Adding a Point to a 2x2 Grid Design (q={q}, p={p})\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\nSummary Table (Conceptual):\n\n\n\n\n\n\n\n\n\nScenario\nInitial Phi_q\nAugmented Phi_q\nChange\n\n\n\n\nBaseline (2x2 Grid)\n2.236\n—\n—\n\n\nScenario 1: Add to Center\n2.236\n3.606\n+1.369\n\n\nScenario 2: Add Close to Existing (Cluster)\n2.236\n7.619\n+5.383\n\n\nScenario 3: Add on Edge\n2.236\n3.821\n+1.585",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#a-sample-size-invariant-version-of-the-morris-mitchell-criterion",
    "href": "001_sampling.html#a-sample-size-invariant-version-of-the-morris-mitchell-criterion",
    "title": "3  Sampling Plans",
    "section": "3.5 A Sample-Size Invariant Version of the Morris-Mitchell Criterion",
    "text": "3.5 A Sample-Size Invariant Version of the Morris-Mitchell Criterion\n\n3.5.1 Comparison of mmphi() and mmphi_intensive()\nThe Morris-Mitchell criterion is a widely used metric for evaluating the space-filling properties of Latin hypercube sampling designs. However, it is sensitive to the number of points in the design, which can lead to misleading comparisons between designs with different sample sizes. To address this issue, a sample-size invariant version of the Morris-Mitchell criterion has been proposed. It is avaiable in the spotpython package as mmphi_intensive(), see [SOURCE].\nThe functions mmphi() and mmphi_intensive() both calculate a Morris-Mitchell criterion, but they differ in their normalization, which makes mmphi_intensive() invariant to the sample size.\nLet \\(X\\) be a sampling plan with \\(n\\) points \\(\\{x_1, x_2, \\dots, x_n\\}\\) in a \\(k\\)-dimensional space. Let \\(d_{ij} = \\|x_i - x_j\\|_p\\) be the \\(p\\)-norm distance between points \\(x_i\\) and \\(x_j\\). Let \\(J_l\\) be the multiplicity of the \\(l\\)-th unique distance \\(d_l\\) among all pairs of points in \\(X\\). Let \\(m\\) be the total number of unique distances.\n1. mmphi() (Morris-Mitchell Criterion \\(\\Phi_q\\))\nThe mmphi() function, as defined in the context and implemented in sampling.py, calculates the Morris-Mitchell criterion \\(\\Phi_q\\) as:\n\\[\n\\Phi_q(X) = \\left( \\sum_{l=1}^{m} J_l d_l^{-q} \\right)^{1/q},\n\\] where:\n\n\\(J_l\\) is the number of pairs of points separated by the unique distance \\(d_l\\).\n\\(d_l\\) are the unique pairwise distances.\n\\(q\\) is a user-defined exponent (typically \\(q &gt; 0\\)).\n\nThis formulation is directly based on the sum of inverse powers of distances. The value of \\(\\Phi_q\\) is generally dependent on the number of points \\(n\\) in the design \\(X\\), as the sum \\(\\sum J_l d_l^{-q}\\) will typically increase with more points (and thus more pairs).\n2. mmphi_intensive() (Intensive Morris-Mitchell Criterion)\nThe mmphi_intensive() function, as implemented in sampling.py calculates a sample-size invariant version of the Morris-Mitchell criterion, which will be referred to as \\(\\Phi_q^{I}\\). The formula is:\n\\[\n\\Phi_q^{I}(X) = \\left( \\frac{1}{M} \\sum_{l=1}^{m} J_l d_l^{-q} \\right)^{1/q}\n\\]\nwhere:\n\n\\(M = \\binom{n}{2} = \\frac{n(n-1)}{2}\\) is the total number of unique pairs of points in the design \\(X\\).\nThe other terms \\(J_l\\), \\(d_l\\), \\(q\\) are the same as in mmphi().\n\nThe key mathematical difference is the normalization factor \\(\\frac{1}{M}\\) inside the parentheses before the outer exponent \\(1/q\\) is applied.\n\nmmphi(): Calculates \\(\\left( \\text{SumTerm} \\right)^{1/q}\\), where SumTerm = \\(\\sum J_l d_l^{-q}\\).\nmmphi_intensive(): Calculates \\(\\left( \\frac{\\text{SumTerm}}{M} \\right)^{1/q}\\).\n\nBy dividing the sum \\(\\sum J_l d_l^{-q}\\) by \\(M\\) (the total number of pairs), mmphi_intensive() effectively calculates an average contribution per pair to the \\(-q\\)-th power of distance, before taking the \\(q\\)-th root. This normalization makes the criterion less dependent on the absolute number of points \\(n\\) and allows for more meaningful comparisons of space-fillingness between designs of different sizes. A smaller value indicates a better (more space-filling) design for both criteria.\n\n\n3.5.2 Plotting the Two Morris-Mitchell Criteria for Different Sample Sizes\nFigure 3.11 shows the comparison of the two Morris-Mitchell criteria for different sample sizes using the plot_mmphi_vs_n_lhs function. The red line represents the standard Morris-Mitchell criterion, while the blue line represents the sample-size invariant version. Note the difference in the y-axis scales, which highlights how the sample-size invariant version remains consistent across varying sample sizes.\n\ndef plot_mmphi_vs_n_lhs(k_dim: int, \n                        seed: int, \n                        n_min: int = 10, \n                        n_max: int = 100, \n                        n_step: int = 5,\n                        q_phi: float = 2.0, \n                        p_phi: float = 2.0):\n    \"\"\"\n    Generates LHS designs for varying n, calculates mmphi and mmphi_intensive,\n    and plots them against the number of samples (n).\n\n    Args:\n        k_dim (int): Number of dimensions for the LHS design.\n        seed (int): Random seed for reproducibility.\n        n_min (int): Minimum number of samples.\n        n_max (int): Maximum number of samples.\n        n_step (int): Step size for increasing n.\n        q_phi (float): Exponent q for the Morris-Mitchell criteria.\n        p_phi (float): Distance norm p for the Morris-Mitchell criteria.\n    \"\"\"\n    n_values = list(range(n_min, n_max + 1, n_step))\n    if not n_values:\n        print(\"Warning: n_values list is empty. Check n_min, n_max, and n_step.\")\n        return\n    mmphi_results = []\n    mmphi_intensive_results = []\n    lhs_generator = SpaceFilling(k=k_dim, seed=seed)\n    print(f\"Calculating for n from {n_min} to {n_max} with step {n_step}...\")\n    for n_points in n_values:\n        if n_points &lt; 2 : # mmphi requires at least 2 points to calculate distances\n            print(f\"Skipping n={n_points} as it's less than 2.\")\n            mmphi_results.append(np.nan)\n            mmphi_intensive_results.append(np.nan)\n            continue\n        try:\n            X_design = lhs_generator.generate_qms_lhs_design(n_points=n_points)\n            phi = mmphi(X_design, q=q_phi, p=p_phi)\n            phi_intensive, _, _ = mmphi_intensive(X_design, q=q_phi, p=p_phi)\n            mmphi_results.append(phi)\n            mmphi_intensive_results.append(phi_intensive)\n        except Exception as e:\n            print(f\"Error calculating for n={n_points}: {e}\")\n            mmphi_results.append(np.nan)\n            mmphi_intensive_results.append(np.nan)\n\n    fig, ax1 = plt.subplots(figsize=(9, 6))\n\n    color = 'tab:red'\n    ax1.set_xlabel('Number of Samples (n)')\n    ax1.set_ylabel('mmphi (Phiq)', color=color)\n    ax1.plot(n_values, mmphi_results, color=color, marker='o', linestyle='-', label='mmphi (Phiq)')\n    ax1.tick_params(axis='y', labelcolor=color)\n    ax1.grid(True, linestyle='--', alpha=0.7)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n    color = 'tab:blue'\n    ax2.set_ylabel('mmphi_intensive (PhiqI)', color=color)  # we already handled the x-label with ax1\n    ax2.plot(n_values, mmphi_intensive_results, color=color, marker='x', linestyle='--', label='mmphi_intensive (PhiqI)')\n    ax2.tick_params(axis='y', labelcolor=color)\n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    plt.title(f'Morris-Mitchell Criteria vs. Number of Samples (n)\\nLHS (k={k_dim}, q={q_phi}, p={p_phi})')\n    # Add legends\n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines + lines2, labels + labels2, loc='best')\n    plt.show()\n\n\nN_DIM = 2\nRANDOM_SEED = 42\nplot_mmphi_vs_n_lhs(k_dim=N_DIM, seed=RANDOM_SEED, n_min=10, n_max=100, n_step=5)\n\nCalculating for n from 10 to 100 with step 5...\n\n\n\n\n\n\n\n\nFigure 3.11: Comparison of the two Morris-Mitchell Criteria for Different Sample Sizes",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#jupyter-notebook",
    "href": "001_sampling.html#jupyter-notebook",
    "title": "3  Sampling Plans",
    "section": "3.6 Jupyter Notebook",
    "text": "3.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nBox, G E P. 1957. “Evolutionary operation: A method for increasing industrial productivity.” Applied Statistics 6: 81–101.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nJohnson, M. E., L. M. Moore, and D. Ylvisaker. 1990. “Minimax and Maximin Distance Designs.” Journal of Statistical Planning and Inference 26 (2): 131–48.\n\n\nMorris, Max D., and Toby J. Mitchell. 1995. “Exploratory Designs for Computational Experiments.” Journal of Statistical Planning and Inference 43 (3): 381–402. https://doi.org/https://doi.org/10.1016/0378-3758(94)00035-T.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html",
    "href": "006_constructing_surrogate.html",
    "title": "4  Constructing a Surrogate",
    "section": "",
    "text": "4.1 Stage One: Preparing the Data and Choosing a Modelling Approach\nThis black box could take the form of either a physical or computer experiment, for example, a finite element code, which calculates the maximum stress (\\(\\sigma\\)) for given product dimensions (\\(\\vec{x}\\)).\nThe first step is the identification, through a small number of observations, of the inputs that have a significant impact on \\(f\\); that is the determination of the shortest design variable vector \\(\\vec{x} = \\{x_1, x_2, \\ldots, x_k\\}^T\\) that, by sweeping the ranges of all of its variables, can still elicit most of the behavior the black box is capable of. The ranges of the various design variables also have to be established at this stage.\nThe second step is to recruit \\(n\\) of these \\(k\\)-vectors into a list \\[\nX = \\{ \\vec{x}^{(1)},\\vec{x}^{(2)}, \\ldots, \\vec{x}^{(n)} \\}^T,\n\\] where each \\(\\vec{x}^{(i)}\\) is a \\(k\\)-vector. The corresponding responses are collected in a vector such that this represents the design space as thoroughly as possible.\nIn the surrogate modeling process, the number of samples \\(n\\) is often limited, as it is constrained by the computational cost (money and/or time) associated with obtaining each observation.\nIt is advisable to scale \\(\\vec{x}\\) at this stage into the unit cube \\([0, 1]^k\\), a step that can simplify the subsequent mathematics and prevent multidimensional scaling issues.\nWe now focus on the attempt to learn \\(f\\) through data pairs \\[\n\\{ (\\vec{x}^{(1)}, y^{(1)}), (\\vec{x}^{(2)}, y^{(2)}), \\ldots, (\\vec{x}^{(n)}, y^{(n)}) \\}.\n\\]\nThis supervised learning process essentially involves searching across the space of possible functions \\(\\hat{f}\\) that would replicate observations of \\(f\\). This space of functions is infinite. Any number of hypersurfaces could be drawn to pass through or near the known observations, accounting for experimental error. However, most of these would generalize poorly; they would be practically useless at predicting responses at new sites, which is the ultimate goal.\nThere are countless other configurations, perhaps less contrived, that still generalize poorly. This suggests a need for systematic means to filter out nonsensical predictors. In our approach, we embed the structure of \\(f\\) into the model selection algorithm and search over its parameters to fine-tune the approximation to observations. For instance, consider one of the simplest models, \\[\nf(x, \\vec{w}) = \\vec{w}^T\\vec{x} + v.\n\\tag{4.1}\\] Learning \\(f\\) with this model implies that its structure—a hyperplane—is predetermined, and the fitting process involves finding the \\(k + 1\\) parameters (the slope vector \\(\\vec{w}\\) and the intercept \\(v\\)) that best fit the data. This will be accomplished in Stage Two.\nComplicating this further is the noise present in observed responses (we assume design vectors \\(\\vec{x}\\) are not corrupted). Here, we focus on learning from such data, which sometimes risks overfitting.\nIn the surrogate modeling process, the second stage as described in Section 4.2, addresses this issue of complexity control by estimating the parameters of the fixed structure model. However, foresight is necessary even at the model type selection stage.\nModel selection often involves physics-based considerations, where the modeling technique is chosen based on expected underlying responses.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#stage-one-preparing-the-data-and-choosing-a-modelling-approach",
    "href": "006_constructing_surrogate.html#stage-one-preparing-the-data-and-choosing-a-modelling-approach",
    "title": "4  Constructing a Surrogate",
    "section": "",
    "text": "Example 4.1 (The Needle(s) in the Haystack Function) An extreme example is the ‘needle(s) in the haystack’ function:\n\\[\nf(x) = \\begin{cases}\ny^{(1)}, & \\text{if } x = \\vec{x}^{(1)} \\\\\ny^{(2)}, & \\text{if } x = \\vec{x}^{(2)} \\\\\n\\vdots & \\\\\ny^{(n)}, & \\text{if } x = \\vec{x}^{(n)} \\\\\n0, & \\text{otherwise.}\n\\end{cases}\n\\]\nWhile this predictor reproduces all training data, it seems counter-intuitive and unsettling to predict 0 everywhere else for most engineering functions. Although there is a small chance that the function genuinely resembles the equation above and we sampled exactly where the needles are, it is highly unlikely.\n\n\n\n\nDefinition 4.3 (Overfitting) Overfitting occurs when the model becomes too flexible and captures not only the underlying trend but also the noise in the data.\n\n\n\n\nExample 4.2 (Model Selection) Modeling stress in an elastically deformed solid due to small strains may justify using a simple linear approximation. Without insights into the physics, and if one fails to account for the simplicity of the data, a more complex and excessively flexible model may be incorrectly chosen. Although parameter estimation might still adjust the approximation to become linear, an opportunity to develop a simpler and robust model may be lost.\n\nSimple linear (or polynomial) models, despite their lack of flexibility, have advantages like applicability in further symbolic computations.\nConversely, if we incorrectly assume a quadratic process when multiple peaks and troughs exist, the parameter estimation stage will not compensate for an unsuitable model choice. A quadratic model is too rigid to fit a multimodal function, regardless of parameter adjustments.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#sec-stage-two",
    "href": "006_constructing_surrogate.html#sec-stage-two",
    "title": "4  Constructing a Surrogate",
    "section": "4.2 Stage Two: Parameter Estimation and Training",
    "text": "4.2 Stage Two: Parameter Estimation and Training\nAssuming that Stage One helped identify the \\(k\\) critical design variables, acquire the learning data set, and select a generic model structure \\(f(\\vec{x}, \\vec{w})\\), the task now is to estimate parameters \\(\\vec{w}\\) to ensure the model fits the data optimally. Among several estimation criteria, we will discuss two methods here.\n\nDefinition 4.4 (Maximum Likelihood Estimation) Given a set of parameters \\(\\vec{w}\\), the model \\(f(\\vec{x}, \\vec{w})\\) allows computation of the probability of the data set \\[\n\\{(\\vec{x}^{(1)}, y^{(1)} \\pm \\epsilon), (\\vec{x}^{(2)}, y^{(2)} \\pm \\epsilon), \\ldots, (\\vec{x}^{(n)}, y^{(n)} \\pm \\epsilon)\\}\n\\] resulting from \\(f\\) (where \\(\\epsilon\\) is a small error margin around each data point).\n\n\n\n\n\n\n\nNoteMaximum Likelihood Estimation\n\n\n\n?sec-max-likelihood presents a more detailed discussion of the maximum likelihood estimation (MLE) method.\n\n\nTaking ?eq-likelihood-mvn and assuming errors \\(\\epsilon\\) are independently and normally distributed with standard deviation \\(\\sigma\\), the probability of the data set is given by:\n\\[\nP = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp \\left[ -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} \\left( y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w}) \\right)^2 \\epsilon \\right].\n\\]\nIntuitively, this is equivalent to the likelihood of the parameters given the data. Accepting this intuitive relationship as a mathematical one aids in model parameter estimation. This is achieved by maximizing the likelihood or, more conveniently, minimizing the negative of its natural logarithm:\n\\[\n\\min_{\\vec{w}} \\sum_{i=1}^{n} \\frac{[y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w})]^2}{2\\sigma^2} + \\frac{n}{2} \\ln \\epsilon .\n\\tag{4.2}\\]\nIf we assume \\(\\sigma\\) and \\(\\epsilon\\) are constants, Equation 4.2 simplifies to the well-known least squares criterion:\n\\[\n\\min_{\\vec{w}} \\sum_{i=1}^{n} [y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w})]^2 .\n\\]\nCross-validation is another method used to estimate model performance.\n\nDefinition 4.5 (Cross-Validation) Cross-validation splits the data randomly into \\(q\\) roughly equal subsets, and then cyclically removing each subset and fitting the model to the remaining \\(q - 1\\) subsets. A loss function \\(L\\) is then computed to measure the error between the predictor and the withheld subset for each iteration, with contributions summed over all \\(q\\) iterations. More formally, if a mapping \\(\\theta: \\{1, \\ldots, n\\} \\to \\{1, \\ldots, q\\}\\) describes the allocation of the \\(n\\) training points to one of the \\(q\\) subsets and \\(f^{(-\\theta(i))}(\\vec{x})\\) is the predicted value by removing the subset \\(\\theta(i)\\) (i.e., the subset where observation \\(i\\) belongs), the cross-validation measure, used as an estimate of prediction error, is:\n\\[\nCV = \\frac{1}{n} \\sum_{i=1}^{n} L(y^{(i)}, f^{(-\\theta(i))}(\\vec{x}^{(i)})) .\n\\tag{4.3}\\]\n\nIntroducing the squared error as the loss function and considering our generic model \\(f\\) still dependent on undetermined parameters, we write Equation 4.3 as:\n\\[\nCV = \\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)} - f^{(-\\theta(i))}(\\vec{x}^{(i)})]^2 .\n\\tag{4.4}\\]\nThe extent to which Equation 4.4 is an unbiased estimator of true risk depends on \\(q\\). It is shown that if \\(q = n\\), the leave-one-out cross-validation (LOOCV) measure is almost unbiased. However, LOOCV can have high variance because subsets are very similar. Hastie, Tibshirani, and Friedman (2017)) suggest using compromise values like \\(q = 5\\) or \\(q = 10\\). Using fewer subsets also reduces the computational cost of the cross-validation process, see also Arlot, Celisse, et al. (2010) and Kohavi (1995).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#stage-three-model-testing",
    "href": "006_constructing_surrogate.html#stage-three-model-testing",
    "title": "4  Constructing a Surrogate",
    "section": "4.3 Stage Three: Model Testing",
    "text": "4.3 Stage Three: Model Testing\nIf there is a sufficient amount of observational data, a random subset should be set aside initially for model testing. Hastie, Tibshirani, and Friedman (2017) recommend setting aside approximately \\(0.25n\\) of \\(\\vec{x} \\rightarrow y\\) pairs for testing purposes. These observations must remain untouched during Stages One and Two, as their sole purpose is to evaluate the testing error—the difference between true and approximated function values at the test sites—once the model has been built. Interestingly, if the main goal is to construct an initial surrogate for seeding a global refinement criterion-based strategy (as discussed in Section 3.2 in Forrester, Sóbester, and Keane (2008)), the model testing phase might be skipped.\nIt is noted that, ideally, parameter estimation (Stage Two) should also rely on a separate subset. However, observational data is rarely abundant enough to afford this luxury (if the function is cheap to evaluate and evaluation sites are selectable, a surrogate model might not be necessary).\nWhen data are available for model testing and the primary objective is a globally accurate model, using either a root mean square error (RMSE) metric or the correlation coefficient (\\(r^2\\)) is recommended. To test the model, a test data set of size \\(n_t\\) is used alongside predictions at the corresponding locations to calculate these metrics.\nThe RMSE is defined as follows:\n\nDefinition 4.6 (Root Mean Square Error (RMSE)) \\[\n\\text{RMSE} = \\sqrt{\\frac{1}{n_t} \\sum_{i=1}^{n_t} (y^{(i)} - \\hat{y}^{(i)})^2},\n\\]\n\nIdeally, the RMSE should be minimized, acknowledging its limitation by errors in the objective function \\(f\\) calculation. If the error level is known, like a standard deviation, the aim might be to achieve an RMSE within this value. Often, the target is an RMSE within a specific percentage of the observed data’s objective value range.\nThe squared correlation coefficient \\(r\\), see ?eq-pears-corr, between the observed \\(y\\) and predicted \\(\\hat{y}\\) values can be computed as:\n\\[\nr^2 = \\left( \\frac{\\text{cov}(y, \\hat{y})}{\\sqrt{\\text{var}(y)\\text{var}(\\hat{y})}} \\right)^2,\n\\tag{4.5}\\]\nEquation 4.5 and can be expanded as:\n\\[\nr^2 =\n\\left(\n\\frac{n_t \\sum_{i=1}^{n_t} y^{(i)} \\hat{y}^{(i)} - \\sum_{i=1}^{n_t} y^{(i)} \\sum_{i=1}^{n_t} \\hat{y}^{(i)}}{ \\sqrt{\\left( n_t \\sum_{i=1}^{n_t} (y^{(i)})^2 - \\left(\\sum_{i=1}^{n_t} y^{(i)}\\right)^2 \\right) \\left( n_t \\sum_{i=1}^{n_t} (\\hat{y}^{(i)})^2 - \\left(\\sum_{i=1}^{n_t} \\hat{y}^{(i)}\\right)^2 \\right)}}\n\\right)^2.\n\\]\nThe correlation coefficient \\(r^2\\) does not require scaling the data sets and only compares landscape shapes, not values. An \\(r^2 &gt; 0.8\\) typically indicates a surrogate with good predictive capability.\nThe methods outlined provide quantitative assessments of model accuracy, yet visual evaluations can also be insightful. In general, the RMSE will not reach zero but will stabilize around a low value. At this point, the surrogate model is saturated with data, and further additions do not enhance the model globally (though local improvements can occur at newly added points if using an interpolating model).\n\nExample 4.3 (The Tea and Sugar Analogy) Forrester, Sóbester, and Keane (2008) illustrates this saturation point using a comparison with a cup of tea and sugar. The tea represents the surrogate model, and sugar represents data. Initially, the tea is unsweetened, and adding sugar increases its sweetness. Eventually, a saturation point is reached where no more sugar dissolves, and the tea cannot get any sweeter. Similarly, a more flexible model, like one with additional parameters or employing interpolation rather than regression, can increase the saturation point—akin to making a hotter cup of tea for dissolving more sugar.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#jupyter-notebook",
    "href": "006_constructing_surrogate.html#jupyter-notebook",
    "title": "4  Constructing a Surrogate",
    "section": "4.4 Jupyter Notebook",
    "text": "4.4 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nArlot, Sylvain, Alain Celisse, et al. 2010. “A Survey of Cross-Validation Procedures for Model Selection.” Statistics Surveys 4: 40–79.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The Elements of Statistical Learning. Second. Springer.\n\n\nKohavi, Ron. 1995. “A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection.” In Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2, 1137–43. IJCAI’95. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html",
    "href": "005_num_rsm.html",
    "title": "5  Response Surface Methods",
    "section": "",
    "text": "5.1 What is RSM?\nThis part deals with numerical implementations of optimization methods. The goal is to understand the implementation of optimization methods and to solve real-world problems numerically and efficiently. We will focus on the implementation of surrogate models, because they are the most efficient way to solve real-world problems.\nStarting point is the well-established response surface methodology (RSM). It will be extended to the design and analysis of computer experiments (DACE). The DACE methodology is a modern extension of the response surface methodology. It is based on the use of surrogate models, which are used to replace the real-world problem with a simpler problem. The simpler problem is then solved numerically. The solution of the simpler problem is then used to solve the real-world problem.\nResponse Surface Methods (RSM) refer to a collection of statistical and mathematical tools that are valuable for developing, improving, and optimizing processes. The overarching theme of RSM involves studying how input variables that control a product or process can potentially influence a response that measures performance or quality characteristics.\nThe advantages of RSM include a rich literature, well-established methods often used in manufacturing, the importance of careful experimental design combined with a well-understood model, and the potential to add significant value to scientific inquiry, process refinement, optimization, and more. However, there are also drawbacks to RSM, such as the use of simple and crude surrogates, the hands-on nature of the methods, and the limitation of local methods.\nRSM is related to various fields, including Design of Experiments (DoE), quality management, reliability, and productivity. Its applications are widespread in industry and manufacturing, focusing on designing, developing, and formulating new products and improving existing ones, as well as from laboratory research. RSM is commonly applied in domains such as materials science, manufacturing, applied chemistry, climate science, and many others.\nAn example of RSM involves studying the relationship between a response variable, such as yield (\\(y\\)) in a chemical process, and two process variables: reaction time (\\(\\xi_1\\)) and reaction temperature (\\(\\xi_2\\)). The provided code illustrates this scenario, following a variation of the so-called “banana function.”\nIn the context of visualization, RSM offers the choice between 3D plots and contour plots. In a 3D plot, the independent variables \\(\\xi_1\\) and \\(\\xi_2\\) are represented, with \\(y\\) as the dependent variable.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef fun_rosen(x1, x2):\n    b = 10\n    return (x1-1)**2 + b*(x2-x1**2)**2\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx = np.arange(-2.0, 2.0, 0.05)\ny = np.arange(-1.0, 3.0, 0.05)\nX, Y = np.meshgrid(x, y)\nzs = np.array(fun_rosen(np.ravel(X), np.ravel(Y)))\nZ = zs.reshape(X.shape)\n\nax.plot_surface(X, Y, Z)\n\nax.set_xlabel('X1')\nax.set_ylabel('X2')\nax.set_zlabel('Y')\n\nplt.show()\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-1.0, 3.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_rosen(X1, X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y , 50)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title(\"Rosenbrock's Banana Function\")\n\nText(0.5, 1.0, \"Rosenbrock's Banana Function\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#sec-rsm-intro",
    "href": "005_num_rsm.html#sec-rsm-intro",
    "title": "5  Response Surface Methods",
    "section": "",
    "text": "contour plot example:\n\n\\(x_1\\) and \\(x_2\\) are the independent variables\n\\(y\\) is the dependent variable\n\n\n\n\nVisual inspection: yield is optimized near \\((\\xi_1. \\xi_2)\\)\n\n\n5.1.1 Visualization: Problems in Practice\n\nTrue response surface is unknown in practice\nWhen yield evaluation is not as simple as a toy banana function, but a process requiring care to monitor, reconfigure and run, it’s far too expensive to observe over a dense grid\nAnd, measuring yield may be a noisy/inexact process\nThat’s where stats (RSM) comes in\n\n\n\n5.1.2 RSM: Strategies\n\nRSMs consist of experimental strategies for\nexploring the space of the process (i.e., independent/input) variables (above \\(\\xi_1\\) and \\(\\xi2)\\)\nempirical statistical modeling targeted toward development of an appropriate approximating relationship between the response (yield) and process variables local to a study region of interest\noptimization methods for sequential refinement in search of the levels or values of process variables that produce desirable responses (e.g., that maximize yield or explain variation)\nRSM used for fitting an Empirical Model\nTrue response surface driven by an unknown physical mechanism\nObservations corrupted by noise\nHelpful: fit an empirical model to output collected under different process configurations\nConsider response \\(Y\\) that depends on controllable input variables \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\)\nRSM: Equations of the Empirical Model\n\n\\(Y=f(\\xi_1, \\xi_2, \\ldots, \\xi_m) + \\epsilon\\)\n\\(\\mathbb{E}\\{Y\\} = \\eta = f(\\xi1_1, \\xi_2, \\ldots, \\xi_m)\\)\n\\(\\epsilon\\) is treated as zero mean idiosyncratic noise possibly representing\n\ninherent variation, or\nthe effect of other systems or\nvariables not under our purview at this time\n\n\n\n\n\n5.1.3 RSM: Noise in the Empirical Model\n\nTypical simplifying assumption: \\(\\epsilon \\sim N(0,\\sigma^2)\\)\nWe seek estimates for \\(f\\) and \\(\\sigma^2\\) from noisy observations \\(Y\\) at inputs \\(\\xi\\)\n\n\n\n5.1.4 RSM: Natural and Coded Variables\n\nInputs \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\) called natural variables:\n\nexpressed in natural units of measurement, e.g., degrees Celsius, pounds per square inch (psi), etc.\n\nTransformed to coded variables \\(x_1, x_2, \\ldots, x_m\\):\n\nto mitigate hassles and confusion that can arise when working with a multitude of scales of measurement\n\nTypical Transformations offering dimensionless inputs \\(x_1, x_2, \\ldots, x_m\\)\n\nin the unit cube, or\nscaled to have a mean of zero and standard deviation of one, are common choices.\n\nEmpirical model becomes \\(\\eta = f(x_1, x_2, \\ldots, x_m)\\)\n\n\n\n5.1.5 RSM Low-order Polynomials\n\nLow-order polynomial make the following simplifying Assumptions\n\nLearning about \\(f\\) is lots easier if we make some simplifying approximations\nAppealing to Taylor’s theorem, a low-order polynomial in a small, localized region of the input (\\(x\\)) space is one way forward\nClassical RSM:\n\ndisciplined application of local analysis and\nsequential refinement of locality through conservative extrapolation\n\nInherently a hands-on process",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#first-order-models-main-effects-model",
    "href": "005_num_rsm.html#first-order-models-main-effects-model",
    "title": "5  Response Surface Methods",
    "section": "5.2 First-Order Models (Main Effects Model)",
    "text": "5.2 First-Order Models (Main Effects Model)\n\nFirst-order model (sometimes called main effects model) useful in parts of the input space where it’s believed that there’s little curvature in \\(f\\): \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\]\nFor example: \\[\\eta = 50 + 8 x_1 + 3x_2\\]\nIn practice, such a surface would be obtained by fitting a model to the outcome of a designed experiment\nFirst-Order Model in python Evaluated on a Grid\nEvaluate model on a grid in a double-unit square centered at the origin\nCoded units are chosen arbitrarily, although one can imagine deploying this approximating function nearby \\(x^{(0)} = (0,0)\\)\n\n\ndef fun_1(x1,x2):\n    return 50 + 8*x1 + 3*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-1.0, 1.0, delta)\nx2 = np.arange(-1.0, 1.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_1(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model: $50 + 8x_1 + 3x_2$')\n\nText(0.5, 1.0, 'First Order Model: $50 + 8x_1 + 3x_2$')\n\n\n\n\n\n\n\n\n\n\n5.2.1 First-Order Model Properties\n\nFirst-order model in 2d traces out a plane in \\(y \\times (x_1, x_2)\\) space\nOnly be appropriate for the most trivial of response surfaces, even when applied in a highly localized part of the input space\nAdding curvature is key to most applications:\n\nFirst-order model with interactions induces limited degree of curvature via different rates of change of \\(y\\) as \\(x_1\\) is varied for fixed \\(x_2\\), and vice versa: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_{12} \\]\n\nFor example \\(\\eta = 50+8x_1+3x_2-4x_1x_2\\)\n\n\n\n5.2.2 First-order Model with Interactions in python\n\nCode below facilitates evaluations for pairs \\((x_1, x_2)\\)\nResponses may be observed over a mesh in the same double-unit square\n\n\ndef fun_11(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_11(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model with Interactions')\n\nText(0.5, 1.0, 'First Order Model with Interactions')\n\n\n\n\n\n\n\n\n\n\n\n5.2.3 Observations: First-Order Model with Interactions\n\nMean response \\(\\eta\\) is increasing marginally in both \\(x_1\\) and \\(x_2\\), or conditional on a fixed value of the other until \\(x_1\\) is 0.75\nRate of increase slows as both coordinates grow simultaneously since the coefficient in front of the interaction term \\(x_1 x_2\\) is negative\nCompared to the first-order model (without interactions): surface is far more useful locally\nLeast squares regressions often flag up significant interactions when fit to data collected on a design far from local optima",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#second-order-models",
    "href": "005_num_rsm.html#second-order-models",
    "title": "5  Response Surface Methods",
    "section": "5.3 Second-Order Models",
    "text": "5.3 Second-Order Models\n\nSecond-order model may be appropriate near local optima where \\(f\\) would have substantial curvature: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2  + \\beta_{11}x_1^2 + \\beta_{22}x^2 + \\beta_{12} x_1 x_2\\]\nFor example \\[\\eta = 50 + 8 x_1 + 3x_2 - 7x_1^2 - 3 x_2^2 - 4x_1x_2\\]\nImplementation of the Second-Order Model as fun_2().\n\n\ndef fun_2(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 7 * x1**2 - 3*x2**2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_2(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\nText(0.5, 1.0, 'Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\n\n\n\n\n\n\n\n\n\n5.3.1 Second-Order Models: Properties\n\nNot all second-order models would have a single stationary point (in RSM jargon called “a simple maximum”)\nIn “yield maximizing” setting we’re presuming response surface is concave down from a global viewpoint\n\neven though local dynamics may be more nuanced\n\nExact criteria depend upon the eigenvalues of a certain matrix built from those coefficients\nBox and Draper (2007) provide a diagram categorizing all of the kinds of second-order surfaces in RSM analysis, where finding local maxima is the goal\n\n\n\n5.3.2 Example: Stationary Ridge\n\nExample set of coefficients describing what’s called a stationary ridge is provided by the code below\n\n\ndef fun_ridge(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Example of a stationary ridge')\n\nText(0.5, 1.0, 'Example of a stationary ridge')\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 Observations: Second-Order Model (Ridge)\n\nRidge: a whole line of stationary points corresponding to maxima\nSituation means that the practitioner has some flexibility when it comes to optimizing:\n\ncan choose the precise setting of \\((x_1, x_2)\\) either arbitrarily or (more commonly) by consulting some tertiary criteria\n\n\n\n\n5.3.4 Example: Rising Ridge\n\nAn example of a rising ridge is implemented by the code below.\n\n\ndef fun_ridge_rise(x1, x2):\n     return 80 - 4*x1 + 12*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge_rise(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n5.3.5 Summary: Rising Ridge\n\nThe stationary point is remote to the study region\nCcontinuum of (local) stationary points along any line going through the 2d space, excepting one that lies directly on the ridge\nAlthough estimated response will increase while moving along the axis of symmetry toward its stationary point, this situation indicates\n\neither a poor fit by the approximating second-order function, or\nthat the study region is not yet precisely in the vicinity of a local optima—often both.\n\n\n\n\n5.3.6 Falling Ridge\n\nInversion of a rising ridge is a falling ridge\nSimilarly indicating one is far from local optima, except that the response decreases as you move toward the stationary point\nFinding a falling ridge system can be a back-to-the-drawing-board affair.\n\n\n\n5.3.7 Saddle Point\n\nFinally, we can get what’s called a saddle or minimax system.\n\n\ndef fun_saddle(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 2*x2**2 - 12*x1*x2 \n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_saddle(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n5.3.8 Interpretation: Saddle Points\n\nLikely further data collection, and/or outside expertise, is needed before determining a course of action in this situation\n\n\n\n5.3.9 Summary: Ridge Analysis\n\nFinding a simple maximum, or stationary ridge, represents ideals in the spectrum of second-order approximating functions\nBut getting there can be a bit of a slog\nUsing models fitted from data means uncertainty due to noise, and therefore uncertainty in the type of fitted second-order model\nA ridge analysis attempts to offer a principled approach to navigating uncertainties when one is seeking local maxima\nThe two-dimensional setting exemplified above is convenient for visualization, but rare in practice\nComplications compound when studying the effect of more than two process variables",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-rsm-models",
    "href": "005_num_rsm.html#general-rsm-models",
    "title": "5  Response Surface Methods",
    "section": "5.4 General RSM Models",
    "text": "5.4 General RSM Models\n\nGeneral first-order model on \\(m\\) process variables \\(x_1, x_2, \\cdots, x_m\\) is \\[\\eta = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_m x_m\\]\nGeneral second-order model on \\(m\\) process variables \\[\n\\eta= \\beta_0 + \\sum_{j=1}^m + \\sum_{j=1}^m x_j^2 + \\sum_{j=2}^m \\sum_{k=1}^j \\beta_{kj}x_k x_j.\n\\]\n\n\n5.4.1 Ordinary Least Squares\n\nInference from data is carried out by ordinary least squares (OLS)\nFor an excellent review including R examples, see Sheather (2009)\nOLS and maximum likelihood estimators (MLEs) are in the typical Gaussian linear modeling setup basically equivalent",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-linear-regression",
    "href": "005_num_rsm.html#general-linear-regression",
    "title": "5  Response Surface Methods",
    "section": "5.5 General Linear Regression",
    "text": "5.5 General Linear Regression\nWe are considering a model, which can be written in the form\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\) is an \\((n \\times 1)\\) vector of observations (responses), \\(X\\) is an \\((n \\times p)\\) matrix of known form, \\(\\beta\\) is a \\((1 \\times p)\\) vector of unknown parameters, and \\(\\epsilon\\) is an \\((n \\times 1)\\) vector of errors. Furthermore, \\(E(\\epsilon) = 0\\), \\(Var(\\epsilon) = \\sigma^2 I\\) and the \\(\\epsilon_i\\) are uncorrelated.\nUsing the normal equations \\[\n(X'X)b = X'Y,\n\\]\nthe solution is given by\n\\[\nb = (X'X)^{-1}X'Y.\n\\]\n\nExample 5.1 (Linear Regression)  \n\nimport numpy as np\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\nprint(np.round(X, 2))\ny = np.sin(X)\nprint(np.round(y, 2))\n# fit an OLS model to the data, predict the response based on the 1ßß x values\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X, y)\ny_pred = model.predict(x)\n# visualize the data and the fitted model\nimport matplotlib.pyplot as plt\nplt.scatter(X, y, color='black')\nplt.plot(x, y_pred, color='blue', linewidth=1)\n# add the ground truth (sine function) in orange\nplt.plot(x, np.sin(x), color='orange', linewidth=1)\nplt.show()\n\n[[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\n[[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#designs",
    "href": "005_num_rsm.html#designs",
    "title": "5  Response Surface Methods",
    "section": "5.6 Designs",
    "text": "5.6 Designs\n\nImportant: Organize the data collection phase of a response surface study carefully\nDesign: choice of \\(x\\)’s where we plan to observe \\(y\\)’s, for the purpose of approximating \\(f\\)\nAnalyses and designs need to be carefully matched\nWhen using a first-order model, some designs are preferred over others\nWhen using a second-order model to capture curvature, a different sort of design is appropriate\nDesign choices often contain features enabling modeling assumptions to be challenged\n\ne.g., to check if initial impressions are supported by the data ultimately collected\n\n\n\n5.6.1 Different Designs\n\nScreening desings: determine which variables matter so that subsequent experiments may be smaller and/or more focused\nThen there are designs tailored to the form of model (first- or second-order, say) in the screened variables\nAnd then there are more designs still",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-experimentation",
    "href": "005_num_rsm.html#rsm-experimentation",
    "title": "5  Response Surface Methods",
    "section": "5.7 RSM Experimentation",
    "text": "5.7 RSM Experimentation\n\n5.7.1 First Step\n\nRSM-based experimentation begins with a first-order model, possibly with interactions\nPresumption: current process operating far from optimal conditions\nCollect data and apply method of steepest ascent (gradient) on fitted surfaces to move to the optimum\n\n\n\n5.7.2 Second Step\n\nEventually, if all goes well after several such carefully iterated refinements, second-order models are used on appropriate designs in order to zero-in on ideal operating conditions\nCareful analysis of the fitted surface:\n\nRidge analysis with further refinement using gradients of, and\nstandard errors associated with, the fitted surfaces, and so on\n\n\n\n\n5.7.3 Third Step\n\nOnce the practitioner is satisfied with the full arc of\n\ndesign(s),\nfit(s), and\ndecision(s):\n\nA small experiment called confirmation test may be performed to check if the predicted optimal settings are realizable in practice",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-review-and-general-considerations",
    "href": "005_num_rsm.html#rsm-review-and-general-considerations",
    "title": "5  Response Surface Methods",
    "section": "5.8 RSM: Review and General Considerations",
    "text": "5.8 RSM: Review and General Considerations\n\nFirst Glimpse, RSM seems sensible, and pretty straightforward as quantitative statistics-based analysis goes\nBut: RSM can get complicated, especially when input dimensions are not very low\nDesign considerations are particularly nuanced, since the goal is to obtain reliable estimates of main effects, interaction, and curvature while minimizing sampling effort/expense\nRSM Downside: Inefficiency\n\nDespite intuitive appeal, several RSM downsides become apparent upon reflection\nProblems in practice\nStepwise nature of sequential decision making is inefficient:\n\nNot obvious how to re-use or update analysis from earlier phases, or couple with data from other sources/related experiments\n\n\nRSM Downside: Locality\n\nIn addition to being local in experiment-time (stepwise approach), it’s local in experiment-space\nBalance between\n\nexploration (maybe we’re barking up the wrong tree) and\nexploitation (let’s make things a little better) is modest at best\n\n\nRSM Downside: Expert Knowledge\n\nInterjection of expert knowledge is limited to hunches about relevant variables (i.e., the screening phase), where to initialize search, how to design the experiments\nYet at the same time classical RSMs rely heavily on constant examination throughout stages of modeling and design and on the instincts of seasoned practitioners\n\nRSM Downside: Replicability\n\nParallel analyses, conducted according to the same best intentions, rarely lead to the same designs, model fits and so on\nSometimes that means they lead to different conclusions, which can be cause for concern\n\n\n\n5.8.1 Historical Considerations about RSM\n\nIn spite of those criticisms, however, there was historically little impetus to revise the status quo\nClassical RSM was comfortable in its skin, consistently led to improvements or compelling evidence that none can reasonably be expected\nBut then in the late 20th century came an explosive expansion in computational capability, and with it a means of addressing many of those downsides\n\n\n\n5.8.2 Status Quo\n\nNowadays, field experiments and statistical models, designs and optimizations are coupled with with mathematical models\nSimple equations are not regarded as sufficient to describe real-world systems anymore\nPhysicists figured that out fifty years ago; industrial engineers followed, biologists, social scientists, climate scientists and weather forecasters, etc.\nSystems of equations are required, solved over meshes (e.g., finite elements), or stochastically interacting agents\nGoals for those simulation experiments are as diverse as their underlying dynamics\nOptimization of systems is common, e.g., to identify worst-case scenarios\n\n\n\n5.8.3 The Role of Statistics\n\nSolving systems of equations, or interacting agents, requires computing\nStatistics involved at various stages:\n\nchoosing the mathematical model\nsolving by stochastic simulation (Monte Carlo)\ndesigning the computer experiment\nsmoothing over idiosyncrasies or noise\nfinding optimal conditions, or\ncalibrating mathematical/computer models to data from field experiments\n\n\n\n\n5.8.4 New RSM is needed: DACE\n\nClassical RSMs are not well-suited to any of those tasks, because\n\nthey lack the fidelity required to model these data\ntheir intended application is too local\nthey’re also too hands-on.\n\nOnce computers are involved, a natural inclination is to automate—to remove humans from the loop and set the computer running on the analysis in order to maximize computing throughput, or minimize idle time\nDesign and Analysis of Computer Experiments as a modern extension of RSM\nExperimentation is changing due to advances in machine learning\nGaussian process (GP) regression is the canonical surrogate model\nOrigins in geostatistics (gold mining)\nWide applicability in contexts where prediction is king\nMachine learners exposed GPs as powerful predictors for all sorts of tasks:\nfrom regression to classification,\nactive learning/sequential design,\nreinforcement learning and optimization,\nlatent variable modeling, and so on",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#exercises",
    "href": "005_num_rsm.html#exercises",
    "title": "5  Response Surface Methods",
    "section": "5.9 Exercises",
    "text": "5.9 Exercises\n\nGenerate 3d Plots for the Contour Plots in this notebook.\nWrite a plot_3d function, that takes the objective function fun as an argument.\n\n\nIt should provide the following interface: plot_3d(fun).\n\n\nWrite a plot_contour function, that takes the objective function fun as an argument:\n\n\nIt should provide the following interface: plot_contour(fun).\n\n\nConsider further arguments that might be useful for both function, e.g., ranges, size, etc.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#jupyter-notebook",
    "href": "005_num_rsm.html#jupyter-notebook",
    "title": "5  Response Surface Methods",
    "section": "5.10 Jupyter Notebook",
    "text": "5.10 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html",
    "href": "006_num_poly.html",
    "title": "6  Polynomial Models",
    "section": "",
    "text": "6.1 Fitting a Polynomial\nWe will consider one-variable cases, i.e., \\(k=1\\), first.\nLet us consider the scalar-valued function \\(f: \\mathbb{R} \\to \\mathbb{R}\\) observed according to the sampling plan \\(X = \\{x^{(1)}, x^{(2)} \\dots, x^{(n)}\\}^T\\), yielding the responses \\(\\vec{y} = \\{y^{(1)}, y^{(2)}, \\dots, y^{(n)}\\}^T\\).\nA polynomial approximation of \\(f\\) of order \\(m\\) can be written as:\n\\[\n\\hat{f}(x, m, \\vec{w}) = \\sum_{i=0}^m w_i x^i.\n\\]\nIn the spirit of the earlier discussion of maximum likelihood parameter estimation, we seek to estimate \\(w = {w_0, w_1, \\dots, w_m}^T\\) through a least squares solution of:\n\\[\n\\Phi \\vec{w} = \\vec{y}\n\\] where \\(\\Phi\\) is the Vandermonde matrix:\n\\[\n\\Phi =\n\\begin{bmatrix}\n1 & x_1 & x_1^2 & \\dots & x_1^m \\\\\n1 & x_2 & x_2^2 & \\dots & x_2^m \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_n & x_n^2 & \\dots & x_n^m\n\\end{bmatrix}.\n\\]\nThe maximum likelihood estimate of \\(w\\) is given by:\n\\[\n\\vec{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T y,\n\\]\nwhere \\(\\Phi^+ = (\\Phi^T \\Phi)^{-1} \\Phi^T\\) is the Moore-Penrose pseudo-inverse of \\(\\Phi\\) (see Section 9.3).\nThe polynomial approximation of order \\(m\\) is essentially a truncated Taylor series expansion. While higher values of \\(m\\) yield more accurate approximations, they risk overfitting the noise in the data.\nTo prevent this, we estimate \\(m\\) using cross-validation. This involves minimizing the cross-validation error over a discrete set of possible orders \\(m\\) (e.g., \\(m \\in {1, 2, \\dots, 15}\\)).\nFor each \\(m\\), the data is split into \\(q\\) subsets. The model is trained on \\(q-1\\) subsets, and the error is computed on the left-out subset. This process is repeated for all subsets, and the cross-validation error is summed. The order \\(m\\) with the smallest cross-validation error is chosen.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#polynomial-fitting-in-python",
    "href": "006_num_poly.html#polynomial-fitting-in-python",
    "title": "6  Polynomial Models",
    "section": "6.2 Polynomial Fitting in Python",
    "text": "6.2 Polynomial Fitting in Python\n\n6.2.1 Fitting the Polynomial\n\nfrom sklearn.model_selection import KFold\ndef polynomial_fit(X, Y, max_order=15, q=5):\n    \"\"\"\n    Fits a one-variable polynomial to one-dimensional data using cross-validation.\n\n    Args:\n        X (array-like): Training data vector (independent variable).\n        Y (array-like): Training data vector (dependent variable).\n        max_order (int): Maximum polynomial order to consider. Default is 15.\n        q (int): Number of cross-validation folds. Default is 5.\n\n    Returns:\n        best_order (int): The optimal polynomial order.\n        coeff (array): Coefficients of the best-fit polynomial.\n        mnstd (tuple): Normalization parameters (mean, std) for X.\n    \"\"\"\n    X = np.array(X)\n    Y = np.array(Y)\n    n = len(X)\n    # Normalize X\n    mnstd = (np.mean(X), np.std(X))\n    X_norm = (X - mnstd[0]) / mnstd[1]\n    # Cross-validation setup\n    kf = KFold(n_splits=q, shuffle=True, random_state=42)\n    cross_val_errors = np.zeros(max_order)\n    for order in range(1, max_order + 1):\n        fold_errors = []\n        for train_idx, val_idx in kf.split(X_norm):\n            X_train, X_val = X_norm[train_idx], X_norm[val_idx]\n            Y_train, Y_val = Y[train_idx], Y[val_idx]\n            # Fit polynomial\n            coeff = np.polyfit(X_train, Y_train, order)\n            # Predict on validation set\n            Y_pred = np.polyval(coeff, X_val)\n            # Compute mean squared error\n            mse = np.mean((Y_val - Y_pred) ** 2)\n            fold_errors.append(mse)\n        cross_val_errors[order - 1] = np.mean(fold_errors)\n    # Find the best order\n    best_order = np.argmin(cross_val_errors) + 1\n    # Fit the best polynomial on the entire dataset\n    best_coeff = np.polyfit(X_norm, Y, best_order)\n    return best_order, best_coeff, mnstd\n\n\n\n6.2.2 Explaining the \\(k\\)-fold Cross-Validation\nThe line\nkf = KFold(n_splits=q, shuffle=True, random_state=42)\ninitializes a \\(k\\)-Fold cross-validator object from the sklearn.model_selection library. The n_splits parameter specifies the number of folds. The data will be divided into q parts. In each iteration of the cross-validation, one part will be used as the validation set, and the remaining q-1 parts will be used as the training set.\nThe kf.split method takes the dataset X_norm as input and yields pairs of index arrays for each fold: * train_idx: In each iteration, train_idx is an array containing the indices of the data points that belong to the training set for that specific fold. * val_idx: Similarly, val_idx is an array containing the indices of the data points that belong to the validation (or test) set for that specific fold.\nThe loop will run q times (the number of splits). In each iteration, a different fold serves as the validation set, while the other q-1 folds form the training set.\nHere’s a Python example to demonstrate the values of train_idx and val_idx:\n\n# Sample data (e.g., X_norm)\nX_norm = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\nprint(f\"Original data indices: {np.arange(len(X_norm))}\\n\")\n# Number of splits (folds)\nq = 3 # Let's use 3 folds for this example\n# Initialize KFold\nkf = KFold(n_splits=q, shuffle=True, random_state=42)\n# Iterate through the splits and print the indices\nfold_number = 1\nfor train_idx, val_idx in kf.split(X_norm):\n    print(f\"--- Fold {fold_number} ---\")\n    print(f\"Train indices: {train_idx}\")\n    print(f\"Validation indices: {val_idx}\")\n    print(f\"Training data for this fold: {X_norm[train_idx]}\")\n    print(f\"Validation data for this fold: {X_norm[val_idx]}\\n\")\n    fold_number += 1\n\nOriginal data indices: [0 1 2 3 4 5 6 7 8 9]\n\n--- Fold 1 ---\nTrain indices: [2 3 4 6 7 9]\nValidation indices: [0 1 5 8]\nTraining data for this fold: [0.3 0.4 0.5 0.7 0.8 1. ]\nValidation data for this fold: [0.1 0.2 0.6 0.9]\n\n--- Fold 2 ---\nTrain indices: [0 1 3 4 5 6 8]\nValidation indices: [2 7 9]\nTraining data for this fold: [0.1 0.2 0.4 0.5 0.6 0.7 0.9]\nValidation data for this fold: [0.3 0.8 1. ]\n\n--- Fold 3 ---\nTrain indices: [0 1 2 5 7 8 9]\nValidation indices: [3 4 6]\nTraining data for this fold: [0.1 0.2 0.3 0.6 0.8 0.9 1. ]\nValidation data for this fold: [0.4 0.5 0.7]\n\n\n\n\n\n6.2.3 Making Predictions\nTo make predictions, we can use the coefficients. The data is standardized around its mean in the polynomial function, which is why the vector mnstd is required. The coefficient vector is computed based on the normalized data, and this must be taken into account if further analytical calculations are performed on the fitted model.\nThe polynomial approximation of \\(C_D\\) is:\n\\[\nC_D(x) = w_8 x^8 + w_7 x^7 + \\dots + w_1 x + w_0,\n\\]\nwhere \\(x\\) is normalized as:\n\\[\n\\bar{x} = \\frac{x - \\mu(X)}{\\sigma(X)}\n\\]\n\ndef predict_polynomial_fit(X, coeff, mnstd):\n    \"\"\"\n    Generates predictions for the polynomial fit.\n\n    Args:\n        X (array-like): Original independent variable data.\n        coeff (array): Coefficients of the best-fit polynomial.\n        mnstd (tuple): Normalization parameters (mean, std) for X.\n\n    Returns:\n        tuple: De-normalized predicted X values and corresponding Y predictions.\n    \"\"\"\n    # Normalize X\n    X_norm = (X - mnstd[0]) / mnstd[1]\n\n    # Generate predictions\n    X_pred = np.linspace(min(X_norm), max(X_norm), 100)\n    Y_pred = np.polyval(coeff, X_pred)\n\n    # De-normalize X for plotting\n    X_pred_original = X_pred * mnstd[1] + mnstd[0]\n\n    return X_pred_original, Y_pred\n\n\n\n6.2.4 Plotting the Results\n\ndef plot_polynomial_fit(X, Y, X_pred_original, Y_pred, best_order, y_true=None):\n    \"\"\"\n    Visualizes the polynomial fit.\n\n    Args:\n        X (array-like): Original independent variable data.\n        Y (array-like): Original dependent variable data.\n        X_pred_original (array): De-normalized predicted X values.\n        Y_pred (array): Predicted Y values.\n        y_true (array): True Y values.\n        best_order (int): The optimal polynomial order.\n    \"\"\"\n    plt.scatter(X, Y, label=\"Training Data\", color=\"grey\", marker=\"o\")\n    plt.plot(X_pred_original, Y_pred, label=f\"Order {best_order} Polynomial\", color=\"red\")\n    if y_true is not None:\n        plt.plot(X, y_true, label=\"True Function\", color=\"blue\", linestyle=\"--\")\n    plt.title(f\"Polynomial Fit (Order {best_order})\")\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.legend()\n    plt.show()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#example-one-aerofoil-drag",
    "href": "006_num_poly.html#example-one-aerofoil-drag",
    "title": "6  Polynomial Models",
    "section": "6.3 Example One: Aerofoil Drag",
    "text": "6.3 Example One: Aerofoil Drag\nThe circles in Figure 6.1 represent 101 drag coefficient values obtained through a numerical simulation by iterating each member of a family of aerofoils towards a target lift value (see the Appendix, Section A.3 in Forrester, Sóbester, and Keane (2008)). The members of the family have different shapes, as determined by the sampling plan:\n\\[\nX = {x_1, x_2, \\dots, x_{101}}\n\\]\nThe responses are:\n\\[\nC_D = \\{C_{D}^{(1)}, C_{D}^{(2)}, \\dots, C_{D}^{(101)}\\}\n\\]\nThese responses are corrupted by “noise,” which are deviations of the systematic variety caused by small changes in the computational mesh from one design to the next.\nThe original data is measured in natural units, i.e., from \\(-0.3\\) untion to \\(0.1\\) unit. The data is normalized to the range of \\(0\\) to \\(1\\) for the computation with the aerofoilcd function. The data is then fitted with a polynomial of order \\(m\\). To obtain the best polynomial through this data, the following Python code can be used:\n\nfrom spotpython.surrogate.functions.forr08a import aerofoilcd\nimport numpy as np\nimport matplotlib.pyplot as plt\nX = np.linspace(-0.3, 0.1, 101)\n# normalize the data so that it will be in the range of 0 to 1\na = np.min(X)\nb = np.max(X)\nX_cod = (X - a) / (b - a)\ny = aerofoilcd(X_cod)\nbest_order, best_coeff, mnstd = polynomial_fit(X, y)\nX_pred_original, Y_pred = predict_polynomial_fit(X, best_coeff, mnstd)\n\n\nplot_polynomial_fit(X, y, X_pred_original, Y_pred, best_order)\n\n\n\n\n\n\n\nFigure 6.1: Aerofoil drag data\n\n\n\n\n\nFigure 6.1 shows an eighth-order polynomial fitted through the aerofoil drag data. The order was selected via cross-validation, and the coefficients were determined through likelihood maximization. Results, i.e, the best polynomial order and coefficients, are printed in the console. The coefficients are stored in the vector best_coeff, which contains the coefficients of the polynomial in descending order. The first element is the coefficient of \\(x^8\\), and the last element is the constant term. The vector mnstd, containing the mean and standard deviation of \\(X\\), is:\n\nprint(f\"Best polynomial order: {best_order}\\n\")\nprint(f\"Coefficients (starting with w0):\\n {best_coeff}\\n\")\nprint(f\"Normalization parameters (mean, std):\\n {mnstd}\\n\")\n\nBest polynomial order: 8\n\nCoefficients (starting with w0):\n [-0.00022964 -0.00014636  0.00116742  0.00052988 -0.0016912  -0.00047398\n  0.00244373  0.00270342  0.03041508]\n\nNormalization parameters (mean, std):\n (np.float64(-0.09999999999999999), np.float64(0.11661903789690602))",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#example-two-a-multimodal-test-case",
    "href": "006_num_poly.html#example-two-a-multimodal-test-case",
    "title": "6  Polynomial Models",
    "section": "6.4 Example Two: A Multimodal Test Case",
    "text": "6.4 Example Two: A Multimodal Test Case\nLet us consider the one-variable test function:\n\\[\nf(x) = (6x - 2)^2 \\sin(12x - 4).\n\\]\n\nimport numpy as np\nfrom spotpython.surrogate.functions.forr08a import onevar\nX = np.linspace(0, 1, 51)\ny_true = onevar(X)\n# initialize random seed\nnp.random.seed(42)\ny = y_true + np.random.normal(0, 1, len(X))*1.1\nbest_order, best_coeff, mnstd = polynomial_fit(X, y)\nX_pred_original, Y_pred = predict_polynomial_fit(X, best_coeff, mnstd)\n\n\nplot_polynomial_fit(X, y, X_pred_original, Y_pred, best_order, y_true=y_true)\n\n\n\n\n\n\n\nFigure 6.2: Onevar function\n\n\n\n\n\nThis function, depicted by the dotted line in Figure 6.2, has local minima of different depths, which can be deceptive to some surrogate-based optimization procedures. Here, we use it as an example of a multimodal function for polynomial fitting.\nWe generate the training data (depicted by circles in Figure 6.2) by adding normally distributed noise to the function. Figure 6.2 shows a seventh-order polynomial fitted through the noisy data. This polynomial was selected as it minimizes the cross-validation metric.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#extending-to-multivariable-polynomial-models",
    "href": "006_num_poly.html#extending-to-multivariable-polynomial-models",
    "title": "6  Polynomial Models",
    "section": "6.5 Extending to Multivariable Polynomial Models",
    "text": "6.5 Extending to Multivariable Polynomial Models\nWhile the examples above focus on the one-variable case, real-world engineering problems typically involve multiple input variables. For \\(k\\)-variable problems, polynomial approximation becomes significantly more complex but follows the same fundamental principles. For a \\(k\\)-dimensional input space, the polynomial approximation can be expressed as:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^N w_i \\phi_i(\\vec{x}),\n\\] where \\(\\phi_i(\\vec{x})\\) represents multivariate basis functions, and \\(N\\) is the total number of terms in the polynomial. Unlike the univariate case, these basis functions include all possible combinations of variables up to the selected polynomial order \\(m\\), which might result in a “basis function explosion” as the number of variables increases.\nFor a third-order polynomial (\\(m = 3\\)) with three variables (\\(k = 3\\)), the complete set of basis functions would include 20 terms:\n\\[\\begin{align}\n\\text{Constant term: } & {1} \\\\\n\\text{First-order terms: } & {x_1, x_2, x_3} \\\\\n\\text{Second-order terms: } & {x_1^2, x_2^2, x_3^2, x_1x_2, x_1x_3, x_2x_3} \\\\\n\\text{Third-order terms: } & {x_1^3, x_2^3, x_3^3, x_1^2x_2, x_1^2x_3, x_2^2x_1, x_2^2x_3, x_3^2x_1, x_3^2x_2, x_1x_2x_3}\n\\end{align}\\]\nThe total number of terms grows combinatorially as \\(N = \\binom{k+m}{m}\\), which quickly becomes prohibitive as dimensionality increases. For example, a 10-variable cubic polynomial requires \\(\\binom{13}{3} = 286\\) coefficients! This exponential growth creates three interrelated challenges:\n\nModel Selection: Determining the appropriate polynomial order \\(m\\) that balances complexity with generalization ability\nCoefficient Estimation: Computing the potentially large number of weights \\(\\vec{w}\\) while avoiding numerical instability\nTerm Selection: Identifying which specific basis functions should be included, as many may be irrelevant to the response\n\nSeveral techniques have been developed to address these challenges:\n\nRegularization methods (LASSO, ridge regression) that penalize model complexity\nStepwise regression algorithms that incrementally add or remove terms\nDimension reduction techniques that project the input space to lower dimensions\nOrthogonal polynomials that improve numerical stability for higher-order models\n\nThese limitations of polynomial models in higher dimensions motivate the exploration of more flexible surrogate modeling approaches like Radial Basis Functions and Kriging, which we’ll examine in subsequent sections.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#jupyter-notebook",
    "href": "006_num_poly.html#jupyter-notebook",
    "title": "6  Polynomial Models",
    "section": "6.6 Jupyter Notebook",
    "text": "6.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html",
    "href": "006_num_rbf.html",
    "title": "7  Radial Basis Function Models",
    "section": "",
    "text": "7.1 Radial Basis Function Models\nScientists and engineers frequently tackle complex functions by decomposing them into a “vocabulary” of simpler, well-understood basic functions. These fundamental building blocks possess properties that make them easier to analyze mathematically and implement computationally. We explored this concept earlier with multivariable polynomials, where complex behaviors were modeled using combinations of polynomial terms such as \\(1\\), \\(x_1\\), \\(x_2\\), \\(x_1^2\\), and \\(x_1 x_2\\). This approach is not limited to polynomials; it extends to various function classes, including trigonometric functions, exponential functions, and even more complex structures.\nWhile Fourier analysis—perhaps the most widely recognized example of this approach—excels at representing periodic phenomena through sine and cosine functions, the focus in Forrester, Sóbester, and Keane (2008) is broader. They aim to approximate arbitrary smooth, continuous functions using strategically positioned basis functions. Specifically, radial basis function (RBF) models employ symmetrical basis functions centered at selected points distributed throughout the design space. These basis functions have the unique property that their output depends only on the distance from their center point.\nFirst, we give a definition of the Euclidean distance, which is the most common distance measure used in RBF models.\nThe Euclidean distance measure represents the straight-line distance between two points in Euclidean space.\nUsing the Euclidean distance, we can define the radial basis function (RBF) model.\nIn the context of RBFs, the Euclidean distance calculation determines how much influence a particular center point \\(\\vec{c}\\) has on the prediction at point \\(\\vec{x}\\).\nWe will first examine interpolating RBF models, which assume noise-free data and pass exactly through all training points. This approach provides an elegant mathematical foundation before we consider more practical scenarios where data contains measurement or process noise.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#radial-basis-function-models",
    "href": "006_num_rbf.html#radial-basis-function-models",
    "title": "7  Radial Basis Function Models",
    "section": "",
    "text": "Definition 7.1 (Euclidean Distance) The Euclidean distance between two points in a \\(k\\)-dimensional space is defined as:\n\\[\n\\|\\vec{x} - \\vec{c}\\| = \\sqrt{\\sum_{i=1}^{k} (x_i - c_i)^2},\n\\tag{7.1}\\]\nwhere:\n\n\\(\\vec{x} = (x_1, x_2, \\ldots, x_d)\\) is the first point,\n\\(\\vec{c} = (c_1, c_2, \\ldots, c_d)\\) is the second point, and\n\\(k\\) is the number of dimensions.\n\n\n\n\n\nDefinition 7.2 (Radial Basis Function (RBF)) Mathematically, a radial basis function \\(\\psi\\) can be expressed as:\n\\[\n\\psi(\\vec{x}) = \\psi(\\|\\vec{x} - \\vec{c}\\|),\n\\tag{7.2}\\] where \\(\\vec{x}\\) is the input vector, \\(\\vec{c}\\) is the center of the function, and \\(\\|\\vec{x} - \\vec{c}\\|\\) denotes the Euclidean distance between \\(\\vec{x}\\) and \\(\\vec{c}\\).\n\n\n\n\n7.1.1 Fitting Noise-Free Data\nLet us consider the scalar valued function \\(f\\) observed without error, according to the sampling plan \\(X = \\{\\vec{x}^{(1)}, \\vec{x}^{(2)}, \\ldots, \\vec{x}^{(n)}\\}^T\\), yielding the responses \\(\\vec{y} = \\{y^{(1)}, y^{(2)}, \\ldots, y^{(n)}\\}^T\\).\nFor a given set of \\(n_c\\) centers \\(\\vec{c}^{(i)}\\), we would like to express the RBF model as a linear combination of the basis functions centered at these points. The goal is to find the weights \\(\\vec{w}\\) that minimize the error between the predicted and observed values. Thus, we seek a radial basis function approximation to \\(f\\) of the fixed form:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n_c} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||),\n\\tag{7.3}\\] where\n\n\\(w_i\\) are the weights of the \\(n_c\\) basis functions,\n\\(\\vec{c}^{(i)}\\) are the \\(n_c\\) centres of the basis functions, and\n\\(\\psi\\) is a radial basis function.\n\nThe notation \\(||\\cdot||\\) denotes the Euclidean distance between two points in the design space as defined in Equation 7.1.\n\n7.1.1.1 Selecting Basis Functions: From Fixed to Parametric Forms\nWhen implementing a radial basis function model, we initially have one undetermined parameter per basis function: the weight applied to each function’s output. This simple parameterization remains true when we select from several standard fixed-form basis functions, such as:\n\nLinear (\\(\\psi(r) = r\\)): The simplest form, providing a response proportional to distance\nCubic (\\(\\psi(r) = r^3\\)): Offers stronger emphasis on points farther from the center\nThin plate spline (\\(\\psi(r) = r^2 \\ln r\\)): Models the physical bending of a thin sheet, providing excellent smoothness properties\n\nWhile these fixed basis functions are computationally efficient, they offer limited flexibility in how they generalize across the design space. For more adaptive modeling power, we can employ parametric basis functions that introduce additional tunable parameters:\n\nGaussian (\\(\\psi(r) = e^{-r^2/(2\\sigma^2)}\\)): Produces bell-shaped curves with \\(\\sigma\\) controlling the width of influence\nMultiquadric (\\(\\psi(r) = (r^2 + \\sigma^2)^{1/2}\\)): Provides broader coverage with less localized effects\nInverse multiquadric (\\(\\psi(r) = (r^2 + \\sigma^2)^{-1/2}\\)): Offers sharp peaks near centers with asymptotic behavior\n\nThe parameter \\(\\sigma\\) in these functions serves as a shape parameter that controls how rapidly the function’s influence decays with distance. This added flexibility enables significantly better generalization, particularly when modeling complex responses, though at the cost of a more involved parameter estimation process requiring optimization of both weights and shape parameters.\n\nExample 7.1 (Gaussian RBF) Using the general definition of a radial basis function (Equation 7.2), we can express the Gaussian RBF as: \\[\n\\psi(\\vec{x}) = \\exp\\left(-\\frac{\\|\\vec{x} - \\vec{c}\\|^2}{2\\sigma^2}\\right)  = \\exp\\left(-\\frac{\\sum_{j=1}^{k} (x_j - c_j)^2}{2\\sigma^2}\\right)\n\\tag{7.4}\\] where:\n\n\\(\\vec{x}\\) is the input vector,\n\\(\\vec{c}\\) is the center vector,\n\\(\\|\\vec{x} - \\vec{c}\\|\\) is the Euclidean distance between the input and center, and\n\\(\\sigma\\) is the width parameter that controls how quickly the function’s response diminishes with distance from the center.\n\nThe Gaussian RBF produces a bell-shaped response that reaches its maximum value of 1 when \\(\\vec{x} = \\vec{c}\\) and asymptotically approaches zero as the distance increases. The parameter \\(\\sigma\\) determines how “localized” the response is—smaller values create a narrower peak with faster decay, while larger values produce a broader, more gradual response across the input space. Figure 7.1 shows the Gaussian RBF for different values of \\(\\sigma\\) in an one-dimensional space. The center of the RBF is set at 0, and the width parameter \\(\\sigma\\) varies to illustrate how it affects the shape of the function.\n\ndef gaussian_rbf(x, center, sigma):\n    \"\"\"\n    Compute the Gaussian Radial Basis Function.\n\n    Args:\n        x (ndarray): Input points\n        center (float): Center of the RBF\n        sigma (float): Width parameter\n\n    Returns:\n        ndarray: RBF values\n    \"\"\"\n    return np.exp(-((x - center)**2) / (2 * sigma**2))\n\n\n\n\n\n\n\n\n\nFigure 7.1: Gaussian RBF\n\n\n\n\n\nThe sum of Gaussian RBFs can be visualized by summing the individual Gaussian RBFs centered at different points as shown in Figure 7.2. The following code snippet demonstrates how to create this plot showing the sum of three Gaussian RBFs with different centers and a common width parameter \\(\\sigma\\).\n\n\n\n\n\n\n\n\nFigure 7.2: Sum of Gaussian RBFs\n\n\n\n\n\n\n\n\n7.1.1.2 The Interpolation Condition: Elegant Solutions Through Linear Systems\nA remarkable property of radial basis function models is that regardless of which basis functions we choose—parametric or fixed—determining the weights \\(\\vec{w}\\) remains straightforward through interpolation. The core principle is elegantly simple: we require our model to exactly reproduce the observed data points:\n\\[\n\\hat{f}(\\vec{x}^{(i)}) = y^{(i)}, \\quad i = 1, 2, \\ldots, n.\n\\tag{7.5}\\]\nThis constraint produces one of the most powerful aspects of RBF modeling: while the system in Equation 7.5 is linear with respect to the weights \\(\\vec{w}\\), the resulting predictor \\(\\hat{f}\\) can capture highly nonlinear relationships in the data. The RBF approach transforms a complex nonlinear modeling problem into a solvable linear algebra problem.\nFor a unique solution to exist, we require that the number of basis functions equals the number of data points (\\(n_c = n\\)). The standard practice, which greatly simplifies implementation, is to center each basis function at a training data point, setting \\(\\vec{c}^{(i)} = \\vec{x}^{(i)}\\) for all \\(i = 1, 2, \\ldots, n\\). This choice allows us to express the interpolation condition as a compact matrix equation:\n\\[\n\\Psi \\vec{w} = \\vec{y}.\n\\]\nHere, \\(\\Psi\\) represents the Gram matrix (also called the design matrix or kernel matrix), whose elements measure the similarity between data points:\n\\[\n\\Psi_{i,j} = \\psi(||\\vec{x}^{(i)} - \\vec{x}^{(j)}||), \\quad i, j = 1, 2, \\ldots, n.\n\\]\nThe solution for the weight vector becomes:\n\\[\n\\vec{w} = \\Psi^{-1} \\vec{y}.\n\\]\nThis matrix inversion step is the computational core of the RBF model fitting process, and the numerical properties of this operation depend critically on the chosen basis function. Different basis functions produce Gram matrices with distinct conditioning properties, directly affecting both computational stability and the model’s generalization capabilities.\n\n\n\n7.1.2 Numerical Stability Through Positive Definite Matrices\nA significant advantage of Gaussian and inverse multiquadric basis functions lies in their mathematical guarantees. Vapnik (1998) demonstrated that these functions always produce symmetric positive definite Gram matrices when using strictly positive definite kernels (see Section 9.4), which is a critical property for numerical reliability. Unlike other basis functions that may lead to ill-conditioned systems, these functions ensure the existence of unique, stable solutions.\nThis positive definiteness enables the use of Cholesky factorization, which offers substantial computational advantages over standard matrix inversion techniques. The Cholesky approach reduces the computational cost (reducing from \\(O(n^3)\\) to roughly \\(O(n^3/3)\\)) while significantly improving numerical stability when handling the inevitable rounding errors in floating-point arithmetic. This robustness to numerical issues explains why Gaussian and inverse multiquadric basis functions remain the preferred choice in many practical RBF implementations.\nFurthermore, the positive definiteness guarantee provides theoretical assurances about the model’s interpolation properties—ensuring that the RBF interpolant exists and is unique for any distinct set of centers. This mathematical foundation gives practitioners confidence in the method’s reliability, particularly for complex engineering applications where model stability is paramount.\nThe computational advantage stems from how a symmetric positive definite matrix \\(\\Psi\\) can be efficiently decomposed into the product of an upper triangular matrix \\(U\\) and its transpose:\n\\[\n\\Psi = U^T U.\n\\]\nThis decomposition transforms the system \\[\n\\Psi \\vec{w} = \\vec{y}\n\\] into \\[\nU^T U \\vec{w} = \\vec{y},\n\\] which can be solved through two simpler triangular systems:\n\nFirst solve \\(U^T \\vec{v} = \\vec{y}\\) for the intermediate vector \\(\\vec{v}\\)\nThen solve \\(U \\vec{w} = \\vec{v}\\) for the desired weights \\(\\vec{w}\\)\n\nIn Python implementations, this process is elegantly handled using NumPy’s or SciPy’s Cholesky decomposition functions, followed by specialized solvers that exploit the triangular structure:\nfrom scipy.linalg import cholesky, cho_solve\n# Compute the Cholesky factorization\nL = cholesky(Psi, lower=True)  # L is the lower triangular factor\nweights = cho_solve((L, True), y)  # Efficient solver for (L L^T)w = y\n\n\n7.1.3 Ill-Conditioning\nAn important numerical consideration in RBF modeling is that points positioned extremely close to each other in the input space \\(X\\) can lead to severe ill-conditioning of the Gram matrix (Micchelli 1986). This ill-conditioning manifests as nearly linearly dependent rows and columns in \\(\\Psi\\), potentially causing the Cholesky factorization to fail.\nWhile this problem rarely arises with initial space-filling experimental designs (such as Latin Hypercube or quasi-random sequences), it frequently emerges during sequential optimization processes that adaptively add infill points in promising regions. As these clusters of points concentrate in areas of high interest, the condition number of the Gram matrix deteriorates, jeopardizing numerical stability.\nSeveral mitigation strategies exist: regularization through ridge-like penalties (modifying the standard RBF interpolation problem by adding a penalty term to the diagonal of the Gram matrix. This creates a literal “ridge” along the diagonal of the matrix), removing nearly coincident points, clustering, or applying more sophisticated approaches. One theoretically elegant solution involves augmenting non-conditionally positive definite basis functions with polynomial terms (Keane and Nair 2005). This technique not only improves conditioning but also ensures polynomial reproduction properties, enhancing the approximation quality for certain function classes while maintaining numerical stability.\nBeyond determining \\(\\vec{w}\\), there is, of course, the additional task of estimating any other parameters introduced via the basis functions. A typical example is the \\(\\sigma\\) of the Gaussian basis function, usually taken to be the same for all basis functions, though a different one can be selected for each centre, as is customary in the case of the Kriging basis function, to be discussed shortly (once again, we trade additional parameter estimation complexity versus increased flexibility and, hopefully, better generalization).\n\n\n7.1.4 Parameter Optimization: A Two-Level Approach\nWhen building RBF models, we face two distinct parameter estimation challenges:\n\nDetermining the weights (\\(\\vec{w}\\)): These parameters ensure our model precisely reproduces the training data. For any fixed basis function configuration, we can calculate these weights directly through linear algebra as shown earlier.\nOptimizing shape parameters (like \\(\\sigma\\) in Gaussian RBF): These parameters control how the model generalizes to new, unseen data. Unlike weights, there’s no direct formula to find their optimal values.\n\nTo address this dual challenge, we employ a nested optimization strategy (inner and outer levels):\n\n7.1.4.1 Inner Level (\\(\\vec{w}\\))\nFor each candidate value of shape parameters (e.g., \\(\\sigma\\)), we determine the corresponding optimal weights \\(\\vec{w}\\) by solving the linear system. The estim_weights() method implements the inner level optimization by calculating the optimal weights \\(\\vec{w}\\) for a given shape parameter (\\(\\sigma\\)):\ndef estim_weights(self):\n    # [...]\n    \n    # Construct the Phi (Psi) matrix\n    self.Phi = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i+1):\n            self.Phi[i, j] = self.basis(d[i, j], self.sigma)\n            self.Phi[j, i] = self.Phi[i, j]\n    \n    # Calculate weights using appropriate method\n    if self.code == 4 or self.code == 6:\n        # Use Cholesky factorization for Gaussian or inverse multiquadric\n        try:\n            L = cholesky(self.Phi, lower=True)\n            self.weights = cho_solve((L, True), self.y)\n            self.success = True\n        except np.linalg.LinAlgError:\n            # Error handling...\n    else:\n        # Use direct solve for other basis functions\n        try:\n            self.weights = np.linalg.solve(self.Phi, self.y)\n            self.success = True\n        except np.linalg.LinAlgError:\n            # Error handling...\n    \n    return self\nThis method:\n\nCreates the Gram matrix (Phi) based on distances between points\nSolves the linear system \\(\\Psi\\vec{w} = \\vec{y}\\) for weights\nUses appropriate numerical methods based on the basis function type (Cholesky factorization or direct solve)\n\n\n\n7.1.4.2 Outer Level (\\(\\sigma\\))\nWe use cross-validation to evaluate how well the model generalizes with different shape parameter values. The outer level optimization is implemented within the fit() method, where cross-validation is used to evaluate different \\(\\sigma\\) values:\ndef fit(self):\n    if self.code &lt; 4:\n        # Fixed basis function, only w needs estimating\n        self.estim_weights()\n    else:\n        # Basis function requires a sigma, estimate first using cross-validation\n        # [...]\n        \n        # Generate candidate sigma values\n        sigmas = np.logspace(-2, 2, 30)\n        \n        # Setup cross-validation (determine number of folds)\n        # [...]\n        \n        cross_val = np.zeros(len(sigmas))\n        \n        # For each candidate sigma value\n        for sig_index, sigma in enumerate(sigmas):\n            print(f\"Computing cross-validation metric for Sigma={sigma:.4f}...\")\n            \n            # Perform k-fold cross-validation\n            for j in range(len(from_idx)):\n                # Create and fit model on training subset\n                temp_model = Rbf(\n                    X=X_orig[xs_temp],\n                    y=y_orig[xs_temp],\n                    code=self.code\n                )\n                temp_model.sigma = sigma\n                \n                # Call inner level optimization\n                temp_model.estim_weights()\n                \n                # Evaluate on held-out data\n                # [...]\n            \n        # Select best sigma based on cross-validation performance\n        min_cv_index = np.argmin(cross_val)\n        best_sig = sigmas[min_cv_index]\n        \n        # Use the best sigma for final model\n        self.sigma = best_sig\n        self.estim_weights()  # Call inner level again with optimal sigma\nThe outer level:\n\nGenerates a range of candidate \\(\\sigma\\) values\nFor each \\(\\sigma\\), performs k-fold cross-validation:\n\nCreates models on subsets of the data\nCalls the inner level method (estim_weights()) to determine weights\nEvaluates prediction quality on held-out data\n\nSelects the \\(\\sigma\\) that minimizes cross-validation error\nPerforms a final call to the inner level method with the optimal \\(\\sigma\\)\n\nThis two-level approach is particularly critical for parametric basis functions (Gaussian, multiquadric, etc.), where the wrong choice of shape parameter could lead to either overfitting (too much flexibility) or underfitting (too rigid). Cross-validation provides an unbiased estimate of how well different parameter choices will perform on new data, helping us balance the trade-off between fitting the training data perfectly and generalizing well.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#sec-rbf-python",
    "href": "006_num_rbf.html#sec-rbf-python",
    "title": "7  Radial Basis Function Models",
    "section": "7.2 Python Implementation of the RBF Model",
    "text": "7.2 Python Implementation of the RBF Model\nSection 7.2 shows a Python implementation of this parameter estimation process (based on a cross-validation routine), which will represent the surrogate, once its parameters have been estimated. The model building process is very simple.\nInstead of using a dictionary for bookkeeping, we implement a Python class Rbf that encapsulates all the necessary data and functionality. The class stores the sampling plan \\(X\\) as the X attribute and the corresponding \\(n\\)-vector of responses \\(y\\) as the y attribute. The code attribute specifies the type of basis function to be used. After fitting the model, the class will also contain the estimated parameter values \\(\\vec{w}\\) and, if a parametric basis function is used, \\(\\sigma\\). These are stored in the weights and sigma attributes respectively.\nFinally, a note on prediction error estimation. We have already indicated that the guarantee of a positive definite \\(\\Psi\\) is one of the advantages of Gaussian radial basis functions. They also possess another desirable feature: it is relatively easy to estimate their prediction error at any \\(\\vec{x}\\) in the design space. Additionally, the expectation function of the improvement in minimum (or maximum) function value with respect to the minimum (or maximum) known so far can also be calculated quite easily, both of these features being very useful when the optimization of \\(f\\) is the goal of the surrogate modelling process.\n\n7.2.1 The Rbf Class\nThe Rbf class implements the Radial Basis Function model. It encapsulates all the data and methods needed for fitting the model and making predictions.\n\nimport numpy as np\nfrom scipy.linalg import cholesky, cho_solve\nimport numpy.random as rnd\n\nclass Rbf:\n    \"\"\"Radial Basis Function model implementation.\n    \n    Attributes:\n        X (ndarray): The sampling plan (input points).\n        y (ndarray): The response vector.\n        code (int): Type of basis function to use.\n        weights (ndarray, optional): The weights vector (set after fitting).\n        sigma (float, optional): Parameter for parametric basis functions.\n        Phi (ndarray, optional): The Gram matrix (set during fitting).\n        success (bool, optional): Flag indicating successful fitting.\n    \"\"\"\n    \n    def __init__(self, X=None, y=None, code=3):\n        \"\"\"Initialize the RBF model.\n        \n        Args:\n            X (ndarray, optional):\n                The sampling plan.\n            y (ndarray, optional):\n                The response vector.\n            code (int, optional):\n                Type of basis function.\n                Default is 3 (thin plate spline).\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.code = code\n        self.weights = None\n        self.sigma = None\n        self.Phi = None\n        self.success = None\n    \n    def basis(self, r, sigma=None):\n        \"\"\"Compute the value of the basis function.\n        \n        Args:\n            r (float): Radius (distance)\n            sigma (float, optional): Parameter for parametric basis functions\n            \n        Returns:\n            float: Value of the basis function\n        \"\"\"\n        # Use instance sigma if not provided\n        if sigma is None and hasattr(self, 'sigma'):\n            sigma = self.sigma\n            \n        if self.code == 1:\n            # Linear function\n            return r\n        elif self.code == 2:\n            # Cubic\n            return r**3\n        elif self.code == 3:\n            # Thin plate spline\n            if r &lt; 1e-200:\n                return 0\n            else:\n                return r**2 * np.log(r)\n        elif self.code == 4:\n            # Gaussian\n            return np.exp(-(r**2)/(2*sigma**2))\n        elif self.code == 5:\n            # Multi-quadric\n            return (r**2 + sigma**2)**0.5\n        elif self.code == 6:\n            # Inverse Multi-Quadric\n            return (r**2 + sigma**2)**(-0.5)\n        else:\n            raise ValueError(\"Invalid basis function code\")\n    \n    def estim_weights(self):\n        \"\"\"Estimates the basis function weights if sigma is known or not required.\n        \n        Returns:\n            self: The updated model instance\n        \"\"\"\n        # Check if sigma is required but not provided\n        if self.code &gt; 3 and self.sigma is None:\n            raise ValueError(\"The basis function requires a sigma parameter\")\n        \n        # Number of points\n        n = len(self.y)\n        \n        # Build distance matrix\n        d = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i+1):\n                d[i, j] = np.linalg.norm(self.X[i] - self.X[j])\n                d[j, i] = d[i, j]\n        \n        # Construct the Phi (Psi) matrix\n        self.Phi = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i+1):\n                self.Phi[i, j] = self.basis(d[i, j], self.sigma)\n                self.Phi[j, i] = self.Phi[i, j]\n        \n        # Calculate weights using appropriate method\n        if self.code == 4 or self.code == 6:\n            # Use Cholesky factorization for Gaussian or inverse multiquadric\n            try:\n                L = cholesky(self.Phi, lower=True)\n                self.weights = cho_solve((L, True), self.y)\n                self.success = True\n            except np.linalg.LinAlgError:\n                print(\"Cholesky factorization failed.\")\n                print(\"Two points may be too close together.\")\n                self.weights = None\n                self.success = False\n        else:\n            # Use direct solve for other basis functions\n            try:\n                self.weights = np.linalg.solve(self.Phi, self.y)\n                self.success = True\n            except np.linalg.LinAlgError:\n                self.weights = None\n                self.success = False\n        \n        return self\n    \n    def fit(self):\n        \"\"\"Estimates the parameters of the Radial Basis Function model.\n        \n        Returns:\n            self: The updated model instance\n        \"\"\"\n        if self.code &lt; 4:\n            # Fixed basis function, only w needs estimating\n            self.estim_weights()\n        else:\n            # Basis function also requires a sigma, estimate first\n            # Save original model data\n            X_orig = self.X.copy()\n            y_orig = self.y.copy()\n            \n            # Direct search between 10^-2 and 10^2\n            sigmas = np.logspace(-2, 2, 30)\n            \n            # Number of cross-validation subsets\n            if len(self.X) &lt; 6:\n                q = 2\n            elif len(self.X) &lt; 15:\n                q = 3\n            elif len(self.X) &lt; 50:\n                q = 5\n            else:\n                q = 10\n            \n            # Number of sample points\n            n = len(self.X)\n            \n            # X split into q randomly selected subsets\n            xs = rnd.permutation(n)\n            full_xs = xs.copy()\n            \n            # The beginnings of the subsets...\n            from_idx = np.arange(0, n, n//q)\n            if from_idx[-1] &gt;= n:\n                from_idx = from_idx[:-1]\n            \n            # ...and their ends\n            to_idx = np.zeros_like(from_idx)\n            for i in range(len(from_idx) - 1):\n                to_idx[i] = from_idx[i+1] - 1\n            to_idx[-1] = n - 1\n            \n            cross_val = np.zeros(len(sigmas))\n            \n            # Cycling through the possible values of Sigma\n            for sig_index, sigma in enumerate(sigmas):\n                print(f\"Computing cross-validation metric for Sigma={sigma:.4f}...\")\n                \n                cross_val[sig_index] = 0\n                \n                # Model fitting to subsets of the data\n                for j in range(len(from_idx)):\n                    removed = xs[from_idx[j]:to_idx[j]+1]\n                    xs_temp = np.delete(xs, np.arange(from_idx[j], to_idx[j]+1))\n                    \n                    # Create a temporary model for CV\n                    temp_model = Rbf(\n                        X=X_orig[xs_temp],\n                        y=y_orig[xs_temp],\n                        code=self.code\n                    )\n                    temp_model.sigma = sigma\n                    \n                    # Sigma and subset chosen, now estimate w\n                    temp_model.estim_weights()\n                    \n                    if temp_model.weights is None:\n                        cross_val[sig_index] = 1e20\n                        xs = full_xs.copy()\n                        break\n                    \n                    # Compute vector of predictions at the removed sites\n                    pr = np.zeros(len(removed))\n                    for jj, idx in enumerate(removed):\n                        pr[jj] = temp_model.predict(X_orig[idx])\n                    \n                    # Calculate cross-validation error\n                    cross_val[sig_index] += np.sum((y_orig[removed] - pr)**2) / len(removed)\n                    \n                    xs = full_xs.copy()\n                \n                # Now attempt Cholesky on the full set, in case the subsets could\n                # be fitted correctly, but the complete X could not\n                temp_model = Rbf(\n                    X=X_orig,\n                    y=y_orig,\n                    code=self.code\n                )\n                temp_model.sigma = sigma\n                temp_model.estim_weights()\n                \n                if temp_model.weights is None:\n                    cross_val[sig_index] = 1e20\n                    print(\"Failed to fit complete sample data.\")\n            \n            # Find the best sigma\n            min_cv_index = np.argmin(cross_val)\n            best_sig = sigmas[min_cv_index]\n            \n            # Set the best sigma and recompute weights\n            print(f\"Selected sigma={best_sig:.4f}\")\n            self.sigma = best_sig\n            self.estim_weights()\n        \n        return self\n    \n    def predict(self, x):\n        \"\"\"Calculates the value of the Radial Basis Function surrogate model at x.\n        \n        Args:\n            x (ndarray): Point at which to make prediction\n            \n        Returns:\n            float: Predicted value\n        \"\"\"\n        # Calculate distances to all sample points\n        d = np.zeros(len(self.X))\n        for k in range(len(self.X)):\n            d[k] = np.linalg.norm(x - self.X[k])\n        \n        # Calculate basis function values\n        phi = np.zeros(len(self.X))\n        for k in range(len(self.X)):\n            phi[k] = self.basis(d[k], self.sigma)\n        \n        # Calculate prediction\n        y = np.dot(phi, self.weights)\n        return y",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#rbf-example-the-one-dimensional-sin-function",
    "href": "006_num_rbf.html#rbf-example-the-one-dimensional-sin-function",
    "title": "7  Radial Basis Function Models",
    "section": "7.3 RBF Example: The One-Dimensional sin Function",
    "text": "7.3 RBF Example: The One-Dimensional sin Function\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import cholesky, cho_solve\n\n# Define the data points for fitting\nx_centers = np.array([np.pi/2, np.pi, 3*np.pi/2]).reshape(-1, 1)  # Centers for RBFs\ny_values = np.sin(x_centers.flatten())  # Sine values at these points\n\n# Create and fit the RBF model\nrbf_model = Rbf(X=x_centers, y=y_values, code=4)  # Code 4 is Gaussian RBF\nrbf_model.sigma = 1.0  # Set sigma parameter directly\nrbf_model.estim_weights()  # Calculate optimal weights\n\n# Print the weights\nprint(\"RBF model weights:\", rbf_model.weights)\n\n# Create a grid for visualization\nx_grid = np.linspace(0, 2*np.pi, 1000).reshape(-1, 1)\ny_true = np.sin(x_grid.flatten())  # True sine function\n\n# Generate predictions using the RBF model\ny_pred = np.zeros(len(x_grid))\nfor i in range(len(x_grid)):\n    y_pred[i] = rbf_model.predict(x_grid[i])\n\n# Calculate individual basis functions for visualization\nbasis_funcs = np.zeros((len(x_grid), len(x_centers)))\nfor i in range(len(x_grid)):\n    for j in range(len(x_centers)):\n        # Calculate distance\n        distance = np.linalg.norm(x_grid[i] - x_centers[j])\n        # Compute basis function value scaled by its weight\n        basis_funcs[i, j] = rbf_model.basis(distance, rbf_model.sigma) * rbf_model.weights[j]\n\n# Plot the results\nplt.figure(figsize=(6, 4))\n\n# Plot the true sine function\nplt.plot(x_grid, y_true, 'k-', label='True sine function', linewidth=2)\n\n# Plot individual basis functions\nfor i in range(len(x_centers)):\n    plt.plot(x_grid, basis_funcs[:, i], '--', \n             label=f'Basis function at x={x_centers[i][0]:.2f}')\n\n# Plot the RBF fit (sum of basis functions)\nplt.plot(x_grid, y_pred, 'r-', label='RBF fit', linewidth=2)\n\n# Plot the sample points\nplt.scatter(x_centers, y_values, color='blue', s=100, label='Sample points')\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n\nplt.title('RBF Approximation of Sine Function')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nRBF model weights: [ 1.00724398e+00  2.32104414e-16 -1.00724398e+00]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#rbf-example-the-two-diemnsional-dome-function",
    "href": "006_num_rbf.html#rbf-example-the-two-diemnsional-dome-function",
    "title": "7  Radial Basis Function Models",
    "section": "7.4 RBF Example: The Two-Diemnsional dome Function",
    "text": "7.4 RBF Example: The Two-Diemnsional dome Function\nThe dome function is an example of a test function that can be used to evaluate the performance of the Radial Basis Function model. It is a simple mathematical function defined over a two-dimensional space.\n\ndef dome(x) -&gt; float:\n  \"\"\"\n  Dome test function.\n  \n  Args:\n      x (ndarray): Input vector (1D array of length 2)\n  \n  Returns:\n      float: Function value\n  \n  Examples:\n      dome(np.array([0.5, 0.5]))\n  \"\"\"\n  return np.sum(1 - (2*x - 1)**2) / len(x)\n\nThe following code demonstrates how to use the Radial Basis Function model to approximate a function. It generates a Latin Hypercube sample, computes the objective function values, estimates the model parameters, and plots the results.\n\ndef generate_rbf_data(n_samples=10, grid_points=41):\n    \"\"\"\n    Generates data for RBF visualization.\n\n    Args:\n        n_samples (int): Number of samples for the RBF model\n        grid_points (int): Number of grid points for prediction\n\n    Returns:\n        tuple: (rbf_model, X, Y, Z, Z_0) - Model and grid data for plotting\n    \"\"\"\n    from spotpython.utils.sampling import bestlh as best_lh\n    # Generate sampling plan\n    X_samples = best_lh(n_samples, 2, population=10, iterations=100)\n    # Compute objective function values\n    y_samples = np.zeros(len(X_samples))\n    for i in range(len(X_samples)):\n        y_samples[i] = dome(X_samples[i])\n    # Create and fit RBF model\n    rbf_model = Rbf(X=X_samples, y=y_samples, code=3)  # Thin plate spline\n    rbf_model.fit()\n    # Generate grid for prediction\n    x = np.linspace(0, 1, grid_points)\n    y = np.linspace(0, 1, grid_points)\n    X, Y = np.meshgrid(x, y)\n    Z_0 = np.zeros_like(X)\n    Z = np.zeros_like(X)\n    \n    # Evaluate model at grid points\n    for i in range(len(x)):\n        for j in range(len(y)):\n            Z_0[j, i] = dome(np.array([x[i], y[j]]))\n            Z[j, i] = rbf_model.predict(np.array([x[i], y[j]]))\n    \n    return rbf_model, X, Y, Z, Z_0\n\ndef plot_rbf_results(rbf_model, X, Y, Z, Z_0=None, n_contours=10):\n    \"\"\"\n    Plots RBF approximation results.\n\n    Args:\n        rbf_model (Rbf): Fitted RBF model\n        X (ndarray): Grid X-coordinates\n        Y (ndarray): Grid Y-coordinates\n        Z (ndarray): RBF model predictions\n        Z_0 (ndarray, optional): True function values for comparison\n        n_contours (int): Number of contour levels to plot\n    \"\"\"\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 8))\n    \n    # Plot the contour\n    contour = plt.contour(X, Y, Z, n_contours)\n\n    if Z_0 is not None:\n        contour_0 = plt.contour(X, Y, Z_0, n_contours, colors='k', linestyles='dashed')\n    \n    # Plot the sample points\n    plt.scatter(rbf_model.X[:, 0], rbf_model.X[:, 1], \n                c='r', marker='o', s=50)\n    \n    plt.title('RBF Approximation (Thin Plate Spline)')\n    plt.xlabel('x1')\n    plt.ylabel('x2')\n    plt.colorbar(label='f(x1, x2)')\n    plt.show()\n\nFigure 7.3 shows the contour plots of the underlying function \\(f(x_1, x_2) = 0.5[-(2x_1-1)^2-(2x_2-1)^2]\\) and its thin plate spline radial basis function approximation, along with the 10 points of a Morris-Mitchell optimal Latin hypercube sampling plan (obtained via best_lh()).\n\nrbf_model, X, Y, Z, Z_0 = generate_rbf_data(n_samples=10, grid_points=41)\nplot_rbf_results(rbf_model, X, Y, Z, Z_0)\n\n\n\n\n\n\n\nFigure 7.3: RBF Approximation.\n\n\n\n\n\n\n7.4.1 The Connection Between RBF Models and Neural Networks\nRadial basis function models share a profound architectural similarity with artificial neural networks, specifically with what’s known as RBF networks. This connection provides valuable intuition about how RBF models function. A radial basis function model can be viewed as a specialized neural network with the following structure:\n\nInput Layer: Receives the feature vector \\(\\vec{x}\\)\nHidden Layer: Contains neurons (basis functions) that compute radial distances\nOutput Layer: Produces a weighted sum of the hidden unit activations\n\nUnlike traditional neural networks that use dot products followed by nonlinear activation functions, RBF networks measure the distance between inputs and learned center points. This distance is then transformed by the radial basis function.\nMathematically, the equivalence between RBF models and RBF networks can be expressed as follows:\nThe RBF model equation:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n_c} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||)\n\\]\ndirectly maps to the following neural network components:\n\n\\(\\vec{x}\\): Input vector\n\\(\\vec{c}^{(i)}\\): Center vectors for each hidden neuron\n\\(\\psi(\\cdot)\\): Activation function (Gaussian, inverse multiquadric, etc.)\n\\(w_i\\): Output weights\n\\(\\hat{f}(\\vec{x})\\): Network output\n\n\nExample 7.2 (Comparison of RBF Networks and Traditional Neural Networks) Consider approximating a simple 1D function \\(f(x) = \\sin(2\\pi x)\\) over the interval \\([0,1]\\):\nThe neral network approach would use multiple layers with neurons computing \\(\\sigma(w \\cdot x + b)\\). It would require a large number of neurons and layers to capture the sine wave’s complexity. The network would learn both weights and biases, making it less interpretable.\nThe RBF network approach, on the other hand, places basis functions at strategic points (e.g., 5 evenly spaced centers). Each neuron computes \\(\\psi(||x - c_i||)\\) (e.g., using Gaussian RBF). The output layer combines these values with learned weights. If we place Gaussian RBFs with \\(\\sigma=0.15\\) at \\({0.1, 0.3, 0.5, 0.7, 0.9}\\), each neuron responds strongly when the input is close to its center and weakly otherwise. The network can then learn weights that, when multiplied by these response patterns and summed, closely approximate the sine function.\nThis locality property gives RBF networks a notable advantage: they offer more interpretable internal representations and often require fewer neurons for certain types of function approximation compared to traditional multilayer perceptrons.\nThe key insight is that while standard neural networks create complex decision boundaries through compositions of hyperplanes, RBF networks directly model functions using a set of overlapping “bumps” positioned strategically in the input space.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#radial-basis-function-models-for-noisy-data",
    "href": "006_num_rbf.html#radial-basis-function-models-for-noisy-data",
    "title": "7  Radial Basis Function Models",
    "section": "7.5 Radial Basis Function Models for Noisy Data",
    "text": "7.5 Radial Basis Function Models for Noisy Data\nWhen the responses \\(\\vec{y} = {y^{(1)}, y^{(2)}, \\ldots, y^{(n)}}^T\\) contain measurement or simulation noise, the standard RBF interpolation approach can lead to overfitting—the model captures both the underlying function and the random noise. This compromises generalization performance on new data points. Two principal strategies address this challenge:\n\n7.5.1 Ridge Regularization Approach\nThe most straightforward solution involves introducing regularization through the parameter \\(\\lambda\\) (Poggio and Girosi 1990). This is implemented by adding \\(\\lambda\\) to the diagonal elements of the Gram matrix, creating a “ridge” that improves numerical stability. Mathematically, the weights are determined by:\n\\[\n\\vec{w} = (\\Psi + \\lambda I)^{-1} \\vec{y},\n\\]\nwhere \\(I\\) is an \\(n \\times n\\) identity matrix. This regularized solution balances two competing objectives:\n\nfitting the training data accurately versus\nkeeping the magnitude of weights controlled to prevent overfitting.\n\nTheoretically, optimal performance is achieved when \\(\\lambda\\) equals the variance of the noise in the response data \\(\\vec{y}\\) (Keane and Nair 2005). Since this information is rarely available in practice, \\(\\lambda\\) is typically estimated through cross-validation alongside other model parameters.\n\n\n7.5.2 Reduced Basis Approach\nAn alternative strategy involves reducing \\(m\\), the number of basis functions. This might result in a non-square \\(\\Psi\\) matrix. With a non-square \\(\\Psi\\) matrix, the weights are found through least squares minimization:\n\\[\n\\vec{w} = (\\Psi^T\\Psi)^{-1}\\Psi^T\\vec{y}\n\\]\nThis approach introduces an important design decision: which subset of points should serve as basis function centers? Several selection strategies exist:\n\nClustering methods that identify representative points\nGreedy algorithms that sequentially select influential centers\nSupport vector regression techniques (discussed elsewhere in the literature)\n\nAdditional parameters such as the width parameter \\(\\sigma\\) in Gaussian bases can be optimized through cross-validation to minimize generalization error estimates.\nThe ridge regularization and reduced basis approaches can be combined, allowing for a flexible modeling framework, though at the cost of a more complex parameter estimation process. This hybrid approach often yields superior results for highly noisy datasets or when the underlying function has varying complexity across the input space.\nThe broader challenge of building accurate models from noisy observations is examined comprehensively in the context of Kriging models, which provide a statistical framework for explicitly modeling both the underlying function and the noise process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#jupyter-notebook",
    "href": "006_num_rbf.html#jupyter-notebook",
    "title": "7  Radial Basis Function Models",
    "section": "7.6 Jupyter Notebook",
    "text": "7.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nKeane, Andrew J, and Prasanth B Nair. 2005. Computational Approaches for Aerospace Design: The Pursuit of Excellence. Wiley.\n\n\nMicchelli, Charles A. 1986. “Interpolation of Scattered Data: Distance Matrices and Conditionally Positive Definite Functions.” Constructive Approximation 2 (1): 11–22. https://doi.org/10.1007/BF01893414.\n\n\nPoggio, T, and F Girosi. 1990. “Regularization Algorithms for Learning That Are Equivalent to Multilayer Networks.” Science 247 (4945): 978–82. https://doi.org/10.1126/science.247.4945.978.\n\n\nVapnik, V N. 1998. Statistical learning theory. Wiley; Wiley.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html",
    "href": "006_num_gp.html",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "8.1 From Gaussian RBF to Kriging Basis Functions\nKriging can be explained using the concept of radial basis functions (RBFs), which were introduced in Chapter 7. An RBF is a real-valued function whose value depends only on the distance from a certain point, called the center, usually in a multidimensional space. The basis function is a function of the distance between the point \\(\\vec{x}\\) and the center \\(\\vec{x}^{(i)}\\). Other names for basis functions are kernel or covariance functions.\nKriging uses a specialized basis function that offers greater flexibility than standard RBFs. Examining Equation 8.1, we can observe how Kriging builds upon and extends the Gaussian basis concept. The key enhancements of Kriging over Gaussian RBF can be summarized as follows:\nThese enhancements make Kriging particularly well-suited for engineering problems where variables may operate at different scales or exhibit varying degrees of smoothness across dimensions. For now, we will only consider Kriging interpolation. We will cover Kriging regression later.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#from-gaussian-rbf-to-kriging-basis-functions",
    "href": "006_num_gp.html#from-gaussian-rbf-to-kriging-basis-functions",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "Definition 8.1 (The Kriging Basis Functions) Kriging (also known as Gaussian Process Regression) uses \\(k\\)-dimensional basis functions of the form \\[\n\\psi^{(i)}(\\vec{x}) =\n\\psi(\\vec{x}^{(i)}, \\vec{x}) = \\exp \\left( - \\sum_{j=1}^k \\theta_j | x_{j}^{(i)} - x_{j} | ^{p_j} \\right),\n\\tag{8.1}\\] where \\(\\vec{x}\\) and \\(\\vec{x}^{(i)}\\) denote the \\(k\\)-dim vector \\(\\vec{x}= (x_1, \\ldots, x_k)^T\\) and \\(\\vec{x}^{(i)}= (x_1^{(i)}, \\ldots, x_k^{(i)})^T\\), respectively.\n\\(\\Box\\)\n\n\n\nDimension-specific width parameters: While a Gaussian RBF uses a single width parameter \\(1/\\sigma^2\\), Kriging employs a vector \\(\\vec{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_k)^T\\). This allows the model to automatically adjust its sensitivity to each input dimension, effectively performing automatic feature relevance determination.\nFlexible smoothness control: The Gaussian RBF fixes the exponent at 2, producing uniformly smooth functions. In contrast, Kriging’s dimension-specific exponents \\(\\vec{p} = (p_1, p_2, \\ldots, p_k)^T\\) (typically with \\(p_j \\in [1, 2]\\)) enable precise control over smoothness properties in each dimension.\nUnifying framework: When all exponents are set to \\(p_j = 2\\) and all width parameters are equal (\\(\\theta_j = 1/\\sigma^2\\) for all \\(j\\)), the Kriging basis function reduces exactly to the Gaussian RBF. This makes Gaussian RBF a special case within the more general Kriging framework.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#building-the-kriging-model",
    "href": "006_num_gp.html#building-the-kriging-model",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.2 Building the Kriging Model",
    "text": "8.2 Building the Kriging Model\nConsider sample data \\(X\\) and \\(\\vec{y}\\) from \\(n\\) locations that are available in matrix form: \\(X\\) is a \\((n \\times k)\\) matrix, where \\(k\\) denotes the problem dimension and \\(\\vec{y}\\) is a \\((n\\times 1)\\) vector. We want to find an expression for a predicted values at a new point \\(\\vec{x}\\), denoted as \\(\\hat{y}\\).\nWe start with an abstract, not really intuitive concept: The observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process, which will be denoted as \\[\n\\begin{pmatrix}\nY(\\vec{x}^{(1)})\\\\\n\\vdots\\\\\nY(\\vec{x}^{(n)})\\\\\n\\end{pmatrix}.\n\\tag{8.2}\\]\nThe set of random vectors from Equation 8.2 (also referred to as a random field) has a mean of \\(\\vec{1} \\mu\\), which is a \\((n\\times 1)\\) vector. The random vectors are correlated with each other using the basis function expression from Equation 8.1: \\[\n\\text{cor} \\left(Y(\\vec{x}^{(i)}),Y(\\vec{x}^{(l)}) \\right) = \\exp\\left(- \\sum_{j=1}^k \\theta_j |x_j^{(i)} - x_j^{(l)} |^{p_j}\\right).\n\\tag{8.3}\\] Using Equation 8.3, we can compute the \\((n \\times n)\\) correlation matrix \\(\\Psi\\) of the observed sample data as shown in Equation 8.4,\n\\[\n\\Psi = \\begin{pmatrix}\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x}^{(1)})\n\\right) & \\ldots &\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x}^{(n)})\n\\right)\\\\\n\\vdots  & \\vdots &  \\vdots\\\\\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x}^{(1)})\n\\right)&\n\\ldots &\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x}^{(n)})\n\\right)\n\\end{pmatrix},\n\\tag{8.4}\\]\nand a covariance matrix as shown in Equation 8.5,\n\\[\n\\text{Cov}(Y, Y ) = \\sigma^2\\Psi.\n\\tag{8.5}\\]\nThis assumed correlation between the sample data reflects our expectation that an engineering function will behave in a certain way and it will be smoothly and continuous.\n\nRemark 8.1 (Note on Stochastic Processes). See ?sec-random-samples-gp for a more detailed discussion on realizations of stochastic processes.\n\\(\\Box\\)\n\nWe now have a set of \\(n\\) random variables (\\(\\mathbf{Y}\\)) that are correlated with each other as described in the \\((n \\times n)\\) correlation matrix \\(\\Psi\\), see Equation 8.4. The correlations depend on the absolute distances in dimension \\(j\\) between the \\(i\\)-th and the \\(l\\)-th sample point \\(|x_j^{(i)} - x_j^{(l)}|\\) and the corresponding parameters \\(p_j\\) and \\(\\theta_j\\) for dimension \\(j\\). The correlation is intuitive, because when\n\ntwo points move close together, then \\(|x_j^{(i)} - x_j| \\to 0\\) and \\(\\exp \\left(-|x_j^{(i)} - x_j|^{p_j} \\right) \\to 1\\) (these points show very close correlation and \\(Y(x_j^{(i)}) = Y(x_j)\\)).\ntwo points move far apart, then \\(|x_j^{(i)} - x_j| \\to \\infty\\) and \\(\\exp \\left(-|x_j^{(i)} - x_j|^{p_j} \\right) \\to 0\\) (these points show very low correlation).\n\n\nExample 8.1 (Correlations for different \\(p_j\\)) Three different correlations are shown in Figure 8.1: \\(p_j= 0.1, 1, 2\\). The smoothness parameter \\(p_j\\) affects the correlation:\n\nWith \\(p_j=0.1\\), there is basicaly no immediate correlation between the points and there is a near discontinuity between the points \\(Y(\\vec{x}_j^{(i)})\\) and \\(Y(\\vec{x}_j)\\).\nWith \\(p_j=2\\), the correlation is more smooth and we have a continuous gradient through \\(x_j^{(i)} - x_j\\).\n\nReducing \\(p_j\\) increases the rate at which the correlation initially drops with distance. This is shown in Figure 8.1.\n\n\n\n\n\n\n\n\nFigure 8.1: Correlations with varying \\(p\\). \\(\\theta\\) set to 1.\n\n\n\n\n\n\\(\\Box\\)\n\n\nExample 8.2 (Correlations for different \\(\\theta\\)) Figure 8.2 visualizes the correlation between two points \\(Y(\\vec{x}_j^{(i)})\\) and \\(Y(\\vec{x}_j)\\) for different values of \\(\\theta\\). The parameter \\(\\theta\\) can be seen as a width parameter:\n\nlow \\(\\theta_j\\) means that all points will have a high correlation, with \\(Y(x_j)\\) being similar across the sample.\nhigh \\(\\theta_j\\) means that there is a significant difference between the \\(Y(x_j)\\)’s.\n\\(\\theta_j\\) is a measure of how active the function we are approximating is.\nHigh \\(\\theta_j\\) indicate important parameters, see Figure 8.2.\n\n\n\n\n\n\n\n\n\nFigure 8.2: Correlations with varying \\(\\theta\\). \\(p\\) set to 2.\n\n\n\n\n\n\\(\\Box\\)\n\nConsidering the activity parameter \\(\\theta\\) is useful in high-dimensional problems where it is difficult to visualize the design landscape and the effect of the variable is unknown. By examining the elements of the vector \\(\\vec{\\theta}\\), we can identify the most important variables and focus on them. This is a crucial step in the optimization process, as it allows us to reduce the dimensionality of the problem and focus on the most important variables.\n\nExample 8.3 (The Correlation Matrix (Detailed Computation)) Let \\(n=4\\) and \\(k=3\\). The sample plan is represented by the following matrix \\(X\\): \\[\nX = \\begin{pmatrix} x_{11} & x_{12} & x_{13}\\\\\nx_{21} & x_{22} & x_{23}\\\\\nx_{31} & x_{32} & x_{33}\\\\\nx_{41} & x_{42} & x_{43}\\\\\n\\end{pmatrix}\n\\]\nTo compute the elements of the matrix \\(\\Psi\\), the following \\(k\\) (one for each of the \\(k\\) dimensions) \\((n,n)\\)-matrices have to be computed:\n\nFor \\(k=1\\), i.e., the first column of \\(X\\): \\[\nD_1 = \\begin{pmatrix} x_{11} - x_{11} & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  x_{21} - x_{11} & x_{21} - x_{21} & x_{21} -x_{31} & x_{21} - x_{41} \\\\ x_{31} - x_{11} & x_{31} - x_{21} & x_{31} -x_{31} & x_{31} - x_{41} \\\\ x_{41} - x_{11} & x_{41} - x_{21} & x_{41} -x_{31} & x_{41} - x_{41} \\\\\n\\end{pmatrix}\n\\]\nFor \\(k=2\\), i.e., the second column of \\(X\\): \\[\nD_2 = \\begin{pmatrix} x_{12} - x_{12} & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  x_{22} - x_{12} & x_{22} - x_{22} & x_{22} -x_{32} & x_{22} - x_{42} \\\\ x_{32} - x_{12} & x_{32} - x_{22} & x_{32} -x_{32} & x_{32} - x_{42} \\\\ x_{42} - x_{12} & x_{42} - x_{22} & x_{42} -x_{32} & x_{42} - x_{42} \\\\\n\\end{pmatrix}\n\\]\nFor \\(k=3\\), i.e., the third column of \\(X\\): \\[\nD_3 = \\begin{pmatrix} x_{13} - x_{13} & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  x_{23} - x_{13} & x_{23} - x_{23} & x_{23} -x_{33} & x_{23} - x_{43} \\\\ x_{33} - x_{13} & x_{33} - x_{23} & x_{33} -x_{33} & x_{33} - x_{43} \\\\ x_{43} - x_{13} & x_{43} - x_{23} & x_{43} -x_{33} & x_{43} - x_{43} \\\\\\end{pmatrix}\n\\]\n\nSince the matrices are symmetric and the main diagonals are zero, it is sufficient to compute the following matrices: \\[\nD_1 = \\begin{pmatrix} 0 & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  0 &  0 & x_{21} -x_{31} & x_{21} - x_{41} \\\\ 0 & 0 & 0 & x_{31} - x_{41} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\] \\[\nD_2 = \\begin{pmatrix} 0 & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  0 & 0 & x_{22} -x_{32} & x_{22} - x_{42} \\\\ 0 & 0 & 0 & x_{32} - x_{42} \\\\ 0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\n\\[\nD_3 = \\begin{pmatrix} 0 & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  0 & 0 & x_{23} -x_{33} & x_{23} - x_{43} \\\\ 0 & 0 & 0 & x_{33} - x_{43} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nWe will consider \\(p_l=2\\). The differences will be squared and multiplied by \\(\\theta_i\\), i.e.:\n\\[\nD_1 = \\theta_1 \\begin{pmatrix} 0 & (x_{11} - x_{21})^2 & (x_{11} -x_{31})^2 & (x_{11} - x_{41})^2 \\\\  0 &  0 & (x_{21} -x_{31})^2 & (x_{21} - x_{41})^2 \\\\ 0 & 0 & 0 & (x_{31} - x_{41})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_2 = \\theta_2 \\begin{pmatrix} 0 & (x_{12} - x_{22})^2 & (x_{12} -x_{32})^2 & (x_{12} - x_{42})^2 \\\\  0 & 0 & (x_{22} -x_{32})^2 & (x_{22} - x_{42})^2 \\\\ 0 & 0 & 0 & (x_{32} - x_{42})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_3 = \\theta_3 \\begin{pmatrix} 0 & (x_{13} - x_{23})^2 & (x_{13} -x_{33})^2 & (x_{13} - x_{43})^2 \\\\  0 & 0 & (x_{23} -x_{33})^2 & (x_{23} - x_{43})^2 \\\\ 0 & 0 & 0 & (x_{33} - x_{43})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nThe sum of the three matrices \\(D=D_1+ D_2 + D_3\\) will be calculated next:\n\\[\n\\begin{pmatrix} 0 &\n\\theta_1  (x_{11} - x_{21})^2 + \\theta_2 (x_{12} - x_{22})^2 + \\theta_3  (x_{13} - x_{23})^2  &\n\\theta_1 (x_{11} -x_{31})^2 + \\theta_2  (x_{12} -x_{32})^2 + \\theta_3  (x_{13} -x_{33})^2 &\n\\theta_1  (x_{11} - x_{41})^2 + \\theta_2  (x_{12} - x_{42})^2 + \\theta_3 (x_{13} - x_{43})^2\n\\\\  0 &  0 &\n\\theta_1  (x_{21} -x_{31})^2 + \\theta_2 (x_{22} -x_{32})^2 + \\theta_3  (x_{23} -x_{33})^2 &\n\\theta_1  x_{21} - x_{41})^2 + \\theta_2  (x_{22} - x_{42})^2 + \\theta_3 (x_{23} - x_{43})^2\n\\\\ 0 & 0 & 0 &\n\\theta_1 (x_{31} - x_{41})^2 + \\theta_2 (x_{32} - x_{42})^2 + \\theta_3 (x_{33} - x_{43})^2\n\\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nFinally, \\[ \\Psi = \\exp(-D)\\] is computed.\nNext, we will demonstrate how this computation can be implemented in Python. We will consider four points in three dimensions and compute the correlation matrix \\(\\Psi\\) using the basis function from Equation 8.1. These points are placed at the origin, at the unit vectors, and at the points \\((100, 100, 100)\\) and \\((101, 100, 100)\\). So, they form two clusters: one at the origin and one at \\((100, 100, 100)\\).\n\ntheta = np.array([1,2,3])\nX = np.array([ [1,0,0], [0,1,0], [100, 100, 100], [101, 100, 100]])\nX\n\narray([[  1,   0,   0],\n       [  0,   1,   0],\n       [100, 100, 100],\n       [101, 100, 100]])\n\n\n\ndef build_Psi(X, theta):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)  \n\n\nPsi = build_Psi(X, theta)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\n\n\n\n\n\n\n\n\nFigure 8.3: Correlation matrix \\(\\Psi\\).\n\n\n\n\n\n\\(\\Box\\)\n\n\nExample 8.4 (Example: The Correlation Matrix (Using Existing Functions)) The same result as computed in Example 8.3 can be obtained with existing python functions, e.g., from the package scipy.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    return exp(- squareform(pdist(X,\n                            metric='sqeuclidean',\n                            out=None,\n                            w=theta))) +  multiply(eye(X.shape[0]),\n                                                   eps)\n\nPsi = build_Psi(X, theta, eps=.0)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\nThe condition number of the correlation matrix \\(\\Psi\\) is a measure of how well the matrix can be inverted. A high condition number indicates that the matrix is close to singular, which can lead to numerical instability in computations involving the inverse of the matrix, see Section 9.2.\n\nnp.linalg.cond(Psi)\n\nnp.float64(2.163953413738652)\n\n\n\\(\\Box\\)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#mle-to-estimate-theta-and-p",
    "href": "006_num_gp.html#mle-to-estimate-theta-and-p",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.3 MLE to estimate \\(\\theta\\) and \\(p\\)",
    "text": "8.3 MLE to estimate \\(\\theta\\) and \\(p\\)\n\n8.3.1 The Log-Likelihood\nUntil now, the observed data \\(\\vec{y}\\) was not used. We know what the correlations mean, but how do we estimate the values of \\(\\theta_j\\) and where does our observed data \\(y\\) come in? To estimate the values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\), they are chosen to maximize the likelihood of \\(\\vec{y}\\), \\[\nL = L\\left(Y(\\vec{x}^{(1)}), \\ldots, Y(\\vec{x}^{(n)}) | \\mu, \\sigma \\right) = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp\\left[ - \\frac{\\sum_{i=1}^n(Y(\\vec{x}^{(i)})-\\mu)^2}{2 \\sigma^2}\\right],\n\\tag{8.6}\\] where \\(\\mu\\) is the mean of the observed data \\(\\vec{y}\\) and \\(\\sigma\\) is the standard deviation of the errors \\(\\epsilon\\), which can be expressed in terms of the sample data \\[\nL = \\frac{1}{(2\\pi \\sigma^2)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left[ - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}\\right].\n\\tag{8.7}\\]\n\nRemark 8.2. The transition from Equation 8.6 to Equation 8.7 reflects a shift from assuming independent errors in the observed data to explicitly modeling the correlation structure between the observed responses, which is a key aspect of the stochastic process framework used in methods like Kriging. It can be explained as follows:\n\nInitial Likelihood Expression (assuming independent errors): Equation 8.6 is an expression for the likelihood of the data set, which is based on the assumption that the errors \\(\\epsilon\\) are independently randomly distributed according to a normal distribution with standard deviation \\(\\sigma\\). This form is characteristic of the likelihood of \\(n\\) independent observations \\(Y(\\vec{x}^{(i)})\\), each following a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nUsing Vector Notation. The sum in the exponent, i.e., \\[\n\\sum_{i=1}^n(Y(\\vec{x}^{(i)})-\\mu)^2\n\\] is equivalent to \\[\n(\\vec{y} - \\vec{1}\\mu)^T (\\vec{y} - \\vec{1}\\mu),\n\\] assuming \\(Y(\\vec{x}^{(i)}) = y^{(i)}\\) and using vector notation for \\(\\vec{y}\\) and \\(\\vec{1}\\mu\\).\nAssuming Independent Observations: Equation 8.6 assumes that the observations are independent, which means that the covariance between any two observations \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is zero for \\(i \\neq l\\). In this case, the covariance matrix of the observations would be a diagonal matrix with \\(\\sigma^2\\) along the diagonal (i.e., \\(\\sigma^2 I\\)), where \\(I\\) is the identity matrix.\nStochastic Process and Correlation: In the context of Kriging, the observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process or random field. This means the random variables \\(Y(\\vec{x}^{(i)})\\) at different locations \\(\\vec{x}^{(i)}\\) are not independent, but they correlated with each other. This correlation is described by an \\((n \\times n)\\) correlation matrix \\(\\Psi\\), which is used instead of \\(\\sigma^2 I\\). The strength of the correlation between two points \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) depends on the distance between them and model parameters \\(\\theta_j\\) and \\(p_j\\).\nMultivariate Normal Distribution: When random variables are correlated, their joint probability distribution is generally described by a multivariate distribution. Assuming the stochastic process follows a Gaussian process, the joint distribution of the observed responses \\(\\vec{y}\\) is a multivariate normal distribution. A multivariate normal distribution for a vector \\(\\vec{Y}\\) with mean vector \\(\\vec{\\mu}\\) and covariance matrix \\(\\Sigma\\) has a probability density function given by: \\[\np(\\vec{y}) = \\frac{1}{\\sqrt{(2\\pi)^n |\\Sigma|}} \\exp\\left[ -\\frac{1}{2}(\\vec{y} - \\vec{\\mu})^T \\Sigma^{-1}(\\vec{y} - \\vec{\\mu}) \\right].\n\\]\nConnecting the Expressions: In the stochastic process framework, the following holds:\n\nThe mean vector of the observed data \\(\\vec{y}\\) is \\(\\vec{1}\\mu\\).\nThe covariance matrix \\(\\Sigma\\) is constructed by considering both the variance \\(\\sigma^2\\) and the correlations \\(\\Psi\\).\nThe covariance between \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is \\(\\sigma^2 \\text{cor}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)}))\\).\nTherefore, the covariance matrix is \\(\\Sigma = \\sigma^2 \\vec{\\Psi}\\).\nSubstituting \\(\\vec{\\mu} = \\vec{1}\\mu\\) and \\(\\Sigma = \\sigma^2 \\vec{\\Psi}\\) into the multivariate normal PDF formula, we get: \\[\n\\Sigma^{-1} = (\\sigma^2 \\vec{\\Psi})^{-1} = \\frac{1}{\\sigma^2} \\vec{\\Psi}^{-1}\n\\] and \\[\n|\\Sigma| = |\\sigma^2 \\vec{\\Psi}| = (\\sigma^2)^n |\\vec{\\Psi}|.\n\\] The PDF becomes: \\[\np(\\vec{y}) = \\frac{1}{\\sqrt{(2\\pi)^n (\\sigma^2)^n |\\vec{\\Psi}|}} \\exp\\left[ -\\frac{1}{2}(\\vec{y} - \\vec{1}\\mu)^T \\left(\\frac{1}{\\sigma^2} \\vec{\\Psi}^{-1}\\right)(\\vec{y} - \\vec{1}\\mu) \\right]\n\\] and simplifies to: \\[\np(\\vec{y}) = \\frac{1}{(2\\pi \\sigma^2)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left[ -\\frac{1}{2\\sigma^2}(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) \\right].\n\\] This is the likelihood of the sample data \\(\\vec{y}\\) given the parameters \\(\\mu\\), \\(\\sigma\\), and the correlation structure defined by the parameters within \\(\\vec{\\Psi}\\) (i.e., \\(\\vec{\\theta}\\) and \\(\\vec{p}\\)).\n\n\nIn summary, the Equation 8.6 represents the likelihood under a simplified assumption of independent errors, whereas Equation 8.7 is the likelihood derived from the assumption that the observed data comes from a multivariate normal distribution where observations are correlated according to the matrix \\(\\vec{\\Psi}\\). Equation 8.7, using the sample data vector \\(\\vec{y}\\) and the correlation matrix \\(\\vec{\\Psi}\\), properly accounts for the dependencies between data points inherent in the stochastic process model. Maximizing this likelihood is how the correlation parameters \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are estimated in Kriging.\n\\(\\Box\\)\n\nEquation 8.7 can be formulated as the log-likelihood: \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi \\sigma) - \\frac{1}{2} \\ln |\\vec{\\Psi}| - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}.\n\\tag{8.8}\\]\n\n\n8.3.2 Differentiation with Respect to \\(\\mu\\)\nLooking at the log-likelihood function, only the last term depends on \\(\\mu\\):\n\\[\n\\frac{1}{2 \\sigma^2} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nTo differentiate this with respect to the scalar \\(\\mu\\), we can use matrix calculus rules.\nLet \\(\\mathbf{v} = \\vec{y} - \\vec{1}\\mu\\). \\(\\vec{y}\\) is a constant vector with respect to \\(\\mu\\), and \\(\\vec{1}\\mu\\) is a vector whose derivative with respect to the scalar \\(\\mu\\) is \\(\\vec{1}\\). So, \\(\\frac{\\partial \\mathbf{v}}{\\partial \\mu} = -\\vec{1}\\).\nThe term is in the form \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\), where \\(\\mathbf{A} = \\vec{\\Psi}^{-1}\\) is a symmetric matrix. The derivative of \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to \\(\\mathbf{v}\\) is \\(2 \\mathbf{A} \\mathbf{v}\\) as explained in Remark 8.3.\n\nRemark 8.3 (Derivative of a Quadratic Form). Consider the derivative of \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to \\(\\mathbf{v}\\):\n\nThe derivative of a scalar function \\(f(\\mathbf{v})\\) with respect to a vector \\(\\mathbf{v}\\) is a vector (the gradient).\nFor a quadratic form \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\), where \\(\\mathbf{A}\\) is a matrix and \\(\\mathbf{v}\\) is a vector, the general formula for the derivative with respect to \\(\\mathbf{v}\\) is \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}\\). (This is a standard result in matrix calculus and explained in Equation 9.1).\nSince \\(\\mathbf{A} = \\vec{\\Psi}^{-1}\\) is a symmetric matrix, its transpose \\(\\mathbf{A}^T\\) is equal to \\(\\mathbf{A}\\).\nSubstituting \\(\\mathbf{A}^T = \\mathbf{A}\\) into the general derivative formula, we get \\(\\mathbf{A} \\mathbf{v} + \\mathbf{A} \\mathbf{v} = 2 \\mathbf{A} \\mathbf{v}\\).\n\n\\(\\Box\\)\n\nUsing the chain rule for differentiation with respect to the scalar \\(\\mu\\): \\[ \\frac{\\partial}{\\partial \\mu} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = 2 \\left(\\frac{\\partial \\mathbf{v}}{\\partial \\mu}\\right)^T \\mathbf{A} \\mathbf{v} \\] Substituting \\(\\frac{\\partial \\mathbf{v}}{\\partial \\mu} = -\\vec{1}\\) and \\(\\mathbf{v} = \\vec{y} - \\vec{1}\\mu\\): \\[\n\\frac{\\partial}{\\partial \\mu} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 2 (-\\vec{1})^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = -2 \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nNow, differentiate the full log-likelihood term depending on \\(\\mu\\):\n\\[\n\\frac{\\partial}{\\partial \\mu} \\left( - \\frac{1}{2 \\sigma^2} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) \\right) = - \\frac{1}{2 \\sigma^2} \\left( -2 \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) \\right) = \\frac{1}{\\sigma^2} \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nSetting this to zero for maximization gives:\n\\[\n\\frac{1}{\\sigma^2} \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 0.\n\\]\nRearranging gives: \\[\n\\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 0.\n\\]\nSolving for \\(\\mu\\) gives: \\[\n\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y} = \\mu \\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}.\n\\]\n\n\n8.3.3 Differentiation with Respect to \\(\\sigma\\)\nLet \\(\\nu = \\sigma^2\\) for simpler differentiation notation. The log-likelihood becomes: \\[\n\\ln(L) = C_1 - \\frac{n}{2} \\ln(\\nu) - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\nu},\n\\] where \\(C_1 = - \\frac{n}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln |\\vec{\\Psi}|\\) is a constant with respect to \\(\\nu = \\sigma^2\\).\nWe differentiate with respect to \\(\\nu\\): \\[\n\\frac{\\partial \\ln(L)}{\\partial \\nu} = \\frac{\\partial}{\\partial \\nu} \\left( -\\frac{n}{2} \\ln(\\nu) \\right) + \\frac{\\partial}{\\partial \\nu} \\left( - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\nu} \\right).\n\\]\nThe first term’s derivative is straightforward: \\[\n\\frac{\\partial}{\\partial \\nu} \\left( -\\frac{n}{2} \\ln(\\nu) \\right) = -\\frac{n}{2} \\cdot \\frac{1}{\\nu} = -\\frac{n}{2\\sigma^2}.\n\\]\nFor the second term, let \\(C_2 = (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)\\). This term is constant with respect to \\(\\sigma^2\\). The derivative is:\n\\[\n\\frac{\\partial}{\\partial \\nu} \\left( - \\frac{C_2}{2\\nu} \\right) = - \\frac{C_2}{2} \\frac{\\partial}{\\partial \\nu} (\\nu^{-1}) = - \\frac{C_2}{2} (-\\nu^{-2}) = \\frac{C_2}{2\\nu^2} = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2}.\n\\]\nCombining the derivatives, the gradient of the log-likelihood with respect to \\(\\sigma^2\\) is: \\[\n\\frac{\\partial \\ln(L)}{\\partial \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2}.\n\\]\nSetting this to zero for maximization gives: \\[\n-\\frac{n}{2\\sigma^2} + \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2} = 0.\n\\]\n\n\n8.3.4 Results of the Optimizations\nOptimization of the log-likelihood by taking derivatives with respect to \\(\\mu\\) and \\(\\sigma\\) results in \\[\n\\hat{\\mu} = \\frac{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y}^T}{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}^T}\n\\tag{8.9}\\] and \\[\n\\hat{\\sigma}^2 = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{n}.\n\\tag{8.10}\\]\n\n\n8.3.5 The Concentrated Log-Likelihood Function\nCombining the equations, i.e., substituting Equation 8.9 and Equation 8.10 into Equation 8.8 leads to the concentrated log-likelihood function: \\[\n\\ln(L) \\approx - \\frac{n}{2} \\ln(\\hat{\\sigma}) - \\frac{1}{2} \\ln |\\vec{\\Psi}|.\n\\tag{8.11}\\]\n\nRemark 8.4 (The Concentrated Log-Likelihood). \n\nThe first term in Equation 8.11 requires information about the measured point (observations) \\(y_i\\).\nTo maximize \\(\\ln(L)\\), optimal values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are determined numerically, because the function (Equation 8.11) is not differentiable.\n\n\\(\\Box\\)\n\n\n\n8.3.6 Optimizing the Parameters \\(\\vec{\\theta}\\) and \\(\\vec{p}\\)\nThe concentrated log-likelihood function is very quick to compute. We do not need a statistical model, because we are only interested in the maximum likelihood estimate (MLE) of \\(\\theta\\) and \\(p\\). Optimizers such as Nelder-Mead, Conjugate Gradient, or Simulated Annealing can be used to determine optimal values for \\(\\theta\\) and \\(p\\). After the optimization, the correlation matrix \\(\\Psi\\) is build with the optimized \\(\\theta\\) and \\(p\\) values. This is best (most likely) Kriging model for the given data \\(y\\).\nObserving Figure 8.2, there’s significant change between \\(\\theta = 0.1\\) and \\(\\theta = 1\\), just as there is between \\(\\theta = 1\\) and \\(\\theta = 10\\). Hence, it is sensible to search for \\(\\theta\\) on a logarithmic scale. Suitable search bounds typically range from \\(10^{-3}\\) to \\(10^2\\), although this is not a stringent requirement. Importantly, the scaling of the observed data does not affect the values of \\(\\hat{\\theta}\\), but the scaling of the design space does. Therefore, it is advisable to consistently scale variable ranges between zero and one to ensure consistency in the degree of activity \\(\\hat{\\theta}_j\\) represents across different problems.\n\n\n8.3.7 Correlation and Covariance Matrices Revisited\nThe covariance matrix \\(\\Sigma\\) is constructed by considering both the variance \\(\\sigma^2\\) and the correlation matrix \\(\\Psi\\). They are related as follows:\n\nCovariance vs. Correlation: Covariance is a measure of the joint variability of two random variables, while correlation is a standardized measure of this relationship, ranging from -1 to 1. The relationship between covariance and correlation for two random variables \\(X\\) and \\(Y\\) is given by \\(\\text{cor}(X, Y) = \\text{cov}(X, Y) / (\\sigma_X \\sigma_Y)\\), where \\(\\sigma_X\\) and \\(\\sigma_Y\\) are their standard deviations.\nThe Covariance Matrix \\(\\Sigma\\): The covariance matrix \\(\\Sigma\\) (or \\(\\text{Cov}(Y, Y)\\) for the vector \\(\\vec{Y}\\)) captures the pairwise covariances between all elements of the vector of observed responses.\nConnecting \\(\\sigma^2\\) and \\(\\Psi\\) to \\(\\Sigma\\): In the Kriging framework described, the variance of each observation is often assumed to be constant, \\(\\sigma^2\\). The covariance between any two observations \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is given by \\(\\sigma^2\\) multiplied by their correlation. That is, \\[\n\\text{cov}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)})) = \\sigma^2 \\text{cor}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)})).\n\\] This relationship holds for all pairs of points. When expressed in matrix form, the covariance matrix \\(\\Sigma\\) is the product of the variance \\(\\sigma^2\\) (a scalar) and the correlation matrix \\(\\Psi\\): \\[\n\\Sigma = \\sigma^2 \\Psi.\n\\]\n\nIn essence, the correlation matrix \\(\\Psi\\) defines the structure or shape of the dependencies between the data points based on their locations. The parameter \\(\\sigma^2\\) acts as a scaling factor that converts these unitless correlation values (which are between -1 and 1) into actual covariance values with units of variance, setting the overall level of variability in the system.\nSo, \\(\\sigma^2\\) tells us about the general spread or variability of the underlying process, while \\(\\Psi\\) tells you how that variability is distributed and how strongly points are related to each other based on their positions. Together, they completely define the covariance structure of your observed data in the multivariate normal distribution used in Kriging.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#implementing-an-mle-of-the-model-parameters",
    "href": "006_num_gp.html#implementing-an-mle-of-the-model-parameters",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.4 Implementing an MLE of the Model Parameters",
    "text": "8.4 Implementing an MLE of the Model Parameters\nThe matrix algebra necessary for calculating the likelihood is the most computationally intensive aspect of the Kriging process. It is crucial to ensure that the code implementation is as efficient as possible.\nGiven that \\(\\Psi\\) (our correlation matrix) is symmetric, only half of the matrix needs to be computed before adding it to its transpose. When calculating the log-likelihood, several matrix inversions are required. The fastest approach is to conduct one Cholesky factorization and then apply backward and forward substitution for each inverse.\nThe Cholesky factorization is applicable only to positive-definite matrices, which \\(\\Psi\\) generally is. However, if \\(\\Psi\\) becomes nearly singular, such as when the \\(\\vec{x}^{(i)}\\)’s are densely packed, the Cholesky factorization might fail. In these cases, one could employ an LU-decomposition, though the result might be unreliable. When \\(\\Psi\\) is near singular, the best course of action is to either use regression techniques or, as we do here, assign a poor likelihood value to parameters generating the near singular matrix, thus diverting the MLE search towards better-conditioned \\(\\Psi\\) matrices.\nWhen working with correlation matrices, increasing the values on the main diagonal of a matrix will increase the absolute value of its determinant. A critical numerical consideration in calculating the concentrated log-likelihood is that for poorly conditioned matrices, \\(\\det(\\Psi)\\) approaches zero, leading to potential numerical instability. To address this issue, it is advisable to calculate \\(\\ln(\\lvert\\Psi\\rvert)\\) in Equation 8.11 using twice the sum of the logarithms of the diagonal elements of the Cholesky factorization. This approach provides a more numerically stable method for computing the log-determinant, as the Cholesky decomposition \\(\\Psi = L L^T\\) allows us to express \\(\\ln(\\lvert\\Psi\\rvert) = 2\\sum_{i=1}^{n} \\ln(L_{ii})\\), avoiding the direct computation of potentially very small determinant values.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-prediction",
    "href": "006_num_gp.html#kriging-prediction",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.5 Kriging Prediction",
    "text": "8.5 Kriging Prediction\nWe will use the Kriging correlation \\(\\Psi\\) to predict new values based on the observed data. The presentation follows the approach described in Forrester, Sóbester, and Keane (2008) and Bartz et al. (2022).\nMain idea for prediction is that the new \\(Y(\\vec{x})\\) should be consistent with the old sample data \\(X\\). For a new prediction \\(\\hat{y}\\) at \\(\\vec{x}\\), the value of \\(\\hat{y}\\) is chosen so that it maximizes the likelihood of the sample data \\(X\\) and the prediction, given the (optimized) correlation parameter \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) from above. The observed data \\(\\vec{y}\\) is augmented with the new prediction \\(\\hat{y}\\) which results in the augmented vector \\(\\vec{\\tilde{y}} = ( \\vec{y}^T, \\hat{y})^T\\). A vector of correlations between the observed data and the new prediction is defined as\n\\[ \\vec{\\psi} = \\begin{pmatrix}\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x})\n\\right) \\\\\n\\vdots  \\\\\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x})\n\\right)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\vec{\\psi}^{(1)}\\\\\n\\vdots\\\\\n\\vec{\\psi}^{(n)}\n\\end{pmatrix}.\n\\]\n\nDefinition 8.2 (The Augmented Correlation Matrix) The augmented correlation matrix is constructed as \\[ \\tilde{\\vec{\\Psi}} =\n\\begin{pmatrix}\n\\vec{\\Psi} & \\vec{\\psi} \\\\\n\\vec{\\psi}^T & 1\n\\end{pmatrix}.\n\\]\n\\(\\Box\\)\n\nThe log-likelihood of the augmented data is \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\hat{\\sigma}^2) - \\frac{1}{2} \\ln |\\vec{\\hat{\\Psi}}| -  \\frac{(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})^T \\vec{\\tilde{\\Psi}}^{-1}(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})}{2 \\hat{\\sigma}^2},\n\\tag{8.12}\\]\nwhere \\(\\vec{1}\\) is a vector of ones and \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}^2\\) are the MLEs from Equation 8.9 and Equation 8.10. Only the last term in Equation 8.12 depends on \\(\\hat{y}\\), so we need only consider this term in the maximization. Details can be found in Forrester, Sóbester, and Keane (2008). Finally, the MLE for \\(\\hat{y}\\) can be calculated as \\[\n\\hat{y}(\\vec{x}) = \\hat{\\mu} + \\vec{\\psi}^T \\vec{\\tilde{\\Psi}}^{-1} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\tag{8.13}\\]\nEquation 8.13 reveals two important properties of the Kriging predictor:\n\nBasis functions: The basis function impacts the vector \\(\\vec{\\psi}\\), which contains the \\(n\\) correlations between the new point \\(\\vec{x}\\) and the observed locations. Values from the \\(n\\) basis functions are added to a mean base term \\(\\mu\\) with weightings \\[\n\\vec{w} = \\vec{\\tilde{\\Psi}}^{(-1)} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\]\nInterpolation: The predictions interpolate the sample data. When calculating the prediction at the \\(i\\)th sample point, \\(\\vec{x}^{(i)}\\), the \\(i\\)th column of \\(\\vec{\\Psi}^{-1}\\) is \\(\\vec{\\psi}\\), and \\(\\vec{\\psi}  \\vec{\\Psi}^{-1}\\) is the \\(i\\)th unit vector. Hence,\n\n\\[\n\\hat{y}(\\vec{x}^{(i)}) = y^{(i)}.\n\\]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-example-sinusoid-function",
    "href": "006_num_gp.html#kriging-example-sinusoid-function",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.6 Kriging Example: Sinusoid Function",
    "text": "8.6 Kriging Example: Sinusoid Function\nToy example in 1d where the response is a simple sinusoid measured at eight equally spaced \\(x\\)-locations in the span of a single period of oscillation.\n\n8.6.1 Calculating the Correlation Matrix \\(\\Psi\\)\nThe correlation matrix \\(\\Psi\\) is based on the pairwise squared distances between the input locations. Here we will use \\(n=8\\) sample locations and \\(\\theta\\) is set to 1.0.\n\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\nprint(np.round(X, 2))\n\n[[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\n\n\nEvaluate at sample points\n\ny = np.sin(X)\nprint(np.round(y, 2))\n\n[[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]\n\n\nWe have the data points shown in Table 8.1.\n\n\n\nTable 8.1: Data points for the sinusoid function\n\n\n\n\n\n\\(x\\)\n\\(y\\)\n\n\n\n\n0.0\n0.0\n\n\n0.79\n0.71\n\n\n1.57\n1.0\n\n\n2.36\n0.71\n\n\n3.14\n0.0\n\n\n3.93\n-0.71\n\n\n4.71\n-1.0\n\n\n5.5\n-0.71\n\n\n\n\n\n\nThe data points are visualized in Figure 8.4.\n\nplt.plot(X, y, \"bo\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\nFigure 8.4: Sin(x) evaluated at 8 points.\n\n\n\n\n\n\n\n8.6.2 Computing the \\(\\Psi\\) Matrix\nWe will use the build_Psi function from Example 8.4 to compute the correlation matrix \\(\\Psi\\). \\(\\theta\\) should be an array of one value, because we are only working in one dimension (\\(k=1\\)).\n\ntheta = np.array([1.0])\nPsi = build_Psi(X, theta)\nprint(np.round(Psi, 2))\n\n[[1.   0.54 0.08 0.   0.   0.   0.   0.  ]\n [0.54 1.   0.54 0.08 0.   0.   0.   0.  ]\n [0.08 0.54 1.   0.54 0.08 0.   0.   0.  ]\n [0.   0.08 0.54 1.   0.54 0.08 0.   0.  ]\n [0.   0.   0.08 0.54 1.   0.54 0.08 0.  ]\n [0.   0.   0.   0.08 0.54 1.   0.54 0.08]\n [0.   0.   0.   0.   0.08 0.54 1.   0.54]\n [0.   0.   0.   0.   0.   0.08 0.54 1.  ]]\n\n\nFigure 8.5 visualizes the \\((8, 8)\\) correlation matrix \\(\\Psi\\).\n\n\n\n\n\n\n\n\nFigure 8.5: Correlation matrix \\(\\Psi\\) for the sinusoid function.\n\n\n\n\n\n\n\n8.6.3 Selecting the New Locations\nWe would like to predict at \\(m = 100\\) new locations (or testign locations) in the interval \\([0, 2\\pi]\\). The new locations are stored in the variable x.\n\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\n\n\n\n8.6.4 Computing the \\(\\psi\\) Vector\nDistances between testing locations \\(x\\) and training data locations \\(X\\).\n\ndef build_psi(X, x, theta, eps=sqrt(spacing(1))):\n    n = X.shape[0]\n    k = X.shape[1]\n    m = x.shape[0]\n    psi = zeros((n, m))\n    theta = theta * ones(k)\n    D = zeros((n, m))\n    D = cdist(x.reshape(-1, k),\n              X.reshape(-1, k),\n              metric='sqeuclidean',\n              out=None,\n              w=theta)    \n    psi = exp(-D)\n    # return psi transpose to be consistent with the literature\n    print(f\"Dimensions of psi: {psi.T.shape}\")\n    return(psi.T)\n\npsi = build_psi(X, x, theta)\n\nDimensions of psi: (8, 100)\n\n\nFigure 8.6 visualizes the \\((8, 100)\\) prediction matrix \\(\\psi\\).\n\n\n\n\n\n\n\n\nFigure 8.6: Visualization of the predition matrix \\(\\psi\\)\n\n\n\n\n\n\n\n8.6.5 Predicting at New Locations\nComputation of the predictive equations.\n\nU = cholesky(Psi).T\none = np.ones(n).reshape(-1,1)\nmu = (one.T.dot(solve(U, solve(U.T, y)))) / one.T.dot(solve(U, solve(U.T, one)))\nf = mu * ones(m).reshape(-1,1) + psi.T.dot(solve(U, solve(U.T, y - one * mu)))\nprint(f\"Dimensions of f: {f.shape}\")\n\nDimensions of f: (100, 1)\n\n\nTo compute \\(f\\), Equation 8.13 is used.\n\n\n8.6.6 Visualization\n\nplt.plot(x, f, color = \"orange\", label=\"Fitted\")\nplt.plot(x, np.sin(x), color = \"grey\", label=\"Original\")\nplt.plot(X, y, \"bo\", label=\"Measurements\")\nplt.title(\"Kriging prediction of sin(x) with {} points.\\n theta: {}\".format(n, theta[0]))\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n8.6.7 The Complete Python Code for the Example\nHere is the self-contained Python code for direct use in a notebook:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import (array, zeros, power, ones, exp, multiply, eye, linspace, spacing, sqrt, arange, append, ravel)\nfrom numpy.linalg import cholesky, solve\nfrom scipy.spatial.distance import squareform, pdist, cdist\n\n# --- 1. Kriging Basis Functions (Defining the Correlation) ---\n# The core of Kriging uses a specialized basis function for correlation:\n# psi(x^(i), x) = exp(- sum_{j=1}^k theta_j |x_j^(i) - x_j|^p_j)\n# For this 1D example (k=1), and with p_j=2 (squared Euclidean distance implicit from pdist usage)\n# and theta_j = theta (a single value), it simplifies.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    \"\"\"\n    Computes the correlation matrix Psi based on pairwise squared Euclidean distances\n    between input locations, scaled by theta.\n    Adds a small epsilon to the diagonal for numerical stability (nugget effect).\n    \"\"\"\n    # Calculate pairwise squared Euclidean distances (D) between points in X\n    D = squareform(pdist(X, metric='sqeuclidean', out=None, w=theta))\n    # Compute Psi = exp(-D)\n    Psi = exp(-D)\n    # Add a small value to the diagonal for numerical stability (nugget)\n    # This is often done in Kriging implementations, though a regression method\n    # with a 'nugget' parameter (Lambda) is explicitly mentioned for noisy data later.\n    # The source code snippet for build_Psi explicitly includes `multiply(eye(X.shape), eps)`.\n    # FIX: Use X.shape to get the number of rows for the identity matrix\n    Psi += multiply(eye(X.shape[0]), eps) # Corrected line\n    return Psi\n\ndef build_psi(X_train, x_predict, theta):\n    \"\"\"\n    Computes the correlation vector (or matrix) psi between new prediction locations\n    and training data locations.\n    \"\"\"\n    # Calculate pairwise squared Euclidean distances (D) between prediction points (x_predict)\n    # and training points (X_train).\n    # `cdist` computes distances between each pair of the two collections of inputs.\n    D = cdist(x_predict, X_train, metric='sqeuclidean', out=None, w=theta)\n    # Compute psi = exp(-D)\n    psi = exp(-D)\n    return psi.T # Return transpose to be consistent with literature (n x m or n x 1)\n\n# --- 2. Data Points for the Sinusoid Function Example ---\n# The example uses a 1D sinusoid measured at eight equally spaced x-locations [153, Table 9.1].\nn = 8 # Number of sample locations\nX_train = np.linspace(0, 2 * np.pi, n, endpoint=False).reshape(-1, 1) # Generate x-locations\ny_train = np.sin(X_train) # Corresponding y-values (sine of x)\n\nprint(\"--- Training Data (X_train, y_train) ---\")\nprint(\"x values:\\n\", np.round(X_train, 2))\nprint(\"y values:\\n\", np.round(y_train, 2))\nprint(\"-\" * 40)\n\n# Visualize the data points\nplt.figure(figsize=(8, 5))\nplt.plot(X_train, y_train, \"bo\", label=f\"Measurements ({n} points)\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.xlabel(\"x\")\nplt.ylabel(\"sin(x)\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# --- 3. Calculating the Correlation Matrix (Psi) ---\n# Psi is based on pairwise squared distances between input locations.\n# theta is set to 1.0 for this 1D example.\ntheta = np.array([1.0])\nPsi = build_Psi(X_train, theta)\n\nprint(\"\\n--- Computed Correlation Matrix (Psi) ---\")\nprint(\"Dimensions of Psi:\", Psi.shape) # Should be (8, 8)\nprint(\"First 5x5 block of Psi:\\n\", np.round(Psi[:5,:5], 2))\nprint(\"-\" * 40)\n\n# --- 4. Selecting New Locations (for Prediction) ---\n# We want to predict at m = 100 new locations in the interval [0, 2*pi].\nm = 100 # Number of new locations\nx_predict = np.linspace(0, 2 * np.pi, m, endpoint=True).reshape(-1, 1)\n\nprint(\"\\n--- New Locations for Prediction (x_predict) ---\")\nprint(f\"Number of prediction points: {m}\")\nprint(\"First 5 prediction points:\\n\", np.round(x_predict[:5], 2).flatten())\nprint(\"-\" * 40)\n\n# --- 5. Computing the psi Vector ---\n# This vector contains correlations between each of the n observed data points\n# and each of the m new prediction locations.\npsi = build_psi(X_train, x_predict, theta)\n\nprint(\"\\n--- Computed Prediction Correlation Matrix (psi) ---\")\nprint(\"Dimensions of psi:\", psi.shape) # Should be (8, 100)\nprint(\"First 5x5 block of psi:\\n\", np.round(psi[:5,:5], 2))\nprint(\"-\" * 40)\n\n# --- 6. Predicting at New Locations (Kriging Prediction) ---\n# The Maximum Likelihood Estimate (MLE) for y_hat is calculated using the formula:\n# y_hat(x) = mu_hat + psi.T @ Psi_inv @ (y - 1 * mu_hat) [p. 2 of previous response, and 263]\n# Matrix inversion is efficiently performed using Cholesky factorization.\n\n# Step 6a: Cholesky decomposition of Psi\nU = cholesky(Psi).T # Note: `cholesky` in numpy returns lower triangular L, we need U (upper) so transpose L.\n\n# Step 6b: Calculate mu_hat (estimated mean)\n# mu_hat = (one.T @ Psi_inv @ y) / (one.T @ Psi_inv @ one) [p. 2 of previous response]\none = np.ones(n).reshape(-1, 1) # Vector of ones\nmu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one)))\nmu_hat = mu_hat.item() # Extract scalar value\n\nprint(\"\\n--- Kriging Prediction Calculation ---\")\nprint(f\"Estimated mean (mu_hat): {np.round(mu_hat, 4)}\")\n\n# Step 6c: Calculate predictions f (y_hat) at new locations\n# f = mu_hat * ones(m) + psi.T @ Psi_inv @ (y - one * mu_hat)\nf_predict = mu_hat * np.ones(m).reshape(-1, 1) + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat))\n\nprint(f\"Dimensions of predicted values (f_predict): {f_predict.shape}\") # Should be (100, 1)\nprint(\"First 5 predicted f values:\\n\", np.round(f_predict[:5], 2).flatten())\nprint(\"-\" * 40)\n\n# --- 7. Visualization ---\n# Plot the original sinusoid function, the measured points, and the Kriging predictions.\n\nplt.figure(figsize=(10, 6))\nplt.plot(x_predict, f_predict, color=\"orange\", label=\"Kriging Prediction\")\nplt.plot(x_predict, np.sin(x_predict), color=\"grey\", linestyle='--', label=\"True Sinusoid Function\")\nplt.plot(X_train, y_train, \"bo\", markersize=8, label=\"Measurements\")\nplt.title(f\"Kriging prediction of sin(x) with {n} points. (theta: {theta})\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.show()\n\n--- Training Data (X_train, y_train) ---\nx values:\n [[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\ny values:\n [[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]\n----------------------------------------\n\n\n\n\n\n\n\n\n\n\n--- Computed Correlation Matrix (Psi) ---\nDimensions of Psi: (8, 8)\nFirst 5x5 block of Psi:\n [[1.   0.54 0.08 0.   0.  ]\n [0.54 1.   0.54 0.08 0.  ]\n [0.08 0.54 1.   0.54 0.08]\n [0.   0.08 0.54 1.   0.54]\n [0.   0.   0.08 0.54 1.  ]]\n----------------------------------------\n\n--- New Locations for Prediction (x_predict) ---\nNumber of prediction points: 100\nFirst 5 prediction points:\n [0.   0.06 0.13 0.19 0.25]\n----------------------------------------\n\n--- Computed Prediction Correlation Matrix (psi) ---\nDimensions of psi: (8, 100)\nFirst 5x5 block of psi:\n [[1.   1.   0.98 0.96 0.94]\n [0.54 0.59 0.65 0.7  0.75]\n [0.08 0.1  0.12 0.15 0.18]\n [0.   0.01 0.01 0.01 0.01]\n [0.   0.   0.   0.   0.  ]]\n----------------------------------------\n\n--- Kriging Prediction Calculation ---\nEstimated mean (mu_hat): -0.0499\nDimensions of predicted values (f_predict): (100, 1)\nFirst 5 predicted f values:\n [0.   0.05 0.1  0.15 0.21]\n----------------------------------------",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#jupyter-notebook",
    "href": "006_num_gp.html#jupyter-notebook",
    "title": "8  Kriging (Gaussian Process Regression)",
    "section": "8.7 Jupyter Notebook",
    "text": "8.7 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_matrices.html",
    "href": "006_matrices.html",
    "title": "9  Matrices",
    "section": "",
    "text": "9.1 Derivatives of Quadratic Forms\nWe present a step-by-step derivation of the general formula \\[\n\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}.\n\\tag{9.1}\\]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-derivative-quadratic-form",
    "href": "006_matrices.html#sec-derivative-quadratic-form",
    "title": "9  Matrices",
    "section": "",
    "text": "Define the components. Let \\(\\mathbf{v}\\) be a vector of size \\(n \\times 1\\), and let \\(\\mathbf{A}\\) be a matrix of size \\(n \\times n\\).\nWrite out the quadratic form in summation notation. The product \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) is a scalar. It can be expanded and be rewritten as a double summation: \\[\n\\mathbf{v}^T \\mathbf{A} \\mathbf{v} = \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j.\n\\]\nCalculate the partial derivative with respect to a component \\(v_k\\): The derivative of the scalar \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to the vector \\(\\mathbf{v}\\) is the gradient vector, whose \\(k\\)-th component is \\(\\frac{\\partial}{\\partial v_k} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v})\\). We need to find \\(\\frac{\\partial}{\\partial v_k} \\left( \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j \\right)\\). Consider the terms in the summation that involve \\(v_k\\). A term \\(v_i a_{ij} v_j\\) involves \\(v_k\\) if \\(i=k\\) or \\(j=k\\) (or both).\n\nTerms where \\(i=k\\): \\(v_k a_{kj} v_j\\). The derivative with respect to \\(v_k\\) is \\(a_{kj} v_j\\).\nTerms where \\(j=k\\): \\(v_i a_{ik} v_k\\). The derivative with respect to \\(v_k\\) is \\(v_i a_{ik}\\).\nThe term where \\(i=k\\) and \\(j=k\\): \\(v_k a_{kk} v_k = a_{kk} v_k^2\\). Its derivative with respect to \\(v_k\\) is \\(2 a_{kk} v_k\\). Notice this term is included in both cases above when \\(i=k\\) and \\(j=k\\). When \\(i=k\\), the term is \\(v_k a_{kk} v_k\\), derivative is \\(a_{kk} v_k\\). When \\(j=k\\), the term is \\(v_k a_{kk} v_k\\), derivative is \\(v_k a_{kk}\\). Summing these two gives \\(2 a_{kk} v_k\\).\n\nLet’s differentiate the sum \\(\\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j\\) with respect to \\(v_k\\): \\[\n\\frac{\\partial}{\\partial v_k} \\left( \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j \\right) = \\sum_{i=1}^n \\sum_{j=1}^n \\frac{\\partial}{\\partial v_k} (v_i a_{ij} v_j).\n\\]\nThe partial derivative \\(\\frac{\\partial}{\\partial v_k} (v_i a_{ij} v_j)\\) is non-zero only if \\(i=k\\) or \\(j=k\\).\n\nIf \\(i=k\\) and \\(j \\ne k\\): \\(\\frac{\\partial}{\\partial v_k} (v_k a_{kj} v_j) = a_{kj} v_j\\).\nIf \\(i \\ne k\\) and \\(j = k\\): \\(\\frac{\\partial}{\\partial v_k} (v_i a_{ik} v_k) = v_i a_{ik}\\).\nIf \\(i=k\\) and \\(j=k\\): \\(\\frac{\\partial}{\\partial v_k} (v_k a_{kk} v_k) = \\frac{\\partial}{\\partial v_k} (a_{kk} v_k^2) = 2 a_{kk} v_k\\).\n\nSo, the partial derivative is the sum of derivatives of all terms involving \\(v_k\\): \\(\\frac{\\partial}{\\partial v_k} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\sum_{j \\ne k} (a_{kj} v_j) + \\sum_{i \\ne k} (v_i a_{ik}) + (2 a_{kk} v_k)\\).\nWe can rewrite this by including the \\(i=k, j=k\\) term back into the summations: \\(\\sum_{j \\ne k} (a_{kj} v_j) + a_{kk} v_k + \\sum_{i \\ne k} (v_i a_{ik}) + v_k a_{kk}\\) (since \\(v_k a_{kk} = a_{kk} v_k\\)) \\(= \\sum_{j=1}^n a_{kj} v_j + \\sum_{i=1}^n v_i a_{ik}\\).\nConvert back to matrix/vector notation: The first summation \\(\\sum_{j=1}^n a_{kj} v_j\\) is the \\(k\\)-th component of the matrix-vector product \\(\\mathbf{A} \\mathbf{v}\\).The second summation \\(\\sum_{i=1}^n v_i a_{ik}\\) can be written as \\(\\sum_{i=1}^n a_{ik} v_i\\). Recall that the element in the \\(k\\)-th row and \\(i\\)-th column of the transpose matrix \\(\\mathbf{A}^T\\) is \\((A^T)_{ki} = a_{ik}\\). So, \\(\\sum_{i=1}^n a_{ik} v_i = \\sum_{i=1}^n (A^T)_{ki} v_i\\), which is the \\(k\\)-th component of the matrix-vector product \\(\\mathbf{A}^T \\mathbf{v}\\).\nAssemble the gradient vector: The \\(k\\)-th component of the gradient \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v})\\) is \\((\\mathbf{A} \\mathbf{v})_k + (\\mathbf{A}^T \\mathbf{v})_k\\). Since this holds for all \\(k = 1, \\dots, n\\), the gradient vector is the sum of the two vectors \\(\\mathbf{A} \\mathbf{v}\\) and \\(\\mathbf{A}^T \\mathbf{v}\\). Therefore, the general formula for the derivative is \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-conditon-number",
    "href": "006_matrices.html#sec-conditon-number",
    "title": "9  Matrices",
    "section": "9.2 The Condition Number",
    "text": "9.2 The Condition Number\nA small value, eps, can be passed to the function build_Psi to improve the condition number. For example, eps=sqrt(spacing(1)) can be used. The numpy function spacing() returns the distance between a number and its nearest adjacent number.\nThe condition number of a matrix is a measure of its sensitivity to small changes in its elements. It is used to estimate how much the output of a function will change if the input is slightly altered.\nA matrix with a low condition number is well-conditioned, which means its behavior is relatively stable, while a matrix with a high condition number is ill-conditioned, meaning its behavior is unstable with respect to numerical precision.\n\nimport numpy as np\n\n# Define a well-conditioned matrix (low condition number)\nA = np.array([[1, 0.1], [0.1, 1]])\nprint(\"Condition number of A: \", np.linalg.cond(A))\n\n# Define an ill-conditioned matrix (high condition number)\nB = np.array([[1, 0.99999999], [0.99999999, 1]])\nprint(\"Condition number of B: \", np.linalg.cond(B))\n\nCondition number of A:  1.2222222222222225\nCondition number of B:  200000000.57495335",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-matrix-pseudoinverse",
    "href": "006_matrices.html#sec-matrix-pseudoinverse",
    "title": "9  Matrices",
    "section": "9.3 The Moore-Penrose Pseudoinverse",
    "text": "9.3 The Moore-Penrose Pseudoinverse\n\n9.3.1 Definitions\nThe Moore-Penrose pseudoinverse is a generalization of the inverse matrix for non-square or singular matrices. It is computed as\n\\[\nA^+ = (A^* A)^{-1} A^*,\n\\] where \\(A^*\\) is the conjugate transpose of \\(A\\).\nIt satisfies the following properties:\n\n\\(AA^+A = A\\)\n\\(A^+AA^+ = A^+\\)\n\\((AA^+)^* = AA^+\\).\n\\((A^+A)^* = A^+A\\)\n\\(A^+ = (A^*)^+\\)\n\\(A^+ = A^T\\) if \\(A\\) is a square matrix and \\(A\\) is invertible.\n\nThe pseudoinverse can be computed using Singular Value Decomposition (SVD).\n\n\n9.3.2 Implementation in Python\n\nimport numpy as np\nfrom numpy.linalg import pinv\nA = np.array([[1, 2], [3, 4], [5, 6]])\nprint(f\"Matrix A:\\n {A}\")\nA_pseudo_inv = pinv(A)\nprint(f\"Moore-Penrose Pseudoinverse:\\n {A_pseudo_inv}\")\n\nMatrix A:\n [[1 2]\n [3 4]\n [5 6]]\nMoore-Penrose Pseudoinverse:\n [[-1.33333333 -0.33333333  0.66666667]\n [ 1.08333333  0.33333333 -0.41666667]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-strictly-positive-definite",
    "href": "006_matrices.html#sec-strictly-positive-definite",
    "title": "9  Matrices",
    "section": "9.4 Strictly Positive Definite Kernels",
    "text": "9.4 Strictly Positive Definite Kernels\n\n9.4.1 Definition\n\nDefinition 9.1 (Strictly Positive Definite Kernel) A kernel function \\(k(x,y)\\) is called strictly positive definite if for any finite collection of distinct points \\({x_1, x_2, \\ldots, x_n}\\) in the input space and any non-zero vector of coefficients \\(\\alpha = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_n)\\), the following inequality holds:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_i \\alpha_j k(x_i, x_j) &gt; 0.\n\\tag{9.2}\\]\n\nIn contrast, a kernel function \\(k(x,y)\\) is called positive definite (but not strictly) if the “\\(&gt;\\)” sign is replaced by “\\(\\geq\\)” in the above inequality.\n\n\n9.4.2 Connection to Positive Definite Matrices\nThe connection between strictly positive definite kernels and positive definite matrices lies in the Gram matrix construction:\n\nWhen we evaluate a kernel function \\(k(x,y)\\) at all pairs of data points in our sample, we construct the Gram matrix \\(K\\) where \\(K_{ij} = k(x_i, x_j)\\).\nIf the kernel function \\(k\\) is strictly positive definite, then for any set of distinct points, the resulting Gram matrix will be symmetric positive definite.\n\nA symmetric matrix is positive definite if and only if for any non-zero vector \\(\\alpha\\), the quadratic form \\(\\alpha^T K \\alpha &gt; 0\\), which directly corresponds to the kernel definition above.\n\n\n9.4.3 Connection to RBF Models\nFor RBF models, the kernel function is the radial basis function itself: \\[\nk(x,y) = \\psi(||x-y||).\n\\]\nThe Gaussian RBF kernel \\(\\psi(r) = e^{-r^2/(2\\sigma^2)}\\) is strictly positive definite in \\(\\mathbb{R}^n\\) for any dimension \\(n\\). The inverse multiquadric kernel \\(\\psi(r) = (r^2 + \\sigma^2)^{-1/2}\\) is also strictly positive definite in any dimension.\nThis mathematical property guarantees that the interpolation problem has a unique solution (the weight vector \\(\\vec{w}\\) is uniquely determined). The linear system \\(\\Psi \\vec{w} = \\vec{y}\\) can be solved reliably using Cholesky decomposition. The RBF interpolant exists and is unique for any distinct set of centers.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#cholesky-decomposition-and-positive-definite-matrices",
    "href": "006_matrices.html#cholesky-decomposition-and-positive-definite-matrices",
    "title": "9  Matrices",
    "section": "9.5 Cholesky Decomposition and Positive Definite Matrices",
    "text": "9.5 Cholesky Decomposition and Positive Definite Matrices\nWe consider the definiteness of a matrix, before discussing the Cholesky decomposition.\n\nDefinition 9.2 (Positive Definite Matrix) A symmetric matrix \\(A\\) is positive definite if all its eigenvalues are positive.\n\n\nExample 9.1 (Positive Definite Matrix) Given a symmetric matrix \\(A = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\), the eigenvalues of \\(A\\) are \\(\\lambda_1 = 13\\) and \\(\\lambda_2 = 5\\). Since both eigenvalues are positive, the matrix \\(A\\) is positive definite.\n\n\nDefinition 9.3 (Negative Definite, Positive Semidefinite, and Negative Semidefinite Matrices) Similarily, a symmetric matrix \\(A\\) is negative definite if all its eigenvalues are negative. It is positive semidefinite if all its eigenvalues are non-negative, and negative semidefinite if all its eigenvalues are non-positive.\n\nThe covariance matrix must be positive definite for a multivariate normal distribution for a couple of reasons:\n\nSemidefinite vs Definite: A covariance matrix is always symmetric and positive semidefinite. However, for a multivariate normal distribution, it must be positive definite, not just semidefinite. This is because a positive semidefinite matrix can have zero eigenvalues, which would imply that some dimensions in the distribution have zero variance, collapsing the distribution in those dimensions. A positive definite matrix has all positive eigenvalues, ensuring that the distribution has positive variance in all dimensions.\nInvertibility: The multivariate normal distribution’s probability density function involves the inverse of the covariance matrix. If the covariance matrix is not positive definite, it may not be invertible, and the density function would be undefined.\n\nIn summary, the covariance matrix being positive definite ensures that the multivariate normal distribution is well-defined and has positive variance in all dimensions.\nThe definiteness of a matrix can be checked by examining the eigenvalues of the matrix. If all eigenvalues are positive, the matrix is positive definite.\n\nimport numpy as np\n\ndef is_positive_definite(matrix):\n    return np.all(np.linalg.eigvals(matrix) &gt; 0)\n\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_positive_definite(matrix))  # Outputs: True\n\nTrue\n\n\nHowever, a more efficient way to check the definiteness of a matrix is through the Cholesky decomposition.\n\nDefinition 9.4 (Cholesky Decomposition) For a given symmetric positive-definite matrix \\(A \\in \\mathbb{R}^{n \\times n}\\), there exists a unique lower triangular matrix \\(L \\in \\mathbb{R}^{n \\times n}\\) with positive diagonal elements such that:\n\\[\nA = L L^T.\n\\]\nHere, \\(L^T\\) denotes the transpose of \\(L\\).\n\n\nExample 9.2 (Cholesky decomposition using numpy) linalg.cholesky computes the Cholesky decomposition of a matrix, i.e., it computes a lower triangular matrix \\(L\\) such that \\(LL^T = A\\). If the matrix is not positive definite, an error (LinAlgError) is raised.\n\nimport numpy as np\n\n# Define a Hermitian, positive-definite matrix\nA = np.array([[9, 4], [4, 9]]) \n\n# Compute the Cholesky decomposition\nL = np.linalg.cholesky(A)\n\nprint(\"L = \\n\", L)\nprint(\"L*LT = \\n\", np.dot(L, L.T))\n\nL = \n [[3.         0.        ]\n [1.33333333 2.68741925]]\nL*LT = \n [[9. 4.]\n [4. 9.]]\n\n\n\n\nExample 9.3 (Cholesky Decomposition) Given a symmetric positive-definite matrix \\(A = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\), the Cholesky decomposition computes the lower triangular matrix \\(L\\) such that \\(A = L L^T\\). The matrix \\(L\\) is computed as: \\[\nL = \\begin{pmatrix} 3 & 0 \\\\ 4/3 & 2 \\end{pmatrix},\n\\] so that \\[\nL L^T = \\begin{pmatrix} 3 & 0 \\\\ 4/3 & \\sqrt{65}/3 \\end{pmatrix} \\begin{pmatrix} 3 & 4/3 \\\\ 0 & \\sqrt{65}/3 \\end{pmatrix} = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix} = A.\n\\]\n\nAn efficient implementation of the definiteness-check based on Cholesky is already available in the numpy library. It provides the np.linalg.cholesky function to compute the Cholesky decomposition of a matrix. This more efficient numpy-approach can be used as follows:\n\nimport numpy as np\n\ndef is_pd(K):\n    try:\n        np.linalg.cholesky(K)\n        return True\n    except np.linalg.linalg.LinAlgError as err:\n        if 'Matrix is not positive definite' in err.message:\n            return False\n        else:\n            raise\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_pd(matrix))  # Outputs: True\n\nTrue\n\n\n\n9.5.1 Example of Cholesky Decomposition\nWe consider dimension \\(k=1\\) and \\(n=2\\) sample points. The sample points are located at \\(x_1=1\\) and \\(x_2=5\\). The response values are \\(y_1=2\\) and \\(y_2=10\\). The correlation parameter is \\(\\theta=1\\) and \\(p\\) is set to \\(1\\). Using Equation 8.1, we can compute the correlation matrix \\(\\Psi\\):\n\\[\n\\Psi = \\begin{pmatrix}\n1 & e^{-1}\\\\\ne^{-1} & 1\n\\end{pmatrix}.\n\\]\nTo determine MLE as in Equation 8.13, we need to compute \\(\\Psi^{-1}\\):\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nCholesky-decomposition of \\(\\Psi\\) is recommended to compute \\(\\Psi^{-1}\\). Cholesky decomposition is a decomposition of a positive definite symmetric matrix into the product of a lower triangular matrix \\(L\\), a diagonal matrix \\(D\\) and the transpose of \\(L\\), which is denoted as \\(L^T\\). Consider the following example:\n\\[\nLDL^T=\n\\begin{pmatrix}\n1 & 0 \\\\\nl_{21} & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nd_{11} & 0 \\\\\n0 & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}=\n\\]\n\\[\n\\begin{pmatrix}\nd_{11} & 0 \\\\\nd_{11} l_{21} & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nd_{11} & d_{11} l_{21} \\\\\nd_{11} l_{21} & d_{11} l_{21}^2 + d_{22}\n\\end{pmatrix}.\n\\tag{9.3}\\]\nUsing Equation 9.3, we can compute the Cholesky decomposition of \\(\\Psi\\):\n\n\\(d_{11} = 1\\),\n\\(l_{21}d_{11} = e^{-1} \\Rightarrow l_{21} = e^{-1}\\), and\n\\(d_{11} l_{21}^2 + d_{22} = 1 \\Rightarrow d_{22} = 1 - e^{-2}\\).\n\nThe Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & 1\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 1 - e^{-2}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & 1\\\\\n\\end{pmatrix}\n= LDL^T\\]\nSome programs use \\(U\\) instead of \\(L\\). The Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = LDL^T = U^TDU.\n\\]\nUsing \\[\n\\sqrt{D} =\\begin{pmatrix}\n1 & 0\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix},\n\\] we can write the Cholesky decomposition of \\(\\Psi\\) without a diagonal matrix \\(D\\) as \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n= U^TU.\n\\]\n\n\n9.5.2 Inverse Matrix Using Cholesky Decomposition\nTo compute the inverse of a matrix using the Cholesky decomposition, you can follow these steps:\n\nDecompose the matrix \\(A\\) into \\(L\\) and \\(L^T\\), where \\(L\\) is a lower triangular matrix and \\(L^T\\) is the transpose of \\(L\\).\nCompute \\(L^{-1}\\), the inverse of \\(L\\).\nThe inverse of \\(A\\) is then \\((L^{-1})^T  L^-1\\).\n\nPlease note that this method only applies to symmetric, positive-definite matrices.\nThe inverse of the matrix \\(\\Psi\\) from above is:\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nHere’s an example of how to compute the inverse of a matrix using Cholesky decomposition in Python:\n\nimport numpy as np\nfrom scipy.linalg import cholesky, inv\nE = np.exp(1)\n\n# Psi is a symmetric, positive-definite matrix \nPsi = np.array([[1, 1/E], [1/E, 1]])\nL = cholesky(Psi, lower=True)\nL_inv = inv(L)\n# The inverse of A is (L^-1)^T * L^-1\nPsi_inv = np.dot(L_inv.T, L_inv)\n\nprint(\"Psi:\\n\", Psi)\nprint(\"Psi Inverse:\\n\", Psi_inv)\n\nPsi:\n [[1.         0.36787944]\n [0.36787944 1.        ]]\nPsi Inverse:\n [[ 1.15651764 -0.42545906]\n [-0.42545906  1.15651764]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#nyström-approximation",
    "href": "006_matrices.html#nyström-approximation",
    "title": "9  Matrices",
    "section": "9.6 Nyström Approximation",
    "text": "9.6 Nyström Approximation\n\n9.6.1 What’s the Big Idea?\nImagine you have a huge, detailed map of a country. Working with the full, high-resolution map is slow and takes up a lot of computer memory. The Nyström method is like creating a smaller-scale summary map by only looking at a few key, representative locations.\nIn machine learning, we often work with a kernel matrix (or Gram matrix), which tells us how similar every pair of data points is to each other. For very large datasets, this matrix can become massive, making it computationally expensive to store and process.\nThe Nyström method provides an efficient way to create a low-rank approximation of this large kernel matrix. In simple terms, it finds a “simpler” version of the matrix that captures its most important properties without needing to compute or store the whole thing.\n\n\n\n9.6.2 How Does It Work?\nThe core idea is to select a small, random subset of the columns of the full kernel matrix and use them to reconstruct the entire matrix. Let’s say our full kernel matrix is \\(K\\).\n\nSample: Randomly select \\(l\\) columns from the \\(n\\) total columns of \\(K\\). Let \\(C\\) be the \\(n \\times l\\) matrix of these sampled columns.\nIntersect: Take the rows of \\(C\\) corresponding to the sampled column indices to form the \\(l \\times l\\) matrix \\(W\\).\nApproximate: Using \\(C\\) and \\(W\\), calculate the Nyström approximation \\(\\tilde{K}\\) of \\(K\\): \\[\n\\tilde{K} \\approx C W^{+} C^T\n\\] where \\(W^{+}\\) is the pseudoinverse of \\(W\\).\n\n\n\n\n9.6.3 Example\nSuppose we have 4 data points and the full kernel matrix \\(K\\) is: \\[\nK = \\begin{pmatrix}\n9 & 6 & 3 & 1 \\\\\n6 & 4 & 2 & 0.5 \\\\\n3 & 2 & 1 & 0.25 \\\\\n1 & 0.5 & 0.25 & 0.1\n\\end{pmatrix}\n\\]\nLet’s approximate it by sampling 2 columns (\\(l=2\\)):\n\nSample: Pick the 1st and 3rd columns: \\[\nC = \\begin{pmatrix}\n9 & 3 \\\\\n6 & 2 \\\\\n3 & 1 \\\\\n1 & 0.25\n\\end{pmatrix}\n\\]\nIntersect: Take the 1st and 3rd rows from \\(C\\) to form \\(W\\): \\[\nW = \\begin{pmatrix}\n9 & 3 \\\\\n3 & 1\n\\end{pmatrix}\n\\]\nApproximate: Suppose the pseudoinverse of \\(W\\) is: \\[\nW^{+} = \\begin{pmatrix}\n0.09 & -0.27 \\\\\n-0.27 & 0.81\n\\end{pmatrix}\n\\] Then, \\[\n\\tilde{K} = C W^{+} C^T = \\begin{pmatrix}\n9 & 6 & 3 & 0.675 \\\\\n6 & 4 & 2 & 0.45 \\\\\n3 & 2 & 1 & 0.225 \\\\\n0.675 & 0.45 & 0.225 & 0.05\n\\end{pmatrix}\n\\]\n\n\\(\\tilde{K}\\) is a good approximation of the original \\(K\\), especially in the top-left portion.\n\n\n\n9.6.4 Why Is This Useful?\n\nSpeed: The Nyström method is much faster than computing the full kernel matrix. The complexity is roughly \\(O(l^2 n)\\) instead of \\(O(n^2 d)\\) (where \\(d\\) is the number of features).\nScalability: It allows kernel methods (like SVM or Kernel PCA) to be used on much larger datasets.\nFeature Mapping: The method can be used to project new data points into the same feature space for prediction tasks.\n\nThe quality of the approximation depends on the columns you sample. Uniform random sampling is common and often effective, but more advanced techniques exist to select more informative columns.\n\n\n9.6.5 Applying the Nyström Approximation: How Nyström Approximation Helps Kriging\nKriging can significantly benefit from the Nyström approximation, especially when dealing with large datasets. Kriging is a spatial interpolation method used to estimate values at unmeasured locations based on observed points. It relies on a covariance matrix (often denoted as K) that describes the spatial correlation between all observed data points.\nThe Problem with Standard Kriging:\nThe main computational challenge in Kriging is solving for the weights needed for prediction, which requires inverting the covariance matrix K. For n data points, K is an n x n matrix, and inverting it has computational complexity \\(O(n^3)\\). This becomes impractical for large datasets.\nThe Nyström Solution:\nSince the covariance matrix in Kriging is a type of kernel matrix, we can use the Nyström method to create a low-rank approximation, \\(\\tilde{K}\\). Instead of inverting the full matrix, we use the Woodbury matrix identity on the Nyström approximation, allowing us to efficiently compute \\(\\tilde{K}^{-1}\\) without forming the full matrix. This reduces computational complexity to roughly \\(O(l^2 n)\\), where l is the number of sampled columns.\nIn summary, Nyström makes Kriging feasible for large-scale problems by replacing expensive matrix inversion with a faster, memory-efficient approximation.\n\n\n\n9.6.6 Example: Predicting Temperature with Nyström-Kriging\nSuppose we have temperature readings from 100 weather stations (n=100) and want to predict the temperature at a new location.\nData:\n\nObserved Locations (X): 100 coordinate pairs\nObserved Temperatures (y): 100 values\nPrediction Location (x*): Coordinates of the new location\n\n\n9.6.6.1 Step 1: Nyström Approximation of the Covariance Matrix\n\nSample Representative Points: Randomly select l=10 stations as landmarks.\nCompute C and W:\n\nC: Covariance between all 100 stations and the 10 landmarks (100x10 matrix)\nW: Covariance among the 10 landmarks (10x10 matrix)\n\n\nNyström approximation: \\(\\tilde{K} = C W^{+} C^T\\)\n\n\n9.6.6.2 Step 2: Modeling and Prediction\nStandard Kriging prediction: \\[\ny(x^*) = \\mathbf{k}^{*T} \\mathbf{K}^{-1} \\mathbf{y}\n\\] where \\(\\mathbf{k}^{*T}\\) is the covariance vector between the prediction location and all observed locations.\nNyström-Kriging prediction: \\[\ny(x^*) \\approx \\mathbf{k}^{*T} (\\text{fast\\_approx\\_inverse}(\\mathbf{C}, \\mathbf{W})) \\mathbf{y}\n\\]\nPrediction Steps:\n\nCalculate \\(\\mathbf{k}^{*T}\\): Covariance between new location and all stations.\nApproximate the inverse term using the Woodbury identity with C and W.\nMake the prediction: Take the dot product of \\(\\mathbf{k}^{*T}\\) and the weights vector.\n\nThis yields an accurate prediction efficiently, enabling rapid mapping for large regions.\n\n\n\n9.6.7 Details: Woodbury Matrix Identity for Avoiding the Big Inversion\nFirst, what is the Woodbury matrix identity? It’s a mathematical rule that tells you how to find the inverse of a matrix that’s been modified slightly. Its most useful form is for a “low-rank update”:\n\\[\n(A + UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1}VA^{-1}\n\\]\nThis looks complicated, but the core idea is simple:\n\nIf you have a matrix \\(A\\) that is easy to invert (like a diagonal matrix).\nAnd you add a low-rank matrix to it (the \\(UCV\\) part, where \\(C\\) is small).\nYou can find the new inverse without directly inverting the big \\((A + UCV)\\) matrix. Instead, you only need to invert the much smaller matrix in the middle of the formula: \\((C^{-1} + VA^{-1}U)\\).\n\nHow does this apply to the Nyström approximation?\nIn many machine learning and Kriging applications, we don’t just need the kernel matrix \\(\\tilde{K}\\), but a “regularized” version, \\((\\lambda I + \\tilde{K})\\), where \\(\\lambda I\\) is a diagonal matrix that helps prevent overfitting. We need to find the inverse of this:\n\\[\n(\\lambda I + \\tilde{K})^{-1}\n\\]\nSubstituting the Nyström formula \\(\\tilde{K} = C W^{+} C^T\\), we get:\n\\[\n(\\lambda I + C W^{+} C^T)^{-1}\n\\]\nThis expression fits the Woodbury identity perfectly!\n\n\\(A = \\lambda I\\) (very easy to invert: \\(A^{-1} = \\frac{1}{\\lambda}I\\))\n\\(U = C\\) (our \\(n \\times l\\) matrix)\n\\(C\\) (middle matrix) \\(= W^{+}\\) (our small \\(l \\times l\\) matrix)\n\\(V = C^T\\) (our \\(l \\times n\\) matrix)\n\nBy plugging these into the Woodbury formula, we get an expression for the inverse that only requires inverting a small \\(l \\times l\\) matrix. This means we never have to build the full \\(n \\times n\\) matrix \\(\\tilde{K}\\) or invert it directly. This is the source of the massive speed-up.\n\n\n\n9.6.8 The Example: Step-by-Step\nLet’s reuse our 4-point example and show both the slow way and the fast Woodbury way.\nRecall our matrices:\n\n\\(C = \\begin{pmatrix} 9 & 3 \\\\ 6 & 2 \\\\ 3 & 1 \\\\ 1 & 0.25 \\end{pmatrix}\\)\n\\(W^{+} = \\begin{pmatrix} 0.09 & -0.27 \\\\ -0.27 & 0.81 \\end{pmatrix}\\)\nLet’s use a regularization value \\(\\lambda = 0.1\\).\n\n\n9.6.8.1 Method 1: The Slow Way (Forming the full matrix)\n\nConstruct \\(\\tilde{K}\\): First, we explicitly calculate the full \\(4 \\times 4\\) Nyström approximation \\(\\tilde{K} = C W^{+} C^T\\).\n\\[\n\\tilde{K} = \\begin{pmatrix}\n9 & 6 & 3 & 0.675 \\\\\n6 & 4 & 2 & 0.45 \\\\\n3 & 2 & 1 & 0.225 \\\\\n0.675 & 0.45 & 0.225 & 0.05\n\\end{pmatrix}\n\\]\nAdd the regularization: Now we compute \\((\\lambda I + \\tilde{K})\\).\n\\[\n(\\lambda I + \\tilde{K}) = \\begin{pmatrix}\n9.1 & 6 & 3 & 0.675 \\\\\n6 & 4.1 & 2 & 0.45 \\\\\n3 & 2 & 1.1 & 0.225 \\\\\n0.675 & 0.45 & 0.225 & 0.15\n\\end{pmatrix}\n\\]\nInvert the \\(4 \\times 4\\) matrix: This is the expensive step. The result is:\n\\[\n(\\lambda I + \\tilde{K})^{-1} \\approx\n\\begin{pmatrix}\n9.85 & -14.78 & -0.07 & 0.27 \\\\\n-14.78 & 22.22 & 0.09 & -0.41 \\\\\n-0.07 & 0.09 & 0.91 & -0.03 \\\\\n0.27 & -0.41 & -0.03 & 6.67\n\\end{pmatrix}\n\\]\n\nThis works for our tiny \\(4 \\times 4\\) example, but it would be computationally infeasible if \\(n\\) was 10,000.\n\n\n9.6.8.2 Method 2: The Fast Way (Using Woodbury Identity)\nWe use the Woodbury formula to get the same result without ever creating a \\(4 \\times 4\\) matrix. The formula simplifies to:\n\\[\n(\\lambda I + \\tilde{K})^{-1} = \\frac{1}{\\lambda}I - \\frac{1}{\\lambda^2} C \\left(W + \\frac{1}{\\lambda}C^T C\\right)^{-1} C^T\n\\]\n\nCompute the small \\(2 \\times 2\\) pieces:\n\n\\(C^T C = \\begin{pmatrix} 127 & 42.25 \\\\ 42.25 & 14.0625 \\end{pmatrix}\\)\n\\(W = \\begin{pmatrix} 9 & 3 \\\\ 3 & 1 \\end{pmatrix}\\)\nThe matrix to invert is \\(W + \\frac{1}{0.1}C^T C = W + 10 \\cdot (C^T C)\\), which is: \\[\n\\begin{pmatrix} 9 & 3 \\\\ 3 & 1 \\end{pmatrix} +\n\\begin{pmatrix} 1270 & 422.5 \\\\ 422.5 & 140.625 \\end{pmatrix} =\n\\begin{pmatrix} 1279 & 425.5 \\\\ 425.5 & 141.625 \\end{pmatrix}\n\\]\n\nInvert the small \\(2 \\times 2\\) matrix: This is the only inversion we need, and it’s extremely fast.\n\\[\n(W + \\frac{1}{\\lambda}C^T C)^{-1} \\approx\n\\begin{pmatrix}\n0.22 & -0.66 \\\\\n-0.66 & 1.99\n\\end{pmatrix}\n\\]\nCombine the results: Now we plug this small inverse back into the full formula. The rest is just matrix multiplication, no more inversions.\n\nFirst, calculate the middle term: \\(M = \\frac{1}{\\lambda^2} C (\\dots)^{-1} C^T\\). This will result in a \\(4 \\times 4\\) matrix.\nThen, calculate the final result: \\(\\frac{1}{\\lambda}I - M\\).\n\n\nAfter performing these multiplications, you will get the exact same \\(4 \\times 4\\) inverse matrix as in the slow method.\nThe crucial difference is that the most expensive operation—the matrix inversion—was performed on a tiny \\(2 \\times 2\\) matrix instead of a \\(4 \\times 4\\) one. For a large-scale problem, this is the difference between a calculation that takes seconds and one that could take hours or even be impossible.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#extending-spotpythons-kriging-surrogate-with-nyström-approximation-for-enhanced-scalability",
    "href": "006_matrices.html#extending-spotpythons-kriging-surrogate-with-nyström-approximation-for-enhanced-scalability",
    "title": "9  Matrices",
    "section": "9.7 Extending spotpython’s Kriging Surrogate with Nyström Approximation for Enhanced Scalability",
    "text": "9.7 Extending spotpython’s Kriging Surrogate with Nyström Approximation for Enhanced Scalability\n\n9.7.1 Introduction: Overcoming the Scalability Challenge in Kriging for Sequential Optimization\nThe Sequential Parameter Optimization Toolbox (spotpython) is a framework for hyperparameter tuning and black-box optimization based on Sequential Model-Based Optimization (SMBO). At the core of SMBO lies a surrogate model that approximates the true, expensive objective. Kriging (Gaussian Process regression) is a premier choice because it provides both predictions and a principled measure of uncertainty. This uncertainty enables a balance between exploration and exploitation. In each SMBO iteration, the Kriging model is updated with new evaluations, refining its approximation and proposing the next points.\nStandard Kriging requires constructing and inverting an \\(n \\times n\\) covariance matrix, where \\(n\\) is the number of data points. Matrix inversion scales as \\(O(n^3)\\). During SMBO, \\(n\\) can reach hundreds or thousands; refitting the surrogate each iteration becomes prohibitively expensive. This cubic scaling is the key obstacle to applying Kriging at larger scales.\nWe integrate the Nyström method into the spotpython Kriging class. The Nyström method yields a low-rank approximation of a symmetric positive semidefinite (SPSD) kernel matrix by selecting \\(l \\ll n\\) “landmark” points. It approximates the full \\(n \\times n\\) covariance while requiring inversion of only an \\(l \\times l\\) matrix, reducing fitting cost from \\(O(n^3)\\) to \\(O(n\\,l^2)\\). This makes Kriging viable even when the number of function evaluations is large.\n\n\n9.7.2 Report Objectives and Structure\n\nReview theoretical foundations of Kriging and Nyström approximation\nPresent documented Python code updates for Kriging (as in kriging.py)\nExplain changes to __init__, fit, and predict\nShow how mixed variable types are preserved via build_Psi and build_psi_vec\nProvide practical usage guidance and a formal complexity analysis",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#theoretical-foundations-the-nyströmkriging-framework",
    "href": "006_matrices.html#theoretical-foundations-the-nyströmkriging-framework",
    "title": "9  Matrices",
    "section": "9.8 Theoretical Foundations: The Nyström–Kriging Framework",
    "text": "9.8 Theoretical Foundations: The Nyström–Kriging Framework\n\n9.8.1 A Primer on Kriging (Gaussian Process Regression)\nKriging models \\(f(x)\\) as a Gaussian Process with mean function \\(m(\\cdot)\\) and covariance (kernel) \\(k(\\cdot,\\cdot)\\). For training inputs \\(X = \\{x_1,\\dots,x_n\\}\\) and observations \\(y = \\{y_1,\\dots,y_n\\}\\): \\[\ny \\sim \\mathcal{N}\\!\\big(m(X),\\, K(X,X) + \\sigma_n^2 I\\big)\n\\] For a new point \\(x_\\ast\\): \\[\n\\mu(x_\\ast) = k(x_\\ast, X)\\,[K(X,X) + \\sigma_n^2 I]^{-1} y\n\\] \\[\n\\sigma^2(x_\\ast) = k(x_\\ast, x_\\ast) - k(x_\\ast, X)\\,[K(X,X) + \\sigma_n^2 I]^{-1} k(X, x_\\ast)\n\\] The challenge is inverting the \\(n \\times n\\) matrix \\(K(X,X) + \\sigma_n^2 I\\).\n\n\n9.8.2 The Nyström Method for Low-Rank Kernel Approximation\nSelect \\(l\\) landmark points \\(X_m \\subset X\\). Let: - \\(C = K_{nm} = K(X, X_m) \\in \\mathbb{R}^{n \\times l}\\) - \\(W = K_{mm} = K(X_m, X_m) \\in \\mathbb{R}^{l \\times l}\\) Then the Nyström approximation is: \\[\n\\tilde{K}_{nn} = C\\,W^{+}\\,C^\\top = K_{nm}\\,K_{mm}^{+}\\,K_{mn}\n\\] where \\(W^{+}\\) is the pseudoinverse of \\(W\\). The approximation has rank \\(\\le l\\).\n\n\n9.8.3 Justification for Landmark Selection\nUniform sampling without replacement is an effective and inexpensive strategy for selecting landmarks across varied datasets and kernels.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#implementation-a-scalable-kriging-class-for-spotpython",
    "href": "006_matrices.html#implementation-a-scalable-kriging-class-for-spotpython",
    "title": "9  Matrices",
    "section": "9.9 Implementation: A Scalable Kriging Class for spotpython",
    "text": "9.9 Implementation: A Scalable Kriging Class for spotpython\n\n9.9.1 Updated kriging.py with Nyström Approximation (excerpt)\n\"\"\"\nKriging surrogate with optional Nyström approximation.\n\"\"\"\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom scipy.linalg import cholesky, cho_solve, solve_triangular\n\nclass Kriging:\n    def __init__(self, fun_control, n_theta=None, theta=None, p=2.0,\n                 corr=\"squared_exponential\", isotropic=False,\n                 approximation=\"None\", n_landmarks=100):\n        self.fun_control = fun_control\n        self.dim = self.fun_control[\"lower\"].shape\n        self.p = p\n        self.corr = corr\n        self.isotropic = isotropic\n        self.approximation = approximation\n        self.n_landmarks = n_landmarks\n        self.factor_mask = self.fun_control[\"var_type\"] == \"factor\"\n        self.ordered_mask = ~self.factor_mask\n        self.n_theta = 1 if isotropic else (n_theta or self.dim)\n        self.theta = np.full(self.n_theta, 0.1) if theta is None else theta\n        self.X_, self.y_, self.L_, self.alpha_ = None, None, None, None\n        self.landmarks_, self.W_cho_, self.nystrom_alpha_ = None, None, None\n\n    def fit(self, X, y):\n        self.X_, self.y_ = X, y\n        n_samples = X.shape[0]\n        if self.approximation.lower() == \"nystroem\" and n_samples &gt; self.n_landmarks:\n            return self._fit_nystrom(X, y)\n        return self._fit_standard(X, y)\n\n    def _fit_standard(self, X, y):\n        Psi = self.build_Psi(X, X)\n        Psi[np.diag_indices_from(Psi)] += 1e-8\n        try:\n            self.L_ = cholesky(Psi, lower=True)\n            self.alpha_ = cho_solve((self.L_, True), y)\n        except np.linalg.LinAlgError:\n            self.L_ = None\n            self.alpha_ = np.linalg.pinv(Psi) @ y\n\n    def _fit_nystrom(self, X, y):\n        n_samples = X.shape[0]\n        idx = np.random.choice(n_samples, self.n_landmarks, replace=False)\n        self.landmarks_ = X[idx, :]\n        W = self.build_Psi(self.landmarks_, self.landmarks_) + 1e-8 * np.eye(self.n_landmarks)\n        C = self.build_Psi(X, self.landmarks_)\n        try:\n            self.W_cho_ = cholesky(W, lower=True)\n            self.nystrom_alpha_ = cho_solve((self.W_cho_, True), C.T @ y)\n        except np.linalg.LinAlgError:\n            self.W_cho_ = None\n            self._fit_standard(X, y)\n\n    def predict(self, X_star):\n        if self.approximation.lower() == \"nystroem\" and self.landmarks_ is not None:\n            return self._predict_nystrom(X_star)\n        return self._predict_standard(X_star)\n\n    def _predict_standard(self, X_star):\n        psi = self.build_Psi(X_star, self.X_)\n        y_pred = psi @ self.alpha_\n        if self.L_ is not None:\n            v = solve_triangular(self.L_, psi.T, lower=True)\n            y_mse = 1.0 - np.sum(v**2, axis=0)\n        else:\n            Psi = self.build_Psi(self.X_, self.X_) + 1e-8 * np.eye(self.X_.shape[0])\n            pi_Psi = np.linalg.pinv(Psi)\n            y_mse = 1.0 - np.sum((psi @ pi_Psi) * psi, axis=1)\n        y_mse[y_mse &lt; 0] = 0\n        return y_pred, y_mse.reshape(-1, 1)\n\n    def _predict_nystrom(self, X_star):\n        psi_star_m = self.build_Psi(X_star, self.landmarks_)\n        y_pred = psi_star_m @ self.nystrom_alpha_\n        if self.W_cho_ is not None:\n            v = cho_solve((self.W_cho_, True), psi_star_m.T)\n            quad = np.sum(psi_star_m * v.T, axis=1)\n            y_mse = 1.0 - quad\n        else:\n            y_mse = np.ones(X_star.shape[0])\n        y_mse[y_mse &lt; 0] = 0\n        return y_pred, y_mse.reshape(-1, 1)\n\n    def build_Psi(self, X1, X2):\n        n1 = X1.shape[0]\n        Psi = np.zeros((n1, X2.shape[0]))\n        for i in range(n1):\n            Psi[i, :] = self.build_psi_vec(X1[i, :], X2)\n        return Psi\n\n    def build_psi_vec(self, x, X_):\n        theta10 = np.full(self.dim, 10**self.theta) if self.isotropic else 10**self.theta\n        D = np.zeros(X_.shape[0])\n        if self.ordered_mask.any():\n            Xo = X_[:, self.ordered_mask]\n            xo = x[self.ordered_mask]\n            D += cdist(xo.reshape(1, -1), Xo, metric=\"sqeuclidean\",\n                       w=theta10[self.ordered_mask]).ravel()\n        if self.factor_mask.any():\n            Xf = X_[:, self.factor_mask]\n            xf = x[self.factor_mask]\n            D += cdist(xf.reshape(1, -1), Xf, metric=\"hamming\",\n                       w=theta10[self.factor_mask]).ravel() * self.factor_mask.sum()\n        return np.exp(-D) if self.corr == \"squared_exponential\" else np.exp(-(D**self.p))",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#implementation-details",
    "href": "006_matrices.html#implementation-details",
    "title": "9  Matrices",
    "section": "9.10 Implementation Details",
    "text": "9.10 Implementation Details\n\n9.10.1 Architectural Enhancements to init\n\nNew argument approximation=\"None\" for backward-compatible selection between exact Kriging and Nyström\nNew argument n_landmarks (default 100) controls the number of inducing points when using Nyström\nState attributes for both exact and Nyström paths are maintained separately\n\n\n\n9.10.2 The fit() Method: A Dual-Pathway Approach\n\nDispatcher selecting exact or Nyström pathway\nThe Nyström fit Pathway (_fit_nystrom):\n\nLandmark selection via uniform sampling without replacement\nCore matrices:\n\n\\(W = K_{mm}\\) (landmark-landmark)\n\\(C = K_{nm}\\) (data-landmark)\n\nCholesky factorization of \\(W\\) (with jitter) for stability\nPre-computation: \\(\\alpha_{nys} = W^{-1} C^T y\\) via cho_solve\n\nThe Standard fit Pathway (_fit_standard):\n\nFull \\(\\Psi\\) construction, Cholesky decomposition, and solve for \\(\\alpha\\)\nFallback to pseudoinverse if Cholesky fails\n\n\n\n\n9.10.3 The predict() Method: Conditional Prediction Logic\n\nRoutes to Nyström or standard prediction path based on fitted model state\nThe Nyström predict Pathway (_predict_nystrom):\n\nCross-covariance \\(\\psi\\) between test points and landmarks\nMean: \\(\\psi \\cdot \\alpha_{nys}\\)\nVariance: uses cho_solve with \\(W\\) Cholesky; non-negative clipping\n\nThe Standard predict Pathway (_predict_standard):\n\nCross-covariance with all training points\nMean from \\(\\alpha\\); variance via triangular solves or pseudoinverse fallback\n\n\n\n\n9.10.4 Critical Detail: Preserving Mixed Variable Type Functionality\nThe Significance of build_psi_vec:\n\nMixed spaces: continuous (ordered) and categorical (factor) variables\nDistances:\n\nWeighted squared Euclidean for ordered variables\nWeighted Hamming for factors\n\nAnisotropic kernel via per-dimension length-scales \\(\\theta\\)\nNyström path reuses build_Psi → build_psi_vec, preserving mixed-type handling\n\n\n\n9.10.5 Seamless Integration into the Nyström Workflow\nAll covariance computations (\\(W\\), \\(C\\), predictive cross-covariance) use build_Psi, ensuring identical handling for mixed variable types in both standard and Nyström modes.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#jupyter-notebook",
    "href": "006_matrices.html#jupyter-notebook",
    "title": "9  Matrices",
    "section": "9.11 Jupyter Notebook",
    "text": "9.11 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_infill.html",
    "href": "006_infill.html",
    "title": "10  Infill Criteria",
    "section": "",
    "text": "10.1 Balancing Exploitation and Exploration\nIn the context of computer experiments and surrogate modeling, a sampling plan refers to the set of input values, often denoted as \\(X\\), at which a computer code is evaluated. The primary objective of a sampling plan is to efficiently explore the input space to understand the behavior of the computer code and to construct a surrogate model that accurately represents that behavior. Historically, Response Surface Methodology (RSM) provided methods for designing such plans, often based on rectangular grids or factorial designs. More recently, Design and Analysis of Computer Experiments (DACE) has emerged as a more flexible and powerful approach for this purpose.\nA surrogate model, or \\(\\hat{f}\\), is built to approximate the expensive response of a black-box function \\(f(x)\\). Since evaluating \\(f\\) is costly, only a sparse set of samples is used to construct \\(\\hat{f}\\), which can then provide inexpensive predictions for any point in the design space. However, as a surrogate model is inherently an approximation of the true function, its accuracy and predictive capabilities can be significantly improved by incorporating new data points, known as infill points. Infill points are strategically chosen to either reduce uncertainty, improve predictions in specific regions of interest, or enhance the model’s ability to identify optima or trends.\nThe process of updating a surrogate model with infill points is iterative. It typically involves:\nA crucial aspect of selecting infill points is navigating the inherent trade-off between exploitation and exploration.\nForrester, Sóbester, and Keane (2008) emphasizes that effective infill criteria are designed to combine both exploitation and exploration.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#balancing-exploitation-and-exploration",
    "href": "006_infill.html#balancing-exploitation-and-exploration",
    "title": "10  Infill Criteria",
    "section": "",
    "text": "Definition 10.1 (Exploitation) Exploitation refers to sampling near predicted optima to refine the solution. This strategy aims to rapidly converge on a good solution by focusing computational effort where the surrogate model suggests the best values might lie.\n\n\nDefinition 10.2 (Exploration) Exploration involves sampling in regions of high uncertainty to improve the global accuracy of the model. This approach ensures that the model is well-informed across the entire design space, preventing it from getting stuck in local optima.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#expected-improvement-ei",
    "href": "006_infill.html#expected-improvement-ei",
    "title": "10  Infill Criteria",
    "section": "10.2 Expected Improvement (EI)",
    "text": "10.2 Expected Improvement (EI)\nExpected Improvement (EI) is one of the most influential and widely-used infill criteria. Formalized by Jones, Schonlau, and Welch (1998) and building upon the work of Močkus (1974), EI provides a mathematically elegant framework that naturally balances exploitation and exploration. Rather than simply picking the point with the best predicted value (pure exploitation) or the point with the highest uncertainty (pure exploration), EI asks a more nuanced question: “How much improvement over the current best solution can we expect to gain by evaluating the true function at a new point \\(x\\)?”.\nThe Expected Improvement, \\(EI(x)\\), can be calculated using the following formula:\n\\[\nEI(x) = \\sigma(x) \\left[ Z \\Phi(Z) + \\phi(Z) \\right]\n\\] where:\n\n\\(\\mu(x)\\) (or \\(\\hat{y}(x)\\)) is the Kriging prediction (mean of the stochastic process) at a new, unobserved point \\(x\\).\n\\(\\sigma(x)\\) (or \\(\\hat{s}(x)\\)) is the estimated standard deviation (square root of the variance \\(\\hat{s}^2(x)\\)) of the prediction at point \\(x\\).\n\\(f_{best}\\) (or \\(y_{min}\\)) is the best (minimum, for minimization problems) observed function value found so far.\n\\(Z = \\frac{f_{best} - \\mu(x)}{\\sigma(x)}\\) is the standardized improvement.\n\\(\\Phi(Z)\\) is the cumulative distribution function (CDF) of the standard normal distribution.\n\\(\\phi(Z)\\) is the probability density function (PDF) of the standard normal distribution.\n\nIf \\(\\sigma(x) = 0\\) (meaning there is no uncertainty at point \\(x\\), typically because it’s an already sampled point), then \\(EI(x) = 0\\), reflecting the intuition that no further improvement can be expected at a known point. A maximization of Expected Improvement as an infill criterion will eventually lead to the global optimum.\nThe elegance of the EI formula lies in its combination of two distinct terms:\n\nExploitation Term: \\((f_{best} - \\mu(x)) \\Phi(Z)\\). This part of the formula contributes more when the predicted value \\(\\mu(x)\\) is significantly lower (better) than the current best observed value \\(f_{best}\\). It is weighted by the probability \\(\\Phi(Z)\\) that the true function value at \\(x\\) will indeed be an improvement over \\(f_{best}\\).\nExploration Term: \\(\\sigma(x) \\phi(Z)\\). This term becomes larger when there is high uncertainty (\\(\\sigma(x)\\) is large) in the model’s prediction at \\(x\\). It accounts for the potential of discovering unexpectedly good values in areas that have not been thoroughly explored, even if the current mean prediction there is not the absolute best.\n\nExpected Improvement offers several significant practical benefits:\n\nAutomatic Balance: It inherently balances exploitation and exploration without requiring any manual adjustment of weights or parameters.\nScale Invariance: EI is relatively insensitive to the scaling of the objective function, making it robust across various problem types.\nTheoretical Foundation: It is underpinned by a strong theoretical basis derived from decision theory and information theory.\nEfficient Optimization: The smooth and differentiable nature of the EI function allows for efficient optimization using gradient-based algorithms to find the next infill point.\nProven Performance: EI has demonstrated consistent and strong performance in numerous real-world applications across various domains.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#expected-improvement-in-the-hyperparameter-tuning-cookbook-python-implementation",
    "href": "006_infill.html#expected-improvement-in-the-hyperparameter-tuning-cookbook-python-implementation",
    "title": "10  Infill Criteria",
    "section": "10.3 Expected Improvement in the Hyperparameter Tuning Cookbook (Python Implementation)",
    "text": "10.3 Expected Improvement in the Hyperparameter Tuning Cookbook (Python Implementation)\nWithin the context of the Hyperparameter Tuning Cookbook, Expected Improvement serves a critical role in Sequential Model-Based Optimization. It systematically guides the selection of which hyperparameter configurations to evaluate next, facilitating the efficient utilization of computational resources. By intelligently balancing the need to exploit promising regions and explore uncertain areas, EI helps identify optimal hyperparameters with a reduced number of expensive model training runs. This provides a principled and automated method for navigating complex hyperparameter spaces without extensive manual intervention.\nWhile the foundational concepts in Forrester, Sóbester, and Keane (2008) are often illustrated with MATLAB code, the Hyperparameter Tuning Cookbook emphasizes and provides implementations in Python. The spotpython package, consistent with the Cookbook’s approach, provides a Python implementation of Expected Improvement within its Kriging class. For minimization problems, spotpython typically calculates and returns the negative Expected Improvement, aligning with standard optimization algorithm conventions. Furthermore, to enhance numerical stability and mitigate issues when EI values are very small, spotpython often works with a logarithmic transformation of EI and incorporates a small epsilon value.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "006_infill.html#jupyter-notebook",
    "href": "006_infill.html#jupyter-notebook",
    "title": "10  Infill Criteria",
    "section": "10.4 Jupyter Notebook",
    "text": "10.4 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nJones, Donald R., Matthias Schonlau, and William J. Welch. 1998. “Efficient Global Optimization of Expensive Black-Box Functions.” Journal of Global Optimization 13 (4): 455–92.\n\n\nMočkus, J. 1974. “On Bayesian Methods for Seeking the Extremum.” In Optimization Techniques IFIP Technical Conference, 400–404.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Infill Criteria</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html",
    "href": "spot_step_by_step.html",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "",
    "text": "12 Introduction\nThis document provides a comprehensive step-by-step explanation of the optimization process in the SpotOptim class. We’ll use the 2-dimensional Rosenbrock function as our example and cover all methods involved in each stage of optimization.\nTopics Covered:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-initialization-and-setup",
    "href": "spot_step_by_step.html#phase-initialization-and-setup",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.1 Phase: Initialization and Setup",
    "text": "14.1 Phase: Initialization and Setup\nWhen you create a SpotOptim instance, several initialization steps occur during the __init__() method, see DOC.\n\nObjective function (fun) and bounds are stored.\nAcquisition function (acquisition) is stored (default is y).\nDetermine if noise handling is active (based on repeats_initial and repeats_surrogate)\nFor dimensions with tuple bounds (factor variables), internal integer mappings are created and bounds are replaced with (0, n_levels-1). This is handled by _process_factor_bounds(). So, e.g., [('red', 'green', 'blue')] is mapped to the integer interval [(0, 2)] internally.\nThe dimension of the problem (n_dim) is inferred from the bounds.\nIf var_type is not provided, it defaults to all “float” (continuous) variables, except for factor variables which are set to “factor” via _process_factor_bounds().\nDefault variable names (var_name) are set if not provided.\nDefault variable transformations (var_transform) are set if not provided.\nTransformations are applied to bounds based on var_transform settings. Natural bounds are stored in _original_lower and _original_upper.\nDimension reduction by identifying fixed dimensions (if any) is performed via _setup_dimension_reduction().\nThe surrogate is initialized (default: Gaussian Process with Matérn kernel) as follows:\n\nkernel = ConstantKernel(\n    constant_value=1.0, constant_value_bounds=(1e-3, 1e3)\n) * Matern(length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=2.5)\nself.surrogate = GaussianProcessRegressor(\n    kernel=kernel,\n    n_restarts_optimizer=10,\n    normalize_y=True,\n    random_state=self.seed,\n)\n\nThe Design generator is initialized (default: Latin Hypercube Sampling).\nThe storage for results ins initialized. This includes the following attributes:\n\nX_: Evaluated design points\ny_: Corresponding function values\ny_mo: For multi-objective functions, stores all objectives\nbest_x_: Best point found so far\nbest_y_: Best function value found so far\nn_iter_: Number of iterations completed\nmean_X, mean_y, var_y: For noisy functions, mean and variance tracking\nmin_mean_X: Best mean point for noisy functions\nmin_mean_y: Best mean value for noisy functions\nmin_var_y: Variance at best mean point\nmin_X: Best point found (deterministic)\nmin_y: Best function value found (deterministic)\ncounter: Total number of function evaluations\nsuccess_rate: Ratio of successful evaluations\nsuccess_counter: Count of successful evaluations\nwindow_size: For moving average of success rate\nsuccess_history: History of success/failure for evaluations\n\n\n\n# Create optimizer\nopt = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (1, 2)],\n    n_initial=10,\n    max_iter=30,\n    verbose=True,\n    seed=42,\n    var_trans=[\"id\", \"log\"]\n)\n\nTensorBoard logging disabled",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-initial-design-generation",
    "href": "spot_step_by_step.html#phase-initial-design-generation",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.2 Phase: Initial Design Generation",
    "text": "14.2 Phase: Initial Design Generation\n\n14.2.1 Method: get_initial_design()\nThis method generates or processes the initial sample points. It is manually called here for demonstration (normally done inside optimize()).\nWhat happens in get_initial_design():\n\nIf X0=None: Generate space-filling design using Latin Hypercube Sampling (LHS)\nIf x0 (starting point) provided: Include it as first point and transform user’s points to internal scale\nApply dimension reduction if configured\nRound integer/factor variables\n\n\nX0 = opt.get_initial_design(X0=None)\n\nprint(f\"Generated {len(X0)} initial design points using Latin Hypercube Sampling\")\nprint(f\"Design shape: {X0.shape}\")\nprint(f\"\\nFirst 3 points (internal scale):\")\nprint(X0[:3])\n\nGenerated 10 initial design points using Latin Hypercube Sampling\nDesign shape: (10, 2)\n\nFirst 3 points (internal scale):\n[[-1.10958242  0.45478229]\n [ 1.65656083  0.228921  ]\n [-1.63767094  0.55620747]]\n\n\nNote, because bounds were set to [(-2, 2), (-2, 2)] and n_initial=10, the generated points are within this range and the design has two-dimensional shape (10, 2).\n\nPrint initial design in original scale and in internal scale:\n\n\nX0_original = opt._inverse_transform_X(X0)\nprint(f\"\\nFirst 3 points (original scale):\")\nprint(X0_original[:3])\nprint(f\"\\nFirst 3 points (internal scale):\")\nprint(X0[:3])\n\n\nFirst 3 points (original scale):\n[[-1.10958242  1.57583027]\n [ 1.65656083  1.25724272]\n [-1.63767094  1.7440456 ]]\n\nFirst 3 points (internal scale):\n[[-1.10958242  0.45478229]\n [ 1.65656083  0.228921  ]\n [-1.63767094  0.55620747]]\n\n\n\nPlot initial design in original scale:\n\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6, 6))\nplt.scatter(X0_original[:, 0], X0_original[:, 1], c='blue', label='Initial Design Points')\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.title(\"Initial Design Points (Original Scale)\")\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-3-initial-design-curation",
    "href": "spot_step_by_step.html#phase-3-initial-design-curation",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.3 Phase 3: Initial Design Curation",
    "text": "14.3 Phase 3: Initial Design Curation\n\n14.3.1 Method: _curate_initial_design()\nThis method ensures we have sufficient unique points and handles repeats.\nWhat happens in _curate_initial_design():\n\nRemove duplicate points (can occur after rounding integers)\nGenerate additional points if duplicates reduced count below n_initial\nRepeat each point repeats_initial times if &gt; 1 (for noisy functions)\n\n\nX0_curated = opt._curate_initial_design(X0)\nprint(f\"Curated design shape: {X0_curated.shape}\")\nprint(f\"Unique points: {len(np.unique(X0_curated, axis=0))}\")\nprint(f\"Total points (with repeats): {len(X0_curated)}\")\n\nCurated design shape: (10, 2)\nUnique points: 10\nTotal points (with repeats): 10",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-4-initial-design-evaluation",
    "href": "spot_step_by_step.html#phase-4-initial-design-evaluation",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.4 Phase 4: Initial Design Evaluation",
    "text": "14.4 Phase 4: Initial Design Evaluation\n\n14.4.1 Method: _evaluate_function()\nEvaluates the objective function at all initial design points. The points are converted back to the original scale for evaluation.\nWhat happens in _evaluate_function():\n\nConvert points from internal to original scale\nCall objective function with batch of points\nConvert multi-objective to single-objective if needed\nReturn array of function values\n\n\nX0_original = opt._inverse_transform_X(X0_curated)\ny0 = opt._evaluate_function(X0_curated)\n\nprint(f\"Evaluated {len(y0)} points\")\nprint(f\"Function values shape: {y0.shape}\")\nprint(f\"First 5 points with function values:\")\nfor i in range(min(5, len(y0))):\n    print(f\"  Point {i+1}: {X0_original[i]} → f(x)={y0[i]:.6f}\")\nprint(f\"\\nBest initial value: {np.min(y0):.6f}\")\nprint(f\"Worst initial value: {np.max(y0):.6f}\")\nprint(f\"Mean initial value: {np.mean(y0):.6f}\")\n\nEvaluated 10 points\nFunction values shape: (10,)\nFirst 5 points with function values:\n  Point 1: [-1.10958242  1.57583027] → f(x)=16.329192\n  Point 2: [1.65656083 1.25724272] → f(x)=221.533421\n  Point 3: [-1.63767094  1.7440456 ] → f(x)=94.926795\n  Point 4: [1.29554412 1.1658592 ] → f(x)=26.360696\n  Point 5: [-0.05124545  1.93852778] → f(x)=375.876648\n\nBest initial value: 16.329192\nWorst initial value: 375.876648\nMean initial value: 107.571208",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-5-handling-failed-evaluations",
    "href": "spot_step_by_step.html#phase-5-handling-failed-evaluations",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.5 Phase 5: Handling Failed Evaluations",
    "text": "14.5 Phase 5: Handling Failed Evaluations\n\n14.5.1 Method: _handle_NA_initial_design(X0,y0)\nRemoves points that returned NaN or inf values. In contrasts to later phases, no penalties are applied here; invalid points of the initial design are simply removed.\nWhat happens in _handle_NA_initial_design():\n\nIdentify NaN/inf values in function evaluations\nRemove corresponding design points\nReturn cleaned arrays and original count\nNote: No penalties applied in initial design - invalid points simply removed\n\n\nn_before = len(y0)\nX0_clean, y0_clean, n_evaluated = opt._handle_NA_initial_design(X0_curated, y0)\n\nprint(f\"Points before filtering: {n_before}\")\nprint(f\"Points after filtering: {len(y0_clean)}\")\nprint(f\"Removed: {n_before - len(y0_clean)} NaN/inf values\")\nprint(f\"\\nAll remaining values finite: {np.all(np.isfinite(y0_clean))}\")\n\nPoints before filtering: 10\nPoints after filtering: 10\nRemoved: 0 NaN/inf values\n\nAll remaining values finite: True",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-6-validation-check",
    "href": "spot_step_by_step.html#phase-6-validation-check",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.6 Phase 6: Validation Check",
    "text": "14.6 Phase 6: Validation Check\n\n14.6.1 Method: _check_size_initial_design(y0, n_evaluated)\nEnsures we have enough valid points to continue. The minimum required is the smaller of:\n\ntypical minimum for surrogate fitting (3 for multi-dimensional, 2 for 1D), or\nwhat the user requested (n_initial).\n\nWhat happens in _check_size_initial_design():\n\nCheck if at least 1 valid point exists\nRaise error if all initial evaluations failed\nPrint warnings if many points were invalid\n\n\ntry:\n    opt._check_size_initial_design(y0_clean, n_evaluated)\n    print(f\"✓ Validation passed: {len(y0_clean)} valid points available\")\n    print(f\"  Minimum required: 1 point\")\n    print(f\"  Original evaluated: {n_evaluated} points\")\nexcept ValueError as e:\n    print(f\"✗ Validation failed: {e}\")\n\n✓ Validation passed: 10 valid points available\n  Minimum required: 1 point\n  Original evaluated: 10 points",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-7-storage-initialization",
    "href": "spot_step_by_step.html#phase-7-storage-initialization",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.7 Phase 7: Storage Initialization",
    "text": "14.7 Phase 7: Storage Initialization\n\n14.7.1 Method: _init_storage()\nStore evaluated points and initialize tracking variables.\nWhat happens during storage initialization:\n\n_init_storage(): Initialize statistics tracking variables.\n\n\nInitialize storage (as done in optimize())\n\n\n# Initialize storage and statistics using the new _init_storage() method\nopt._init_storage(X0_clean, y0_clean)\n\nprint(f\"X_ (evaluated points): shape {opt.X_.shape}\")\nprint(f\"y_ (function values): shape {opt.y_.shape}\")\nprint(f\"n_iter_ (iterations): {opt.n_iter_}\")\n\nX_ (evaluated points): shape (10, 2)\ny_ (function values): shape (10,)\nn_iter_ (iterations): 0",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-statistics-update",
    "href": "spot_step_by_step.html#phase-statistics-update",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.8 Phase: Statistics Update",
    "text": "14.8 Phase: Statistics Update\n\n14.8.1 Method: update_stats()\nUpdate statistics like means and variances for noisy evaluations.\n*** What happens in update_stats():***\n\nIf noise is set (i.e., repeats_initial &gt; 1):\n\nCompute mean and variance of function values for each unique point\nStore in mean_X, mean_y, and var_y\n\n\n\nprint(f\"\\nStatistics updated:\")\nif opt.noise:\n    print(f\"  - mean_X: {opt.mean_X.shape}\")\n    print(f\"  - mean_y: {opt.mean_y.shape}\")\n    print(f\"  - var_y: {opt.var_y.shape}\")\nelse:\n    print(f\"  - No noise tracking (repeats=1)\")\n\n\nStatistics updated:\n  - No noise tracking (repeats=1)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-log-initial-design-to-tensorboard",
    "href": "spot_step_by_step.html#phase-log-initial-design-to-tensorboard",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.9 Phase: Log initial Design to TensorBoard",
    "text": "14.9 Phase: Log initial Design to TensorBoard\n\n14.9.1 Method: _log_initial_design_tensorboard()\nThis method logs the initial design points and their evaluations to TensorBoard for visualization.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#phase-initial-best-point",
    "href": "spot_step_by_step.html#phase-initial-best-point",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.10 Phase: Initial Best Point",
    "text": "14.10 Phase: Initial Best Point\n\n14.10.1 Method: _get_best_xy_initial_design()\nIdentify and report the best point from initial design.\nWhat happens in _get_best_xy_initial_design():\n\nFind minimum value in y_ (or mean_y if noise)\nStore as best_y_\nStore corresponding point as best_x_\nPrint progress if verbose\n\n\nopt._get_best_xy_initial_design()\n\nprint(f\"Best point found: {opt.best_x_}\")\nprint(f\"Best value found: {opt.best_y_:.6f}\")\nprint(f\"\\nOptimum location: [1, 1]\")\nprint(f\"Optimum value: 0\")\nprint(f\"Current gap: {opt.best_y_ - 0:.6f}\")\n\nInitial best: f(x) = 16.329192\nBest point found: [-1.10958242  1.57583027]\nBest value found: 16.329192\n\nOptimum location: [1, 1]\nOptimum value: 0\nCurrent gap: 16.329192",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#illustration-of-the-initial-design-phase-results",
    "href": "spot_step_by_step.html#illustration-of-the-initial-design-phase-results",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "14.11 Illustration of the Initial Design Phase Results",
    "text": "14.11 Illustration of the Initial Design Phase Results\nTo visualize the results, we generate a contour plot with contour lines of the objective function and mark the best point. The other evaluated points are shown as well:\n\n# Create a grid of points for contour plotting\nx = np.linspace(-2, 2, 400)\ny = np.linspace(-2, 2, 400)\nX, Y = np.meshgrid(x, y)\ngrid_points = np.column_stack([X.ravel(), Y.ravel()])\nZ = rosenbrock(grid_points).reshape(X.shape)\nplt.figure(figsize=(8, 6))\n# Contour plot\ncontour = plt.contour(X, Y, Z, levels=np.logspace(-0.5, 3.5, 20), cmap='viridis')\nplt.clabel(contour, inline=True, fontsize=8)\n\n# Plot evaluated points from the initial design phase:\nplt.scatter(opt.X_[:, 0], opt.X_[:, 1], c='blue', label='Evaluated Points', alpha=0.6)\n# Mark best point\nplt.scatter(opt.best_x_[0], opt.best_x_[1], c='red', s=100, label='Best Point', edgecolors='black')\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.title('Objective Function Contours with Evaluated Points')\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-surrogate-model-fitting",
    "href": "spot_step_by_step.html#step-surrogate-model-fitting",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.1 Step: Surrogate Model Fitting",
    "text": "15.1 Step: Surrogate Model Fitting\n\n15.1.1 Method: _fit_scheduler()\nFit surrogate model using appropriate data based on noise handling.\n*** What happens in _fit_scheduler():***\nFirst, the method transforms the input data X to the internal scale used by the optimizer. Then, it decides which data to use for fitting the surrogate model based on whether noise handling is enabled:\n\nIf noise is set (i.e., repeats_surrogate &gt; 1):\n\nFit surrogate using mean points (mean_X, mean_y)\n\nElse:\n\nFit surrogate using all evaluated points (X_, y_)\n\n\n_fit_scheduler() then calls _fit_surrogate() with the selected data.\n\n\n15.1.2 Method: _fit_surrogate()\nFit a surrogate model (Gaussian Process) to current data.\nWhat happens in _fit_surrogate():\n\nIf max_surrogate_points set and exceeded: Select subset of points using the _selection_dispatcher() method.\nFit surrogate model using surrogate.fit(X, y)\nSurrogate learns the function landscape and uncertainty\n\n\nX_for_surrogate = opt._transform_X(opt.X_)\nopt._fit_surrogate(X_for_surrogate, opt.y_)\n\nprint(f\"Surrogate fitted with {len(opt.y_)} points\")\nprint(f\"Surrogate type: {type(opt.surrogate).__name__}\")\nprint(f\"Kernel: {opt.surrogate.kernel_}\")\n\nSurrogate fitted with 10 points\nSurrogate type: GaussianProcessRegressor\nKernel: 1.06**2 * Matern(length_scale=0.355, nu=2.5)\n\n\n\n\n15.1.3 Method: _selection_dispatcher()\nWhat happens in _selection_dispatcher():\n\nIf max_surrogate_points is set and exceeded:\n\nSelect a subset of points from X_ and y_ for fitting the surrogate model.\nStrategies may include random sampling, clustering, or other heuristics to reduce the dataset size while preserving important information.\n\n\nSurrogate Model Selection:\n\nDefault: Gaussian Process with Matérn kernel\nProvides: Mean prediction \\(\\mu(x)\\) and uncertainty \\(\\sigma(x)\\)\nCan be replaced with Random Forest, Kriging, etc.\nThe fitted surrogate can be plotted with the following code:\n\n\nopt.plot_surrogate()\n\n\n\n\n\n\n\n\n\n\n15.1.4 Step: Apply OCBA\n\n\n15.1.5 Method: _apply_ocba()\nWhat happens in _apply_ocba():\n\nCompute the optimality criteria for each point in the design space.\nSelect the most promising points based on the criteria.\nUpdate the surrogate model with the selected points.\n\n\nX_ocba = opt._apply_ocba()\nif X_ocba is not None:\n    print(f\"OCBA selected {X_ocba.shape[0]} points for re-evaluation\")\n    print(f\"OCBA points shape: {X_ocba.shape}\")\nelse:\n    print(\"OCBA not applied (noise=False or ocba_delta=0)\")\n\nOCBA not applied (noise=False or ocba_delta=0)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-predict-with-uncertainty",
    "href": "spot_step_by_step.html#step-predict-with-uncertainty",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.2 Step: Predict with Uncertainty",
    "text": "15.2 Step: Predict with Uncertainty\n\n15.2.1 Method: _predict_with_uncertainty()\nMake predictions at new locations with uncertainty estimates.\nWhat happens in _predict_with_uncertainty():\n\nCall surrogate.predict(X, return_std=True)\nReturns mean μ(x) and standard deviation σ(x)\nUsed by acquisition function to balance exploitation (low μ) and exploration (high σ)\n\nHere we test prediction at a few points:\n\nX_test = np.array([[0.5, 0.5], [1.0, 1.0], [-0.5, 0.5]])\nmu, sigma = opt._predict_with_uncertainty(X_test)\n\nprint(f\"Test points: {X_test.shape}\")\nprint(f\"\\nPredictions (μ ± σ):\")\nfor i, (x, m, s) in enumerate(zip(X_test, mu, sigma)):\n    print(f\"  x={x} → μ={m:.4f}, σ={s:.4f}\")\n\nTest points: (3, 2)\n\nPredictions (μ ± σ):\n  x=[0.5 0.5] → μ=135.9904, σ=96.1193\n  x=[1. 1.] → μ=97.6979, σ=104.5930\n  x=[-0.5  0.5] → μ=169.1890, σ=64.4389",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-next-point-suggestion",
    "href": "spot_step_by_step.html#step-next-point-suggestion",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.3 Step: Next Point Suggestion",
    "text": "15.3 Step: Next Point Suggestion\n\n15.3.1 Method: _suggest_next_point()\nOptimize acquisition function to find next evaluation point.\nWhat happens in _suggest_next_point():\n\nUse differential_evolution to optimize acquisition function\nFind point that maximizes EI (or minimizes predicted value for ‘y’)\nApply rounding for integer/factor variables\nCheck distance to existing points (avoid duplicates)\nIf duplicate or too close: Use fallback strategy\nReturn suggested point\n\n\nx_next = opt._suggest_next_point()\nprint(f\"Next point suggested: {x_next}\")\n\nNext point suggested: [1.13866324 0.15750508]\n\n\nPredict at suggested point:\n\nmu_next, sigma_next = opt._predict_with_uncertainty(x_next.reshape(1, -1))\nprint(f\"\\nPrediction at suggested point:\")\nprint(f\"  μ(x_next) = {mu_next[0]:.4f}\")\nprint(f\"  σ(x_next) = {sigma_next[0]:.4f}\")\n\n\nPrediction at suggested point:\n  μ(x_next) = 1.3255\n  σ(x_next) = 50.4602\n\n\nFallback Strategies (if acquisition optimization fails):\n\n'best': Re-evaluate current best point\n'mean': Select point with best predicted mean\n'random': Random point in search space",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-acquisition-function-evaluation",
    "href": "spot_step_by_step.html#step-acquisition-function-evaluation",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.4 Step: Acquisition Function Evaluation",
    "text": "15.4 Step: Acquisition Function Evaluation\n\n15.4.1 Method: _acquisition_function()\nCompute acquisition function value to guide search. The acquisition function is used as an objective function by the optimizer on the surrogate, e.g., differential evolution. It determines where to sample next.\n\n# Evaluate acquisition at test points\nprint(f\"Acquisition type: {opt.acquisition} (Expected Improvement)\")\nprint(f\"\\nAcquisition values at test points:\")\n\nfor x in X_test:\n    acq_val = opt._acquisition_function(x)\n    print(f\"  x={x} → acq={acq_val:.6f}\")\n\nAcquisition type: y (Expected Improvement)\n\nAcquisition values at test points:\n  x=[0.5 0.5] → acq=135.990446\n  x=[1. 1.] → acq=97.697886\n  x=[-0.5  0.5] → acq=169.189001\n\n\nAcquisition function can be used to balance:\n\nexploitation, i.e., low predicted mean \\(\\mu(x)\\) and\nexploration, i.e., high uncertainty \\(\\sigma(x)\\)\n\nAcquisition Functions Available:\n\nExpected Improvement (EI) - Default, best balance \\[\n\\text{EI}(x) = (f^* - \\mu(x))\\Phi(Z) + \\sigma(x)\\phi(Z)\n\\] where \\(Z = \\frac{f^* - \\mu(x)}{\\sigma(x)}\\)\nProbability of Improvement (PI) - More exploitative \\[\n\\text{PI}(x) = \\Phi\\left(\\frac{f^* - \\mu(x)}{\\sigma(x)}\\right)\n\\]\nMean (‘y’) - Pure exploitation \\[\n\\text{acq}(x) = \\mu(x)\n\\]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-update-repeats-for-infill-points",
    "href": "spot_step_by_step.html#step-update-repeats-for-infill-points",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.5 Step: Update Repeats for Infill Points",
    "text": "15.5 Step: Update Repeats for Infill Points\n\n15.5.1 Method: _update_repeats_infill_points()\nRepeat the infill point for noisy function evaluation if repeats_surrogate &gt; 1.\nWhat happens in _update_repeats_infill_points():\n\nTakes the suggested next point (x_next)\nIf repeats_surrogate &gt; 1: Creates multiple copies for repeated evaluation\nOtherwise: Returns point as 2D array (shape: 1 × n_features)\nReturns array ready for function evaluation\n\n\nx_next_repeated = opt._update_repeats_infill_points(x_next)\nprint(f\"Shape before repeating: {x_next.shape}\")\nprint(f\"Shape after repeating: {x_next_repeated.shape}\")\nprint(f\"Number of evaluations planned: {x_next_repeated.shape[0]}\")\n\nShape before repeating: (2,)\nShape after repeating: (1, 2)\nNumber of evaluations planned: 1",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#append-ocba-points-to-infill-points",
    "href": "spot_step_by_step.html#append-ocba-points-to-infill-points",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.6 Append OCBA Points to Infill Points",
    "text": "15.6 Append OCBA Points to Infill Points\nCombines OCBA selected points with the next suggested point for evaluation.\n\nif X_ocba is not None:\n    x_next_repeated = np.append(X_ocba, x_next_repeated, axis=0)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-evaluation-of-new-points",
    "href": "spot_step_by_step.html#step-evaluation-of-new-points",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.7 Step: Evaluation of New Points",
    "text": "15.7 Step: Evaluation of New Points\n\n15.7.1 Method: _evaluate_function() (again)\nEvaluate the objective function at the suggested points.\n\nx_next_2d = x_next.reshape(1, -1)\ny_next = opt._evaluate_function(x_next_2d)\n\nprint(f\"Evaluated point: {x_next}\")\nprint(f\"Function value: {y_next[0]:.6f}\")\nprint(f\"Current best: {opt.best_y_:.6f}\")\n\nEvaluated point: [1.13866324 0.15750508]\nFunction value: 1.606003\nCurrent best: 16.329192",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-handle-failed-evaluations-sequential",
    "href": "spot_step_by_step.html#step-handle-failed-evaluations-sequential",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.8 Step: Handle Failed Evaluations (Sequential)",
    "text": "15.8 Step: Handle Failed Evaluations (Sequential)\n\n15.8.1 Method: _handle_NA_new_points()\nHandle NaN/inf values in new evaluations with penalty approach.\nWhat happens in _handle_NA_new_points():\n\nApply penalty to NaN/inf values (unlike initial design)\n\nPenalty = max(history) + 3×std(history) + random noise\n\nRemove remaining invalid values after penalty\nReturn None if all evaluations failed → skip iteration\nContinue if any valid evaluations exist\n\n\nx_clean, y_clean = opt._handle_NA_new_points(x_next_2d, y_next)\n\nif x_clean is not None:\n    print(f\"✓ Valid evaluations: {len(y_clean)}\")\n    print(f\"  All values finite: {np.all(np.isfinite(y_clean))}\")\nelse:\n    print(f\"✗ All evaluations failed - iteration would be skipped\")\n\n✓ Valid evaluations: 1\n  All values finite: True\n\n\nWhy penalties in sequential phase?\n\nPreserves optimization history\nAllows surrogate to learn “bad” regions\nRandom noise prevents identical penalties",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-update-success-rate",
    "href": "spot_step_by_step.html#step-update-success-rate",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.9 Step: Update Success Rate",
    "text": "15.9 Step: Update Success Rate\n\n15.9.1 Method: _update_success_rate(y0)\nUpdate success rate BEFORE updating storage (initial design - all should be successes since starting from scratch)\nWhat happens in _update_success_rate():\n\nCalculate success rate as ratio of valid evaluations to total evaluated\n\n\nopt._update_success_rate(y0_clean)\nprint(f\"\\nSuccess rate updated: {opt.success_rate:.2%} (valid evaluations / total evaluations)\")\n\n\nSuccess rate updated: 0.00% (valid evaluations / total evaluations)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-update-storage",
    "href": "spot_step_by_step.html#step-update-storage",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.10 Step: Update Storage",
    "text": "15.10 Step: Update Storage\n\n15.10.1 Internal updates\nAdd new evaluations to storage.\n\nopt._update_storage(x_next_repeated, y_next)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#update-statistics",
    "href": "spot_step_by_step.html#update-statistics",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.11 Update Statistics",
    "text": "15.11 Update Statistics\nUpdate statistics after new evaluations.\n\n15.11.1 What happens in update_stats():\nAlways updated:\n\nmin_y: Best (minimum) function value\nmin_X: Design point with best value\ncounter: Total number of evaluations\n\nFor noisy functions only (if noise=True):\n\nmean_X: Unique design points\nmean_y: Mean values per design point\nvar_y: Variance per design point\n\n\nopt.update_stats()\nprint(f\"Basic statistics:\")\nprint(f\"  min_y: {opt.min_y:.6f}\")\nprint(f\"  min_X: {opt.min_X}\")\nprint(f\"  counter: {opt.counter}\")\n\nif opt.noise:\n    print(f\"\\nNoise statistics:\")\n    print(f\"  mean_X shape: {opt.mean_X.shape}\")\n    print(f\"  mean_y shape: {opt.mean_y.shape}\")\n    print(f\"  var_y shape: {opt.var_y.shape}\")\nelse:\n    print(f\"\\nNoise handling: disabled (deterministic function)\")\n\nBasic statistics:\n  min_y: 1.606003\n  min_X: [1.13866324 1.1705867 ]\n  counter: 11\n\nNoise handling: disabled (deterministic function)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#step-update-best-solution",
    "href": "spot_step_by_step.html#step-update-best-solution",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "15.12 Step: Update Best Solution",
    "text": "15.12 Step: Update Best Solution\n\n15.12.1 Method: _update_best_main_loop()\nUpdate the best solution if improvement found.\n\nbest_before = opt.best_y_\nopt._update_best_main_loop(x_clean, y_clean)\n\nprint(f\"Best before: {best_before:.6f}\")\nprint(f\"Best after: {opt.best_y_:.6f}\")\n\nif opt.best_y_ &lt; best_before:\n    print(f\"\\n✓ New best found!\")\n    print(f\"  Location: {opt.best_x_}\")\n    print(f\"  Value: {opt.best_y_:.6f}\")\nelse:\n    print(f\"\\n○ Best unchanged\")\n\nIteration 0: New best f(x) = 1.606003\nBest before: 16.329192\nBest after: 1.606003\n\n✓ New best found!\n  Location: [1.13866324 1.1705867 ]\n  Value: 1.606003\n\n\nLoop Termination Conditions:\nThe optimization continues until:\n\nlen(y_) &gt;= max_iter (reached evaluation budget), OR\nelapsed_time &gt;= max_time (reached time limit)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#configuration-for-noisy-functions",
    "href": "spot_step_by_step.html#configuration-for-noisy-functions",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "17.1 Configuration for Noisy Functions",
    "text": "17.1 Configuration for Noisy Functions\n\nNOISE_STD = 10.0\nprint(\"\\n\" + \"=\"*70)\nprint(\"NOISY FUNCTION OPTIMIZATION\")\nprint(\"=\"*70)\nprint(f\"\\nConfiguration for noisy optimization with noise std = {NOISE_STD}:\")\n\n\n# Wrapper to add noise\ndef rosenbrock_noisy_wrapper(X):\n    return rosenbrock_noisy(X, noise_std=NOISE_STD)\n\nopt_noisy = SpotOptim(\n    fun=rosenbrock_noisy_wrapper,\n    bounds=[(-2, 2), (-2, 2)],\n    n_initial=6,\n    max_iter=20,\n    repeats_initial=3,      # Evaluate each initial point 3 times\n    repeats_surrogate=2,    # Evaluate each sequential point 2 times\n    verbose=False,\n    seed=42\n)\n\nprint(\"Configuration for noisy optimization:\")\nprint(f\"  repeats_initial: {opt_noisy.repeats_initial}\")\nprint(f\"  repeats_surrogate: {opt_noisy.repeats_surrogate}\")\nprint(f\"  noise: {opt_noisy.noise}\")\n\n\n======================================================================\nNOISY FUNCTION OPTIMIZATION\n======================================================================\n\nConfiguration for noisy optimization with noise std = 10.0:\nConfiguration for noisy optimization:\n  repeats_initial: 3\n  repeats_surrogate: 2\n  noise: True",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#noisy-optimization-workflow-differences",
    "href": "spot_step_by_step.html#noisy-optimization-workflow-differences",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "17.2 Noisy Optimization Workflow Differences",
    "text": "17.2 Noisy Optimization Workflow Differences\n\n17.2.1 Modified Initial Design\nWith repeats_initial &gt; 1:\n\nresult_noisy = opt_noisy.optimize()\n\nprint(f\"\\nInitial design with repeats:\")\nprint(f\"  n_initial = {opt_noisy.n_initial}\")\nprint(f\"  repeats_initial = {opt_noisy.repeats_initial}\")\nprint(f\"  Total initial evaluations: {opt_noisy.n_initial * opt_noisy.repeats_initial}\")\n\nprint(f\"\\nStatistics tracked:\")\nprint(f\"  mean_X shape: {opt_noisy.mean_X.shape} (unique points)\")\nprint(f\"  mean_y shape: {opt_noisy.mean_y.shape} (mean values)\")\nprint(f\"  var_y shape: {opt_noisy.var_y.shape} (variances)\")\n\nprint(f\"\\nExample statistics for first point:\")\nidx = 0\nprint(f\"  Point: {opt_noisy.mean_X[idx]}\")\nprint(f\"  Mean value: {opt_noisy.mean_y[idx]:.4f}\")\nprint(f\"  Variance: {opt_noisy.var_y[idx]:.4f}\")\nprint(f\"  Std dev: {np.sqrt(opt_noisy.var_y[idx]):.4f}\")\n\n\nInitial design with repeats:\n  n_initial = 6\n  repeats_initial = 3\n  Total initial evaluations: 18\n\nStatistics tracked:\n  mean_X shape: (7, 2) (unique points)\n  mean_y shape: (7,) (mean values)\n  var_y shape: (7,) (variances)\n\nExample statistics for first point:\n  Point: [-1.90573195 -1.79824535]\n  Mean value: 2960.5138\n  Variance: 68.6148\n  Std dev: 8.2834\n\n\nKey Differences with Noise:\n\nRepeated Evaluations: Each point evaluated multiple times\nStatistics Tracking:\n\nmean_X: Unique evaluation locations\nmean_y: Mean function values at each location\nvar_y: Variance of function values\nn_eval: Number of evaluations per location\n\nSurrogate Fitting: Uses mean_y instead of y_\nBest Selection: Based on mean_y not individual y_\n\n\n\n17.2.2 Update Statistics Method\n\nprint(f\"After optimization:\")\nprint(f\"  Total evaluations: {len(opt_noisy.y_)}\")\nprint(f\"  Unique points: {len(opt_noisy.mean_X)}\")\nprint(f\"  Average repeats per point: {len(opt_noisy.y_) / len(opt_noisy.mean_X):.2f}\")\n\nprint(f\"\\nVariance statistics:\")\nprint(f\"  Mean variance: {np.mean(opt_noisy.var_y):.6f}\")\nprint(f\"  Max variance: {np.max(opt_noisy.var_y):.6f}\")\nprint(f\"  Min variance: {np.min(opt_noisy.var_y):.6f}\")\n\nAfter optimization:\n  Total evaluations: 20\n  Unique points: 7\n  Average repeats per point: 2.86\n\nVariance statistics:\n  Mean variance: 43.630970\n  Max variance: 94.990756\n  Min variance: 6.357449",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#ocba-configuration",
    "href": "spot_step_by_step.html#ocba-configuration",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "18.1 OCBA Configuration",
    "text": "18.1 OCBA Configuration\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"OPTIMAL COMPUTING BUDGET ALLOCATION (OCBA)\")\nprint(\"=\"*70)\n\nopt_ocba = SpotOptim(\n    fun=rosenbrock_noisy_wrapper,\n    bounds=[(-2, 2), (-2, 2)],\n    n_initial=8,\n    max_iter=30,\n    repeats_initial=2,\n    repeats_surrogate=1,\n    ocba_delta=3,           # Allocate 3 additional evaluations per iteration\n    verbose=False,\n    seed=42\n)\n\nprint(\"OCBA Configuration:\")\nprint(f\"  ocba_delta: {opt_ocba.ocba_delta}\")\nprint(f\"  Purpose: Intelligently re-evaluate existing points\")\nprint(f\"  Benefit: Better distinguish between similar solutions\")\n\n\n======================================================================\nOPTIMAL COMPUTING BUDGET ALLOCATION (OCBA)\n======================================================================\nOCBA Configuration:\n  ocba_delta: 3\n  Purpose: Intelligently re-evaluate existing points\n  Benefit: Better distinguish between similar solutions",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#ocba-method",
    "href": "spot_step_by_step.html#ocba-method",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "18.2 OCBA Method",
    "text": "18.2 OCBA Method\n\n18.2.1 Method: _apply_ocba()\n\nresult_ocba = opt_ocba.optimize()\n\nprint(f\"\\nOCBA applied during optimization\")\nprint(f\"  Final total evaluations: {result_ocba.nfev}\")\nprint(f\"  Expected without OCBA: ~{opt_ocba.n_initial * opt_ocba.repeats_initial + result_ocba.nit * opt_ocba.repeats_surrogate}\")\nprint(f\"  Additional OCBA evaluations: ~{result_ocba.nit * opt_ocba.ocba_delta}\")\n\nprint(f\"\\nOCBA intelligently allocated extra evaluations to:\")\nprint(f\"  - Current best candidate (confirm it's truly best)\")\nprint(f\"  - Close competitors (distinguish between similar solutions)\")\nprint(f\"  - High-variance points (reduce uncertainty)\")\n\n\nOCBA applied during optimization\n  Final total evaluations: 30\n  Expected without OCBA: ~27\n  Additional OCBA evaluations: ~33\n\nOCBA intelligently allocated extra evaluations to:\n  - Current best candidate (confirm it's truly best)\n  - Close competitors (distinguish between similar solutions)\n  - High-variance points (reduce uncertainty)\n\n\nOCBA Algorithm:\n\nIdentify best solution (lowest mean value)\nCalculate allocation ratios based on:\n\nDistance to best solution\nVariance of each solution\n\nAllocate ocba_delta additional evaluations\nReturns points to re-evaluate\nRequires: ≥3 points with variance &gt; 0\n\nOCBA Activation Conditions: - noise = True (repeats &gt; 1) - ocba_delta &gt; 0 - At least 3 design points exist - All points have variance &gt; 0",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#example-with-failures",
    "href": "spot_step_by_step.html#example-with-failures",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "19.1 Example with Failures",
    "text": "19.1 Example with Failures\n\nopt_failures = SpotOptim(\n    fun=rosenbrock_with_failures,\n    bounds=[(-2, 2), (-2, 2)],\n    n_initial=12,\n    max_iter=35,\n    verbose=False,\n    seed=42\n)\n\nresult_failures = opt_failures.optimize()\n\nprint(f\"\\nOptimization with ~15% random failure rate:\")\nprint(f\"  Function evaluations: {result_failures.nfev}\")\nprint(f\"  Sequential iterations: {result_failures.nit}\")\nprint(f\"  Success: {result_failures.success}\")\n\n# Count how many values are non-finite in raw evaluations\nn_total = len(opt_failures.y_)\nn_finite = np.sum(np.isfinite(opt_failures.y_))\nprint(f\"\\nEvaluation statistics:\")\nprint(f\"  Total evaluations: {n_total}\")\nprint(f\"  Finite values: {n_finite}\")\nprint(f\"  Note: Failed evaluations handled transparently\")\n\n\nOptimization with ~15% random failure rate:\n  Function evaluations: 35\n  Sequential iterations: 27\n  Success: True\n\nEvaluation statistics:\n  Total evaluations: 35\n  Finite values: 35\n  Note: Failed evaluations handled transparently",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#failure-handling-in-initial-design",
    "href": "spot_step_by_step.html#failure-handling-in-initial-design",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "19.2 Failure Handling in Initial Design",
    "text": "19.2 Failure Handling in Initial Design\n\n19.2.1 Method: _handle_NA_initial_design()\n\nprint(\"Initial design failure handling:\")\nprint(\"  1. Identify NaN/inf values\")\nprint(\"  2. Remove invalid points entirely\")\nprint(\"  3. Continue with valid points only\")\nprint(\"  4. No penalties applied\")\nprint(\"  5. Require at least 1 valid point\")\n\nprint(\"\\nRationale:\")\nprint(\"  - Initial design should be clean\")\nprint(\"  - Invalid regions identified naturally\")\nprint(\"  - Surrogate trained on good data only\")\n\nInitial design failure handling:\n  1. Identify NaN/inf values\n  2. Remove invalid points entirely\n  3. Continue with valid points only\n  4. No penalties applied\n  5. Require at least 1 valid point\n\nRationale:\n  - Initial design should be clean\n  - Invalid regions identified naturally\n  - Surrogate trained on good data only",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#failure-handling-in-sequential-phase",
    "href": "spot_step_by_step.html#failure-handling-in-sequential-phase",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "19.3 Failure Handling in Sequential Phase",
    "text": "19.3 Failure Handling in Sequential Phase\n\n19.3.1 Method: _handle_NA_new_points()\n\nprint(\"Sequential phase failure handling:\")\nprint(\"  1. Apply penalty to NaN/inf values\")\nprint(\"     - Penalty = max(history) + 3×std(history)\")\nprint(\"     - Add random noise to avoid duplicates\")\nprint(\"  2. Remove remaining invalid values\")\nprint(\"  3. Skip iteration if all evaluations failed\")\nprint(\"  4. Continue if any valid evaluations\")\n\nprint(\"\\nPenalty approach benefits:\")\nprint(\"  ✓ Preserves optimization history\")\nprint(\"  ✓ Surrogate learns to avoid bad regions\")\nprint(\"  ✓ Better exploration-exploitation balance\")\nprint(\"  ✓ More robust convergence\")\n\nSequential phase failure handling:\n  1. Apply penalty to NaN/inf values\n     - Penalty = max(history) + 3×std(history)\n     - Add random noise to avoid duplicates\n  2. Remove remaining invalid values\n  3. Skip iteration if all evaluations failed\n  4. Continue if any valid evaluations\n\nPenalty approach benefits:\n  ✓ Preserves optimization history\n  ✓ Surrogate learns to avoid bad regions\n  ✓ Better exploration-exploitation balance\n  ✓ More robust convergence",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#penalty-application",
    "href": "spot_step_by_step.html#penalty-application",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "19.4 Penalty Application",
    "text": "19.4 Penalty Application\n\n19.4.1 Method: _apply_penalty_NA()\nLet’s demonstrate penalty calculation:\n\n# Simulate historical values\ny_history_sim = np.array([10.0, 15.0, 8.0, 12.0, 20.0, 9.0])\ny_new_sim = np.array([7.0, np.nan, 11.0, np.inf])\n\nprint(\"Historical values:\", y_history_sim)\nprint(\"New evaluations:\", y_new_sim)\n\n# Apply penalty\ny_repaired = opt_failures._apply_penalty_NA(\n    y_new_sim, \n    y_history=y_history_sim,\n    penalty_value=None,  # Compute adaptively\n    sd=0.1\n)\n\nprint(f\"\\nAfter penalty application:\", y_repaired)\nprint(f\"All finite: {np.all(np.isfinite(y_repaired))}\")\n\n# Show penalty calculation\nmax_hist = np.max(y_history_sim)\nstd_hist = np.std(y_history_sim, ddof=1)\npenalty_base = max_hist + 3 * std_hist\n\nprint(f\"\\nPenalty calculation:\")\nprint(f\"  max(history) = {max_hist:.2f}\")\nprint(f\"  std(history) = {std_hist:.2f}\")\nprint(f\"  Base penalty = {max_hist:.2f} + 3×{std_hist:.2f} = {penalty_base:.2f}\")\nprint(f\"  Actual penalty = {penalty_base:.2f} + noise\")\n\nHistorical values: [10. 15.  8. 12. 20.  9.]\nNew evaluations: [ 7. nan 11. inf]\n\nAfter penalty application: [ 7.         33.62137308 11.         33.5370057 ]\nAll finite: True\n\nPenalty calculation:\n  max(history) = 20.00\n  std(history) = 4.50\n  Base penalty = 20.00 + 3×4.50 = 33.51\n  Actual penalty = 33.51 + noise",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#methods-called-during-optimize",
    "href": "spot_step_by_step.html#methods-called-during-optimize",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "20.1 Methods Called During optimize()",
    "text": "20.1 Methods Called During optimize()\n\n20.1.1 Preparation Phase\n\nget_initial_design() - Generate/process initial sample points\n_curate_initial_design() - Remove duplicates, handle repeats\n_evaluate_function() - Evaluate objective function\n_handle_NA_initial_design() - Remove NaN/inf from initial design\n_check_size_initial_design() - Validate sufficient points\n_init_storage() - Initialize storage (X_, y_, n_iter_)\nupdate_stats() - Compute mean/variance for noisy functions\n_init_tensorboard() - Log initial design to TensorBoard (if enabled)\n_get_best_xy_initial_design() - Identify initial best\n\n\n\n20.1.2 Sequential Optimization Loop (each iteration)\n\n_fit_scheduler() - Select data and fit surrogate based on noise handling\n\nInternally calls _transform_X() - Transform to internal scale\nInternally calls _fit_surrogate() - Fit Gaussian Process to data\n\n_apply_ocba() - OCBA allocation (if enabled)\n_suggest_next_point() - Optimize acquisition function\n\nInternally calls _acquisition_function()\nInternally calls _predict_with_uncertainty()\n\n_update_repeats_infill_points() - Repeat suggested point for noisy functions\n_evaluate_function() - Evaluate at suggested point(s)\n_handle_NA_new_points() - Handle failures with penalties\n\nInternally calls _apply_penalty_NA()\nInternally calls _remove_nan()\n\n_update_success_rate() - Update success tracking\n_update_storage() - Append new evaluations to storage\n\nInternally calls _inverse_transform_X() - Convert back to original scale\n\nupdate_stats() - Update mean/variance statistics\n_write_tensorboard_hparams() - Log hyperparameters (if enabled)\n_write_tensorboard_scalars() - Log scalar metrics (if enabled)\n_update_best_main_loop() - Update best solution\n\n\n\n20.1.3 Finalization\n\nto_all_dim() - Expand to full dimensions (if dimensionality reduction used)\n_determine_termination() - Determine termination reason\n_close_tensorboard_writer() - Close logging (if enabled)\n_map_to_factor_values() - Convert factors back to strings\nReturn OptimizeResult object",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#helper-methods-used",
    "href": "spot_step_by_step.html#helper-methods-used",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "20.2 Helper Methods Used",
    "text": "20.2 Helper Methods Used\n\n_generate_initial_design() - LHS generation\n_repair_non_numeric() - Round integer/factor variables\n_select_new() - Check for duplicate points\n_handle_acquisition_failure() - Fallback strategies\nto_red_dim() - Dimension reduction (if enabled)\n_selection_dispatcher() - Subset selection for large datasets",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#method-_determine_termination",
    "href": "spot_step_by_step.html#method-_determine_termination",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "21.1 Method: _determine_termination()",
    "text": "21.1 Method: _determine_termination()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TERMINATION CONDITIONS\")\nprint(\"=\"*70)\nprint(\"\\nMethod: _determine_termination()\")\nprint(\"-\" * 70)\n\nprint(\"Optimization terminates when:\")\nprint(\"  1. len(y_) &gt;= max_iter (evaluation budget exhausted)\")\nprint(\"  2. elapsed_time &gt;= max_time (time limit reached)\")\nprint(\"  3. Whichever comes first\")\n\nprint(f\"\\nExample from previous run:\")\nprint(f\"  Message: {result_failures.message}\")\nprint(f\"  Evaluations: {result_failures.nfev}/{opt_failures.max_iter}\")\nprint(f\"  Iterations: {result_failures.nit}\")\n\n\n======================================================================\nTERMINATION CONDITIONS\n======================================================================\n\nMethod: _determine_termination()\n----------------------------------------------------------------------\nOptimization terminates when:\n  1. len(y_) &gt;= max_iter (evaluation budget exhausted)\n  2. elapsed_time &gt;= max_time (time limit reached)\n  3. Whichever comes first\n\nExample from previous run:\n  Message: Optimization terminated: maximum evaluations (35) reached\n  Evaluations: 35/35\n  Iterations: 27",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#complete-workflow-diagram",
    "href": "spot_step_by_step.html#complete-workflow-diagram",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "23.1 Complete Workflow Diagram",
    "text": "23.1 Complete Workflow Diagram\n┌─────────────────────────────────────────────────────────────────┐\n│                     SPOTOPTIM WORKFLOW                          │\n└─────────────────────────────────────────────────────────────────┘\n\nINITIALIZATION PHASE\n  │\n  ├─► get_initial_design()\n  │     └─► Generate LHS or process user design\n  │\n  ├─► _curate_initial_design()\n  │     └─► Remove duplicates, add repeats\n  │\n  ├─► _evaluate_function()\n  │     └─► Evaluate objective function\n  │\n  ├─► _handle_NA_initial_design()\n  │     └─► Remove NaN/inf points\n  │\n  ├─► _check_size_initial_design()\n  │     └─► Validate sufficient points\n  │\n  ├─► _init_storage()\n  │     └─► Initialize X_, y_, n_iter_\n  │\n  ├─► update_stats()\n  │     └─► Compute mean/variance (if noise)\n  │\n  ├─► _init_tensorboard() [if enabled]\n  │     └─► Log initial design to TensorBoard\n  │\n  └─► _get_best_xy_initial_design()\n        └─► Identify initial best\n\n\nSEQUENTIAL OPTIMIZATION LOOP (until max_iter or max_time)\n  │\n  ├─► _fit_scheduler()\n  │     ├─► _transform_X() - Transform to internal scale\n  │     └─► _fit_surrogate() - Fit GP to current data\n  │\n  ├─► _apply_ocba() [if enabled]\n  │     └─► Allocate additional evaluations\n  │\n  ├─► _suggest_next_point()\n  │     ├─► _acquisition_function()\n  │     │     └─► _predict_with_uncertainty()\n  │     └─► Optimize to find next point\n  │\n  ├─► _update_repeats_infill_points()\n  │     └─► Repeat point if repeats_surrogate &gt; 1\n  │\n  ├─► _evaluate_function()\n  │     └─► Evaluate at suggested point(s)\n  │\n  ├─► _handle_NA_new_points()\n  │     ├─► _apply_penalty_NA()\n  │     └─► _remove_nan()\n  │\n  ├─► _update_success_rate()\n  │     └─► Track evaluation success\n  │\n  ├─► _update_storage()\n  │     └─► Append new evaluations (with scale conversion)\n  │\n  ├─► update_stats()\n  │     └─► Update mean/variance\n  │\n  ├─► _write_tensorboard_hparams() [if enabled]\n  │     └─► Log hyperparameters\n  │\n  ├─► _write_tensorboard_scalars() [if enabled]\n  │     └─► Log scalar metrics\n  │\n  └─► _update_best_main_loop()\n        └─► Update best if improved\n\n\nFINALIZATION\n  │\n  ├─► to_all_dim() [if dimensionality reduction used]\n  │     └─► Expand to full dimensions\n  │\n  ├─► _determine_termination()\n  │     └─► Set termination message\n  │\n  ├─► _close_tensorboard_writer() [if enabled]\n  │     └─► Close TensorBoard logging\n  │\n  ├─► _map_to_factor_values() [if factors used]\n  │     └─► Convert factors back to strings\n  │\n  └─► Return OptimizeResult",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#key-concepts",
    "href": "spot_step_by_step.html#key-concepts",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "23.2 Key Concepts",
    "text": "23.2 Key Concepts\n\n23.2.1 1. Initial Design\n\nLatin Hypercube Sampling: Space-filling design for efficient exploration\nCuration: Remove duplicates from integer/factor rounding\nFailure Handling: Remove invalid points, no penalties\n\n\n\n23.2.2 2. Surrogate Model\n\nDefault: Gaussian Process with Matérn kernel\nProvides: Mean μ(x) and uncertainty σ(x) predictions\nPurpose: Learn function landscape with limited evaluations\n\n\n\n23.2.3 3. Acquisition Function\n\nEI: Expected Improvement (default) - best balance\nPI: Probability of Improvement - more exploitative\nMean: Pure exploitation of surrogate predictions\n\n\n\n23.2.4 4. Noise Handling\n\nRepeats: Evaluate each point multiple times\nStatistics: Track mean and variance\nOCBA: Intelligently allocate additional evaluations\n\n\n\n23.2.5 5. Failure Handling\n\nInitial Phase: Remove invalid points\nSequential Phase: Apply adaptive penalties with noise\nRobustness: Continue optimization despite failures",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#best-practices",
    "href": "spot_step_by_step.html#best-practices",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "23.3 Best Practices",
    "text": "23.3 Best Practices\n\nFor deterministic functions:\n\nUse default settings (no repeats)\nAcquisition = ‘ei’\nFocus on n_initial and max_iter\n\nFor noisy functions:\n\nSet repeats_initial ≥ 2\nSet repeats_surrogate ≥ 1\nConsider OCBA with ocba_delta ≥ 2\n\nFor unreliable functions:\n\nSpotOptim handles failures automatically\nNo special configuration needed\nPenalties guide search away from bad regions\n\nFor expensive functions:\n\nIncrease n_initial (better initial model)\nUse ‘ei’ acquisition (best sample efficiency)\nConsider max_time limit",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spot_step_by_step.html#conclusion",
    "href": "spot_step_by_step.html#conclusion",
    "title": "11  SpotOptim Step-by-Step Optimization Process",
    "section": "23.4 Conclusion",
    "text": "23.4 Conclusion\nSpotOptim provides a robust and flexible framework for surrogate-based optimization with:\n✓ Efficient space-filling initial designs (LHS)\n✓ Powerful Gaussian Process surrogate models\n✓ Smart acquisition functions (EI, PI, Mean)\n✓ Automatic noise handling with statistics\n✓ Intelligent budget allocation (OCBA)\n✓ Robust failure handling\n✓ Comprehensive progress tracking\nThe modular design allows easy customization while maintaining robust defaults for most use cases.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>SpotOptim Step-by-Step Optimization Process</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html",
    "href": "spotoptim_examples.html",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "",
    "text": "12.1 Setup: Import Required Packages\nFirst, we import all necessary packages for the examples.\n# Core imports\nimport numpy as np\nimport time\nfrom scipy.optimize import OptimizeResult\n\n# SpotOptim\nfrom spotoptim import SpotOptim\n\n# Surrogate models\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\nprint(\"All packages imported successfully!\")\n\nAll packages imported successfully!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#main-optimization-method-optimize",
    "href": "spotoptim_examples.html#main-optimization-method-optimize",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.2 1. Main Optimization Method: optimize()",
    "text": "12.2 1. Main Optimization Method: optimize()\nThe optimize() method is the main entry point for running the optimization process. It coordinates all other methods in the optimization workflow:\n\nInitial Design Phase: get_initial_design(), _curate_initial_design(), _handle_NA_initial_design(), _check_size_initial_design(), _get_best_xy_initial_design()\nMain Loop: Surrogate fitting, OCBA application, point suggestion, evaluation\nTermination: _determine_termination()\n\nLet’s see a complete optimization example:\n\n# Define a simple quadratic function\ndef sphere(X):\n    \"\"\"Sphere function: f(x) = sum(x^2)\"\"\"\n    X = np.atleast_2d(X)\n    return np.sum(X**2, axis=1)\n\n# Create optimizer\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=5,\n    max_iter=20,\n    verbose=True\n)\n\n# Run optimization\nresult = opt.optimize()\n\nprint(f\"\\nBest point found: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Total evaluations: {result.nfev}\")\nprint(f\"Sequential iterations: {result.nit}\")\nprint(f\"Success: {result.success}\")\nprint(f\"Message: {result.message}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 0.444258\nIteration 1: New best f(x) = 0.424920\nIteration 2: New best f(x) = 0.348812\nIteration 3: New best f(x) = 0.142160\nIteration 4: New best f(x) = 0.013049\nIteration 5: New best f(x) = 0.007577\nIteration 6: New best f(x) = 0.000103\nIteration 7: New best f(x) = 0.000020\nIteration 8: New best f(x) = 0.000015\nIteration 9: New best f(x) = 0.000013\nIteration 10: New best f(x) = 0.000010\nIteration 11: New best f(x) = 0.000009\nIteration 12: New best f(x) = 0.000009\nIteration 13: New best f(x) = 0.000009\nIteration 14: New best f(x) = 0.000009\nIteration 15: New best f(x) = 0.000007\n\nBest point found: [ 0.00197758 -0.00180523]\nBest value: 0.000007\nTotal evaluations: 20\nSequential iterations: 15\nSuccess: True\nMessage: Optimization terminated: maximum evaluations (20) reached",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#initial-design-methods",
    "href": "spotoptim_examples.html#initial-design-methods",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.3 2. Initial Design Methods",
    "text": "12.3 2. Initial Design Methods\nThese methods handle the creation and validation of the initial design of experiments.\n\n12.3.1 2.1 get_initial_design()\nPurpose: Generate or process initial design points\nUsed by: optimize() method at the start\nCalls: _generate_initial_design() if X0 is None\nThis method handles three scenarios: 1. Generate LHS design when X0=None 2. Include starting point x0 if provided 3. Transform user-provided X0\n\n# Example 1: Generate default LHS design\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=10,\n    seed=42\n)\nX0 = opt.get_initial_design()\nprint(f\"Generated LHS design shape: {X0.shape}\")\nprint(f\"First 3 points:\\n{X0[:3]}\")\n\n# Example 2: With starting point x0\nopt_x0 = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=10,\n    x0=[0.0, 0.0],\n    seed=42\n)\nX0_with_x0 = opt_x0.get_initial_design()\nprint(f\"\\nDesign with x0, first point: {X0_with_x0[0]}\")\n\n# Example 3: Provide custom initial design\nX0_custom = np.array([[0, 0], [1, 1], [2, 2]])\nX0_processed = opt.get_initial_design(X0_custom)\nprint(f\"\\nCustom design shape: {X0_processed.shape}\")\n\nGenerated LHS design shape: (10, 2)\nFirst 3 points:\n[[-2.77395605  1.56112156]\n [ 4.14140208 -1.69736803]\n [-4.09417735  3.02437765]]\n\nDesign with x0, first point: [0. 0.]\n\nCustom design shape: (3, 2)\n\n\n\n\n12.3.2 2.2 _curate_initial_design()\nPurpose: Remove duplicates and ensure sufficient unique points\nUsed by: optimize() after get_initial_design()\nHandles: Duplicate removal, point generation, repetition for noisy functions\n\n# Example 1: Remove duplicates\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=10,\n    seed=42\n)\nX0_with_dups = np.array([[1, 2], [1, 2], [3, 4], [3, 4], [5, 6]])\nX0_curated = opt._curate_initial_design(X0_with_dups)\nprint(f\"Original points: {len(X0_with_dups)}\")\nprint(f\"After removing duplicates: {len(X0_curated)}\")\n\n# Example 2: With repeats for noisy functions\nopt_repeat = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=5,\n    repeats_initial=3,  # Repeat each point 3 times\n    seed=42\n)\nX0 = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\nX0_repeated = opt_repeat._curate_initial_design(X0)\nprint(f\"\\nOriginal points: {len(X0)}\")\nprint(f\"After repeating (3x): {len(X0_repeated)}\")\n\nOriginal points: 5\nAfter removing duplicates: 10\n\nOriginal points: 5\nAfter repeating (3x): 15\n\n\n\n\n12.3.3 2.3 _handle_NA_initial_design()\nPurpose: Remove NaN/inf values from initial design evaluations\nUsed by: optimize() after evaluating initial design\nReturns: Cleaned arrays and original count\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=10,\n    seed=42\n)\n\n# Simulate initial design with some NaN values\nX0 = np.array([[1, 2], [3, 4], [5, 6]])\ny0 = np.array([5.0, np.nan, np.inf])\n\nX0_clean, y0_clean, n_eval = opt._handle_NA_initial_design(X0, y0)\n\nprint(f\"Original evaluations: {n_eval}\")\nprint(f\"Valid points remaining: {X0_clean.shape[0]}\")\nprint(f\"Clean X0:\\n{X0_clean}\")\nprint(f\"Clean y0: {y0_clean}\")\n\nOriginal evaluations: 3\nValid points remaining: 1\nClean X0:\n[[1 2]]\nClean y0: [5.]\n\n\n\n\n12.3.4 2.4 _check_size_initial_design()\nPurpose: Validate sufficient points for surrogate fitting\nUsed by: optimize() after handling NaN values\nRaises: ValueError if insufficient points\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=10,\n    seed=42\n)\n\n# Example 1: Sufficient points - no error\ny0_sufficient = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\ntry:\n    opt._check_size_initial_design(y0_sufficient, n_evaluated=10)\n    print(\"✓ Sufficient points - validation passed\")\nexcept ValueError as e:\n    print(f\"✗ Error: {e}\")\n\n# Example 2: Insufficient points - raises error\ny0_insufficient = np.array([1.0])  # Only 1 point, need at least 3 for 2D\ntry:\n    opt._check_size_initial_design(y0_insufficient, n_evaluated=10)\n    print(\"✓ Validation passed\")\nexcept ValueError as e:\n    print(f\"✗ Expected error: {e}\")\n\n✓ Sufficient points - validation passed\n✗ Expected error: Insufficient valid initial design points: only 1 finite value(s) out of 10 evaluated. Need at least 3 points to fit surrogate model. Please check your objective function or increase n_initial.\n\n\n\n\n12.3.5 2.5 _get_best_xy_initial_design()\nPurpose: Determine and store the best point from initial design\nUsed by: optimize() after initial design evaluation\nUpdates: self.best_x_ and self.best_y_ attributes\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=5,\n    verbose=True,\n    seed=42\n)\n\n# Simulate initial design (normally done in optimize())\nopt.X_ = np.array([[1, 2], [0, 0], [2, 1]])\nopt.y_ = np.array([5.0, 0.0, 5.0])\n\nopt._get_best_xy_initial_design()\n\nprint(f\"\\nBest x from initial design: {opt.best_x_}\")\nprint(f\"Best y from initial design: {opt.best_y_}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 0.000000\n\nBest x from initial design: [0 0]\nBest y from initial design: 0.0",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#surrogate-model-methods",
    "href": "spotoptim_examples.html#surrogate-model-methods",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.4 3. Surrogate Model Methods",
    "text": "12.4 3. Surrogate Model Methods\nThese methods handle surrogate model operations during the optimization loop.\n\n12.4.1 3.1 _fit_surrogate()\nPurpose: Fit surrogate model to data\nUsed by: optimize() in main loop\nCalls: _selection_dispatcher() if max_surrogate_points exceeded\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_surrogate_points=10,\n    seed=42\n)\n\n# Generate some training data\nX = np.random.rand(50, 2) * 10 - 5  # 50 points in [-5, 5]\ny = np.sum(X**2, axis=1)\n\n# Fit surrogate (will select 10 best points)\nopt._fit_surrogate(X, y)\n\nprint(f\"Surrogate fitted successfully!\")\nprint(f\"Surrogate model: {type(opt.surrogate).__name__}\")\n\nSurrogate fitted successfully!\nSurrogate model: GaussianProcessRegressor\n\n\n\n\n12.4.2 3.2 _predict_with_uncertainty()\nPurpose: Predict with uncertainty estimates, handling surrogates without return_std\nUsed by: _acquisition_function() and plot_surrogate()\nReturns: Predictions and standard deviations\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=GaussianProcessRegressor(),\n    seed=42\n)\n\n# Train surrogate\nX_train = np.array([[0, 0], [1, 1], [2, 2]])\ny_train = np.array([0, 2, 8])\nopt._fit_surrogate(X_train, y_train)\n\n# Predict on new points\nX_test = np.array([[1.5, 1.5], [3.0, 3.0]])\npreds, stds = opt._predict_with_uncertainty(X_test)\n\nprint(f\"Test points:\\n{X_test}\")\nprint(f\"Predictions: {preds}\")\nprint(f\"Uncertainties: {stds}\")\n\nTest points:\n[[1.5 1.5]\n [3.  3. ]]\nPredictions: [5.66013019 3.0829763 ]\nUncertainties: [0.31263595 0.92017596]\n\n\n\n\n12.4.3 3.3 _acquisition_function()\nPurpose: Compute acquisition function value\nUsed by: _suggest_next_point() for optimization\nCalls: _predict_with_uncertainty()\nSupports: Expected Improvement (EI), Probability of Improvement (PI), Mean prediction\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=GaussianProcessRegressor(),\n    acquisition='ei',\n    seed=42\n)\n\n# Setup\nX_train = np.array([[0, 0], [1, 1], [2, 2]])\ny_train = np.array([0, 2, 8])\nopt._fit_surrogate(X_train, y_train)\nopt.y_ = y_train  # Needed for acquisition function\n\n# Evaluate acquisition function\nx_eval = np.array([1.5, 1.5])\nacq_value = opt._acquisition_function(x_eval)\n\nprint(f\"Point to evaluate: {x_eval}\")\nprint(f\"Acquisition function value (EI): {acq_value:.6f}\")\nprint(f\"(Lower is better for minimization)\")\n\nPoint to evaluate: [1.5 1.5]\nAcquisition function value (EI): -0.000000\n(Lower is better for minimization)\n\n\n\n\n12.4.4 3.4 _suggest_next_point()\nPurpose: Suggest next point to evaluate using acquisition function optimization\nUsed by: optimize() in main loop\nCalls: _acquisition_function(), _handle_acquisition_failure() if needed\nHandles: Integer/factor rounding, duplicate avoidance\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=GaussianProcessRegressor(),\n    acquisition='ei',\n    seed=42\n)\n\n# Setup\nX_train = np.array([[0, 0], [1, 1], [2, 2]])\ny_train = np.array([0, 2, 8])\nopt._fit_surrogate(X_train, y_train)\nopt.X_ = X_train\nopt.y_ = y_train\n\n# Suggest next point\nx_next = opt._suggest_next_point()\n\nprint(f\"Next point to evaluate: {x_next}\")\nprint(f\"Expected to be between known points or in unexplored regions\")\n\nNext point to evaluate: [-1.6288683   1.99062025]\nExpected to be between known points or in unexplored regions",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#ocba-method-optimal-computing-budget-allocation",
    "href": "spotoptim_examples.html#ocba-method-optimal-computing-budget-allocation",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.5 4. OCBA Method (Optimal Computing Budget Allocation)",
    "text": "12.5 4. OCBA Method (Optimal Computing Budget Allocation)\n\n12.5.1 4.1 _apply_ocba()\nPurpose: Apply OCBA for noisy functions to determine which points to re-evaluate\nUsed by: optimize() in main loop when noise=True and ocba_delta &gt; 0\nReturns: Points to re-evaluate or None\n\n# Example with OCBA enabled\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    repeats_initial=2,  # Enable noise handling\n    ocba_delta=5,\n    verbose=True,\n    seed=42\n)\n\n# Simulate optimization state\nopt.mean_X = np.array([[1, 2], [0, 0], [2, 1], [1, 1]])\nopt.mean_y = np.array([5.0, 0.1, 5.0, 2.0])\nopt.var_y = np.array([0.1, 0.05, 0.15, 0.08])\n\nX_ocba = opt._apply_ocba()\n\nif X_ocba is not None:\n    print(f\"\\nOCBA returned {X_ocba.shape[0]} points for re-evaluation\")\nelse:\n    print(\"\\nOCBA: No re-evaluation needed\")\n\nTensorBoard logging disabled\n  OCBA: Adding 5 re-evaluation(s)\n\nOCBA returned 5 points for re-evaluation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#naninf-handling-methods",
    "href": "spotoptim_examples.html#naninf-handling-methods",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.6 5. NaN/Inf Handling Methods",
    "text": "12.6 5. NaN/Inf Handling Methods\n\n12.6.1 5.1 _apply_penalty_NA()\nPurpose: Replace NaN and infinite values with penalty plus random noise\nUsed by: _handle_NA_new_points() and indirectly by optimize()\nAlgorithm: penalty = max(finite_y) + 3 * std(finite_y) + noise\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5)],\n    seed=42\n)\n\n# Historical values (used for penalty computation)\ny_hist = np.array([1.0, 2.0, 3.0, 5.0])\n\n# New evaluations with NaN/inf\ny_new = np.array([4.0, np.nan, np.inf])\n\ny_clean = opt._apply_penalty_NA(y_new, y_history=y_hist)\n\nprint(f\"Original: {y_new}\")\nprint(f\"After penalty: {y_clean}\")\nprint(f\"All finite: {np.all(np.isfinite(y_clean))}\")\nprint(f\"Penalty values &gt; max(hist): {y_clean[1] &gt; np.max(y_hist)}\")\n\nOriginal: [ 4. nan inf]\nAfter penalty: [ 4.         10.13557703  9.97718229]\nAll finite: True\nPenalty values &gt; max(hist): True\n\n\n\n\n12.6.2 5.2 _remove_nan()\nPurpose: Remove rows where y contains NaN or inf values\nUsed by: optimize() after function evaluations\nReturns: Cleaned arrays\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5)],\n    seed=42\n)\n\nX = np.array([[1, 2], [3, 4], [5, 6]])\ny = np.array([1.0, np.nan, np.inf])\n\nX_clean, y_clean = opt._remove_nan(X, y, stop_on_zero_return=False)\n\nprint(f\"Original X shape: {X.shape}\")\nprint(f\"Clean X shape: {X_clean.shape}\")\nprint(f\"Clean X:\\n{X_clean}\")\nprint(f\"Clean y: {y_clean}\")\n\nOriginal X shape: (3, 2)\nClean X shape: (1, 2)\nClean X:\n[[1 2]]\nClean y: [1.]\n\n\n\n\n12.6.3 5.3 _handle_NA_new_points()\nPurpose: Handle NaN/inf values in new evaluation points during main loop\nUsed by: optimize() after evaluating new points\nCalls: _apply_penalty_NA() and _remove_nan()\nReturns: None, None if all evaluations invalid (skip iteration)\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=5,\n    verbose=True,\n    seed=42\n)\n\n# Simulate optimization state\nopt.y_ = np.array([1.0, 2.0, 3.0])  # Historical values\nopt.n_iter_ = 1\n\n# Case 1: Some valid values\nprint(\"Case 1: Some valid evaluations\")\nx_next = np.array([[1, 2], [3, 4], [5, 6]])\ny_next = np.array([5.0, np.nan, 10.0])\nx_clean, y_clean = opt._handle_NA_new_points(x_next, y_next)\nprint(f\"Valid points remaining: {x_clean.shape[0] if x_clean is not None else 0}\")\n\n# Case 2: All invalid - should return None\nprint(\"\\nCase 2: All invalid evaluations\")\nx_all_bad = np.array([[1, 2], [3, 4]])\ny_all_bad = np.array([np.nan, np.inf])\nx_clean, y_clean = opt._handle_NA_new_points(x_all_bad, y_all_bad)\nprint(f\"Result: {'None (skip iteration)' if x_clean is None else 'Valid points'}\")\n\nTensorBoard logging disabled\nCase 1: Some valid evaluations\nWarning: Found 1 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 6.0000)\nValid points remaining: 3\n\nCase 2: All invalid evaluations\nWarning: Found 2 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 6.0000)\nResult: Valid points",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#main-loop-update-methods",
    "href": "spotoptim_examples.html#main-loop-update-methods",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.7 6. Main Loop Update Methods",
    "text": "12.7 6. Main Loop Update Methods\n\n12.7.1 6.1 _update_best_main_loop()\nPurpose: Update best solution found during main optimization loop\nUsed by: optimize() after each iteration\nUpdates: self.best_x_ and self.best_y_ if improvement found\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    n_initial=5,\n    verbose=True,\n    seed=42\n)\n\n# Simulate optimization state\nopt.n_iter_ = 1\nopt.best_x_ = np.array([1.0, 1.0])\nopt.best_y_ = 2.0\n\n# Case 1: New best found\nprint(\"Case 1: New best found\")\nx_new = np.array([[0.1, 0.1], [0.5, 0.5]])\ny_new = np.array([0.02, 0.5])\nopt._update_best_main_loop(x_new, y_new)\nprint(f\"Updated best_y: {opt.best_y_}\\n\")\n\n# Case 2: No improvement\nprint(\"Case 2: No improvement\")\nopt.n_iter_ = 2\nx_no_improve = np.array([[1.5, 1.5]])\ny_no_improve = np.array([4.5])\nopt._update_best_main_loop(x_no_improve, y_no_improve)\nprint(f\"Best_y unchanged: {opt.best_y_}\")\n\nTensorBoard logging disabled\nCase 1: New best found\nIteration 1: New best f(x) = 0.020000\nUpdated best_y: 0.02\n\nCase 2: No improvement\nIteration 2: f(x) = 4.500000\nBest_y unchanged: 0.02",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#termination-method",
    "href": "spotoptim_examples.html#termination-method",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.8 7. Termination Method",
    "text": "12.8 7. Termination Method\n\n12.8.1 7.1 _determine_termination()\nPurpose: Determine termination reason for optimization\nUsed by: optimize() at the end\nChecks: Max iterations, time limit, or successful completion\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    max_time=10.0,\n    seed=42\n)\n\n# Case 1: Maximum evaluations reached\nprint(\"Case 1: Maximum evaluations reached\")\nopt.y_ = np.zeros(20)\nstart_time = time.time()\nmsg = opt._determine_termination(start_time)\nprint(f\"Message: {msg}\\n\")\n\n# Case 2: Time limit exceeded (simulated)\nprint(\"Case 2: Time limit exceeded\")\nopt.y_ = np.zeros(10)\nstart_time = time.time() - 700  # 11.67 minutes ago\nmsg = opt._determine_termination(start_time)\nprint(f\"Message: {msg}\\n\")\n\n# Case 3: Successful completion\nprint(\"Case 3: Successful completion\")\nopt.y_ = np.zeros(10)\nstart_time = time.time()\nmsg = opt._determine_termination(start_time)\nprint(f\"Message: {msg}\")\n\nCase 1: Maximum evaluations reached\nMessage: Optimization terminated: maximum evaluations (20) reached\n\nCase 2: Time limit exceeded\nMessage: Optimization terminated: time limit (10.00 min) reached\n\nCase 3: Successful completion\nMessage: Optimization finished successfully",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#utility-methods",
    "href": "spotoptim_examples.html#utility-methods",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.9 8. Utility Methods",
    "text": "12.9 8. Utility Methods\n\n12.9.1 8.1 _select_new()\nPurpose: Select rows from A that are not in X (avoid duplicate evaluations)\nUsed by: _suggest_next_point() to ensure new points are different from evaluated points\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5)],\n    seed=42\n)\n\nA = np.array([[1, 2], [3, 4], [5, 6]])\nX = np.array([[3, 4], [7, 8]])\n\nnew_A, is_new = opt._select_new(A, X)\n\nprint(f\"Candidate points A:\\n{A}\")\nprint(f\"\\nKnown points X:\\n{X}\")\nprint(f\"\\nNew points from A:\\n{new_A}\")\nprint(f\"\\nIs new mask: {is_new}\")\n\nCandidate points A:\n[[1 2]\n [3 4]\n [5 6]]\n\nKnown points X:\n[[3 4]\n [7 8]]\n\nNew points from A:\n[[1 2]\n [5 6]]\n\nIs new mask: [ True False  True]\n\n\n\n\n12.9.2 8.2 _repair_non_numeric()\nPurpose: Round non-numeric values (int, factor) to integers\nUsed by: Various methods to ensure integer/factor variables have valid values\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    var_type=['int', 'float'],\n    seed=42\n)\n\nX = np.array([[1.2, 2.5], [3.7, 4.1], [5.9, 6.8]])\nX_repaired = opt._repair_non_numeric(X.copy(), opt.var_type)\n\nprint(f\"Original X:\\n{X}\")\nprint(f\"\\nRepaired X (first column rounded to int):\\n{X_repaired}\")\n\nOriginal X:\n[[1.2 2.5]\n [3.7 4.1]\n [5.9 6.8]]\n\nRepaired X (first column rounded to int):\n[[1.  2.5]\n [4.  4.1]\n [6.  6.8]]\n\n\n\n\n12.9.3 8.3 _map_to_factor_values()\nPurpose: Map internal integer values to original factor strings\nUsed by: optimize() when preparing results for user\nHandles: Factor (categorical) variables\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), ('red', 'green', 'blue')],\n    var_type=['float', 'factor'],\n    seed=42\n)\n\n# Internal representation (integers for factors)\nX_internal = np.array([[1.0, 0], [2.0, 1], [3.0, 2]])\nX_mapped = opt._map_to_factor_values(X_internal)\n\nprint(f\"Internal representation:\\n{X_internal}\")\nprint(f\"\\nMapped to factor values:\\n{X_mapped}\")\n\nInternal representation:\n[[1. 0.]\n [2. 1.]\n [3. 2.]]\n\nMapped to factor values:\n[[1.0 'red']\n [2.0 'green']\n [3.0 'blue']]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#integration-examples",
    "href": "spotoptim_examples.html#integration-examples",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.10 9. Integration Examples",
    "text": "12.10 9. Integration Examples\n\n12.10.1 9.1 Optimization with Custom Initial Design\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=15,\n    seed=42,\n    verbose=True\n)\n\n# Provide custom initial design\nX0 = np.array([[0, 0], [1, 1], [2, 2], [-1, -1], [-2, -2]])\nresult = opt.optimize(X0=X0)\n\nprint(f\"\\nBest point: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\n\nTensorBoard logging disabled\nNote: Initial design size (5) is smaller than requested (10) due to NaN/inf values\nInitial best: f(x) = 0.000000\nIteration 1: f(x) = 0.000000\nIteration 2: f(x) = 0.000000\nIteration 3: f(x) = 0.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 4: f(x) = 7.878776\nIteration 5: f(x) = 0.000000\nIteration 6: f(x) = 0.099268\nIteration 7: f(x) = 0.003575\nIteration 8: f(x) = 0.003187\nIteration 9: f(x) = 0.000019\nIteration 10: f(x) = 0.000001\n\nBest point: [0 0]\nBest value: 0.000000\n\n\n\n\n12.10.2 9.2 Optimization with Starting Point\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=15,\n    n_initial=5,\n    x0=[0.5, 0.5],  # Starting point near optimum\n    seed=42,\n    verbose=True\n)\n\nresult = opt.optimize()\n\nprint(f\"\\nBest point: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\n\nStarting point x0 validated and processed successfully.\n  Original scale: [0.5 0.5]\n  Internal scale: [0.5 0.5]\nTensorBoard logging disabled\nIncluding starting point x0 in initial design as first evaluation.\nInitial best: f(x) = 0.500000\nIteration 1: f(x) = 0.691041\nIteration 2: New best f(x) = 0.149351\nIteration 3: New best f(x) = 0.015439\nIteration 4: New best f(x) = 0.000530\nIteration 5: New best f(x) = 0.000070\nIteration 6: New best f(x) = 0.000004\nIteration 7: New best f(x) = 0.000003\nIteration 8: New best f(x) = 0.000003\nIteration 9: New best f(x) = 0.000003\nIteration 10: f(x) = 0.000003\n\nBest point: [0.00169077 0.0001854 ]\nBest value: 0.000003\n\n\n\n\n12.10.3 9.3 Optimization with Integer Variables\n\nopt = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    var_type=['int', 'int'],\n    max_iter=20,\n    n_initial=10,\n    seed=42,\n    verbose=True\n)\n\nresult = opt.optimize()\n\nprint(f\"\\nBest point: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Point has integers: {np.all(result.x == np.round(result.x))}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 4.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 1: f(x) = 29.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 2: New best f(x) = 1.000000\nIteration 3: New best f(x) = 0.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 4: f(x) = 25.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 5: f(x) = 9.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 6: f(x) = 5.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 7: f(x) = 13.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 8: f(x) = 13.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 9: f(x) = 10.000000\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 10: f(x) = 8.000000\n\nBest point: [ 0. -0.]\nBest value: 0.000000\nPoint has integers: True\n\n\n\n\n12.10.4 9.4 Noisy Function Optimization with OCBA\n\n# Noisy sphere function\ndef noisy_sphere(X):\n    X = np.atleast_2d(X)\n    return np.sum(X**2, axis=1) + np.random.normal(0, 0.1, X.shape[0])\n\nopt = SpotOptim(\n    fun=noisy_sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=25,\n    n_initial=10,\n    repeats_initial=2,  # Enable noise handling\n    ocba_delta=5,  # Enable OCBA with 5 re-evaluations\n    seed=42,\n    verbose=True\n)\n\nresult = opt.optimize()\n\nprint(f\"\\nBest point: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Note: OCBA re-evaluated promising points to reduce uncertainty\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 2.361893, mean best: f(x) = 2.413787\n  OCBA: Adding 5 re-evaluation(s)\nIteration 1: New best f(x) = 2.328426, mean best: f(x) = 2.328426\n\nBest point: [-1.53293987  0.103415  ]\nBest value: 2.328426\nNote: OCBA re-evaluated promising points to reduce uncertainty\n\n\n\n\n12.10.5 9.5 Optimization with NaN Handling\n\n# Function that sometimes returns NaN\ndef sometimes_nan(X):\n    X = np.atleast_2d(X)\n    y = np.sum(X**2, axis=1)\n    # Return NaN for large values (penalty will be applied)\n    y[y &gt; 100] = np.nan\n    return y\n\nopt = SpotOptim(\n    fun=sometimes_nan,\n    bounds=[(-10, 10), (-10, 10)],\n    max_iter=20,\n    n_initial=10,\n    seed=42,\n    verbose=True\n)\n\nresult = opt.optimize()\n\nprint(f\"\\nBest point: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Optimization succeeded despite NaN values: {result.success}\")\n\nTensorBoard logging disabled\nWarning: 1 initial design point(s) returned NaN/inf and will be ignored (reduced from 10 to 9 points)\nNote: Initial design size (9) is smaller than requested (10) due to NaN/inf values\nInitial best: f(x) = 9.683226\nIteration 1: New best f(x) = 8.496828\nIteration 2: New best f(x) = 4.452328\nIteration 3: New best f(x) = 0.174337\nIteration 4: New best f(x) = 0.038871\nIteration 5: New best f(x) = 0.000492\nIteration 6: f(x) = 0.000649\nIteration 7: New best f(x) = 0.000114\nIteration 8: New best f(x) = 0.000003\nIteration 9: New best f(x) = 0.000002\nIteration 10: f(x) = 0.000002\nIteration 11: f(x) = 0.000002\n\nBest point: [-0.00082295 -0.00113022]\nBest value: 0.000002\nOptimization succeeded despite NaN values: True",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#method-relationship-diagram",
    "href": "spotoptim_examples.html#method-relationship-diagram",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.11 10. Method Relationship Diagram",
    "text": "12.11 10. Method Relationship Diagram\nHere’s how all the methods relate to each other in the optimization workflow:\noptimize()\n│\n├─── Initial Design Phase\n│    ├── get_initial_design()\n│    │   └── _generate_initial_design() [if X0 is None]\n│    ├── _curate_initial_design()\n│    ├── _evaluate_function()\n│    ├── _handle_NA_initial_design()\n│    ├── _check_size_initial_design()\n│    └── _get_best_xy_initial_design()\n│\n├─── Main Optimization Loop (while not terminated)\n│    │\n│    ├── _fit_surrogate()\n│    │   └── _selection_dispatcher() [if max_surrogate_points exceeded]\n│    │\n│    ├── _apply_ocba() [if noise=True and ocba_delta &gt; 0]\n│    │\n│    ├── _suggest_next_point()\n│    │   ├── _acquisition_function()\n│    │   │   └── _predict_with_uncertainty()\n│    │   ├── _repair_non_numeric()\n│    │   ├── _select_new()\n│    │   └── _handle_acquisition_failure() [if needed]\n│    │\n│    ├── _evaluate_function()\n│    │\n│    ├── _handle_NA_new_points()\n│    │   ├── _apply_penalty_NA()\n│    │   └── _remove_nan()\n│    │\n│    └── _update_best_main_loop()\n│\n└─── Termination Phase\n     ├── _determine_termination()\n     └── _map_to_factor_values() [for results]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "spotoptim_examples.html#summary",
    "href": "spotoptim_examples.html#summary",
    "title": "12  SpotOptim Internal Methods Examples",
    "section": "12.12 11. Summary",
    "text": "12.12 11. Summary\nThis notebook demonstrated all major methods in SpotOptim with executable examples:\nCore Flow: 1. Initial Design: Generate/process → Curate → Evaluate → Handle NaN → Validate → Get best 2. Main Loop: Fit surrogate → Apply OCBA → Suggest point → Evaluate → Handle NaN → Update best 3. Termination: Determine reason → Prepare results\nKey Features: - Automatic handling of NaN/inf values with penalties - Support for noisy functions with OCBA re-evaluation - Integer and factor variable support - Flexible initial design (LHS, custom, or with starting point) - Multiple acquisition functions (EI, PI, mean) - Termination by max iterations or time limit\nAll examples can be run independently and demonstrate the modular design of SpotOptim!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>SpotOptim Internal Methods Examples</span>"
    ]
  },
  {
    "objectID": "019_spotoptim_sk_matern.html",
    "href": "019_spotoptim_sk_matern.html",
    "title": "13  Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions",
    "section": "",
    "text": "13.1 SpotOptim with Sklearn Kriging in 6 Dimensions: Rosenbrock Function\nThis section demonstrates how to use the SpotOptim class with sklearn’s Gaussian Process Regressor (using Matern kernel) as a surrogate on the 6-dimensional Rosenbrock function. We use a maximum of 100 function evaluations.\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport json\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.function import rosenbrock",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions</span>"
    ]
  },
  {
    "objectID": "019_spotoptim_sk_matern.html#spotoptim-with-sklearn-kriging-in-6-dimensions-rosenbrock-function",
    "href": "019_spotoptim_sk_matern.html#spotoptim-with-sklearn-kriging-in-6-dimensions-rosenbrock-function",
    "title": "13  Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions",
    "section": "",
    "text": "13.1.1 Define the 6D Rosenbrock Function\n\ndim = 6\nlower = np.full(dim, -2.0)\nupper = np.full(dim, 2.0)\nbounds = list(zip(lower, upper))\nfun = rosenbrock\nmax_iter = 100\n\n\n\n13.1.2 Set up SpotOptim Parameters\n\nn_initial = dim\nseed = 321\n\n\n\n13.1.3 Sklearn Gaussian Process Regressor as Surrogate\n\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, ConstantKernel\n\n# Use a Matern kernel instead of the standard RBF kernel\nkernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n    length_scale=1.0, \n    length_scale_bounds=(1e-4, 1e2), \n    nu=2.5\n)\nsurrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)\n\n# Create SpotOptim instance with sklearn surrogate\nopt_rosen = SpotOptim(\n    fun=fun,\n    bounds=bounds,\n    n_initial=n_initial,\n    max_iter=max_iter,\n    surrogate=surrogate,\n    seed=seed,\n    verbose=1\n)\n\n# Run optimization\nresult_rosen = opt_rosen.optimize()\n\nTensorBoard logging disabled\nInitial best: f(x) = 321.834153\nIteration 1: f(x) = 3523.035877\nIteration 2: f(x) = 1535.228391\nIteration 3: f(x) = 326.971706\nIteration 4: New best f(x) = 179.355508\nIteration 5: New best f(x) = 147.216352\nIteration 6: New best f(x) = 126.875114\nIteration 7: New best f(x) = 106.904521\nIteration 8: New best f(x) = 77.669128\nIteration 9: New best f(x) = 67.617299\nIteration 10: f(x) = 70.961648\nIteration 11: New best f(x) = 66.967286\nIteration 12: New best f(x) = 66.895363\nIteration 13: New best f(x) = 63.361266\nIteration 14: New best f(x) = 53.734207\nIteration 15: New best f(x) = 53.406010\nIteration 16: New best f(x) = 52.732493\nIteration 17: New best f(x) = 51.288924\nIteration 18: New best f(x) = 48.508851\nIteration 19: New best f(x) = 48.416069\nIteration 20: f(x) = 48.607214\nIteration 21: New best f(x) = 46.770668\nIteration 22: New best f(x) = 43.914540\nIteration 23: New best f(x) = 43.254721\nIteration 24: f(x) = 43.291581\nIteration 25: New best f(x) = 42.411817\nIteration 26: New best f(x) = 39.623988\nIteration 27: New best f(x) = 38.502231\nIteration 28: f(x) = 38.770608\nIteration 29: f(x) = 39.369860\nIteration 30: New best f(x) = 34.632973\nIteration 31: New best f(x) = 34.569160\nIteration 32: f(x) = 35.137815\nIteration 33: New best f(x) = 33.742656\nIteration 34: New best f(x) = 31.884739\nIteration 35: New best f(x) = 30.459009\nIteration 36: New best f(x) = 30.174841\nIteration 37: New best f(x) = 28.255525\nIteration 38: New best f(x) = 24.121792\nIteration 39: f(x) = 24.181482\nIteration 40: f(x) = 24.138016\nIteration 41: f(x) = 24.255060\nIteration 42: New best f(x) = 23.871394\nIteration 43: New best f(x) = 23.436325\nIteration 44: New best f(x) = 22.173239\nIteration 45: New best f(x) = 18.185462\nIteration 46: New best f(x) = 12.317941\nIteration 47: New best f(x) = 11.680706\nIteration 48: New best f(x) = 11.619099\nIteration 49: New best f(x) = 11.339768\nIteration 50: f(x) = 11.435165\nIteration 51: New best f(x) = 10.353561\nIteration 52: New best f(x) = 5.761820\nIteration 53: f(x) = 5.929004\nIteration 54: f(x) = 8.091353\nIteration 55: f(x) = 5.781610\nIteration 56: f(x) = 5.775219\nIteration 57: f(x) = 5.968408\nIteration 58: New best f(x) = 5.733723\nIteration 59: New best f(x) = 5.686104\nIteration 60: f(x) = 5.704052\nIteration 61: f(x) = 5.687804\nIteration 62: f(x) = 5.889423\nIteration 63: New best f(x) = 5.582101\nIteration 64: New best f(x) = 5.567810\nIteration 65: f(x) = 5.599297\nIteration 66: New best f(x) = 5.552732\nIteration 67: f(x) = 5.570675\nIteration 68: New best f(x) = 5.550554\nIteration 69: f(x) = 5.566261\nIteration 70: New best f(x) = 5.524807\nIteration 71: New best f(x) = 5.516099\nIteration 72: New best f(x) = 5.514696\nIteration 73: f(x) = 5.518039\nIteration 74: f(x) = 5.544667\nIteration 75: New best f(x) = 5.462185\nIteration 76: New best f(x) = 5.434393\nIteration 77: New best f(x) = 5.429851\nIteration 78: f(x) = 5.433619\nIteration 79: f(x) = 5.454661\nIteration 80: New best f(x) = 5.416503\nIteration 81: New best f(x) = 5.384556\nIteration 82: New best f(x) = 5.336085\nIteration 83: New best f(x) = 5.245265\nIteration 84: New best f(x) = 5.187754\nIteration 85: New best f(x) = 5.158456\nIteration 86: New best f(x) = 5.131915\nIteration 87: New best f(x) = 5.092477\nIteration 88: New best f(x) = 5.052519\nIteration 89: New best f(x) = 5.019587\nIteration 90: f(x) = 5.037044\nIteration 91: New best f(x) = 4.980142\nIteration 92: New best f(x) = 4.906306\nIteration 93: f(x) = 4.960896\nIteration 94: New best f(x) = 4.849446\n\n\n\nprint(f\"[6D] Sklearn Kriging: min y = {result_rosen.fun:.4f} at x = {result_rosen.x}\")\nprint(f\"Number of function evaluations: {result_rosen.nfev}\")\nprint(f\"Number of iterations: {result_rosen.nit}\")\n\n[6D] Sklearn Kriging: min y = 4.8494 at x = [0.06568329 0.00253728 0.01005153 0.00843757 0.01467048 0.00961113]\nNumber of function evaluations: 100\nNumber of iterations: 94\n\n\n\n\n13.1.4 Visualize Optimization Progress\n\nimport matplotlib.pyplot as plt\n\n# Plot the optimization progress\nplt.figure(figsize=(10, 6))\nplt.semilogy(np.minimum.accumulate(opt_rosen.y_), 'b-', linewidth=2)\nplt.xlabel('Function Evaluations', fontsize=12)\nplt.ylabel('Best Objective Value (log scale)', fontsize=12)\nplt.title('6D Rosenbrock: Sklearn Kriging Progress', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n13.1.5 Evaluation of Multiple Repeats\nTo perform 30 repeats and collect statistics:\n\n# Perform 30 independent runs\nn_repeats = 30\nresults = []\n\nprint(f\"Running {n_repeats} independent optimizations...\")\nfor i in range(n_repeats):\n    kernel_i = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n        length_scale=1.0, \n        length_scale_bounds=(1e-4, 1e2), \n        nu=2.5\n    )\n    surrogate_i = GaussianProcessRegressor(kernel=kernel_i, n_restarts_optimizer=100)\n    \n    opt_i = SpotOptim(\n        fun=fun,\n        bounds=bounds,\n        n_initial=n_initial,\n        max_iter=max_iter,\n        surrogate=surrogate_i,\n        seed=seed + i,  # Different seed for each run\n        verbose=0\n    )\n    \n    result_i = opt_i.optimize()\n    results.append(result_i.fun)\n    \n    if (i + 1) % 10 == 0:\n        print(f\"  Completed {i + 1}/{n_repeats} runs\")\n\n# Compute statistics\nmean_result = np.mean(results)\nstd_result = np.std(results)\nmin_result = np.min(results)\nmax_result = np.max(results)\n\nprint(f\"\\nResults over {n_repeats} runs:\")\nprint(f\"  Mean of best values: {mean_result:.6f}\")\nprint(f\"  Std of best values:  {std_result:.6f}\")\nprint(f\"  Min of best values:  {min_result:.6f}\")\nprint(f\"  Max of best values:  {max_result:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions</span>"
    ]
  },
  {
    "objectID": "019_spotoptim_sk_matern.html#spotoptim-with-sklearn-kriging-in-10-dimensions-michalewicz-function",
    "href": "019_spotoptim_sk_matern.html#spotoptim-with-sklearn-kriging-in-10-dimensions-michalewicz-function",
    "title": "13  Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions",
    "section": "13.2 SpotOptim with Sklearn Kriging in 10 Dimensions: Michalewicz Function",
    "text": "13.2 SpotOptim with Sklearn Kriging in 10 Dimensions: Michalewicz Function\nThis section demonstrates how to use the SpotOptim class with sklearn’s Gaussian Process Regressor (using Matern kernel) as a surrogate on the 10-dimensional Michalewicz function. We use a maximum of 300 function evaluations.\n\n13.2.1 Define the 10D Michalewicz Function\n\nfrom spotoptim.function import michalewicz\n\ndim = 10\nlower = np.full(dim, 0.0)\nupper = np.full(dim, np.pi)\nbounds = list(zip(lower, upper))\nfun = michalewicz\nmax_iter = 300\n\n\n\n13.2.2 Set up SpotOptim Parameters\n\nn_initial = dim\nseed = 321\n\n\n\n13.2.3 Sklearn Gaussian Process Regressor as Surrogate\n\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, ConstantKernel\n\n# Use a Matern kernel instead of the standard RBF kernel\nkernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n    length_scale=1.0, \n    length_scale_bounds=(1e-4, 1e2), \n    nu=2.5\n)\nsurrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)\n\n# Create SpotOptim instance with sklearn surrogate\nopt_micha = SpotOptim(\n    fun=fun,\n    bounds=bounds,\n    n_initial=n_initial,\n    max_iter=max_iter,\n    surrogate=surrogate,\n    seed=seed,\n    verbose=1\n)\n\n# Run optimization\nresult_micha = opt_micha.optimize()\n\nTensorBoard logging disabled\nInitial best: f(x) = -1.909129\nIteration 1: f(x) = -0.471751\nIteration 2: New best f(x) = -2.778226\nIteration 3: f(x) = -1.577058\nIteration 4: f(x) = -1.694359\nIteration 5: New best f(x) = -3.210641\nIteration 6: f(x) = -2.819606\nIteration 7: f(x) = -2.982698\nIteration 8: New best f(x) = -3.366470\nIteration 9: f(x) = -3.201759\nIteration 10: New best f(x) = -3.432570\nIteration 11: New best f(x) = -3.527877\nIteration 12: f(x) = -3.504520\nIteration 13: New best f(x) = -3.562644\nIteration 14: f(x) = -3.547038\nIteration 15: New best f(x) = -3.565505\nIteration 16: f(x) = -3.553183\nIteration 17: New best f(x) = -3.595616\nIteration 18: New best f(x) = -3.671383\nIteration 19: New best f(x) = -3.713695\nIteration 20: New best f(x) = -3.737969\nIteration 21: f(x) = -3.727671\nIteration 22: New best f(x) = -3.781389\nIteration 23: New best f(x) = -3.815294\nIteration 24: New best f(x) = -3.817426\nIteration 25: New best f(x) = -4.013697\nIteration 26: f(x) = -3.999787\nIteration 27: New best f(x) = -4.044009\nIteration 28: f(x) = -4.038050\nIteration 29: New best f(x) = -4.073980\nIteration 30: New best f(x) = -4.084493\nIteration 31: New best f(x) = -4.128250\nIteration 32: New best f(x) = -4.168658\nIteration 33: New best f(x) = -4.172880\nIteration 34: f(x) = -4.146185\nIteration 35: New best f(x) = -4.293347\nIteration 36: New best f(x) = -4.312362\nIteration 37: f(x) = -4.289076\nIteration 38: f(x) = -4.294401\nIteration 39: New best f(x) = -4.339989\nIteration 40: New best f(x) = -4.347110\nIteration 41: New best f(x) = -4.496414\nIteration 42: New best f(x) = -4.720985\nIteration 43: New best f(x) = -4.769322\nIteration 44: New best f(x) = -4.820892\nIteration 45: New best f(x) = -5.523194\nIteration 46: New best f(x) = -5.544444\nIteration 47: f(x) = -5.485251\nIteration 48: New best f(x) = -5.679042\nIteration 49: New best f(x) = -5.728856\nIteration 50: f(x) = -5.713454\nIteration 51: New best f(x) = -5.810308\nIteration 52: New best f(x) = -5.822810\nIteration 53: New best f(x) = -6.007102\nIteration 54: New best f(x) = -6.065657\nIteration 55: f(x) = -5.894116\nIteration 56: New best f(x) = -6.128321\nIteration 57: f(x) = -6.117134\nIteration 58: f(x) = -6.089022\nIteration 59: New best f(x) = -6.153586\nIteration 60: f(x) = -6.153496\nIteration 61: New best f(x) = -6.154117\nIteration 62: f(x) = -6.145165\nIteration 63: f(x) = -6.153499\nIteration 64: f(x) = -6.147537\nIteration 65: New best f(x) = -6.176618\nIteration 66: New best f(x) = -6.198679\nIteration 67: New best f(x) = -6.199809\nIteration 68: New best f(x) = -6.212758\nIteration 69: f(x) = -6.209788\nIteration 70: New best f(x) = -6.225959\nIteration 71: f(x) = -6.221108\nIteration 72: New best f(x) = -6.235835\nIteration 73: New best f(x) = -6.239913\nIteration 74: f(x) = -6.236491\nIteration 75: New best f(x) = -6.249874\nIteration 76: f(x) = -6.248650\nIteration 77: New best f(x) = -6.254337\nIteration 78: New best f(x) = -6.255686\nIteration 79: f(x) = -6.253849\nIteration 80: New best f(x) = -6.260994\nIteration 81: f(x) = -6.260993\nIteration 82: f(x) = -6.260468\nIteration 83: New best f(x) = -6.274534\nIteration 84: New best f(x) = -6.274590\nIteration 85: New best f(x) = -6.296523\nIteration 86: New best f(x) = -6.298934\nIteration 87: New best f(x) = -6.299100\nIteration 88: f(x) = -6.298132\nIteration 89: New best f(x) = -6.307340\nIteration 90: New best f(x) = -6.307582\nIteration 91: New best f(x) = -6.307747\nIteration 92: New best f(x) = -6.316321\nIteration 93: f(x) = -6.316074\nIteration 94: f(x) = -6.314603\nIteration 95: New best f(x) = -6.316471\nIteration 96: New best f(x) = -6.317010\nIteration 97: New best f(x) = -6.317641\nIteration 98: New best f(x) = -6.321132\nIteration 99: f(x) = -6.320694\nIteration 100: f(x) = -6.319272\nIteration 101: New best f(x) = -6.331238\nIteration 102: New best f(x) = -6.333815\nIteration 103: New best f(x) = -6.334254\nIteration 104: f(x) = -6.334095\nIteration 105: f(x) = -6.333526\nIteration 106: f(x) = -6.313235\nIteration 107: New best f(x) = -6.340705\nIteration 108: New best f(x) = -6.342540\nIteration 109: New best f(x) = -6.346718\nIteration 110: New best f(x) = -6.347457\nIteration 111: f(x) = -6.347277\nIteration 112: New best f(x) = -6.349371\nIteration 113: New best f(x) = -6.349385\nIteration 114: New best f(x) = -6.349796\nIteration 115: New best f(x) = -6.351657\nIteration 116: f(x) = -6.351468\nIteration 117: New best f(x) = -6.358798\nIteration 118: New best f(x) = -6.363537\nIteration 119: f(x) = -6.329287\nIteration 120: New best f(x) = -6.370744\nIteration 121: New best f(x) = -6.375039\nIteration 122: f(x) = -6.364329\nIteration 123: New best f(x) = -6.380095\nIteration 124: New best f(x) = -6.380149\nIteration 125: New best f(x) = -6.380542\nIteration 126: New best f(x) = -6.380722\nIteration 127: f(x) = -6.378664\nIteration 128: f(x) = -6.377485\nIteration 129: New best f(x) = -6.382280\nIteration 130: New best f(x) = -6.383360\nIteration 131: New best f(x) = -6.389637\nIteration 132: f(x) = -6.389593\nIteration 133: New best f(x) = -6.389650\nIteration 134: New best f(x) = -6.389938\nIteration 135: New best f(x) = -6.389962\nIteration 136: f(x) = -6.389737\nIteration 137: New best f(x) = -6.391061\nIteration 138: New best f(x) = -6.391178\nIteration 139: New best f(x) = -6.391350\nIteration 140: f(x) = -6.336366\nIteration 141: New best f(x) = -6.392279\nIteration 142: f(x) = -6.392114\nIteration 143: New best f(x) = -6.394001\nIteration 144: New best f(x) = -6.394823\nIteration 145: New best f(x) = -6.395547\nIteration 146: New best f(x) = -6.396330\nIteration 147: New best f(x) = -6.398681\nIteration 148: New best f(x) = -6.400004\nIteration 149: New best f(x) = -6.408147\nIteration 150: New best f(x) = -6.411590\nIteration 151: New best f(x) = -6.445504\nIteration 152: New best f(x) = -6.570437\nIteration 153: New best f(x) = -6.907678\nIteration 154: f(x) = -6.715445\nIteration 155: f(x) = -6.859522\nIteration 156: New best f(x) = -7.058979\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 157: f(x) = -2.167836\nIteration 158: New best f(x) = -7.092411\nIteration 159: New best f(x) = -7.109979\nIteration 160: f(x) = -7.109543\nIteration 161: f(x) = -7.100065\nIteration 162: f(x) = -7.076225\nIteration 163: f(x) = -7.067143\nIteration 164: New best f(x) = -7.157908\nIteration 165: New best f(x) = -7.158954\nIteration 166: f(x) = -7.155147\nIteration 167: f(x) = -7.156493\nIteration 168: f(x) = -7.112127\nIteration 169: New best f(x) = -7.182645\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 170: f(x) = -1.719617\nIteration 171: f(x) = -7.182247\nIteration 172: New best f(x) = -7.182754\nIteration 173: New best f(x) = -7.186636\nIteration 174: f(x) = -7.172811\nIteration 175: New best f(x) = -7.187552\nIteration 176: f(x) = -7.181461\nIteration 177: f(x) = -7.117022\nIteration 178: New best f(x) = -7.195177\nIteration 179: New best f(x) = -7.206760\nIteration 180: New best f(x) = -7.207315\nIteration 181: New best f(x) = -7.207998\nIteration 182: New best f(x) = -7.209295\nIteration 183: New best f(x) = -7.210453\nIteration 184: New best f(x) = -7.211930\nIteration 185: f(x) = -7.210859\nIteration 186: New best f(x) = -7.223471\nIteration 187: New best f(x) = -7.244183\nIteration 188: New best f(x) = -7.249511\nIteration 189: f(x) = -7.249477\nIteration 190: New best f(x) = -7.249743\nIteration 191: New best f(x) = -7.250388\nIteration 192: f(x) = -7.249115\nIteration 193: New best f(x) = -7.254238\nIteration 194: New best f(x) = -7.255252\nIteration 195: New best f(x) = -7.258149\nIteration 196: New best f(x) = -7.259044\nIteration 197: f(x) = -7.257182\nIteration 198: f(x) = -7.253438\nIteration 199: New best f(x) = -7.261403\nIteration 200: New best f(x) = -7.262523\nIteration 201: New best f(x) = -7.264531\nIteration 202: f(x) = -7.264126\nIteration 203: New best f(x) = -7.276752\nIteration 204: New best f(x) = -7.285664\nIteration 205: New best f(x) = -7.285751\nIteration 206: f(x) = -7.285175\nIteration 207: New best f(x) = -7.287979\nIteration 208: New best f(x) = -7.291624\nIteration 209: New best f(x) = -7.293043\nIteration 210: New best f(x) = -7.293667\nIteration 211: New best f(x) = -7.294087\nIteration 212: New best f(x) = -7.294537\nIteration 213: New best f(x) = -7.313151\nIteration 214: New best f(x) = -7.317460\nIteration 215: f(x) = -7.316577\nIteration 216: New best f(x) = -7.321206\nIteration 217: f(x) = -7.319651\nIteration 218: f(x) = -7.320973\nIteration 219: f(x) = -7.320017\nIteration 220: f(x) = -7.320755\nIteration 221: New best f(x) = -7.326544\nIteration 222: New best f(x) = -7.326676\nIteration 223: New best f(x) = -7.326781\nIteration 224: New best f(x) = -7.327023\nIteration 225: f(x) = -7.325760\nIteration 226: f(x) = -7.325290\nIteration 227: New best f(x) = -7.333735\nIteration 228: New best f(x) = -7.334667\nIteration 229: New best f(x) = -7.336343\nIteration 230: New best f(x) = -7.336379\nIteration 231: New best f(x) = -7.336937\nIteration 232: New best f(x) = -7.338846\nIteration 233: f(x) = -7.324801\nIteration 234: New best f(x) = -7.340357\nIteration 235: f(x) = -7.340331\nIteration 236: New best f(x) = -7.340914\nIteration 237: f(x) = -7.340850\nIteration 238: f(x) = -7.340555\nIteration 239: New best f(x) = -7.342492\nIteration 240: New best f(x) = -7.344282\nIteration 241: f(x) = -1.490073\nIteration 242: f(x) = -1.490414\nIteration 243: New best f(x) = -7.344289\nIteration 244: f(x) = -7.344258\nIteration 245: f(x) = -1.525476\nIteration 246: f(x) = -1.529494\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 247: f(x) = -0.531363\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 248: f(x) = -1.677672\nIteration 249: f(x) = -1.677672\nIteration 250: f(x) = -1.677678\nIteration 251: f(x) = -1.692980\nIteration 252: f(x) = -7.344073\nIteration 253: New best f(x) = -7.345125\nIteration 254: f(x) = -1.717307\nIteration 255: f(x) = -1.780155\nIteration 256: f(x) = -1.788536\nIteration 257: f(x) = -1.788457\nIteration 258: f(x) = -1.789952\nIteration 259: f(x) = -1.790588\nIteration 260: f(x) = -1.752082\nIteration 261: f(x) = -1.533725\nIteration 262: f(x) = -1.323585\nIteration 263: f(x) = -1.326084\nIteration 264: New best f(x) = -7.345244\nIteration 265: New best f(x) = -7.345337\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 266: f(x) = -0.041277\nIteration 267: f(x) = -7.345083\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 268: f(x) = -0.595027\nIteration 269: New best f(x) = -7.346771\nIteration 270: f(x) = -7.346679\nIteration 271: New best f(x) = -7.346822\nIteration 272: New best f(x) = -7.346913\nIteration 273: New best f(x) = -7.347292\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 274: f(x) = -0.192104\nIteration 275: f(x) = -7.347276\nIteration 276: New best f(x) = -7.347393\nIteration 277: New best f(x) = -7.347414\nIteration 278: f(x) = -7.347371\nIteration 279: New best f(x) = -7.347513\nIteration 280: f(x) = -7.347511\nIteration 281: f(x) = -7.347509\nIteration 282: f(x) = -7.347502\nIteration 283: New best f(x) = -7.347541\nIteration 284: f(x) = -7.347522\nIteration 285: New best f(x) = -7.347676\nIteration 286: New best f(x) = -7.347911\nIteration 287: f(x) = -1.793091\nIteration 288: New best f(x) = -7.347957\nIteration 289: f(x) = -7.347953\nIteration 290: f(x) = -7.347944\n\n\n\nprint(f\"[10D] Sklearn Kriging: min y = {result_micha.fun:.4f} at x = {result_micha.x}\")\nprint(f\"Number of function evaluations: {result_micha.nfev}\")\nprint(f\"Number of iterations: {result_micha.nit}\")\n\n[10D] Sklearn Kriging: min y = -7.3480 at x = [2.20503242 2.71129625 2.21891182 2.48213434 2.36018149 2.02745108\n 1.87714802 1.36056791 1.28302799 1.21719709]\nNumber of function evaluations: 300\nNumber of iterations: 290\n\n\n\n\n13.2.4 Visualize Optimization Progress\n\nimport matplotlib.pyplot as plt\n\n# Plot the optimization progress\nplt.figure(figsize=(10, 6))\nplt.plot(np.minimum.accumulate(opt_micha.y_), 'b-', linewidth=2)\nplt.xlabel('Function Evaluations', fontsize=12)\nplt.ylabel('Best Objective Value', fontsize=12)\nplt.title('10D Michalewicz: Sklearn Kriging Progress', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n13.2.5 Evaluation of Multiple Repeats\nTo perform 30 repeats and collect statistics:\n\n# Perform 30 independent runs\nn_repeats = 30\nresults = []\n\nprint(f\"Running {n_repeats} independent optimizations...\")\nfor i in range(n_repeats):\n    kernel_i = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(\n        length_scale=1.0, \n        length_scale_bounds=(1e-4, 1e2), \n        nu=2.5\n    )\n    surrogate_i = GaussianProcessRegressor(kernel=kernel_i, n_restarts_optimizer=100)\n    \n    opt_i = SpotOptim(\n        fun=fun,\n        bounds=bounds,\n        n_initial=n_initial,\n        max_iter=max_iter,\n        surrogate=surrogate_i,\n        seed=seed + i,  # Different seed for each run\n        verbose=0\n    )\n    \n    result_i = opt_i.optimize()\n    results.append(result_i.fun)\n    \n    if (i + 1) % 10 == 0:\n        print(f\"  Completed {i + 1}/{n_repeats} runs\")\n\n# Compute statistics\nmean_result = np.mean(results)\nstd_result = np.std(results)\nmin_result = np.min(results)\nmax_result = np.max(results)\n\nprint(f\"\\nResults over {n_repeats} runs:\")\nprint(f\"  Mean of best values: {mean_result:.6f}\")\nprint(f\"  Std of best values:  {std_result:.6f}\")\nprint(f\"  Min of best values:  {min_result:.6f}\")\nprint(f\"  Max of best values:  {max_result:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions</span>"
    ]
  },
  {
    "objectID": "019_spotoptim_sk_matern.html#comparison-spotoptim-vs-spotpython",
    "href": "019_spotoptim_sk_matern.html#comparison-spotoptim-vs-spotpython",
    "title": "13  Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions",
    "section": "13.3 Comparison: SpotOptim vs SpotPython",
    "text": "13.3 Comparison: SpotOptim vs SpotPython\nThe SpotOptim package provides a scipy-compatible interface for Bayesian optimization with the following key features:\n\nScipy-compatible API: Returns OptimizeResult objects that work seamlessly with scipy’s optimization ecosystem\nCustom Surrogates: Supports any sklearn-compatible surrogate model (as demonstrated with GaussianProcessRegressor)\nFlexible Interface: Simplified parameter specification with bounds, n_initial, and max_iter\nAnalytical Test Functions: Built-in test functions (rosenbrock, ackley, michalewicz) for benchmarking\n\nThe main differences from spotpython are:\n\nSpotOptim: Uses bounds, n_initial, max_iter parameters with scipy-style interface\nSpotPython: Uses fun_control, design_control, surrogate_control with more complex configuration\n\nBoth packages support custom surrogates and provide powerful Bayesian optimization capabilities.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions</span>"
    ]
  },
  {
    "objectID": "019_spotoptim_sk_matern.html#summary",
    "href": "019_spotoptim_sk_matern.html#summary",
    "title": "13  Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions",
    "section": "13.4 Summary",
    "text": "13.4 Summary\nThis notebook demonstrated how to:\n\nUse SpotOptim with sklearn’s Gaussian Process Regressor (Matern kernel) as a surrogate\nOptimize 6D Rosenbrock function with 100 evaluations\nOptimize 10D Michalewicz function with 300 evaluations\nVisualize optimization progress\nPerform multiple independent runs for statistical analysis\n\nThe results show that SpotOptim with sklearn surrogates provides effective Bayesian optimization for challenging benchmark functions.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions</span>"
    ]
  },
  {
    "objectID": "019_spotoptim_sk_matern.html#jupyter-notebook",
    "href": "019_spotoptim_sk_matern.html#jupyter-notebook",
    "title": "13  Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions",
    "section": "13.5 Jupyter Notebook",
    "text": "13.5 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThis Quarto document is part of the spotoptim package benchmarking suite\nSource available at: spotoptim GitHub Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Benchmarking SpotOptim with Sklearn Kriging (Matern Kernel) on 6D Rosenbrock and 10D Michalewicz Functions</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html",
    "href": "kriging_surrogate.html",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "",
    "text": "14.1 Introduction\nSpotOptim provides a powerful Kriging (Gaussian Process) surrogate model that can significantly enhance optimization performance. This tutorial introduces the Kriging class, explains its theory and parameters, and demonstrates how to use it effectively with SpotOptim.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#introduction",
    "href": "kriging_surrogate.html#introduction",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "",
    "text": "14.1.1 What is Kriging?\nKriging, also known as Gaussian Process regression, is a sophisticated interpolation method that:\n\nPredicts function values at untested points based on observed data\nProvides uncertainty estimates indicating confidence in predictions\nModels smooth functions common in engineering and scientific optimization\nHandles noisy observations through regression approaches\n\nThe mathematical foundation of Kriging is based on the assumption that the objective function \\(f(\\mathbf{x})\\) can be modeled as:\n\\[\nf(\\mathbf{x}) = \\mu + Z(\\mathbf{x})\n\\]\nwhere \\(\\mu\\) is a constant mean and \\(Z(\\mathbf{x})\\) is a Gaussian process with correlation structure. The correlation between two points \\(\\mathbf{x}_i\\) and \\(\\mathbf{x}_j\\) is typically modeled using a Gaussian (RBF) correlation function:\n\\[\nR(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp\\left(-\\sum_{k=1}^{d} \\theta_k |x_{i,k} - x_{j,k}|^2\\right)\n\\]\nwhere \\(\\theta_k &gt; 0\\) are the correlation length parameters that control smoothness in each dimension.\n\n\n14.1.2 Why Use Kriging in SpotOptim?\n\nBetter Surrogate Models: More accurate predictions than simple interpolation\nUncertainty Quantification: Know where the model is uncertain\nMixed Variable Types: Handle continuous, integer, and categorical variables\nMultiple Methods: Choose between interpolation, regression, and reinterpolation\nCustomizable: Control regularization, correlation parameters, and more",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#basic-usage",
    "href": "kriging_surrogate.html#basic-usage",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.2 Basic Usage",
    "text": "14.2 Basic Usage\n\n14.2.1 Creating a Simple Kriging Model\nLet’s start with the most basic usage - creating a Kriging model with default settings:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\n# Simple objective function\ndef sphere(X):\n    \"\"\"Sphere function: f(x) = sum(x^2)\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create Kriging surrogate with defaults\nkriging = Kriging(seed=42)\n\n# Use with SpotOptim\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=kriging,  # Use Kriging instead of default GP\n    max_iter=20,\n    n_initial=10,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\nprint(f\"\\nBest solution: {result.x}\")\nprint(f\"Best value: {result.fun:.6f}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 2.420807\nIteration 1: New best f(x) = 0.001740\nIteration 2: New best f(x) = 0.000372\nIteration 3: New best f(x) = 0.000254\nIteration 4: f(x) = 0.004013\nIteration 5: f(x) = 0.001046\nIteration 6: f(x) = 0.001192\nIteration 7: f(x) = 0.001219\nIteration 8: f(x) = 0.001147\nIteration 9: New best f(x) = 0.000004\nIteration 10: New best f(x) = 0.000000\n\nBest solution: [2.04416182e-05 5.67177247e-04]\nBest value: 0.000000\n\n\n\n\n14.2.2 Default vs Custom Surrogate\nSpotOptim uses a Gaussian Process Regressor by default. Here’s how Kriging compares:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function: (1-x)^2 + 100(y-x^2)^2\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\n# With default Gaussian Process\nopt_default = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=30,\n    n_initial=15,\n    seed=42,\n    verbose=False\n)\nresult_default = opt_default.optimize()\n\n# With Kriging surrogate\nkriging = Kriging(method='regression', seed=42)\nopt_kriging = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    surrogate=kriging,\n    max_iter=30,\n    n_initial=15,\n    seed=42,\n    verbose=False\n)\nresult_kriging = opt_kriging.optimize()\n\nprint(\"Comparison:\")\nprint(f\"Default GP:  f(x) = {result_default.fun:.6f}\")\nprint(f\"Kriging:     f(x) = {result_kriging.fun:.6f}\")\n\nComparison:\nDefault GP:  f(x) = 0.190180\nKriging:     f(x) = 0.001073\n\n\nBoth approaches work well, but Kriging offers more control over the surrogate behavior.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#understanding-kriging-parameters",
    "href": "kriging_surrogate.html#understanding-kriging-parameters",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.3 Understanding Kriging Parameters",
    "text": "14.3 Understanding Kriging Parameters\n\n14.3.1 Method: Interpolation vs Regression\nThe method parameter controls how Kriging handles data:\n\n“interpolation”: Exact interpolation, passes through all training points\n“regression”: Allows smoothing, better for noisy data\n“reinterpolation”: Hybrid approach\n\n\nimport numpy as np\nfrom spotoptim.surrogate import Kriging\nimport matplotlib.pyplot as plt\n\n# Create noisy training data\nnp.random.seed(42)\nX_train = np.linspace(0, 2*np.pi, 10).reshape(-1, 1)\ny_train = np.sin(X_train.ravel()) + 0.1 * np.random.randn(10)\n\n# Test data for smooth predictions\nX_test = np.linspace(0, 2*np.pi, 100).reshape(-1, 1)\ny_true = np.sin(X_test.ravel())\n\n# Compare methods\nmethods = ['interpolation', 'regression', 'reinterpolation']\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nfor ax, method in zip(axes, methods):\n    model = Kriging(method=method, seed=42, model_fun_evals=50)\n    model.fit(X_train, y_train)\n    y_pred, y_std = model.predict(X_test, return_std=True)\n    \n    # Plot\n    ax.plot(X_test, y_true, 'k--', label='True function', linewidth=2)\n    ax.plot(X_test, y_pred, 'b-', label='Prediction', linewidth=2)\n    ax.fill_between(X_test.ravel(), \n                     y_pred - 2*y_std, \n                     y_pred + 2*y_std, \n                     alpha=0.3, label='95% CI')\n    ax.scatter(X_train, y_train, c='r', s=50, zorder=5, label='Training data')\n    ax.set_title(f'Method: {method}')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key differences:\")\nprint(\"- Interpolation: Passes exactly through training points\")\nprint(\"- Regression: Smooths over noisy data (recommended)\")\nprint(\"- Reinterpolation: Balances between the two\")\n\n\n\n\n\n\n\n\nKey differences:\n- Interpolation: Passes exactly through training points\n- Regression: Smooths over noisy data (recommended)\n- Reinterpolation: Balances between the two\n\n\nRecommendation: Use method='regression' for most optimization problems, especially with noisy objectives.\n\n\n14.3.2 Noise Parameter and Regularization\nThe noise parameter adds a small nugget effect for numerical stability:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef noisy_ackley(X):\n    \"\"\"Ackley function with observation noise\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    base = -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n    noise = np.random.normal(0, 0.5, size=base.shape)  # Add noise\n    return base + noise\n\n# Very small noise (near interpolation)\nkriging_small = Kriging(noise=1e-10, method='interpolation', seed=42)\nopt_small = SpotOptim(\n    fun=noisy_ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=kriging_small,\n    max_iter=25,\n    n_initial=12,\n    seed=42,\n    verbose=False\n)\nresult_small = opt_small.optimize()\n\n# Larger noise (more robust to noise)\nkriging_large = Kriging(noise=0.01, method='interpolation', seed=42)\nopt_large = SpotOptim(\n    fun=noisy_ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=kriging_large,\n    max_iter=25,\n    n_initial=12,\n    seed=42,\n    verbose=False\n)\nresult_large = opt_large.optimize()\n\nprint(\"Impact of noise parameter:\")\nprint(f\"Small noise (1e-10): f(x) = {result_small.fun:.6f}\")\nprint(f\"Large noise (0.01):  f(x) = {result_large.fun:.6f}\")\nprint(\"\\nNote: For noisy functions, use 'regression' method instead,\")\nprint(\"      which automatically optimizes the Lambda (nugget) parameter.\")\n\nImpact of noise parameter:\nSmall noise (1e-10): f(x) = 0.049827\nLarge noise (0.01):  f(x) = 0.012636\n\nNote: For noisy functions, use 'regression' method instead,\n      which automatically optimizes the Lambda (nugget) parameter.\n\n\nBest Practice: For noisy functions, use method='regression' which automatically optimizes the regularization parameter instead of fixing it.\n\n\n14.3.3 Correlation Length Parameters (Theta)\nThe theta parameters control smoothness. SpotOptim optimizes these automatically:\n\nmin_theta: Minimum log₁₀(θ) value (default: -3.0 → θ = 0.001)\nmax_theta: Maximum log₁₀(θ) value (default: 2.0 → θ = 100)\n\nSmaller θ → smoother function, larger θ → more wiggly function.\n\nimport numpy as np\nfrom spotoptim.surrogate import Kriging\n\n# Sample data\nX_train = np.array([[0.0], [0.5], [1.0], [1.5], [2.0]])\ny_train = np.sin(X_train.ravel())\n\n# Tight bounds (smoother)\nmodel_smooth = Kriging(min_theta=-1.0, max_theta=0.0, seed=42, model_fun_evals=30)\nmodel_smooth.fit(X_train, y_train)\n\n# Wide bounds (more flexible)\nmodel_flexible = Kriging(min_theta=-3.0, max_theta=2.0, seed=42, model_fun_evals=30)\nmodel_flexible.fit(X_train, y_train)\n\nprint(\"Theta bounds and optimal values:\")\nprint(f\"Smooth model:   bounds=[-1.0, 0.0], theta={model_smooth.theta_}\")\nprint(f\"Flexible model: bounds=[-3.0, 2.0], theta={model_flexible.theta_}\")\nprint(\"\\nThe optimizer automatically finds the best theta within the bounds.\")\n\nTheta bounds and optimal values:\nSmooth model:   bounds=[-1.0, 0.0], theta=[-0.95216449]\nFlexible model: bounds=[-3.0, 2.0], theta=[-0.95309049]\n\nThe optimizer automatically finds the best theta within the bounds.\n\n\nDefault Values: The defaults min_theta=-3.0 and max_theta=2.0 work well for most problems.\n\n\n14.3.4 Isotropic vs Anisotropic Correlation\n\nIsotropic (isotropic=True): Single θ for all dimensions (faster, fewer parameters)\nAnisotropic (isotropic=False): Different θ per dimension (more flexible, default)\n\n\nimport numpy as np\nfrom spotoptim.surrogate import Kriging\n\n# 3D problem\nnp.random.seed(42)\nX_train = np.random.rand(15, 3) * 10 - 5\ny_train = X_train[:, 0]**2 + 0.1*X_train[:, 1]**2 + 2*X_train[:, 2]**2\n\n# Isotropic: one theta for all dimensions\nmodel_iso = Kriging(isotropic=True, seed=42, model_fun_evals=40)\nmodel_iso.fit(X_train, y_train)\n\n# Anisotropic: different theta per dimension\nmodel_aniso = Kriging(isotropic=False, seed=42, model_fun_evals=40)\nmodel_aniso.fit(X_train, y_train)\n\nprint(\"Correlation structure:\")\nprint(f\"Isotropic:   n_theta={model_iso.n_theta}, theta={model_iso.theta_}\")\nprint(f\"Anisotropic: n_theta={model_aniso.n_theta}, theta={model_aniso.theta_}\")\nprint(\"\\nAnisotropic can capture different smoothness in each dimension.\")\n\n# Test predictions\nX_test = np.array([[0.0, 0.0, 0.0]])\ny_iso = model_iso.predict(X_test)\ny_aniso = model_aniso.predict(X_test)\nprint(f\"\\nPrediction at origin:\")\nprint(f\"Isotropic:   {y_iso[0]:.4f}\")\nprint(f\"Anisotropic: {y_aniso[0]:.4f}\")\n\nCorrelation structure:\nIsotropic:   n_theta=1, theta=[-3.]\nAnisotropic: n_theta=3, theta=[-2.23292358 -3.         -1.97228776]\n\nAnisotropic can capture different smoothness in each dimension.\n\nPrediction at origin:\nIsotropic:   -0.0666\nAnisotropic: -1.0267\n\n\nWhen to Use:\n\nUse isotropic for faster fitting when dimensions have similar characteristics\nUse anisotropic (default) when dimensions behave differently",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#advanced-features",
    "href": "kriging_surrogate.html#advanced-features",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.4 Advanced Features",
    "text": "14.4 Advanced Features\n\n14.4.1 Mixed Variable Types\nKriging supports mixed variable types: continuous (float), integer (int), and categorical (factor):\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef mixed_objective(X):\n    \"\"\"\n    Optimize a system with:\n    - x0: continuous learning rate (0.001 to 0.1)\n    - x1: integer number of layers (1 to 5)\n    - x2: categorical activation (0=ReLU, 1=Tanh, 2=Sigmoid)\n    \"\"\"\n    X = np.atleast_2d(X)\n    learning_rate = X[:, 0]\n    n_layers = X[:, 1]\n    activation = X[:, 2]\n    \n    # Simplified model: prefer lr~0.01, 3 layers, ReLU\n    loss = (learning_rate - 0.01)**2 + (n_layers - 3)**2\n    loss += np.where(activation == 0, 0.0,  # ReLU is best\n                     np.where(activation == 1, 0.5,  # Tanh is ok\n                              1.0))  # Sigmoid is worst\n    return loss\n\n# Define bounds and types\nbounds = [\n    (0.001, 0.1),  # learning_rate (float)\n    (1, 5),        # n_layers (int)\n    (0, 2)         # activation (factor: 0, 1, or 2)\n]\n\nvar_type = ['float', 'int', 'factor']\n\n# Create Kriging with mixed types\nkriging_mixed = Kriging(\n    method='regression',\n    var_type=var_type,\n    seed=42,\n    model_fun_evals=50\n)\n\n# Optimize\noptimizer = SpotOptim(\n    fun=mixed_objective,\n    bounds=bounds,\n    var_type=var_type,\n    surrogate=kriging_mixed,\n    max_iter=30,\n    n_initial=15,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nOptimal configuration:\")\nprint(f\"Learning rate: {result.x[0]:.4f}\")\nprint(f\"Num layers:    {int(result.x[1])}\")\nprint(f\"Activation:    {int(result.x[2])} (0=ReLU, 1=Tanh, 2=Sigmoid)\")\nprint(f\"Loss:          {result.fun:.6f}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 0.000173\nIteration 1: New best f(x) = 0.000081\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 2: f(x) = 1.507094\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 3: f(x) = 0.000599\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 4: f(x) = 0.000587\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 5: f(x) = 5.005398\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 6: f(x) = 1.000342\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 7: f(x) = 1.501632\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 8: f(x) = 0.502100\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 9: f(x) = 2.000762\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 10: f(x) = 4.006134\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 11: f(x) = 1.000430\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 12: f(x) = 1.500167\nIteration 13: New best f(x) = 0.000030\nIteration 14: f(x) = 0.000049\nIteration 15: New best f(x) = 0.000003\n\nOptimal configuration:\nLearning rate: 0.0082\nNum layers:    3\nActivation:    0 (0=ReLU, 1=Tanh, 2=Sigmoid)\nLoss:          0.000003\n\n\nKey Points:\n\nSet var_type in both Kriging and SpotOptim\nFactor variables use specialized distance metrics (default: Canberra)\nInteger variables are treated as ordered but discrete\n\n\n\n14.4.2 Customizing the Distance Metric for Factors\nFor categorical variables, you can choose different distance metrics.\n\nimport numpy as np\nfrom spotoptim.surrogate import Kriging\n\n# Categorical data: 2 factor variables\nX_train = np.array([\n    [0, 0],  # Category A, Color Red\n    [1, 0],  # Category B, Color Red\n    [0, 1],  # Category A, Color Blue\n    [1, 1],  # Category B, Color Blue\n    [2, 2],  # Category C, Color Green\n])\ny_train = np.array([1.0, 1.5, 1.2, 2.0, 3.5])\n\n# Different distance metrics\nmetrics = ['canberra', 'hamming']\n\nfor metric in metrics:\n    model = Kriging(\n        method='regression',\n        var_type=['factor', 'factor'],\n        metric_factorial=metric,\n        seed=42,\n        model_fun_evals=40\n    )\n    model.fit(X_train, y_train)\n    \n    # Test prediction\n    X_test = np.array([[1, 1]])\n    y_pred = model.predict(X_test)\n    \n    print(f\"Metric: {metric:10s} | Prediction at [1,1]: {y_pred[0]:.4f}\")\n\nprint(\"\\nAvailable metrics: 'canberra' (default), 'hamming', 'jaccard', etc.\")\n\nMetric: canberra   | Prediction at [1,1]: 1.9463\nMetric: hamming    | Prediction at [1,1]: 2.0000\n\nAvailable metrics: 'canberra' (default), 'hamming', 'jaccard', etc.\n\n\n\n\n14.4.3 Handling High-Dimensional Problems\nFor high-dimensional problems, Kriging can become computationally expensive. Here are strategies:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef high_dim_sphere(X):\n    \"\"\"10-dimensional sphere function\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Strategy 1: Use isotropic correlation (fewer parameters)\nkriging_iso = Kriging(\n    method='regression',\n    isotropic=True,  # Single theta for all 10 dimensions\n    seed=42,\n    model_fun_evals=50  # Faster optimization\n)\n\noptimizer_iso = SpotOptim(\n    fun=high_dim_sphere,\n    bounds=[(-5, 5)] * 10,  # 10 dimensions\n    surrogate=kriging_iso,\n    max_iter=50,\n    n_initial=30,\n    seed=42,\n    verbose=False\n)\n\nresult_iso = optimizer_iso.optimize()\n\n# Strategy 2: Use max_surrogate_points to limit training set size\nkriging_limited = Kriging(method='regression', seed=42)\n\noptimizer_limited = SpotOptim(\n    fun=high_dim_sphere,\n    bounds=[(-5, 5)] * 10,\n    surrogate=kriging_limited,\n    max_iter=50,\n    n_initial=30,\n    max_surrogate_points=100,  # Limit surrogate training set\n    seed=42,\n    verbose=False\n)\n\nresult_limited = optimizer_limited.optimize()\n\nprint(\"High-dimensional optimization strategies:\")\nprint(f\"Isotropic Kriging:      f(x) = {result_iso.fun:.6f}\")\nprint(f\"Limited training set:   f(x) = {result_limited.fun:.6f}\")\nprint(\"\\nFor &gt;5 dimensions, consider isotropic=True or limit training set.\")\n\nHigh-dimensional optimization strategies:\nIsotropic Kriging:      f(x) = 0.003979\nLimited training set:   f(x) = 0.044950\n\nFor &gt;5 dimensions, consider isotropic=True or limit training set.\n\n\n\n\n14.4.4 Uncertainty Quantification\nKriging provides uncertainty estimates, useful for exploration vs exploitation:\n\nimport numpy as np\nfrom spotoptim.surrogate import Kriging\nimport matplotlib.pyplot as plt\n\n# 1D example for visualization\nnp.random.seed(42)\nX_train = np.array([[0.0], [1.0], [3.0], [5.0], [6.0]])\ny_train = np.sin(X_train.ravel()) + 0.05 * np.random.randn(5)\n\n# Fit Kriging model\nmodel = Kriging(method='regression', seed=42, model_fun_evals=50)\nmodel.fit(X_train, y_train)\n\n# Dense test points\nX_test = np.linspace(-0.5, 6.5, 200).reshape(-1, 1)\ny_pred, y_std = model.predict(X_test, return_std=True)\n\n# True function\ny_true = np.sin(X_test.ravel())\n\n# Plot\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(X_test, y_true, 'k--', label='True function', linewidth=2)\nplt.plot(X_test, y_pred, 'b-', label='Kriging prediction', linewidth=2)\nplt.fill_between(X_test.ravel(), \n                 y_pred - 2*y_std, \n                 y_pred + 2*y_std, \n                 alpha=0.3, color='blue', label='95% confidence')\nplt.scatter(X_train, y_train, c='red', s=100, zorder=5, \n           edgecolors='black', label='Training points')\nplt.xlabel('x', fontsize=12)\nplt.ylabel('y', fontsize=12)\nplt.title('Kriging Predictions with Uncertainty', fontsize=14)\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nplt.plot(X_test, y_std, 'r-', linewidth=2)\nplt.scatter(X_train, np.zeros_like(X_train), c='blue', s=100, \n           zorder=5, edgecolors='black', label='Training points')\nplt.xlabel('x', fontsize=12)\nplt.ylabel('Standard Deviation', fontsize=12)\nplt.title('Uncertainty Estimates', fontsize=14)\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key observations:\")\nprint(\"- Uncertainty is low near training points\")\nprint(\"- Uncertainty is high far from training data\")\nprint(\"- This guides acquisition functions (e.g., EI exploits low uncertainty)\")\n\n\n\n\n\n\n\n\nKey observations:\n- Uncertainty is low near training points\n- Uncertainty is high far from training data\n- This guides acquisition functions (e.g., EI exploits low uncertainty)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#practical-examples",
    "href": "kriging_surrogate.html#practical-examples",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.5 Practical Examples",
    "text": "14.5 Practical Examples\n\n14.5.1 Example 1: Optimizing the Rastrigin Function\nThe Rastrigin function is highly multimodal - a challenging test case:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef rastrigin(X):\n    \"\"\"\n    Rastrigin function: highly multimodal\n    Global minimum: f(0,...,0) = 0\n    \"\"\"\n    A = 10\n    n = X.shape[1]\n    return A * n + np.sum(X**2 - A * np.cos(2 * np.pi * X), axis=1)\n\n# Configure Kriging for multimodal function\nkriging = Kriging(\n    method='regression',      # Smooth over local variations\n    min_theta=-3.0,          # Allow flexible correlation\n    max_theta=2.0,\n    seed=42,\n    model_fun_evals=100      # More budget for better surrogate\n)\n\noptimizer = SpotOptim(\n    fun=rastrigin,\n    bounds=[(-5.12, 5.12), (-5.12, 5.12)],\n    surrogate=kriging,\n    acquisition='ei',         # Expected Improvement for exploration\n    max_iter=60,\n    n_initial=30,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nRastrigin optimization:\")\nprint(f\"Best solution: {result.x}\")\nprint(f\"Best value:    {result.fun:.6f} (global optimum: 0.0)\")\nprint(f\"Distance to optimum: {np.linalg.norm(result.x):.6f}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 6.442225\nIteration 1: f(x) = 28.951536\nIteration 2: f(x) = 22.875749\nIteration 3: f(x) = 21.815864\nIteration 4: f(x) = 7.077873\nIteration 5: f(x) = 13.368250\nIteration 6: f(x) = 16.577976\nIteration 7: f(x) = 25.780045\nIteration 8: f(x) = 10.034344\nIteration 9: f(x) = 19.560557\nIteration 10: f(x) = 12.381235\nIteration 11: f(x) = 20.126829\nIteration 12: f(x) = 27.151349\nIteration 13: New best f(x) = 2.290927\nIteration 14: f(x) = 2.761961\nIteration 15: f(x) = 12.468354\nIteration 16: New best f(x) = 1.208377\nIteration 17: f(x) = 12.566211\nIteration 18: f(x) = 14.965620\nIteration 19: f(x) = 14.295554\nIteration 20: f(x) = 28.107905\nIteration 21: f(x) = 22.687907\nIteration 22: f(x) = 43.729592\nIteration 23: f(x) = 41.636148\nIteration 24: New best f(x) = 1.034573\nIteration 25: f(x) = 3.228327\nIteration 26: f(x) = 7.934136\nIteration 27: f(x) = 21.994039\nIteration 28: f(x) = 27.510661\nIteration 29: f(x) = 9.365219\nIteration 30: f(x) = 1.248535\n\nRastrigin optimization:\nBest solution: [-0.00987679  1.00506675]\nBest value:    1.034573 (global optimum: 0.0)\nDistance to optimum: 1.005115\n\n\n\n\n14.5.2 Example 2: Robust Optimization with Noise\nWhen optimizing noisy functions, Kriging’s regression mode helps:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef noisy_beale(X):\n    \"\"\"\n    Beale function with Gaussian noise\n    Global minimum: f(3, 0.5) = 0\n    \"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    \n    term1 = (1.5 - x + x * y)**2\n    term2 = (2.25 - x + x * y**2)**2\n    term3 = (2.625 - x + x * y**3)**2\n    \n    base = term1 + term2 + term3\n    noise = np.random.normal(0, 0.5, size=base.shape)\n    \n    return base + noise\n\n# Use regression method for noisy objectives\nkriging_robust = Kriging(\n    method='regression',        # Automatically optimizes Lambda (nugget)\n    min_Lambda=-9.0,           # Allow small regularization\n    max_Lambda=-2.0,           # But not too large\n    seed=42,\n    model_fun_evals=80\n)\n\n# Use repeated evaluations for noise handling\noptimizer = SpotOptim(\n    fun=noisy_beale,\n    bounds=[(-4.5, 4.5), (-4.5, 4.5)],\n    surrogate=kriging_robust,\n    max_iter=50,\n    n_initial=20,\n    repeats_initial=3,         # Evaluate each initial point 3 times\n    repeats_surrogate=2,       # Evaluate each new point 2 times\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nNoisy Beale optimization:\")\nprint(f\"Best solution: {result.x}\")\nprint(f\"Best mean value: {optimizer.min_mean_y:.6f}\")\nprint(f\"Variance at best: {optimizer.min_var_y:.6f}\")\nprint(f\"True optimum: [3.0, 0.5]\")\nprint(f\"Distance: {np.linalg.norm(result.x - np.array([3.0, 0.5])):.4f}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 9.379814, mean best: f(x) = 9.729582\n\nNoisy Beale optimization:\nBest solution: [ 0.34789079 -0.3014163 ]\nBest mean value: 9.729582\nVariance at best: 0.214586\nTrue optimum: [3.0, 0.5]\nDistance: 2.7706\n\n\n\n\n14.5.3 Example 3: Real-World Machine Learning Hyperparameter Tuning\nOptimize hyperparameters for a neural network:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef ml_objective(X):\n    \"\"\"\n    Simulate training a neural network\n    Variables:\n    - x0: learning_rate (log scale: 1e-4 to 1e-1)\n    - x1: num_layers (integer: 1 to 5)\n    - x2: hidden_size (integer: 16, 32, 64, 128, 256)\n    - x3: dropout_rate (float: 0.0 to 0.5)\n    \n    Returns validation error\n    \"\"\"\n    X = np.atleast_2d(X)\n    lr = X[:, 0]\n    n_layers = X[:, 1]\n    hidden_size = X[:, 2]\n    dropout = X[:, 3]\n    \n    # Simulate validation error (lower is better)\n    # Optimal around: lr=0.001, 3 layers, 64 hidden, 0.2 dropout\n    error = (np.log10(lr) + 3)**2  # Prefer lr ~ 0.001\n    error += (n_layers - 3)**2     # Prefer 3 layers\n    error += ((hidden_size - 64) / 32)**2  # Prefer 64 hidden units\n    error += (dropout - 0.2)**2 * 10  # Prefer 0.2 dropout\n    \n    # Add some noise to simulate training variance\n    error += np.random.normal(0, 0.1, size=error.shape)\n    \n    return error\n\n# Setup optimization\nbounds = [\n    (1e-4, 1e-1),  # learning_rate\n    (1, 5),        # num_layers\n    (16, 256),     # hidden_size\n    (0.0, 0.5)     # dropout_rate\n]\n\nvar_type = ['float', 'int', 'int', 'float']\n\n# Use Kriging with mixed types\nkriging_ml = Kriging(\n    method='regression',\n    var_type=var_type,\n    seed=42,\n    model_fun_evals=60\n)\n\noptimizer = SpotOptim(\n    fun=ml_objective,\n    bounds=bounds,\n    var_type=var_type,\n    var_trans=['log10', None, None, None],  # Log scale for learning rate\n    surrogate=kriging_ml,\n    max_iter=40,\n    n_initial=20,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nOptimal hyperparameters:\")\nprint(f\"Learning rate: {result.x[0]:.6f}\")\nprint(f\"Num layers:    {int(result.x[1])}\")\nprint(f\"Hidden size:   {int(result.x[2])}\")\nprint(f\"Dropout rate:  {result.x[3]:.3f}\")\nprint(f\"Validation error: {result.fun:.6f}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 1.133527\nIteration 1: f(x) = 5.122533\nIteration 2: f(x) = 5.959913\nIteration 3: f(x) = 1.505793\nIteration 4: New best f(x) = 0.942988\nIteration 5: New best f(x) = 0.280219\nIteration 6: New best f(x) = 0.260858\nIteration 7: f(x) = 1.115300\nIteration 8: f(x) = 0.653129\nIteration 9: New best f(x) = 0.176351\nIteration 10: New best f(x) = 0.084523\nIteration 11: New best f(x) = -0.067705\nIteration 12: f(x) = 0.167623\nIteration 13: f(x) = 0.048797\nIteration 14: f(x) = 0.053888\nIteration 15: f(x) = 0.015810\nIteration 16: New best f(x) = -0.108042\nIteration 17: f(x) = -0.007253\nIteration 18: f(x) = -0.003508\nIteration 19: f(x) = -0.052430\nIteration 20: f(x) = 0.006251\n\nOptimal hyperparameters:\nLearning rate: 0.000987\nNum layers:    3\nHidden size:   68\nDropout rate:  0.158\nValidation error: -0.108042\n\n\n\n\n14.5.4 Example 4: Comparing Kriging Methods\nLet’s compare all three Kriging methods on the same problem:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef levy(X):\n    \"\"\"\n    Levy function N. 13\n    Global minimum: f(1, 1) = 0\n    \"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    \n    w1 = 1 + (x - 1) / 4\n    w2 = 1 + (y - 1) / 4\n    \n    term1 = np.sin(np.pi * w1)**2\n    term2 = (w1 - 1)**2 * (1 + 10 * np.sin(np.pi * w1 + 1)**2)\n    term3 = (w2 - 1)**2 * (1 + np.sin(2 * np.pi * w2)**2)\n    \n    return term1 + term2 + term3\n\nmethods = ['interpolation', 'regression', 'reinterpolation']\nresults_methods = []\n\nfor method in methods:\n    kriging = Kriging(\n        method=method,\n        seed=42,\n        model_fun_evals=60\n    )\n    \n    optimizer = SpotOptim(\n        fun=levy,\n        bounds=[(-10, 10), (-10, 10)],\n        surrogate=kriging,\n        max_iter=40,\n        n_initial=20,\n        seed=42,\n        verbose=False\n    )\n    \n    result = optimizer.optimize()\n    results_methods.append((method, result.fun, result.x))\n    \n    print(f\"{method:15s} | f(x) = {result.fun:8.6f} | x = {result.x}\")\n\nprint(f\"\\nGlobal optimum: f(1, 1) = 0.0\")\nprint(\"\\nAll methods find good solutions, but 'regression' is most robust.\")\n\ninterpolation   | f(x) = 0.001657 | x = [0.98535016 0.85317084]\nregression      | f(x) = 0.027480 | x = [0.8385841 1.068918 ]\nreinterpolation | f(x) = 0.027480 | x = [0.8385841 1.068918 ]\n\nGlobal optimum: f(1, 1) = 0.0\n\nAll methods find good solutions, but 'regression' is most robust.\n\n\n\n\n14.5.5 Example 5: Sensitivity to Theta Bounds\nTheta bounds control the range of smoothness. Let’s see their impact:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef griewank(X):\n    \"\"\"Griewank function\"\"\"\n    sum_sq = np.sum(X**2 / 4000, axis=1)\n    prod_cos = np.prod(np.cos(X / np.sqrt(np.arange(1, X.shape[1] + 1))), axis=1)\n    return sum_sq - prod_cos + 1\n\n# Different theta bounds\ntheta_configs = [\n    (-2.0, 1.0, \"Tight (smoother)\"),\n    (-3.0, 2.0, \"Default\"),\n    (-4.0, 3.0, \"Wide (more flexible)\")\n]\n\nfor min_theta, max_theta, label in theta_configs:\n    kriging = Kriging(\n        method='regression',\n        min_theta=min_theta,\n        max_theta=max_theta,\n        seed=42,\n        model_fun_evals=50\n    )\n    \n    optimizer = SpotOptim(\n        fun=griewank,\n        bounds=[(-600, 600), (-600, 600)],\n        surrogate=kriging,\n        max_iter=35,\n        n_initial=18,\n        seed=42,\n        verbose=False\n    )\n    \n    result = optimizer.optimize()\n    print(f\"{label:20s} [{min_theta:5.1f}, {max_theta:4.1f}] | f(x) = {result.fun:8.6f}\")\n\nprint(\"\\nDefault bounds work well for most problems.\")\n\nTight (smoother)     [ -2.0,  1.0] | f(x) = 8.578706\nDefault              [ -3.0,  2.0] | f(x) = 13.108634\nWide (more flexible) [ -4.0,  3.0] | f(x) = 2.652215\n\nDefault bounds work well for most problems.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#comparing-surrogates",
    "href": "kriging_surrogate.html#comparing-surrogates",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.6 Comparing Surrogates",
    "text": "14.6 Comparing Surrogates\n\n14.6.1 Kriging vs Gaussian Process vs Random Forest\nLet’s compare different surrogate models:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging, SimpleKriging\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, ConstantKernel\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef schwefel(X):\n    \"\"\"Schwefel function\"\"\"\n    return 418.9829 * X.shape[1] - np.sum(X * np.sin(np.sqrt(np.abs(X))), axis=1)\n\nbounds = [(-500, 500), (-500, 500)]\n\n# 1. Kriging (full-featured)\nkriging = Kriging(method='regression', seed=42, model_fun_evals=60)\nopt_kriging = SpotOptim(fun=schwefel, bounds=bounds, surrogate=kriging,\n                        max_iter=35, n_initial=18, seed=42, verbose=False)\nresult_kriging = opt_kriging.optimize()\n\n# 2. SimpleKriging (lightweight)\nsimple_kriging = SimpleKriging(noise=1e-10, seed=42)\nopt_simple = SpotOptim(fun=schwefel, bounds=bounds, surrogate=simple_kriging,\n                       max_iter=35, n_initial=18, seed=42, verbose=False)\nresult_simple = opt_simple.optimize()\n\n# 3. Gaussian Process (sklearn default)\nkernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)\ngp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10,\n                               normalize_y=True, random_state=42)\nopt_gp = SpotOptim(fun=schwefel, bounds=bounds, surrogate=gp,\n                   max_iter=35, n_initial=18, seed=42, verbose=False)\nresult_gp = opt_gp.optimize()\n\n# 4. Random Forest\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nopt_rf = SpotOptim(fun=schwefel, bounds=bounds, surrogate=rf,\n                   max_iter=35, n_initial=18, seed=42, verbose=False)\nresult_rf = opt_rf.optimize()\n\nprint(\"Surrogate Model Comparison:\")\nprint(f\"Kriging (full):     f(x) = {result_kriging.fun:8.2f}\")\nprint(f\"SimpleKriging:      f(x) = {result_simple.fun:8.2f}\")\nprint(f\"Gaussian Process:   f(x) = {result_gp.fun:8.2f}\")\nprint(f\"Random Forest:      f(x) = {result_rf.fun:8.2f}\")\nprint(f\"\\nGlobal optimum: f(420.9687, 420.9687) = 0.0\")\nprint(\"\\nKriging offers:\")\nprint(\"- Mixed variable types (continuous, integer, categorical)\")\nprint(\"- Multiple methods (interpolation, regression, reinterpolation)\")\nprint(\"- Explicit control over regularization and correlation\")\n\nSurrogate Model Comparison:\nKriging (full):     f(x) =   118.47\nSimpleKriging:      f(x) =   118.44\nGaussian Process:   f(x) =   118.44\nRandom Forest:      f(x) =   184.74\n\nGlobal optimum: f(420.9687, 420.9687) = 0.0\n\nKriging offers:\n- Mixed variable types (continuous, integer, categorical)\n- Multiple methods (interpolation, regression, reinterpolation)\n- Explicit control over regularization and correlation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#best-practices",
    "href": "kriging_surrogate.html#best-practices",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.7 Best Practices",
    "text": "14.7 Best Practices\n\n14.7.1 1. Choosing the Right Method\n\n# For smooth, deterministic functions\nkriging = Kriging(method='interpolation', noise=1e-10, seed=42)\n\n# For general optimization (RECOMMENDED)\nkriging = Kriging(method='regression', seed=42)\n\n# For noisy functions with repeated evaluations\nkriging = Kriging(method='regression', seed=42)\n# Use with repeats_initial and repeats_surrogate in SpotOptim\n\n\n\n14.7.2 2. Setting Model Complexity\n\n# For low-dimensional problems (&lt;5D)\nkriging = Kriging(\n    method='regression',\n    isotropic=False,           # Anisotropic (default)\n    model_fun_evals=100,       # More budget for better fit\n    seed=42\n)\n\n# For high-dimensional problems (&gt;5D)\nkriging = Kriging(\n    method='regression',\n    isotropic=True,            # Fewer parameters\n    model_fun_evals=50,        # Faster fitting\n    seed=42\n)\n\n\n\n14.7.3 3. Handling Different Variable Types\n\n# Mixed types example\nbounds = [\n    (0.0, 10.0),    # continuous\n    (1, 10),        # integer\n    (0, 3)          # categorical (4 categories)\n]\n\nvar_type = ['float', 'int', 'factor']\n\nkriging = Kriging(\n    method='regression',\n    var_type=var_type,\n    metric_factorial='canberra',  # For factor variables\n    seed=42\n)\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    var_type=var_type,\n    surrogate=kriging,\n    seed=42\n)\n\n\n\n14.7.4 4. Reproducibility\nAlways set the seed for reproducible results:\n\n# Both Kriging and SpotOptim should have seeds\nkriging = Kriging(method='regression', seed=42)\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    surrogate=kriging,\n    seed=42  # Same seed or different seed\n)\n\n\n\n14.7.5 5. Monitoring Surrogate Quality\nCheck the negative log-likelihood after fitting:\n\nimport numpy as np\nfrom spotoptim.surrogate import Kriging\n\n# Sample data\nX = np.random.rand(20, 2) * 10 - 5\ny = np.sum(X**2, axis=1)\n\nmodel = Kriging(method='regression', seed=42)\nmodel.fit(X, y)\n\nprint(f\"Negative log-likelihood: {model.negLnLike:.4f}\")\nprint(f\"Optimized theta: {model.theta_}\")\nprint(f\"Optimized Lambda: {model.Lambda_:.4f}\")\nprint(f\"Condition number of Psi: {model.cnd_Psi:.2e}\")\n\nprint(\"\\nLower negLnLike = better fit\")\nprint(\"Check condition number for numerical stability\")\n\nNegative log-likelihood: -15.3998\nOptimized theta: [-3. -3.]\nOptimized Lambda: -8.9957\nCondition number of Psi: 4.03e+13\n\nLower negLnLike = better fit\nCheck condition number for numerical stability",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#common-issues-and-solutions",
    "href": "kriging_surrogate.html#common-issues-and-solutions",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.8 Common Issues and Solutions",
    "text": "14.8 Common Issues and Solutions\n\n14.8.1 Issue 1: Slow Fitting for Large Datasets\nProblem: Kriging becomes slow with many training points.\nSolution: Limit surrogate training set size:\n\n# Use max_surrogate_points in SpotOptim\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    surrogate=kriging,\n    max_surrogate_points=200,  # Limit to 200 points\n    selection_method='distant', # or 'best'\n    seed=42\n)\n\n\n\n14.8.2 Issue 2: Poor Predictions for Categorical Variables\nProblem: Kriging doesn’t handle factors well.\nSolution: Try different distance metrics:\n\n# Try different metrics\nfor metric in ['canberra', 'hamming', 'jaccard']:\n    kriging = Kriging(\n        method='regression',\n        var_type=['float', 'factor'],\n        metric_factorial=metric,\n        seed=42\n    )\n    # Test performance\n\n\n\n14.8.3 Issue 3: Numerical Instability\nProblem: Correlation matrix is nearly singular.\nSolution: Increase regularization:\n\n# For interpolation method\nkriging = Kriging(\n    method='interpolation',\n    noise=1e-6,  # Increase from default 1e-8\n    seed=42\n)\n\n# Or use regression method (recommended)\nkriging = Kriging(\n    method='regression',\n    min_Lambda=-6.0,  # Don't go too small\n    seed=42\n)\n\n\n\n14.8.4 Issue 4: Overfitting to Noisy Data\nProblem: Kriging fits noise instead of underlying function.\nSolution: Use regression method with reasonable Lambda bounds:\n\nkriging = Kriging(\n    method='regression',\n    min_Lambda=-5.0,  # Not too small\n    max_Lambda=-1.0,  # Not too large\n    seed=42\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "kriging_surrogate.html#summary",
    "href": "kriging_surrogate.html#summary",
    "title": "14  Kriging Surrogate Models in SpotOptim",
    "section": "14.9 Summary",
    "text": "14.9 Summary\n\n14.9.1 Key Takeaways\n\nUse method='regression' for most optimization problems\nSet seed for reproducibility\nUse var_type for mixed variable types\nDefault parameters work well for most cases\nUse isotropic=True for high-dimensional problems (&gt;5D)\n\n\n\n14.9.2 Quick Reference\n\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\n# Recommended configuration for general use\nkriging = Kriging(\n    method='regression',        # Smooths over noise\n    seed=42                     # Reproducibility\n)\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=bounds,\n    surrogate=kriging,\n    max_iter=50,\n    n_initial=20,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\n\n\n14.9.3 Parameter Cheat Sheet\n\n\n\nParameter\nDefault\nWhen to Change\n\n\n\n\nmethod\n'regression'\nUse 'interpolation' for exact fit\n\n\nnoise\nsqrt(eps)\nRarely; use method='regression' instead\n\n\nmin_theta\n-3.0\nAdjust if default range doesn’t work\n\n\nmax_theta\n2.0\nAdjust if default range doesn’t work\n\n\nisotropic\nFalse\nSet True for &gt;5 dimensions\n\n\nvar_type\n['num']\nSet for mixed variable types\n\n\nmetric_factorial\n'canberra'\nTry 'hamming' for factors\n\n\nmodel_fun_evals\n100\nReduce for faster fitting\n\n\nseed\n124\nAlways set for reproducibility\n\n\n\n\n\n14.9.4 Further Reading\n\nForrester, A., Sobester, A., & Keane, A. (2008). Engineering Design via Surrogate Modelling. Wiley.\nJones, D. R., Schonlau, M., & Welch, W. J. (1998). Efficient global optimization of expensive black-box functions. Journal of Global optimization, 13(4), 455-492.\nRasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT Press.\n\nFor more examples and documentation, visit the SpotOptim GitHub repository.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Kriging Surrogate Models in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html",
    "href": "reproducibility.html",
    "title": "15  Reproducibility in SpotOptim",
    "section": "",
    "text": "15.1 Introduction\nSpotOptim provides full support for reproducible optimization runs through the seed parameter. This is essential for:\nWhen you specify a seed, SpotOptim guarantees that running the same optimization multiple times will produce identical results. Without a seed, each run explores the search space differently, which can be useful for robustness testing.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#introduction",
    "href": "reproducibility.html#introduction",
    "title": "15  Reproducibility in SpotOptim",
    "section": "",
    "text": "Scientific research: Ensuring experiments can be replicated\nDebugging: Reproducing specific optimization behaviors\nBenchmarking: Fair comparison between different configurations\nProduction: Consistent results in deployed applications",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#basic-usage",
    "href": "reproducibility.html#basic-usage",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.2 Basic Usage",
    "text": "15.2 Basic Usage\n\n15.2.1 Making Optimization Reproducible\nTo ensure reproducible results, simply specify the seed parameter when creating the optimizer:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    \"\"\"Simple sphere function: f(x) = sum(x^2)\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Reproducible optimization\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    seed=42,  # This ensures reproducibility\n    verbose=True\n)\n\nresult = optimizer.optimize()\nprint(f\"Best solution: {result.x}\")\nprint(f\"Best value: {result.fun}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 5.542803\nIteration 1: New best f(x) = 0.001070\nIteration 2: New best f(x) = 0.000089\nIteration 3: New best f(x) = 0.000066\nIteration 4: New best f(x) = 0.000036\nIteration 5: New best f(x) = 0.000001\nIteration 6: New best f(x) = 0.000000\nIteration 7: f(x) = 0.000000\nIteration 8: f(x) = 0.000000\nIteration 9: f(x) = 0.000000\nIteration 10: f(x) = 0.000000\nIteration 11: f(x) = 0.000000\nIteration 12: f(x) = 0.000000\nIteration 13: f(x) = 0.000000\nIteration 14: f(x) = 0.000000\nIteration 15: New best f(x) = 0.000000\nBest solution: [3.31436760e-04 4.18312302e-05]\nBest value: 1.1160017787260647e-07\n\n\nKey Point: Running this code multiple times (even on different days or machines) will always produce the same result.\n\n\n15.2.2 Running Independent Experiments\nIf you don’t specify a seed, each optimization run will explore the search space differently:\n\n# Non-reproducible: different results each time\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15\n    # No seed specified\n)\n\nresult = optimizer.optimize()\n# Results will vary between runs\n\nThis is useful when you want to: - Explore different regions of the search space - Test the robustness of your results - Run multiple independent optimization attempts",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#practical-examples",
    "href": "reproducibility.html#practical-examples",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.3 Practical Examples",
    "text": "15.3 Practical Examples\n\n15.3.1 Example 1: Comparing Different Configurations\nWhen comparing different optimizer settings, use the same seed for fair comparison:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\n# Configuration 1: More initial points\nopt1 = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=50,\n    n_initial=20,\n    seed=42  # Same seed for fair comparison\n)\nresult1 = opt1.optimize()\n\n# Configuration 2: Fewer initial points, more iterations\nopt2 = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=50,\n    n_initial=10,\n    seed=42  # Same seed\n)\nresult2 = opt2.optimize()\n\nprint(f\"Config 1 (more initial): {result1.fun:.6f}\")\nprint(f\"Config 2 (fewer initial): {result2.fun:.6f}\")\n\nConfig 1 (more initial): 0.002494\nConfig 2 (fewer initial): 0.011538\n\n\n\n\n15.3.2 Example 2: Reproducible Research Experiment\nFor scientific papers or reports, always use a fixed seed and document it:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rastrigin(X):\n    \"\"\"Rastrigin function (multimodal)\"\"\"\n    A = 10\n    n = X.shape[1]\n    return A * n + np.sum(X**2 - A * np.cos(2 * np.pi * X), axis=1)\n\n# Documented seed for reproducibility\nRANDOM_SEED = 12345\n\noptimizer = SpotOptim(\n    fun=rastrigin,\n    bounds=[(-5.12, 5.12), (-5.12, 5.12), (-5.12, 5.12)],\n    max_iter=100,\n    n_initial=30,\n    seed=RANDOM_SEED,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nExperiment Results (seed={RANDOM_SEED}):\")\nprint(f\"Best solution: {result.x}\")\nprint(f\"Best value: {result.fun}\")\nprint(f\"Iterations: {result.nit}\")\nprint(f\"Function evaluations: {result.nfev}\")\n\n# These results can now be cited in a paper\n\nTensorBoard logging disabled\nInitial best: f(x) = 20.392774\nIteration 1: f(x) = 31.367736\nIteration 2: f(x) = 30.822371\nIteration 3: f(x) = 28.761963\nIteration 4: f(x) = 25.355390\nIteration 5: f(x) = 22.087398\nIteration 6: f(x) = 23.609642\nIteration 7: f(x) = 27.024927\nIteration 8: f(x) = 23.154774\nIteration 9: New best f(x) = 8.927550\nIteration 10: New best f(x) = 8.899624\nIteration 11: f(x) = 19.831800\nIteration 12: f(x) = 19.323148\nIteration 13: New best f(x) = 8.692652\nIteration 14: New best f(x) = 8.244681\nIteration 15: f(x) = 8.404445\nIteration 16: f(x) = 17.268172\nIteration 17: f(x) = 17.250262\nIteration 18: f(x) = 16.989215\nIteration 19: f(x) = 22.061741\nIteration 20: New best f(x) = 8.227940\nIteration 21: New best f(x) = 2.732909\nIteration 22: New best f(x) = 2.236454\nIteration 23: New best f(x) = 2.001414\nIteration 24: f(x) = 2.001821\nIteration 25: f(x) = 2.002706\nIteration 26: f(x) = 24.677487\nIteration 27: f(x) = 25.445950\nIteration 28: f(x) = 22.323886\nIteration 29: New best f(x) = 1.990146\nIteration 30: New best f(x) = 1.989946\nIteration 31: f(x) = 30.157363\nIteration 32: f(x) = 13.980500\nIteration 33: f(x) = 26.257931\nIteration 34: f(x) = 26.086756\nIteration 35: f(x) = 16.955502\nIteration 36: f(x) = 86.774141\nIteration 37: f(x) = 42.005362\nIteration 38: New best f(x) = 1.989929\nIteration 39: f(x) = 1.989930\nIteration 40: New best f(x) = 1.989929\nIteration 41: f(x) = 69.717061\nIteration 42: New best f(x) = 1.989929\nIteration 43: f(x) = 66.932192\nIteration 44: f(x) = 50.905256\nIteration 45: f(x) = 1.989930\nIteration 46: f(x) = 46.800517\nIteration 47: f(x) = 67.429406\nIteration 48: f(x) = 60.775651\nIteration 49: f(x) = 1.989930\nIteration 50: f(x) = 1.989929\nIteration 51: f(x) = 1.989930\nIteration 52: f(x) = 1.989929\nIteration 53: f(x) = 1.989930\nIteration 54: f(x) = 1.989929\nIteration 55: f(x) = 1.989931\nIteration 56: f(x) = 1.989930\nIteration 57: f(x) = 1.989929\nIteration 58: f(x) = 16.986975\nIteration 59: f(x) = 14.520119\nIteration 60: f(x) = 86.774141\nIteration 61: f(x) = 1.989931\nIteration 62: f(x) = 76.830975\nIteration 63: f(x) = 59.126187\nIteration 64: f(x) = 1.989929\nIteration 65: f(x) = 13.047213\nIteration 66: New best f(x) = 1.989929\nIteration 67: New best f(x) = 1.989928\nIteration 68: f(x) = 1.989931\nIteration 69: f(x) = 1.989930\nIteration 70: f(x) = 1.989928\n\nExperiment Results (seed=12345):\nBest solution: [ 9.94876607e-01 -9.94866368e-01  1.89299459e-04]\nBest value: 1.9899282459113223\nIterations: 70\nFunction evaluations: 100\n\n\n\n\n15.3.3 Example 3: Multiple Independent Runs\nTo test robustness, run the same optimization with different seeds:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef ackley(X):\n    \"\"\"Ackley function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\n# Run 5 independent optimizations\nresults = []\nseeds = [42, 123, 456, 789, 1011]\n\nfor seed in seeds:\n    optimizer = SpotOptim(\n        fun=ackley,\n        bounds=[(-5, 5), (-5, 5)],\n        max_iter=40,\n        n_initial=20,\n        seed=seed,\n        verbose=False\n    )\n    result = optimizer.optimize()\n    results.append(result.fun)\n    print(f\"Run with seed {seed:4d}: f(x) = {result.fun:.6f}\")\n\n# Analyze robustness\nprint(f\"\\nBest result: {min(results):.6f}\")\nprint(f\"Worst result: {max(results):.6f}\")\nprint(f\"Mean: {np.mean(results):.6f}\")\nprint(f\"Std dev: {np.std(results):.6f}\")\n\nRun with seed   42: f(x) = 0.000907\nRun with seed  123: f(x) = 0.001394\nRun with seed  456: f(x) = 0.001941\nRun with seed  789: f(x) = 0.000616\nRun with seed 1011: f(x) = 0.003029\n\nBest result: 0.000616\nWorst result: 0.003029\nMean: 0.001578\nStd dev: 0.000854\n\n\n\n\n15.3.4 Example 4: Reproducible Initial Design\nThe seed ensures that even the initial design points are reproducible:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef simple_quadratic(X):\n    return np.sum((X - 1)**2, axis=1)\n\n# Create two optimizers with same seed\nopt1 = SpotOptim(\n    fun=simple_quadratic,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=25,\n    n_initial=10,\n    seed=999\n)\n\nopt2 = SpotOptim(\n    fun=simple_quadratic,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=25,\n    n_initial=10,\n    seed=999  # Same seed\n)\n\n# Run both optimizations\nresult1 = opt1.optimize()\nresult2 = opt2.optimize()\n\n# Verify identical results\nprint(\"Initial design points are identical:\", \n      np.allclose(opt1.X_[:10], opt2.X_[:10]))\nprint(\"All evaluated points are identical:\", \n      np.allclose(opt1.X_, opt2.X_))\nprint(\"All function values are identical:\", \n      np.allclose(opt1.y_, opt2.y_))\nprint(\"Best solutions are identical:\", \n      np.allclose(result1.x, result2.x))\n\nInitial design points are identical: True\nAll evaluated points are identical: True\nAll function values are identical: True\nBest solutions are identical: True\n\n\n\n\n15.3.5 Example 5: Custom Initial Design with Seed\nEven when providing a custom initial design, the seed ensures reproducible subsequent iterations:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef beale(X):\n    \"\"\"Beale function\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    term1 = (1.5 - x + x * y)**2\n    term2 = (2.25 - x + x * y**2)**2\n    term3 = (2.625 - x + x * y**3)**2\n    return term1 + term2 + term3\n\n# Custom initial design (e.g., from previous knowledge)\nX_start = np.array([\n    [0.0, 0.0],\n    [1.0, 1.0],\n    [2.0, 2.0],\n    [-1.0, -1.0]\n])\n\n# Run twice with same seed and initial design\nopt1 = SpotOptim(\n    fun=beale,\n    bounds=[(-4.5, 4.5), (-4.5, 4.5)],\n    max_iter=30,\n    n_initial=10,\n    seed=777\n)\nresult1 = opt1.optimize(X0=X_start)\n\nopt2 = SpotOptim(\n    fun=beale,\n    bounds=[(-4.5, 4.5), (-4.5, 4.5)],\n    max_iter=30,\n    n_initial=10,\n    seed=777  # Same seed\n)\nresult2 = opt2.optimize(X0=X_start)\n\nprint(\"Results are identical:\", np.allclose(result1.x, result2.x))\nprint(f\"Best value: {result1.fun:.6f}\")\n\nResults are identical: True\nBest value: 3.201102",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#advanced-topics",
    "href": "reproducibility.html#advanced-topics",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.4 Advanced Topics",
    "text": "15.4 Advanced Topics\n\n15.4.1 Seed and Noisy Functions\nWhen optimizing noisy functions with repeated evaluations, the seed ensures reproducible noise:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_sphere(X):\n    \"\"\"Sphere function with Gaussian noise\"\"\"\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=40,\n    n_initial=20,\n    repeats_initial=3,  # 3 evaluations per point\n    repeats_surrogate=2,\n    seed=42  # Ensures same noise pattern\n)\n\nresult = optimizer.optimize()\nprint(f\"Best mean value: {optimizer.min_mean_y:.6f}\")\nprint(f\"Variance at best: {optimizer.min_var_y:.6f}\")\n\nBest mean value: -0.006163\nVariance at best: 0.000243\n\n\nImportant: With the same seed, even the noise will be identical across runs!\n\n\n15.4.2 Different Seeds for Different Exploration\nUse different seeds to explore different regions systematically:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef griewank(X):\n    \"\"\"Griewank function\"\"\"\n    sum_sq = np.sum(X**2 / 4000, axis=1)\n    prod_cos = np.prod(np.cos(X / np.sqrt(np.arange(1, X.shape[1] + 1))), axis=1)\n    return sum_sq - prod_cos + 1\n\n# Systematic exploration with different seeds\nbest_overall = float('inf')\nbest_seed = None\n\nfor seed in range(10, 20):  # Seeds 10-19\n    optimizer = SpotOptim(\n        fun=griewank,\n        bounds=[(-600, 600), (-600, 600)],\n        max_iter=50,\n        n_initial=25,\n        seed=seed\n    )\n    result = optimizer.optimize()\n    \n    if result.fun &lt; best_overall:\n        best_overall = result.fun\n        best_seed = seed\n    \n    print(f\"Seed {seed}: f(x) = {result.fun:.6f}\")\n\nprint(f\"\\nBest result with seed {best_seed}: {best_overall:.6f}\")\n\nSeed 10: f(x) = 4.597121\nSeed 11: f(x) = 1.946733\nSeed 12: f(x) = 6.030579\nSeed 13: f(x) = 0.851170\nSeed 14: f(x) = 0.154832\nSeed 15: f(x) = 0.044427\nSeed 16: f(x) = 8.343419\nSeed 17: f(x) = 0.547492\nSeed 18: f(x) = 2.121439\nSeed 19: f(x) = 0.257388\n\nBest result with seed 15: 0.044427",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#best-practices",
    "href": "reproducibility.html#best-practices",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.5 Best Practices",
    "text": "15.5 Best Practices\n\n15.5.1 1. Always Use Seeds for Production Code\n\n# Good: Reproducible\noptimizer = SpotOptim(fun=objective, bounds=bounds, seed=42)\n\n# Risky: Non-reproducible\noptimizer = SpotOptim(fun=objective, bounds=bounds)\n\n\n\n15.5.2 2. Document Your Seeds\n\n# Configuration for experiment reported in Section 4.2\nEXPERIMENT_SEED = 2024\nMAX_ITERATIONS = 100\n\noptimizer = SpotOptim(\n    fun=my_objective,\n    bounds=my_bounds,\n    max_iter=MAX_ITERATIONS,\n    seed=EXPERIMENT_SEED\n)\n\n\n\n15.5.3 3. Use Different Seeds for Different Experiments\n\n# Different experiments should use different seeds\nBASELINE_SEED = 100\nEXPERIMENT_A_SEED = 200\nEXPERIMENT_B_SEED = 300\n\n\n\n15.5.4 4. Test Robustness Across Multiple Seeds\n\n# Run same optimization with multiple seeds\nfor seed in [42, 123, 456, 789, 1011]:\n    optimizer = SpotOptim(fun=objective, bounds=bounds, seed=seed)\n    result = optimizer.optimize()\n    # Analyze results",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#what-the-seed-controls",
    "href": "reproducibility.html#what-the-seed-controls",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.6 What the Seed Controls",
    "text": "15.6 What the Seed Controls\nThe seed parameter ensures reproducibility by controlling:\n\nInitial Design Generation: Latin Hypercube Sampling produces the same initial points\nSurrogate Model: Gaussian Process random initialization is identical\nAcquisition Optimization: Differential evolution explores the same candidates\nRandom Sampling: Any random exploration uses the same random numbers\n\nThis guarantees that the entire optimization pipeline is deterministic and reproducible.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#common-questions",
    "href": "reproducibility.html#common-questions",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.7 Common Questions",
    "text": "15.7 Common Questions\nQ: Can I use seed=0?\nA: Yes, any integer (including 0) is a valid seed.\nQ: Will different Python versions give the same results?\nA: Generally yes, but minor numerical differences may occur due to underlying library changes. Use the same environment for exact reproducibility.\nQ: Does the seed affect the objective function?\nA: No, the seed only affects SpotOptim’s internal random processes. If your objective function has its own randomness, you’ll need to control that separately.\nQ: How do I choose a good seed value?\nA: Any integer works. Common choices are 42, 123, or dates (e.g., 20241112). What matters is consistency, not the specific value.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "reproducibility.html#summary",
    "href": "reproducibility.html#summary",
    "title": "15  Reproducibility in SpotOptim",
    "section": "15.8 Summary",
    "text": "15.8 Summary\n\nUse seed parameter for reproducible optimization\nSame seed → identical results (every time)\nNo seed → different results (random exploration)\n\nEssential for research, debugging, and production\nDocument your seeds for transparency\nTest robustness with multiple different seeds",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibility in SpotOptim</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html",
    "href": "awwe_optimization.html",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "",
    "text": "16.1 The AWWE Objective Function\nWe use the same AWWE function from Chapter 1, which models the weight of an unpainted light aircraft wing. The function accepts inputs in the unit cube \\([0,1]^9\\) and returns the wing weight.\ndef wingwt(x):\n    \"\"\"\n    Aircraft Wing Weight function.\n    \n    Args:\n        x: array-like of 9 values in [0,1]\n           [Sw, Wfw, A, L, q, l, Rtc, Nz, Wdg]\n    \n    Returns:\n        Wing weight (scalar)\n    \"\"\"\n    # Ensure x is a 2D array for batch evaluation\n    x = np.atleast_2d(x)\n    \n    # Transform from unit cube to natural scales\n    Sw = x[:, 0] * (200 - 150) + 150 \n    Wfw = x[:, 1] * (300 - 220) + 220 \n    A = x[:, 2] * (10 - 6) + 6 \n    L = (x[:, 3] * (10 - (-10)) - 10) * np.pi/180\n    q = x[:, 4] * (45 - 16) + 16 \n    l = x[:, 5] * (1 - 0.5) + 0.5  \n    Rtc = x[:, 6] * (0.18 - 0.08) + 0.08\n    Nz = x[:, 7] * (6 - 2.5) + 2.5\n    Wdg = x[:, 8] * (2500 - 1700) + 1700\n    \n    # Calculate weight on natural scale\n    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A/np.cos(L)**2)**0.6 * q**0.006 \n    W = W * l**0.04 * (100*Rtc/np.cos(L))**(-0.3) * (Nz*Wdg)**(0.49)\n    \n    return W.ravel()\n\n\n# Wrapper for scipy.optimize (expects 1D input, returns scalar)\ndef wingwt_scipy(x):\n    return float(wingwt(x.reshape(1, -1))[0])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#baseline-configuration",
    "href": "awwe_optimization.html#baseline-configuration",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.2 Baseline Configuration",
    "text": "16.2 Baseline Configuration\nThe baseline Cessna C172 Skyhawk configuration (coded in unit cube):\n\nbaseline_coded = np.array([0.48, 0.4, 0.38, 0.5, 0.62, 0.344, 0.4, 0.37, 0.38])\nbaseline_weight = wingwt(baseline_coded)[0]\nprint(f\"Baseline wing weight: {baseline_weight:.2f} lb\")\n\nBaseline wing weight: 233.91 lb",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#optimization-setup",
    "href": "awwe_optimization.html#optimization-setup",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.3 Optimization Setup",
    "text": "16.3 Optimization Setup\nWe’ll optimize the AWWE function starting from the baseline configuration using three different methods:\n\nSpotOptim: Bayesian optimization (good for expensive black-box functions)\nNelder-Mead: Derivative-free simplex method (robust but can be slow)\nBFGS: Quasi-Newton method (fast but requires smooth functions)\n\n\n# Starting point (baseline configuration)\nx0 = baseline_coded.copy()\n\n# Bounds for all methods (unit cube)\nbounds = [(0, 1)] * 9\n\n# Number of function evaluations budget\nmax_evals = 30\n\nprint(f\"Starting point: {x0}\")\nprint(f\"Starting weight: {baseline_weight:.2f} lb\")\n\nStarting point: [0.48  0.4   0.38  0.5   0.62  0.344 0.4   0.37  0.38 ]\nStarting weight: 233.91 lb",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#method-1-spotoptim-surrogate-model-based-optimization",
    "href": "awwe_optimization.html#method-1-spotoptim-surrogate-model-based-optimization",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.4 Method 1: SpotOptim (Surrogate Model Based Optimization)",
    "text": "16.4 Method 1: SpotOptim (Surrogate Model Based Optimization)\n\n# Start timing\nstart_time = time.time()\n\n# Configure SpotOptim\noptimizer_spot = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    x0=None,\n    max_iter=max_evals,\n    n_initial=10,  # Initial design points\n    var_name=['Sw', 'Wfw', 'A', 'L', 'q', 'l', 'Rtc', 'Nz', 'Wdg'],\n    acquisition='y',  # ei: Expected Improvement\n    max_surrogate_points=100,\n    seed=42,\n    verbose=True,\n    tensorboard_log=True,\n    tensorboard_clean=True\n)\n\nRemoved old TensorBoard logs: runs/spotoptim_20251202_003129\nCleaned 1 old TensorBoard log directory\nTensorBoard logging enabled: runs/spotoptim_20251202_024332",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#design-table",
    "href": "awwe_optimization.html#design-table",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.5 Design Table",
    "text": "16.5 Design Table\n\npprint.pprint(optimizer_spot.print_design_table())\n\n('| name   | type   |   lower |   upper |   default | trans   |\\n'\n '|--------|--------|---------|---------|-----------|---------|\\n'\n '| Sw     | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| Wfw    | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| A      | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| L      | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| q      | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| l      | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| Rtc    | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| Nz     | float  |  0.0000 |  1.0000 |    0.5000 | -       |\\n'\n '| Wdg    | float  |  0.0000 |  1.0000 |    0.5000 | -       |')",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#run-optimization",
    "href": "awwe_optimization.html#run-optimization",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.6 Run optimization",
    "text": "16.6 Run optimization\n\nresult_spot = optimizer_spot.optimize()\n\nInitial best: f(x) = 212.219714\nIteration 1: New best f(x) = 142.977744\nIteration 2: New best f(x) = 140.904175\nIteration 3: New best f(x) = 120.465251\nIteration 4: f(x) = 121.575842\nIteration 5: New best f(x) = 120.101053\nIteration 6: New best f(x) = 119.997018\nIteration 7: f(x) = 120.018134\nIteration 8: New best f(x) = 119.958665\nIteration 9: f(x) = 120.386522\nIteration 10: New best f(x) = 119.691338\nIteration 11: New best f(x) = 119.530080\nIteration 12: f(x) = 119.539469\nIteration 13: New best f(x) = 119.503677\nIteration 14: f(x) = 119.503691\nIteration 15: New best f(x) = 119.503672\nIteration 16: f(x) = 119.503718\nIteration 17: f(x) = 119.503685\nIteration 18: f(x) = 119.503693\nIteration 19: f(x) = 119.503726\nIteration 20: f(x) = 119.503749\nTensorBoard writer closed. View logs with: tensorboard --logdir=runs/spotoptim_20251202_024332\n\n\n\n# End timing\nspot_time = time.time() - start_time\n\nprint(f\"\\nSpotOptim Results:\")\nprint(f\"  Best weight: {result_spot.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_spot.nfev}\")\nprint(f\"  Time elapsed: {spot_time:.2f} seconds\")\nprint(f\"  Success: {result_spot.success}\")\n\n\nSpotOptim Results:\n  Best weight: 119.5037 lb\n  Function evaluations: 30\n  Time elapsed: 6.69 seconds\n  Success: True\n\n\n\noptimizer_spot.print_best()\n\n\nBest Solution Found:\n--------------------------------------------------\n  Sw: 0.0000\n  Wfw: 0.0000\n  A: 0.0000\n  L: 0.5000\n  q: 0.0000\n  l: 0.0000\n  Rtc: 1.0000\n  Nz: 0.0000\n  Wdg: 0.0000\n  Objective Value: 119.5037\n  Total Evaluations: 30",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#result-table",
    "href": "awwe_optimization.html#result-table",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.7 Result Table",
    "text": "16.7 Result Table\n\npprint.pprint(optimizer_spot.print_results_table(show_importance=True))\n\n('| name   | type   |   lower |   upper |   tuned | trans   |   importance | '\n 'stars   |\\n'\n '|--------|--------|---------|---------|---------|---------|--------------|---------|\\n'\n '| Sw     | float  |  0.0000 |  1.0000 |  0.0000 | -       |         9.52 | '\n '*       |\\n'\n '| Wfw    | float  |  0.0000 |  1.0000 |  0.0000 | -       |        12.76 | '\n '*       |\\n'\n '| A      | float  |  0.0000 |  1.0000 |  0.0000 | -       |        14.11 | '\n '*       |\\n'\n '| L      | float  |  0.0000 |  1.0000 |  0.5000 | -       |         4.30 | '\n '*       |\\n'\n '| q      | float  |  0.0000 |  1.0000 |  0.0000 | -       |         6.10 | '\n '*       |\\n'\n '| l      | float  |  0.0000 |  1.0000 |  0.0000 | -       |        11.05 | '\n '*       |\\n'\n '| Rtc    | float  |  0.0000 |  1.0000 |  1.0000 | -       |        13.87 | '\n '*       |\\n'\n '| Nz     | float  |  0.0000 |  1.0000 |  0.0000 | -       |        14.03 | '\n '*       |\\n'\n '| Wdg    | float  |  0.0000 |  1.0000 |  0.0000 | -       |        14.27 | '\n '*       |\\n'\n '\\n'\n 'Interpretation: ***: &gt;95%, **: &gt;50%, *: &gt;1%, .: &gt;0.1%')",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#progress-of-the-optimization",
    "href": "awwe_optimization.html#progress-of-the-optimization",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.8 Progress of the Optimization",
    "text": "16.8 Progress of the Optimization\n\noptimizer_spot.plot_progress(log_y=False)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#contour-plots-of-most-important-hyperparameters",
    "href": "awwe_optimization.html#contour-plots-of-most-important-hyperparameters",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.9 Contour Plots of Most Important Hyperparameters",
    "text": "16.9 Contour Plots of Most Important Hyperparameters\n\noptimizer_spot.plot_important_hyperparameter_contour(max_imp=3)\n\nPlotting surrogate contours for top 3 most important parameters:\n  Wdg: importance = 14.27% (type: float)\n  A: importance = 14.11% (type: float)\n  Nz: importance = 14.03% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting Wdg vs A\n\n\n\n\n\n\n\n\n\n  Plotting Wdg vs Nz\n\n\n\n\n\n\n\n\n\n  Plotting A vs Nz",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#method-2-nelder-mead-simplex",
    "href": "awwe_optimization.html#method-2-nelder-mead-simplex",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.10 Method 2: Nelder-Mead Simplex",
    "text": "16.10 Method 2: Nelder-Mead Simplex\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Running Nelder-Mead Simplex...\")\nprint(\"=\" * 60)\n\n# Start timing\nstart_time = time.time()\n\n# Run optimization\nresult_nm = minimize(\n    wingwt_scipy,\n    x0=x0,\n    method='Nelder-Mead',\n    bounds=bounds,\n    options={'maxfev': max_evals, 'disp': True}\n)\n\n# End timing\nnm_time = time.time() - start_time\n\nprint(f\"\\nNelder-Mead Results:\")\nprint(f\"  Best weight: {result_nm.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_nm.nfev}\")\nprint(f\"  Time elapsed: {nm_time:.2f} seconds\")\nprint(f\"  Success: {result_nm.success}\")\n\n\n============================================================\nRunning Nelder-Mead Simplex...\n============================================================\n\nNelder-Mead Results:\n  Best weight: 220.5449 lb\n  Function evaluations: 30\n  Time elapsed: 0.00 seconds\n  Success: False",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#method-3-bfgs-quasi-newton",
    "href": "awwe_optimization.html#method-3-bfgs-quasi-newton",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.11 Method 3: BFGS (Quasi-Newton)",
    "text": "16.11 Method 3: BFGS (Quasi-Newton)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Running BFGS (Quasi-Newton)...\")\nprint(\"=\" * 60)\n\n\n# Start timing\nstart_time = time.time()\n\n# Run optimization\nresult_bfgs = minimize(\n    wingwt_scipy,\n    x0=x0,\n    method='L-BFGS-B',  # Bounded BFGS\n    bounds=bounds,\n    options={'maxfun': max_evals, 'disp': True}\n)\n\n# End timing\nbfgs_time = time.time() - start_time\n\nprint(f\"\\nBFGS Results:\")\nprint(f\"  Best weight: {result_bfgs.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_bfgs.nfev}\")\nprint(f\"  Time elapsed: {bfgs_time:.2f} seconds\")\nprint(f\"  Success: {result_bfgs.success}\")\n\n\n============================================================\nRunning BFGS (Quasi-Newton)...\n============================================================\n\nBFGS Results:\n  Best weight: 119.5037 lb\n  Function evaluations: 60\n  Time elapsed: 0.00 seconds\n  Success: False",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#comparison-of-results",
    "href": "awwe_optimization.html#comparison-of-results",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.12 Comparison of Results",
    "text": "16.12 Comparison of Results\n\n# Create comparison DataFrame\ncomparison = pd.DataFrame({\n    'Method': ['Baseline', 'SpotOptim', 'Nelder-Mead', 'BFGS'],\n    'Best Weight (lb)': [\n        baseline_weight,\n        result_spot.fun,\n        result_nm.fun,\n        result_bfgs.fun\n    ],\n    'Improvement (%)': [\n        0.0,\n        (baseline_weight - result_spot.fun) / baseline_weight * 100,\n        (baseline_weight - result_nm.fun) / baseline_weight * 100,\n        (baseline_weight - result_bfgs.fun) / baseline_weight * 100\n    ],\n    'Function Evals': [\n        1,\n        result_spot.nfev,\n        result_nm.nfev,\n        result_bfgs.nfev\n    ],\n    'Time (s)': [\n        0.0,\n        spot_time,\n        nm_time,\n        bfgs_time\n    ],\n    'Success': [\n        True,\n        result_spot.success,\n        result_nm.success,\n        result_bfgs.success\n    ]\n})\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"OPTIMIZATION COMPARISON\")\nprint(\"=\" * 80)\nprint(comparison.to_string(index=False))\nprint(\"=\" * 80)\n\n\n================================================================================\nOPTIMIZATION COMPARISON\n================================================================================\n     Method  Best Weight (lb)  Improvement (%)  Function Evals  Time (s)  Success\n   Baseline        233.908405         0.000000               1  0.000000     True\n  SpotOptim        119.503672        48.910057              30  6.687483     True\nNelder-Mead        220.544928         5.713124              30  0.000900    False\n       BFGS        119.503672        48.910057              60  0.001468    False\n================================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#visualization-convergence-plots",
    "href": "awwe_optimization.html#visualization-convergence-plots",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.13 Visualization: Convergence Plots",
    "text": "16.13 Visualization: Convergence Plots\n\n16.13.1 SpotOptim Convergence\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Best value over iterations\ny_history = optimizer_spot.y_\nbest_so_far = np.minimum.accumulate(y_history)\n\nax1.plot(range(len(y_history)), y_history, 'o', alpha=0.5, label='Evaluated points')\nax1.plot(range(len(best_so_far)), best_so_far, 'r-', linewidth=2, label='Best so far')\nax1.axhline(y=baseline_weight, color='g', linestyle='--', label='Baseline')\nax1.set_xlabel('Function Evaluation')\nax1.set_ylabel('Wing Weight (lb)')\nax1.set_title('SpotOptim Convergence')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Improvement over baseline\nimprovement = (baseline_weight - best_so_far) / baseline_weight * 100\nax2.plot(range(len(improvement)), improvement, 'b-', linewidth=2)\nax2.set_xlabel('Function Evaluation')\nax2.set_ylabel('Improvement over Baseline (%)')\nax2.set_title('SpotOptim Improvement Progress')\nax2.grid(True, alpha=0.3)\nax2.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#optimal-parameter-values",
    "href": "awwe_optimization.html#optimal-parameter-values",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.14 Optimal Parameter Values",
    "text": "16.14 Optimal Parameter Values\nLet’s examine the optimal parameter values found by each method:\n\n# Parameter names\nparam_names = ['Sw', 'Wfw', 'A', 'L', 'q', 'l', 'Rtc', 'Nz', 'Wdg']\n\n# Transform from unit cube to natural scales\ndef decode_params(x):\n    scales = [\n        (150, 200),      # Sw\n        (220, 300),      # Wfw\n        (6, 10),         # A\n        (-10, 10),       # L (degrees)\n        (16, 45),        # q\n        (0.5, 1),        # l\n        (0.08, 0.18),    # Rtc\n        (2.5, 6),        # Nz\n        (1700, 2500)     # Wdg\n    ]\n    decoded = []\n    for i, (low, high) in enumerate(scales):\n        decoded.append(x[i] * (high - low) + low)\n    return decoded\n\n# Create comparison table\nbaseline_decoded = decode_params(baseline_coded)\nspot_decoded = decode_params(result_spot.x)\nnm_decoded = decode_params(result_nm.x)\nbfgs_decoded = decode_params(result_bfgs.x)\n\nparam_comparison = pd.DataFrame({\n    'Parameter': param_names,\n    'Baseline': baseline_decoded,\n    'SpotOptim': spot_decoded,\n    'Nelder-Mead': nm_decoded,\n    'BFGS': bfgs_decoded\n})\n\nprint(\"\\n\" + \"=\" * 100)\nprint(\"OPTIMAL PARAMETER VALUES (Natural Scale)\")\nprint(\"=\" * 100)\nprint(param_comparison.to_string(index=False))\nprint(\"=\" * 100)\n\n\n====================================================================================================\nOPTIMAL PARAMETER VALUES (Natural Scale)\n====================================================================================================\nParameter  Baseline   SpotOptim  Nelder-Mead    BFGS\n       Sw   174.000  150.000000   173.923947  150.00\n      Wfw   252.000  220.000000   254.534988  220.00\n        A     7.520    6.000000     7.484111    6.00\n        L     0.000    0.000531    -0.126137    0.00\n        q    33.980   16.000000    34.156818   16.00\n        l     0.672    0.500000     0.674613    0.50\n      Rtc     0.120    0.180000     0.124872    0.18\n       Nz     3.795    2.500000     3.427058    2.50\n      Wdg  2004.000 1700.000000  2028.938270 1700.00\n====================================================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#analysis-of-optimal-solutions",
    "href": "awwe_optimization.html#analysis-of-optimal-solutions",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.15 Analysis of Optimal Solutions",
    "text": "16.15 Analysis of Optimal Solutions\n\n# Calculate percentage changes from baseline\nchanges_spot = [(spot_decoded[i] - baseline_decoded[i]) / baseline_decoded[i] * 100 \n                for i in range(len(param_names))]\nchanges_nm = [(nm_decoded[i] - baseline_decoded[i]) / baseline_decoded[i] * 100 \n              for i in range(len(param_names))]\nchanges_bfgs = [(bfgs_decoded[i] - baseline_decoded[i]) / baseline_decoded[i] * 100 \n                for i in range(len(param_names))]\n\n# Visualization\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nfor ax, changes, method in zip(axes, \n                                 [changes_spot, changes_nm, changes_bfgs],\n                                 ['SpotOptim', 'Nelder-Mead', 'BFGS']):\n    colors = ['red' if c &lt; 0 else 'green' for c in changes]\n    ax.barh(param_names, changes, color=colors, alpha=0.6)\n    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n    ax.set_xlabel('Change from Baseline (%)')\n    ax.set_title(f'{method}: Parameter Changes')\n    ax.grid(True, alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#key-insights-from-optimal-solutions",
    "href": "awwe_optimization.html#key-insights-from-optimal-solutions",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.16 Key Insights from Optimal Solutions",
    "text": "16.16 Key Insights from Optimal Solutions\n\n# Find parameters with largest changes for each method\ndef analyze_changes(decoded, baseline_decoded, method_name):\n    changes = {param_names[i]: decoded[i] - baseline_decoded[i] \n               for i in range(len(param_names))}\n    sorted_changes = sorted(changes.items(), key=lambda x: abs(x[1]), reverse=True)\n    \n    print(f\"\\n{method_name} - Top 5 Parameter Changes:\")\n    print(\"-\" * 50)\n    for param, change in sorted_changes[:5]:\n        idx = param_names.index(param)\n        pct = change / baseline_decoded[idx] * 100\n        print(f\"  {param:5s}: {change:+8.2f} ({pct:+6.1f}%)\")\n\nanalyze_changes(spot_decoded, baseline_decoded, \"SpotOptim\")\nanalyze_changes(nm_decoded, baseline_decoded, \"Nelder-Mead\")\nanalyze_changes(bfgs_decoded, baseline_decoded, \"BFGS\")\n\n\nSpotOptim - Top 5 Parameter Changes:\n--------------------------------------------------\n  Wdg  :  -304.00 ( -15.2%)\n  Wfw  :   -32.00 ( -12.7%)\n  Sw   :   -24.00 ( -13.8%)\n  q    :   -17.98 ( -52.9%)\n  A    :    -1.52 ( -20.2%)\n\nNelder-Mead - Top 5 Parameter Changes:\n--------------------------------------------------\n  Wdg  :   +24.94 (  +1.2%)\n  Wfw  :    +2.53 (  +1.0%)\n  Nz   :    -0.37 (  -9.7%)\n  q    :    +0.18 (  +0.5%)\n  L    :    -0.13 (  -inf%)\n\nBFGS - Top 5 Parameter Changes:\n--------------------------------------------------\n  Wdg  :  -304.00 ( -15.2%)\n  Wfw  :   -32.00 ( -12.7%)\n  Sw   :   -24.00 ( -13.8%)\n  q    :   -17.98 ( -52.9%)\n  A    :    -1.52 ( -20.2%)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#method-efficiency-comparison",
    "href": "awwe_optimization.html#method-efficiency-comparison",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.17 Method Efficiency Comparison",
    "text": "16.17 Method Efficiency Comparison\n\n# Calculate efficiency metrics\nefficiency = pd.DataFrame({\n    'Method': ['SpotOptim', 'Nelder-Mead', 'BFGS'],\n    'Weight Reduction (lb)': [\n        baseline_weight - result_spot.fun,\n        baseline_weight - result_nm.fun,\n        baseline_weight - result_bfgs.fun\n    ],\n    'Evals to Best': [\n        np.argmin(optimizer_spot.y_) + 1,\n        result_nm.nfev,\n        result_bfgs.nfev\n    ],\n    'Time per Eval (ms)': [\n        spot_time / result_spot.nfev * 1000,\n        nm_time / result_nm.nfev * 1000,\n        bfgs_time / result_bfgs.nfev * 1000\n    ]\n})\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"METHOD EFFICIENCY METRICS\")\nprint(\"=\" * 80)\nprint(efficiency.to_string(index=False))\nprint(\"=\" * 80)\n\n\n================================================================================\nMETHOD EFFICIENCY METRICS\n================================================================================\n     Method  Weight Reduction (lb)  Evals to Best  Time per Eval (ms)\n  SpotOptim             114.404734             25          222.916102\nNelder-Mead              13.363478             30            0.029993\n       BFGS             114.404734             60            0.024470\n================================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#visualization-2d-slices-of-optimal-solutions",
    "href": "awwe_optimization.html#visualization-2d-slices-of-optimal-solutions",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.18 Visualization: 2D Slices of Optimal Solutions",
    "text": "16.18 Visualization: 2D Slices of Optimal Solutions\nLet’s visualize how the optimal solutions compare in the most important 2D subspaces:\n\n# Create 2D slices showing optimal points\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# Important parameter pairs based on sensitivity analysis\npairs = [\n    (7, 2),  # Nz vs A (load factor vs aspect ratio)\n    (0, 8),  # Sw vs Wdg (wing area vs gross weight)\n    (7, 0),  # Nz vs Sw (load factor vs wing area)\n    (2, 6)   # A vs Rtc (aspect ratio vs thickness ratio)\n]\n\nfor ax, (i, j) in zip(axes.flat, pairs):\n    # Create meshgrid for contour plot\n    x_range = np.linspace(0, 1, 50)\n    y_range = np.linspace(0, 1, 50)\n    X, Y = np.meshgrid(x_range, y_range)\n    \n    # Evaluate function on grid (fixing other parameters at baseline)\n    Z = np.zeros_like(X)\n    for ii in range(X.shape[0]):\n        for jj in range(X.shape[1]):\n            point = baseline_coded.copy()\n            point[i] = X[ii, jj]\n            point[j] = Y[ii, jj]\n            Z[ii, jj] = wingwt(point)[0]\n    \n    # Plot contours\n    contour = ax.contourf(X, Y, Z, levels=20, cmap='viridis', alpha=0.6)\n    ax.contour(X, Y, Z, levels=10, colors='black', alpha=0.3, linewidths=0.5)\n    \n    # Plot optimal points\n    ax.plot(baseline_coded[i], baseline_coded[j], 'go', markersize=12, \n            label='Baseline', markeredgecolor='black', markeredgewidth=1.5)\n    ax.plot(result_spot.x[i], result_spot.x[j], 'r*', markersize=15, \n            label='SpotOptim', markeredgecolor='black', markeredgewidth=1)\n    ax.plot(result_nm.x[i], result_nm.x[j], 'bs', markersize=10, \n            label='Nelder-Mead', markeredgecolor='black', markeredgewidth=1)\n    ax.plot(result_bfgs.x[i], result_bfgs.x[j], 'c^', markersize=10, \n            label='BFGS', markeredgecolor='black', markeredgewidth=1)\n    \n    ax.set_xlabel(param_names[i])\n    ax.set_ylabel(param_names[j])\n    ax.set_title(f'{param_names[j]} vs {param_names[i]}')\n    ax.legend(loc='best', fontsize=8)\n    ax.grid(True, alpha=0.3)\n    \n    # Add colorbar\n    plt.colorbar(contour, ax=ax, label='Wing Weight (lb)')\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#conclusion",
    "href": "awwe_optimization.html#conclusion",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.19 Conclusion",
    "text": "16.19 Conclusion\nThis analysis demonstrates the application of different optimization methods to the Aircraft Wing Weight Example. Key takeaways:\n\nSpotOptim provides efficient global optimization with good exploration of the design space\nNelder-Mead offers robust derivative-free optimization but may require more evaluations\nBFGS converges quickly for smooth problems but can get trapped in local minima\n\nFor aircraft design problems with expensive simulations, Bayesian optimization (SpotOptim) offers the best balance of efficiency and solution quality, making it particularly suitable for real-world engineering applications.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "awwe_optimization.html#jupyter-notebook",
    "href": "awwe_optimization.html#jupyter-notebook",
    "title": "16  Optimizing the Aircraft Wing Weight Example",
    "section": "16.20 Jupyter Notebook",
    "text": "16.20 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Optimizing the Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html",
    "href": "surrogate_selection.html",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "",
    "text": "17.1 Introduction\nSurrogate models are the heart of Bayesian optimization. SpotOptim supports any scikit-learn compatible regressor, allowing you to choose the surrogate that best fits your problem characteristics:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#introduction",
    "href": "surrogate_selection.html#introduction",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "",
    "text": "Gaussian Processes: Provide uncertainty estimates, smooth interpolation, good for continuous functions. Support Expected Improvement (EI) acquisition.\nKriging: Similar to GP but with customizable correlation functions. Supports EI acquisition.\nRandom Forests: Robust to noise, handle discontinuities. Don’t provide uncertainty, so use acquisition='y' (greedy).\nXGBoost: Excellent for high-dimensional problems, fast training and prediction. Use acquisition='y'.\nSVR: Good for high-dimensional problems with smooth structure. Use acquisition='y'.\nGradient Boosting: Strong performance on structured problems. Use acquisition='y'.\n\n\n\n\n\n\n\nImportantAcquisition Functions and Uncertainty\n\n\n\nModels that provide uncertainty estimates (Gaussian Process, Kriging) work with all acquisition functions: ‘ei’ (Expected Improvement), ‘pi’ (Probability of Improvement), and ‘y’ (greedy).\nTree-based and other models (Random Forest, XGBoost, SVR, Gradient Boosting) don’t provide uncertainty estimates by default, so they should use acquisition='y' for greedy optimization. SpotOptim automatically handles this gracefully.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#setup-and-imports",
    "href": "surrogate_selection.html#setup-and-imports",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.2 Setup and Imports",
    "text": "17.2 Setup and Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Scikit-learn models\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import (\n    Matern, RBF, ConstantKernel, WhiteKernel, RationalQuadratic\n)\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\n\n\nXGBoost (if available)\n\n\ntry:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    XGBOOST_AVAILABLE = False\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n\nprint(\"Libraries imported successfully!\")\n\nLibraries imported successfully!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#the-awwe-objective-function",
    "href": "surrogate_selection.html#the-awwe-objective-function",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.3 The AWWE Objective Function",
    "text": "17.3 The AWWE Objective Function\nWe use the Aircraft Wing Weight Example function, which models the weight of an unpainted light aircraft wing. The function accepts inputs in the unit cube \\([0,1]^9\\) and returns the wing weight in pounds.\n\ndef wingwt(x):\n    \"\"\"\n    Aircraft Wing Weight function.\n    \n    Args:\n        x: array-like of 9 values in [0,1]\n           [Sw, Wfw, A, L, q, l, Rtc, Nz, Wdg]\n    \n    Returns:\n        Wing weight (scalar)\n    \"\"\"\n    # Ensure x is a 2D array for batch evaluation\n    x = np.atleast_2d(x)\n    \n    # Transform from unit cube to natural scales\n    Sw = x[:, 0] * (200 - 150) + 150      # Wing area (ft²)\n    Wfw = x[:, 1] * (300 - 220) + 220     # Fuel weight (lb)\n    A = x[:, 2] * (10 - 6) + 6            # Aspect ratio\n    L = (x[:, 3] * (10 - (-10)) - 10) * np.pi/180  # Sweep angle (rad)\n    q = x[:, 4] * (45 - 16) + 16          # Dynamic pressure (lb/ft²)\n    l = x[:, 5] * (1 - 0.5) + 0.5         # Taper ratio\n    Rtc = x[:, 6] * (0.18 - 0.08) + 0.08  # Root thickness/chord\n    Nz = x[:, 7] * (6 - 2.5) + 2.5        # Ultimate load factor\n    Wdg = x[:, 8] * (2500 - 1700) + 1700  # Design gross weight (lb)\n    \n    # Calculate weight on natural scale\n    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A/np.cos(L)**2)**0.6 * q**0.006 \n    W = W * l**0.04 * (100*Rtc/np.cos(L))**(-0.3) * (Nz*Wdg)**(0.49)\n    \n    return W.ravel()\n\n# Problem setup\nbounds = [(0, 1)] * 9\nparam_names = ['Sw', 'Wfw', 'A', 'L', 'q', 'l', 'Rtc', 'Nz', 'Wdg']\nmax_iter = 30\nn_initial = 10\nseed = 42\n\nprint(f\"Problem dimension: {len(bounds)}\")\nprint(f\"Optimization budget: {max_iter} evaluations\")\n\nProblem dimension: 9\nOptimization budget: 30 evaluations",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#default-surrogate-gaussian-process-with-matern-kernel",
    "href": "surrogate_selection.html#default-surrogate-gaussian-process-with-matern-kernel",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.4 1. Default Surrogate: Gaussian Process with Matern Kernel",
    "text": "17.4 1. Default Surrogate: Gaussian Process with Matern Kernel\nSpotOptim’s default surrogate is a Gaussian Process with a Matern kernel (ν=2.5), which provides twice-differentiable sample paths and good performance for most optimization problems.\n\nprint(\"=\" * 80)\nprint(\"1. DEFAULT: Gaussian Process with Matern ν=2.5 Kernel\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Default GP (no surrogate specified)\noptimizer_default = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='ei',\n    seed=seed,\n    verbose=False\n)\n\nresult_default = optimizer_default.optimize()\ntime_default = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_default.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_default.nfev}\")\nprint(f\"  Time: {time_default:.2f}s\")\nprint(f\"  Success: {result_default.success}\")\n\n# Store for comparison\nresults_comparison = [{\n    'Surrogate': 'GP Matern ν=2.5 (Default)',\n    'Best Weight': result_default.fun,\n    'Evaluations': result_default.nfev,\n    'Time (s)': time_default,\n    'Success': result_default.success\n}]\n\n================================================================================\n1. DEFAULT: Gaussian Process with Matern ν=2.5 Kernel\n================================================================================\n\nResults:\n  Best weight: 119.5041 lb\n  Function evaluations: 30\n  Time: 40.23s\n  Success: True\n\n\n\n17.4.1 Visualization: Default Surrogate\n\n# Plot convergence\noptimizer_default.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\n# Plot most important hyperparameters\noptimizer_default.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('Default GP Matern ν=2.5: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  A: importance = 19.62% (type: float)\n  Nz: importance = 19.50% (type: float)\n  Rtc: importance = 19.29% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting A vs Nz\n\n\n\n\n\n\n\n\n\n  Plotting A vs Rtc\n\n\n\n\n\n\n\n\n\n  Plotting Nz vs Rtc\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#gaussian-process-with-rbf-radial-basis-function-kernel",
    "href": "surrogate_selection.html#gaussian-process-with-rbf-radial-basis-function-kernel",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.5 2. Gaussian Process with RBF (Radial Basis Function) Kernel",
    "text": "17.5 2. Gaussian Process with RBF (Radial Basis Function) Kernel\nThe RBF kernel (also called squared exponential) produces infinitely differentiable sample paths, resulting in very smooth predictions.\n\nprint(\"=\" * 80)\nprint(\"2. Gaussian Process with RBF Kernel\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure GP with RBF kernel\nkernel_rbf = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(\n    length_scale=1.0, \n    length_scale_bounds=(1e-2, 1e2)\n)\n\ngp_rbf = GaussianProcessRegressor(\n    kernel=kernel_rbf,\n    n_restarts_optimizer=10,\n    normalize_y=True,\n    random_state=seed\n)\n\noptimizer_rbf = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=gp_rbf,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='ei',\n    seed=seed,\n    verbose=False\n)\n\nresult_rbf = optimizer_rbf.optimize()\ntime_rbf = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_rbf.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_rbf.nfev}\")\nprint(f\"  Time: {time_rbf:.2f}s\")\nprint(f\"  Success: {result_rbf.success}\")\n\nresults_comparison.append({\n    'Surrogate': 'GP RBF',\n    'Best Weight': result_rbf.fun,\n    'Evaluations': result_rbf.nfev,\n    'Time (s)': time_rbf,\n    'Success': result_rbf.success\n})\n\n================================================================================\n2. Gaussian Process with RBF Kernel\n================================================================================\n\nResults:\n  Best weight: 119.5037 lb\n  Function evaluations: 30\n  Time: 46.88s\n  Success: True\n\n\n\n17.5.1 Visualization: RBF Kernel\n\noptimizer_rbf.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_rbf.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('GP RBF Kernel: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  A: importance = 19.40% (type: float)\n  Nz: importance = 19.27% (type: float)\n  Rtc: importance = 19.06% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting A vs Nz\n\n\n\n\n\n\n\n\n\n  Plotting A vs Rtc\n\n\n\n\n\n\n\n\n\n  Plotting Nz vs Rtc\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#gaussian-process-with-matern-ν1.5-kernel",
    "href": "surrogate_selection.html#gaussian-process-with-matern-ν1.5-kernel",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.6 3. Gaussian Process with Matern ν=1.5 Kernel",
    "text": "17.6 3. Gaussian Process with Matern ν=1.5 Kernel\nThe Matern ν=1.5 kernel produces once-differentiable sample paths, allowing for more flexible (less smooth) fits than ν=2.5.\n\nprint(\"=\" * 80)\nprint(\"3. Gaussian Process with Matern ν=1.5 Kernel\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure GP with Matern nu=1.5\nkernel_matern15 = ConstantKernel(1.0, (1e-3, 1e3)) * Matern(\n    length_scale=1.0, \n    length_scale_bounds=(1e-2, 1e2),\n    nu=1.5\n)\n\ngp_matern15 = GaussianProcessRegressor(\n    kernel=kernel_matern15,\n    n_restarts_optimizer=10,\n    normalize_y=True,\n    random_state=seed\n)\n\noptimizer_matern15 = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=gp_matern15,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='ei',\n    seed=seed,\n    verbose=False\n)\n\nresult_matern15 = optimizer_matern15.optimize()\ntime_matern15 = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_matern15.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_matern15.nfev}\")\nprint(f\"  Time: {time_matern15:.2f}s\")\nprint(f\"  Success: {result_matern15.success}\")\n\nresults_comparison.append({\n    'Surrogate': 'GP Matern ν=1.5',\n    'Best Weight': result_matern15.fun,\n    'Evaluations': result_matern15.nfev,\n    'Time (s)': time_matern15,\n    'Success': result_matern15.success\n})\n\n================================================================================\n3. Gaussian Process with Matern ν=1.5 Kernel\n================================================================================\n\nResults:\n  Best weight: 119.5056 lb\n  Function evaluations: 30\n  Time: 38.48s\n  Success: True\n\n\n\n17.6.1 Visualization: Matern ν=1.5 Kernel\n\noptimizer_matern15.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_matern15.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('GP Matern ν=1.5 Kernel: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  Wdg: importance = 18.62% (type: float)\n  A: importance = 18.41% (type: float)\n  Nz: importance = 18.30% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting Wdg vs A\n\n\n\n\n\n\n\n\n\n  Plotting Wdg vs Nz\n\n\n\n\n\n\n\n\n\n  Plotting A vs Nz\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#gaussian-process-with-rational-quadratic-kernel",
    "href": "surrogate_selection.html#gaussian-process-with-rational-quadratic-kernel",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.7 4. Gaussian Process with Rational Quadratic Kernel",
    "text": "17.7 4. Gaussian Process with Rational Quadratic Kernel\nThe Rational Quadratic kernel is a scale mixture of RBF kernels with different length scales, providing more flexibility than a single RBF.\n\nprint(\"=\" * 80)\nprint(\"4. Gaussian Process with Rational Quadratic Kernel\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure GP with Rational Quadratic kernel\nkernel_rq = ConstantKernel(1.0, (1e-3, 1e3)) * RationalQuadratic(\n    length_scale=1.0,\n    alpha=1.0,\n    length_scale_bounds=(1e-2, 1e2),\n    alpha_bounds=(1e-2, 1e2)\n)\n\ngp_rq = GaussianProcessRegressor(\n    kernel=kernel_rq,\n    n_restarts_optimizer=10,\n    normalize_y=True,\n    random_state=seed\n)\n\noptimizer_rq = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=gp_rq,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='ei',\n    seed=seed,\n    verbose=False\n)\n\nresult_rq = optimizer_rq.optimize()\ntime_rq = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_rq.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_rq.nfev}\")\nprint(f\"  Time: {time_rq:.2f}s\")\nprint(f\"  Success: {result_rq.success}\")\n\nresults_comparison.append({\n    'Surrogate': 'GP Rational Quadratic',\n    'Best Weight': result_rq.fun,\n    'Evaluations': result_rq.nfev,\n    'Time (s)': time_rq,\n    'Success': result_rq.success\n})\n\n================================================================================\n4. Gaussian Process with Rational Quadratic Kernel\n================================================================================\n\nResults:\n  Best weight: 119.5061 lb\n  Function evaluations: 30\n  Time: 46.24s\n  Success: True\n\n\n\n17.7.1 Visualization: Rational Quadratic Kernel\n\noptimizer_rq.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_rq.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('GP Rational Quadratic Kernel: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  A: importance = 18.94% (type: float)\n  Nz: importance = 18.82% (type: float)\n  Rtc: importance = 18.61% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting A vs Nz\n\n\n\n\n\n\n\n\n\n  Plotting A vs Rtc\n\n\n\n\n\n\n\n\n\n  Plotting Nz vs Rtc\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#spotoptim-kriging-model",
    "href": "surrogate_selection.html#spotoptim-kriging-model",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.8 5. SpotOptim Kriging Model",
    "text": "17.8 5. SpotOptim Kriging Model\nSpotOptim includes its own Kriging implementation optimized for sequential design. It uses Gaussian correlation function and optimizes hyperparameters via differential evolution.\n\nprint(\"=\" * 80)\nprint(\"5. SpotOptim Kriging Model\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure Kriging model\nkriging_model = Kriging(\n    noise=1e-10,          # Regularization parameter\n    kernel='gauss',       # Gaussian/RBF kernel\n    n_theta=None,         # Auto: use number of dimensions\n    min_theta=-3.0,       # Min log10(theta) bound\n    max_theta=2.0,        # Max log10(theta) bound\n    seed=seed\n)\n\noptimizer_kriging = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=kriging_model,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='ei',\n    seed=seed,\n    verbose=False\n)\n\nresult_kriging = optimizer_kriging.optimize()\ntime_kriging = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_kriging.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_kriging.nfev}\")\nprint(f\"  Time: {time_kriging:.2f}s\")\nprint(f\"  Success: {result_kriging.success}\")\n\nresults_comparison.append({\n    'Surrogate': 'SpotOptim Kriging',\n    'Best Weight': result_kriging.fun,\n    'Evaluations': result_kriging.nfev,\n    'Time (s)': time_kriging,\n    'Success': result_kriging.success\n})\n\n================================================================================\n5. SpotOptim Kriging Model\n================================================================================\n\nResults:\n  Best weight: 121.1616 lb\n  Function evaluations: 30\n  Time: 53.36s\n  Success: True\n\n\n\n17.8.1 Visualization: Kriging Model\n\noptimizer_kriging.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_kriging.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('SpotOptim Kriging: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  Nz: importance = 19.13% (type: float)\n  A: importance = 16.01% (type: float)\n  Wdg: importance = 14.70% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting Nz vs A\n\n\n\n\n\n\n\n\n\n  Plotting Nz vs Wdg\n\n\n\n\n\n\n\n\n\n  Plotting A vs Wdg\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#random-forest-regressor",
    "href": "surrogate_selection.html#random-forest-regressor",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.9 6. Random Forest Regressor",
    "text": "17.9 6. Random Forest Regressor\nRandom Forests are ensemble methods that handle noise well and can model discontinuities. They don’t naturally provide uncertainty estimates, so the acquisition function uses predictions only.\n\nprint(\"=\" * 80)\nprint(\"6. Random Forest Regressor\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure Random Forest\nrf_model = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=15,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    random_state=seed,\n    n_jobs=-1\n)\n\noptimizer_rf = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=rf_model,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='y',  # Use 'y' (greedy) since RF doesn't provide std\n    seed=seed,\n    verbose=False\n)\n\nresult_rf = optimizer_rf.optimize()\ntime_rf = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_rf.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_rf.nfev}\")\nprint(f\"  Time: {time_rf:.2f}s\")\nprint(f\"  Success: {result_rf.success}\")\nprint(f\"  Note: Using acquisition='y' (greedy) since RF doesn't provide uncertainty\")\n\nresults_comparison.append({\n    'Surrogate': 'Random Forest',\n    'Best Weight': result_rf.fun,\n    'Evaluations': result_rf.nfev,\n    'Time (s)': time_rf,\n    'Success': result_rf.success\n})\n\n================================================================================\n6. Random Forest Regressor\n================================================================================\n\nResults:\n  Best weight: 156.3874 lb\n  Function evaluations: 30\n  Time: 1178.96s\n  Success: True\n  Note: Using acquisition='y' (greedy) since RF doesn't provide uncertainty\n\n\n\n17.9.1 Visualization: Random Forest\n\noptimizer_rf.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_rf.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('Random Forest: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  Wdg: importance = 14.12% (type: float)\n  A: importance = 13.62% (type: float)\n  Rtc: importance = 13.43% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting Wdg vs A\n\n\n\n\n\n\n\n\n\n  Plotting Wdg vs Rtc\n\n\n\n\n\n\n\n\n\n  Plotting A vs Rtc\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#xgboost-regressor",
    "href": "surrogate_selection.html#xgboost-regressor",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.10 7. XGBoost Regressor",
    "text": "17.10 7. XGBoost Regressor\nXGBoost is a gradient boosting implementation known for excellent performance on structured data and fast training/prediction times.\n\nif XGBOOST_AVAILABLE:\n    print(\"=\" * 80)\n    print(\"7. XGBoost Regressor\")\n    print(\"=\" * 80)\n    \n    start_time = time.time()\n    \n    # Configure XGBoost\n    xgb_model = xgb.XGBRegressor(\n        n_estimators=100,\n        max_depth=6,\n        learning_rate=0.1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=seed,\n        n_jobs=-1\n    )\n    \n    optimizer_xgb = SpotOptim(\n        fun=wingwt,\n        bounds=bounds,\n        surrogate=xgb_model,\n        max_iter=max_iter,\n        n_initial=n_initial,\n        var_name=param_names,\n        acquisition='y',  # Use 'y' (greedy) since XGBoost doesn't provide std\n        seed=seed,\n        verbose=False\n    )\n    \n    result_xgb = optimizer_xgb.optimize()\n    time_xgb = time.time() - start_time\n    \n    print(f\"\\nResults:\")\n    print(f\"  Best weight: {result_xgb.fun:.4f} lb\")\n    print(f\"  Function evaluations: {result_xgb.nfev}\")\n    print(f\"  Time: {time_xgb:.2f}s\")\n    print(f\"  Success: {result_xgb.success}\")\n    print(f\"  Note: Using acquisition='y' (greedy) since XGBoost doesn't provide uncertainty\")\n    \n    results_comparison.append({\n        'Surrogate': 'XGBoost',\n        'Best Weight': result_xgb.fun,\n        'Evaluations': result_xgb.nfev,\n        'Time (s)': time_xgb,\n        'Success': result_xgb.success\n    })\n    \n    # Visualization\n    optimizer_xgb.plot_progress(log_y=False, figsize=(10, 5))\n    plt.title('XGBoost: Convergence')\n    plt.show()\n    \n    optimizer_xgb.plot_important_hyperparameter_contour(max_imp=3)\n    plt.suptitle('XGBoost: Most Important Parameters', y=1.02)\n    plt.show()\nelse:\n    print(\"=\" * 80)\n    print(\"7. XGBoost Regressor - SKIPPED (not installed)\")\n    print(\"=\" * 80)\n    print(\"Install XGBoost with: pip install xgboost\")\n\n================================================================================\n7. XGBoost Regressor\n================================================================================\n\nResults:\n  Best weight: 150.8548 lb\n  Function evaluations: 30\n  Time: 17.16s\n  Success: True\n  Note: Using acquisition='y' (greedy) since XGBoost doesn't provide uncertainty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting surrogate contours for top 3 most important parameters:\n  Nz: importance = 15.18% (type: float)\n  A: importance = 15.04% (type: float)\n  Wdg: importance = 14.49% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting Nz vs A\n\n\n\n\n\n\n\n\n\n  Plotting Nz vs Wdg\n\n\n\n\n\n\n\n\n\n  Plotting A vs Wdg\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#support-vector-regression-svr",
    "href": "surrogate_selection.html#support-vector-regression-svr",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.11 8. Support Vector Regression (SVR)",
    "text": "17.11 8. Support Vector Regression (SVR)\nSVR with RBF kernel can model complex non-linear relationships. It’s particularly good for high-dimensional problems with smooth structure.\n\nprint(\"=\" * 80)\nprint(\"8. Support Vector Regression (SVR)\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure SVR\nsvr_model = SVR(\n    kernel='rbf',\n    C=100.0,\n    epsilon=0.1,\n    gamma='scale'\n)\n\noptimizer_svr = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=svr_model,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='y',  # Use 'y' (greedy) since SVR doesn't provide std by default\n    seed=seed,\n    verbose=False\n)\n\nresult_svr = optimizer_svr.optimize()\ntime_svr = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_svr.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_svr.nfev}\")\nprint(f\"  Time: {time_svr:.2f}s\")\nprint(f\"  Success: {result_svr.success}\")\n\nresults_comparison.append({\n    'Surrogate': 'SVR (RBF)',\n    'Best Weight': result_svr.fun,\n    'Evaluations': result_svr.nfev,\n    'Time (s)': time_svr,\n    'Success': result_svr.success\n})\n\n================================================================================\n8. Support Vector Regression (SVR)\n================================================================================\n\nResults:\n  Best weight: 140.0109 lb\n  Function evaluations: 30\n  Time: 1.71s\n  Success: True\n\n\n\n17.11.1 Visualization: SVR\n\noptimizer_svr.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_svr.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('Support Vector Regression: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  A: importance = 18.74% (type: float)\n  Rtc: importance = 18.17% (type: float)\n  Wdg: importance = 18.14% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting A vs Rtc\n\n\n\n\n\n\n\n\n\n  Plotting A vs Wdg\n\n\n\n\n\n\n\n\n\n  Plotting Rtc vs Wdg\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#gradient-boosting-regressor",
    "href": "surrogate_selection.html#gradient-boosting-regressor",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.12 9. Gradient Boosting Regressor",
    "text": "17.12 9. Gradient Boosting Regressor\nGradient Boosting from scikit-learn is another ensemble method that builds trees sequentially, with each tree correcting errors of the previous ones.\n\nprint(\"=\" * 80)\nprint(\"9. Gradient Boosting Regressor\")\nprint(\"=\" * 80)\n\nstart_time = time.time()\n\n# Configure Gradient Boosting\ngb_model = GradientBoostingRegressor(\n    n_estimators=100,\n    max_depth=5,\n    learning_rate=0.1,\n    subsample=0.8,\n    random_state=seed\n)\n\noptimizer_gb = SpotOptim(\n    fun=wingwt,\n    bounds=bounds,\n    surrogate=gb_model,\n    max_iter=max_iter,\n    n_initial=n_initial,\n    var_name=param_names,\n    acquisition='y',  # Use 'y' (greedy) since GB doesn't provide std\n    seed=seed,\n    verbose=False\n)\n\nresult_gb = optimizer_gb.optimize()\ntime_gb = time.time() - start_time\n\nprint(f\"\\nResults:\")\nprint(f\"  Best weight: {result_gb.fun:.4f} lb\")\nprint(f\"  Function evaluations: {result_gb.nfev}\")\nprint(f\"  Time: {time_gb:.2f}s\")\nprint(f\"  Success: {result_gb.success}\")\n\nresults_comparison.append({\n    'Surrogate': 'Gradient Boosting',\n    'Best Weight': result_gb.fun,\n    'Evaluations': result_gb.nfev,\n    'Time (s)': time_gb,\n    'Success': result_gb.success\n})\n\n================================================================================\n9. Gradient Boosting Regressor\n================================================================================\n\nResults:\n  Best weight: 124.6772 lb\n  Function evaluations: 30\n  Time: 7.34s\n  Success: True\n\n\n\n17.12.1 Visualization: Gradient Boosting\n\noptimizer_gb.plot_progress(log_y=False, figsize=(10, 5))\n\n\n\n\n\n\n\n\n\noptimizer_gb.plot_important_hyperparameter_contour(max_imp=3)\nplt.suptitle('Gradient Boosting: Most Important Parameters', y=1.02)\nplt.show()\n\nPlotting surrogate contours for top 3 most important parameters:\n  Wdg: importance = 16.80% (type: float)\n  A: importance = 16.28% (type: float)\n  Rtc: importance = 15.69% (type: float)\n\nGenerating 3 surrogate plots...\n  Plotting Wdg vs A\n\n\n\n\n\n\n\n\n\n  Plotting Wdg vs Rtc\n\n\n\n\n\n\n\n\n\n  Plotting A vs Rtc\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#comprehensive-comparison",
    "href": "surrogate_selection.html#comprehensive-comparison",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.13 Comprehensive Comparison",
    "text": "17.13 Comprehensive Comparison\nNow let’s compare all surrogate models side-by-side.\n\n# Create comparison DataFrame\ndf_comparison = pd.DataFrame(results_comparison)\n\n# Calculate improvement from best\nbest_weight = df_comparison['Best Weight'].min()\ndf_comparison['Gap to Best (%)'] = (\n    (df_comparison['Best Weight'] - best_weight) / best_weight * 100\n)\n\n# Sort by best weight\ndf_comparison = df_comparison.sort_values('Best Weight')\n\nprint(\"\\n\" + \"=\" * 100)\nprint(\"SURROGATE MODEL COMPARISON\")\nprint(\"=\" * 100)\nprint(df_comparison.to_string(index=False))\nprint(\"=\" * 100)\n\n\n====================================================================================================\nSURROGATE MODEL COMPARISON\n====================================================================================================\n                Surrogate  Best Weight  Evaluations    Time (s)  Success  Gap to Best (%)\n                   GP RBF   119.503672           30   46.875113     True         0.000000\nGP Matern ν=2.5 (Default)   119.504103           30   40.229772     True         0.000361\n          GP Matern ν=1.5   119.505612           30   38.478889     True         0.001624\n    GP Rational Quadratic   119.506083           30   46.236730     True         0.002017\n        SpotOptim Kriging   121.161582           30   53.355859     True         1.387330\n        Gradient Boosting   124.677233           30    7.339404     True         4.329207\n                SVR (RBF)   140.010945           30    1.714387     True        17.160371\n                  XGBoost   150.854809           30   17.155837     True        26.234455\n            Random Forest   156.387440           30 1178.963166     True        30.864130\n====================================================================================================\n\n\n\n17.13.1 Visualization: Performance Comparison\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Plot 1: Best weight comparison\nax1 = axes[0, 0]\ncolors = ['green' if i == 0 else 'steelblue' for i in range(len(df_comparison))]\nax1.barh(df_comparison['Surrogate'], df_comparison['Best Weight'], color=colors)\nax1.set_xlabel('Best Weight (lb)')\nax1.set_title('Best Weight Found by Each Surrogate')\nax1.axvline(x=best_weight, color='red', linestyle='--', linewidth=2, label='Best Overall')\nax1.legend()\nax1.grid(True, alpha=0.3, axis='x')\n\n# Plot 2: Computational time\nax2 = axes[0, 1]\nax2.barh(df_comparison['Surrogate'], df_comparison['Time (s)'], color='coral')\nax2.set_xlabel('Time (seconds)')\nax2.set_title('Computational Time')\nax2.grid(True, alpha=0.3, axis='x')\n\n# Plot 3: Gap to best\nax3 = axes[1, 0]\ncolors_gap = ['green' if gap &lt; 0.1 else 'orange' if gap &lt; 1.0 else 'red' \n              for gap in df_comparison['Gap to Best (%)']]\nax3.barh(df_comparison['Surrogate'], df_comparison['Gap to Best (%)'], color=colors_gap)\nax3.set_xlabel('Gap to Best Solution (%)')\nax3.set_title('Solution Quality (Lower is Better)')\nax3.axvline(x=1.0, color='black', linestyle='--', alpha=0.5, linewidth=1)\nax3.grid(True, alpha=0.3, axis='x')\n\n# Plot 4: Efficiency (weight reduction per second)\nax4 = axes[1, 1]\nbaseline_weight = wingwt(np.array([[0.48, 0.4, 0.38, 0.5, 0.62, 0.344, 0.4, 0.37, 0.38]]))[0]\ndf_comparison['Efficiency'] = (baseline_weight - df_comparison['Best Weight']) / df_comparison['Time (s)']\nax4.barh(df_comparison['Surrogate'], df_comparison['Efficiency'], color='mediumseagreen')\nax4.set_xlabel('Weight Reduction per Second (lb/s)')\nax4.set_title('Optimization Efficiency')\nax4.grid(True, alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#convergence-comparison",
    "href": "surrogate_selection.html#convergence-comparison",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.14 Convergence Comparison",
    "text": "17.14 Convergence Comparison\nLet’s compare how different surrogates converge over iterations.\n\nfig, ax = plt.subplots(figsize=(14, 8))\n\n# Collect convergence data from all optimizers\noptimizers = [\n    (optimizer_default, 'GP Matern ν=2.5 (Default)', 'blue'),\n    (optimizer_rbf, 'GP RBF', 'green'),\n    (optimizer_matern15, 'GP Matern ν=1.5', 'red'),\n    (optimizer_rq, 'GP Rational Quadratic', 'purple'),\n    (optimizer_kriging, 'SpotOptim Kriging', 'orange'),\n    (optimizer_rf, 'Random Forest', 'brown'),\n    (optimizer_svr, 'SVR', 'pink'),\n    (optimizer_gb, 'Gradient Boosting', 'gray')\n]\n\nif XGBOOST_AVAILABLE:\n    optimizers.append((optimizer_xgb, 'XGBoost', 'cyan'))\n\nfor opt, label, color in optimizers:\n    y_history = opt.y_\n    best_so_far = np.minimum.accumulate(y_history)\n    ax.plot(range(len(best_so_far)), best_so_far, linewidth=2, label=label, color=color)\n\nax.set_xlabel('Function Evaluation', fontsize=12)\nax.set_ylabel('Best Wing Weight Found (lb)', fontsize=12)\nax.set_title('Convergence Comparison: All Surrogates', fontsize=14, fontweight='bold')\nax.legend(loc='upper right', fontsize=10)\nax.grid(True, alpha=0.3)\nax.set_xlim(0, max_iter)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#key-insights-and-recommendations",
    "href": "surrogate_selection.html#key-insights-and-recommendations",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.15 Key Insights and Recommendations",
    "text": "17.15 Key Insights and Recommendations\n\nprint(\"\\n\" + \"=\" * 100)\nprint(\"KEY INSIGHTS AND RECOMMENDATIONS\")\nprint(\"=\" * 100)\n\n# Find best surrogate\nbest_surrogate = df_comparison.iloc[0]['Surrogate']\nbest_value = df_comparison.iloc[0]['Best Weight']\nbest_time = df_comparison.iloc[0]['Time (s)']\n\nprint(f\"\\n1. BEST OVERALL PERFORMANCE:\")\nprint(f\"   Surrogate: {best_surrogate}\")\nprint(f\"   Best Weight: {best_value:.4f} lb\")\nprint(f\"   Computation Time: {best_time:.2f}s\")\n\n# Find fastest\nfastest_idx = df_comparison['Time (s)'].idxmin()\nfastest_surrogate = df_comparison.loc[fastest_idx, 'Surrogate']\nfastest_time = df_comparison.loc[fastest_idx, 'Time (s)']\n\nprint(f\"\\n2. FASTEST OPTIMIZATION:\")\nprint(f\"   Surrogate: {fastest_surrogate}\")\nprint(f\"   Time: {fastest_time:.2f}s\")\nprint(f\"   Best Weight: {df_comparison.loc[fastest_idx, 'Best Weight']:.4f} lb\")\n\n# Find most efficient\nmost_efficient_idx = df_comparison['Efficiency'].idxmax()\nmost_efficient = df_comparison.loc[most_efficient_idx, 'Surrogate']\n\nprint(f\"\\n3. MOST EFFICIENT (weight reduction per second):\")\nprint(f\"   Surrogate: {most_efficient}\")\nprint(f\"   Efficiency: {df_comparison.loc[most_efficient_idx, 'Efficiency']:.4f} lb/s\")\n\nprint(f\"\\n4. RECOMMENDATIONS BY PROBLEM TYPE:\")\nprint(f\"   - Smooth, continuous functions: Gaussian Process with RBF or Matern ν=2.5\")\nprint(f\"   - Functions with noise: Random Forest or Gradient Boosting\")\nprint(f\"   - High-dimensional problems (&gt;20D): XGBoost or Random Forest\")\nprint(f\"   - Limited budget (&lt;50 evals): Gaussian Process with Expected Improvement\")\nprint(f\"   - Fast evaluation needed: XGBoost or Random Forest\")\nprint(f\"   - Need uncertainty estimates: Gaussian Process or Kriging\")\nprint(f\"   - Non-smooth/discontinuous: Random Forest or Gradient Boosting\")\n\nprint(f\"\\n5. KERNEL COMPARISON (Gaussian Process):\")\ngp_results = df_comparison[df_comparison['Surrogate'].str.contains('GP')]\nprint(gp_results[['Surrogate', 'Best Weight', 'Time (s)']].to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 100)\n\n\n====================================================================================================\nKEY INSIGHTS AND RECOMMENDATIONS\n====================================================================================================\n\n1. BEST OVERALL PERFORMANCE:\n   Surrogate: GP RBF\n   Best Weight: 119.5037 lb\n   Computation Time: 46.88s\n\n2. FASTEST OPTIMIZATION:\n   Surrogate: SVR (RBF)\n   Time: 1.71s\n   Best Weight: 140.0109 lb\n\n3. MOST EFFICIENT (weight reduction per second):\n   Surrogate: SVR (RBF)\n   Efficiency: 54.7703 lb/s\n\n4. RECOMMENDATIONS BY PROBLEM TYPE:\n   - Smooth, continuous functions: Gaussian Process with RBF or Matern ν=2.5\n   - Functions with noise: Random Forest or Gradient Boosting\n   - High-dimensional problems (&gt;20D): XGBoost or Random Forest\n   - Limited budget (&lt;50 evals): Gaussian Process with Expected Improvement\n   - Fast evaluation needed: XGBoost or Random Forest\n   - Need uncertainty estimates: Gaussian Process or Kriging\n   - Non-smooth/discontinuous: Random Forest or Gradient Boosting\n\n5. KERNEL COMPARISON (Gaussian Process):\n                Surrogate  Best Weight  Time (s)\n                   GP RBF   119.503672 46.875113\nGP Matern ν=2.5 (Default)   119.504103 40.229772\n          GP Matern ν=1.5   119.505612 38.478889\n    GP Rational Quadratic   119.506083 46.236730\n\n====================================================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#summary-statistics",
    "href": "surrogate_selection.html#summary-statistics",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.16 Summary Statistics",
    "text": "17.16 Summary Statistics\n\n# Summary statistics\nprint(\"\\n\" + \"=\" * 100)\nprint(\"SUMMARY STATISTICS\")\nprint(\"=\" * 100)\n\nsummary_stats = pd.DataFrame({\n    'Metric': [\n        'Best Weight Found',\n        'Worst Weight Found',\n        'Average Weight',\n        'Std Dev Weight',\n        'Fastest Time',\n        'Slowest Time',\n        'Average Time',\n    ],\n    'Value': [\n        f\"{df_comparison['Best Weight'].min():.4f} lb\",\n        f\"{df_comparison['Best Weight'].max():.4f} lb\",\n        f\"{df_comparison['Best Weight'].mean():.4f} lb\",\n        f\"{df_comparison['Best Weight'].std():.4f} lb\",\n        f\"{df_comparison['Time (s)'].min():.2f} s\",\n        f\"{df_comparison['Time (s)'].max():.2f} s\",\n        f\"{df_comparison['Time (s)'].mean():.2f} s\",\n    ]\n})\n\nprint(summary_stats.to_string(index=False))\nprint(\"=\" * 100)\n\n\n====================================================================================================\nSUMMARY STATISTICS\n====================================================================================================\n            Metric       Value\n Best Weight Found 119.5037 lb\nWorst Weight Found 156.3874 lb\n    Average Weight 130.1235 lb\n    Std Dev Weight  14.9095 lb\n      Fastest Time      1.71 s\n      Slowest Time   1178.96 s\n      Average Time    158.93 s\n====================================================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#conclusion",
    "href": "surrogate_selection.html#conclusion",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.17 Conclusion",
    "text": "17.17 Conclusion\nThis comprehensive comparison demonstrates that:\n\nGaussian Processes with appropriate kernels (Matern, RBF) provide excellent performance for smooth optimization problems and naturally support Expected Improvement acquisition\nSpotOptim Kriging offers a lightweight alternative to sklearn’s GP with comparable performance\nRandom Forest and XGBoost are robust alternatives that handle noise and discontinuities well, though they require greedy acquisition\nSVR and Gradient Boosting offer middle-ground solutions with good scalability\nThe choice of surrogate should be based on:\n\nFunction smoothness\nComputational budget\nNeed for uncertainty quantification\nProblem dimensionality\nNoise characteristics\n\n\nFor the AWWE problem, Gaussian Process surrogates generally performed best due to the function’s smooth structure, but tree-based methods (RF, XGBoost, GB) can be preferable for more complex, noisy, or high-dimensional problems.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "surrogate_selection.html#jupyter-notebook",
    "href": "surrogate_selection.html#jupyter-notebook",
    "title": "17  Surrogate Model Selection in SpotOptim",
    "section": "17.18 Jupyter Notebook",
    "text": "17.18 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Surrogate Model Selection in SpotOptim</span>"
    ]
  },
  {
    "objectID": "pinns_1.html",
    "href": "pinns_1.html",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "",
    "text": "19 Overview\nThis tutorial demonstrates how to use Physics-Informed Neural Networks (PINNs) to solve ordinary differential equations (ODEs) using SpotOptim’s LinearRegressor class. We’ll solve a first-order ODE with an initial condition, combining data-driven learning with physics constraints.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#the-differential-equation",
    "href": "pinns_1.html#the-differential-equation",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "19.1 The Differential Equation",
    "text": "19.1 The Differential Equation\nWe want to solve the following ODE:\n\\[\n\\frac{dy}{dt} + 0.1 y - \\sin\\left(\\frac{\\pi t}{2}\\right) = 0\n\\]\nwith initial condition:\n\\[\ny(0) = 0\n\\]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#loss-components-explained",
    "href": "pinns_1.html#loss-components-explained",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "24.1 Loss Components Explained",
    "text": "24.1 Loss Components Explained\n\n24.1.1 Neural Network Prediction on Data Points\nThe network predicts values at the training data points:\nyh = model(x_data)\n\n\n24.1.2 Data Loss (Loss1)\nMean squared error between predictions and actual data:\nloss1 = torch.mean((yh - y_data)**2)\n\n\n24.1.3 Neural Network Prediction on Collocation Points\nThe network predicts values at the physics enforcement points:\nyhp = model(x_physics)\n\n\n24.1.4 Computing Derivatives for the ODE\nWe compute dy/dt using automatic differentiation:\ndyhp_dxphysics = torch.autograd.grad(\n    yhp, x_physics, \n    torch.ones_like(yhp), \n    create_graph=True\n)[0]\n\n\n24.1.5 Physics Loss (Loss2)\nThe ODE residual at collocation points:\n\\[\n\\text{residual} = \\frac{dy}{dt} + 0.1 y - \\sin\\left(\\frac{\\pi t}{2}\\right)\n\\]\nphysics = dyhp_dxphysics + 0.1 * yhp - torch.sin(np.pi * x_physics / 2)\nloss2 = torch.mean(physics**2)\n\n\n24.1.6 Total Loss\nCombined loss with weighting factor α:\nloss = loss1 + alpha * loss2",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#training-loop",
    "href": "pinns_1.html#training-loop",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "24.2 Training Loop",
    "text": "24.2 Training Loop\n\nloss_history_pinn = []\nloss2_history_pinn = []\nplot_data_points_pinn = []\n\nalpha = 6e-2  # Weight for physics loss\nn_epochs = 48000\n\nprint(\"Training Physics-Informed Neural Network...\")\nprint(f\"Total epochs: {n_epochs}\")\nprint(f\"Physics loss weight (alpha): {alpha}\")\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    \n    # Data Loss: Fit the training data\n    yh = model(x_data)\n    loss1 = torch.mean((yh - y_data)**2)\n    \n    # Physics Loss: Satisfy the ODE at collocation points\n    yhp = model(x_physics)\n    dyhp_dxphysics = torch.autograd.grad(\n        yhp, x_physics, \n        torch.ones_like(yhp), \n        create_graph=True\n    )[0]\n    physics = dyhp_dxphysics + 0.1 * yhp - torch.sin(np.pi * x_physics / 2)\n    loss2 = torch.mean(physics**2)\n    \n    # Total Loss\n    loss = loss1 + alpha * loss2\n    loss.backward()\n    optimizer.step()\n    \n    # Store history every 100 steps\n    if (i + 1) % 100 == 0:\n        loss_history_pinn.append(loss.detach())\n        loss2_history_pinn.append(loss2.detach())\n    \n    # Store snapshots for visualization every 10000 steps\n    if (i + 1) % 10000 == 0:\n        current_yh_full = model(x).detach()\n        plot_data_points_pinn.append({\n            'yh': current_yh_full, \n            'step': i + 1\n        })\n        print(f\"Epoch {i+1}/{n_epochs}: Total Loss = {loss.item():.6f}, \"\n              f\"Physics Loss = {loss2.item():.6f}\")\n\nprint(\"Training completed!\")\n\nTraining Physics-Informed Neural Network...\nTotal epochs: 48000\nPhysics loss weight (alpha): 0.06\nEpoch 10000/48000: Total Loss = 0.000119, Physics Loss = 0.001705\nEpoch 20000/48000: Total Loss = 0.000035, Physics Loss = 0.000473\nEpoch 30000/48000: Total Loss = 0.000014, Physics Loss = 0.000225\nEpoch 40000/48000: Total Loss = 0.000181, Physics Loss = 0.000391\nTraining completed!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#training-progress",
    "href": "pinns_1.html#training-progress",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "25.1 Training Progress",
    "text": "25.1 Training Progress\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot total loss\nax1.plot(loss_history_pinn, 'b-', linewidth=1.5)\nax1.set_xlabel('Iteration (×100)', fontsize=11)\nax1.set_ylabel('Total Loss', fontsize=11)\nax1.set_title('Training Progress: Total Loss', fontsize=12)\nax1.grid(True, alpha=0.3)\nax1.set_yscale('log')\n\n# Plot physics loss\nax2.plot(loss2_history_pinn, 'r-', linewidth=1.5)\nax2.set_xlabel('Iteration (×100)', fontsize=11)\nax2.set_ylabel('Physics Loss', fontsize=11)\nax2.set_title('Training Progress: Physics Loss (ODE Residual)', fontsize=12)\nax2.grid(True, alpha=0.3)\nax2.set_yscale('log')\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#solution-evolution-during-training",
    "href": "pinns_1.html#solution-evolution-during-training",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "25.2 Solution Evolution During Training",
    "text": "25.2 Solution Evolution During Training\nVisualize how the neural network solution evolves during training:\n\nxp_plot = x_physics.detach()\n\nfor plot_info in plot_data_points_pinn:\n    plt.figure(figsize=(10, 6))\n    \n    # Plot exact solution\n    plt.plot(x.numpy(), y.numpy(), 'b-', linewidth=2, \n             label='Exact solution', alpha=0.7)\n    \n    # Plot training data\n    plt.scatter(x_data.numpy(), y_data.numpy(), color='tab:orange', \n                s=50, label='Training data', zorder=5)\n    \n    # Plot neural network prediction\n    plt.plot(x.numpy(), plot_info['yh'].numpy(), 'r--', linewidth=2,\n             label='PINN prediction', alpha=0.8)\n    \n    # Plot collocation points\n    plt.scatter(xp_plot.numpy(), \n                model(xp_plot).detach().numpy(),\n                color='green', marker='x', s=30, \n                label='Collocation points', alpha=0.6, zorder=4)\n    \n    plt.xlabel('Time t', fontsize=12)\n    plt.ylabel('Solution y(t)', fontsize=12)\n    plt.title(f'PINN Solution at Epoch {plot_info[\"step\"]}', fontsize=14)\n    plt.legend(fontsize=11)\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#final-solution-comparison",
    "href": "pinns_1.html#final-solution-comparison",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "25.3 Final Solution Comparison",
    "text": "25.3 Final Solution Comparison\n\n# Final prediction\nmodel.eval()\nwith torch.no_grad():\n    y_final = model(x)\n\nplt.figure(figsize=(12, 7))\n\n# Plot exact solution\nplt.plot(x.numpy(), y.numpy(), 'b-', linewidth=2.5, \n         label='Exact solution', alpha=0.8)\n\n# Plot PINN prediction\nplt.plot(x.numpy(), y_final.numpy(), 'r--', linewidth=2, \n         label='PINN prediction', alpha=0.8)\n\n# Plot training data\nplt.scatter(x_data.numpy(), y_data.numpy(), color='tab:orange', \n            s=80, label='Training data', zorder=5, edgecolors='black', linewidth=0.5)\n\n# Plot collocation points\nplt.scatter(x_physics.detach().numpy(), \n            model(x_physics).detach().numpy(),\n            color='green', marker='x', s=50, \n            label='Collocation points', alpha=0.7, zorder=4)\n\nplt.xlabel('Time t', fontsize=13)\nplt.ylabel('Solution y(t)', fontsize=13)\nplt.title('Final PINN Solution vs Exact Solution', fontsize=15, fontweight='bold')\nplt.legend(fontsize=12, loc='best')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#error-analysis",
    "href": "pinns_1.html#error-analysis",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "25.4 Error Analysis",
    "text": "25.4 Error Analysis\n\n# Compute absolute error\nerror = torch.abs(y_final - y)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x.numpy(), error.numpy(), 'r-', linewidth=2)\nplt.xlabel('Time t', fontsize=12)\nplt.ylabel('Absolute Error |y_exact - y_PINN|', fontsize=12)\nplt.title('PINN Approximation Error', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nError Statistics:\")\nprint(f\"Maximum absolute error: {error.max().item():.6f}\")\nprint(f\"Mean absolute error: {error.mean().item():.6f}\")\nprint(f\"Root mean squared error: {torch.sqrt(torch.mean(error**2)).item():.6f}\")\n\n\n\n\n\n\n\n\n\nError Statistics:\nMaximum absolute error: 0.072458\nMean absolute error: 0.008300\nRoot mean squared error: 0.013641",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#key-advantages-of-pinns",
    "href": "pinns_1.html#key-advantages-of-pinns",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "26.1 Key Advantages of PINNs",
    "text": "26.1 Key Advantages of PINNs\n\nData Efficiency: Can learn with very few data points\nPhysics Consistency: Solutions automatically satisfy the governing equations\nGeneralization: Better extrapolation beyond training data\nFlexibility: Can handle complex geometries and boundary conditions",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_1.html#using-spotoptim-for-hyperparameter-optimization",
    "href": "pinns_1.html#using-spotoptim-for-hyperparameter-optimization",
    "title": "18  Physics-Informed Neural Networks (PINNs) Demo 1",
    "section": "26.2 Using SpotOptim for Hyperparameter Optimization",
    "text": "26.2 Using SpotOptim for Hyperparameter Optimization\nThe LinearRegressor class integrates seamlessly with SpotOptim for hyperparameter tuning:\nfrom spotoptim import SpotOptim\n\ndef train_pinn(X):\n    \"\"\"Objective function for hyperparameter optimization.\"\"\"\n    results = []\n    for params in X:\n        l1 = int(params[0])           # Hidden layer size\n        num_layers = int(params[1])   # Number of layers\n        lr_unified = 10 ** params[2]  # Learning rate (log scale)\n        \n        # Create model\n        model = LinearRegressor(\n            input_dim=1, output_dim=1,\n            l1=l1, num_hidden_layers=num_layers,\n            activation=\"Tanh\", lr=lr_unified\n        )\n        \n        # Train PINN and compute validation error\n        # ... training code ...\n        \n        results.append(validation_error)\n    return np.array(results)\n\n# Optimize hyperparameters\noptimizer = SpotOptim(\n    fun=train_pinn,\n    bounds=[(16, 128), (1, 5), (-4, 0)],\n    var_type=[\"int\", \"int\", \"float\"],\n    var_name=[\"layer_size\", \"num_layers\", \"log_lr\"],\n    max_iter=50\n)\nresult = optimizer.optimize()\nThis approach allows you to systematically find the best network architecture and learning rate for your specific PINN problem.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Physics-Informed Neural Networks (PINNs) Demo 1</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html",
    "href": "pinns_2_hyperparameter_tuning.html",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "",
    "text": "20 Overview\nThis tutorial demonstrates how to use SpotOptim for hyperparameter optimization of Physics-Informed Neural Networks (PINNs). We’ll optimize the network architecture and training parameters to find the best configuration for solving an ordinary differential equation.\nBuilding on the basic PINN demo, we’ll now systematically search for optimal:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#key-features",
    "href": "pinns_2_hyperparameter_tuning.html#key-features",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "20.1 Key Features",
    "text": "20.1 Key Features\n\n20.1.1 1. PyTorch Dataset and DataLoader\nFollowing PyTorch best practices from the official tutorial, this tutorial implements:\n\nCustom Dataset Classes: Separate classes for supervised data (PINNDataset) and collocation points (CollocationDataset)\nDataLoader Integration: Efficient batch processing with configurable batch size, shuffling, and parallel loading\nProper Data Separation: Clean separation of training, validation, and collocation data\nGradient Tracking: Automatic gradient handling for collocation points needed in physics loss\n\nBenefits:\n\nModularity: Clean separation between data and model code\nEfficiency: Batch processing and optional parallel data loading\nScalability: Easy to extend to larger datasets\nBest Practices: Follows PyTorch conventions used across the ecosystem\n\n\n\n20.1.2 2. Automatic Transformation Handling\nThis tutorial also showcases SpotOptim’s var_trans feature for automatic variable transformations. Learning rates and regularization parameters are often best explored on a log scale, but manually transforming values is tedious and error-prone. With var_trans, you simply specify:\nvar_trans = [None, None, \"log10\", \"log10\"]\nSpotOptim then:\n\nOptimizes internally in log-transformed space (efficient exploration)\nPasses original-scale values to your objective function (no manual conversion needed)\nDisplays all results in original scale (easy interpretation)\n\nThis eliminates the need for manual 10**x conversions throughout your code!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#custom-dataset-classes",
    "href": "pinns_2_hyperparameter_tuning.html#custom-dataset-classes",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "23.1 Custom Dataset Classes",
    "text": "23.1 Custom Dataset Classes\nWe’ll create two dataset types:\n\nPINNDataset for supervised data (training and validation)\nCollocationDataset for physics-informed collocation points\n\n\nfrom torch.utils.data import Dataset, DataLoader\n\ndef oscillator(\n    n_steps: int = 3000,\n    t_min: float = 0.0,\n    t_max: float = 30.0,\n    y0: float = 0.0,\n    alpha: float = 0.1,\n    omega: float = np.pi / 2\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Solve ODE: dy/dt + alpha*y - sin(omega*t) = 0\n    using RK2 (midpoint method).\n    \n    Returns:\n        t_tensor: Time points, shape (n_steps, 1)\n        y_tensor: Solution values, shape (n_steps, 1)\n    \"\"\"\n    t_step = (t_max - t_min) / n_steps\n    t_points = np.arange(t_min, t_min + n_steps * t_step, t_step)[:n_steps]\n    \n    y = [y0]\n    \n    for t_current_step_end in t_points[1:]:\n        t_midpoint = t_current_step_end - t_step / 2.0\n        y_prev = y[-1]\n        \n        slope_at_t_mid = -alpha * y_prev + np.sin(omega * t_midpoint)\n        y_intermediate = y_prev + (t_step / 2.0) * slope_at_t_mid\n        \n        slope_at_t_end = -alpha * y_intermediate + np.sin(omega * t_current_step_end)\n        y_next = y_prev + t_step * slope_at_t_end\n        y.append(y_next)\n    \n    t_tensor = torch.tensor(t_points, dtype=torch.float32).view(-1, 1)\n    y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n    \n    return t_tensor, y_tensor\n\n\nclass PINNDataset(Dataset):\n    \"\"\"PyTorch Dataset for PINN supervised data (training/validation).\n    \n    This dataset stores time-solution pairs (t, y) for supervised learning.\n    \n    Args:\n        t (torch.Tensor): Time points, shape (n_samples, 1)\n        y (torch.Tensor): Solution values, shape (n_samples, 1)\n    \"\"\"\n    \n    def __init__(self, t: torch.Tensor, y: torch.Tensor):\n        self.t = t\n        self.y = y\n        \n    def __len__(self) -&gt; int:\n        return len(self.t)\n    \n    def __getitem__(self, idx: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        return self.t[idx], self.y[idx]\n\n\nclass CollocationDataset(Dataset):\n    \"\"\"PyTorch Dataset for PINN collocation points.\n    \n    This dataset stores time points where physics loss is evaluated.\n    Gradients are required for computing derivatives in the PDE.\n    \n    Args:\n        t (torch.Tensor): Collocation time points, shape (n_points, 1)\n    \"\"\"\n    \n    def __init__(self, t: torch.Tensor):\n        # Store collocation points with gradient tracking\n        self.t = t.requires_grad_(True)\n        \n    def __len__(self) -&gt; int:\n        return len(self.t)\n    \n    def __getitem__(self, idx: int) -&gt; torch.Tensor:\n        # Return single collocation point (still requires_grad)\n        return self.t[idx].unsqueeze(0)\n\nGenerate exact solution using RK2\n\nx_exact, y_exact = oscillator()\n\n# Create training data (sparse sampling)\nt_train = x_exact[0:3000:119]\ny_train = y_exact[0:3000:119]\n\n# Create validation data (different sampling for unbiased evaluation)\nt_val = x_exact[50:3000:120]\ny_val = y_exact[50:3000:120]\n\n# Create collocation points for physics loss\nt_physics = torch.linspace(0, 30, 50).view(-1, 1)\n\n# Create Dataset objects\ntrain_dataset = PINNDataset(t_train, y_train)\nval_dataset = PINNDataset(t_val, y_val)\ncollocation_dataset = CollocationDataset(t_physics)\n\nprint(f\"Training dataset size: {len(train_dataset)}\")\nprint(f\"Validation dataset size: {len(val_dataset)}\")\nprint(f\"Collocation dataset size: {len(collocation_dataset)}\")\nprint(f\"\\nSample from training dataset:\")\nt_sample, y_sample = train_dataset[0]\nprint(f\"  t: {t_sample.item():.4f}, y: {y_sample.item():.4f}\")\n\nTraining dataset size: 26\nValidation dataset size: 25\nCollocation dataset size: 50\n\nSample from training dataset:\n  t: 0.0000, y: 0.0000",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#define-the-objective-function",
    "href": "pinns_2_hyperparameter_tuning.html#define-the-objective-function",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "25.1 Define the Objective Function",
    "text": "25.1 Define the Objective Function\n\ndef objective_pinn(X):\n    \"\"\"\n    Objective function for SpotOptim.\n    \n    Args:\n        X: Array of hyperparameter configurations, shape (n_configs, 6)\n           Each row: [l1, num_layers, activation, optimizer, lr_unified, alpha]\n           Note: SpotOptim handles log transformations and factor mapping automatically\n    \n    Returns:\n        Array of validation errors\n    \"\"\"\n    results = []\n    \n    for i, params in enumerate(X):\n        # Extract parameters (already in original scale thanks to var_trans)\n        # Factor variables (activation, optimizer) are returned as strings\n        l1 = int(params[0])                    # Number of neurons\n        num_layers = int(params[1])            # Number of hidden layers\n        activation = params[2]                 # Activation function\n        optimizer_name = params[3]             # Optimizer algorithm\n        lr_unified = params[4]                 # Learning rate\n        alpha = params[5]                      # Physics weight\n        \n        print(f\"\\nConfiguration {i+1}/{len(X)}:\")\n        print(f\"  l1={l1}, num_layers={num_layers}, activation={activation}, \")\n        print(f\"  optimizer={optimizer_name}, lr_unified={lr_unified:.4f}, alpha={alpha:.4f}\")\n        \n        # Train PINN with these hyperparameters\n        val_error = train_pinn(\n            l1=l1,\n            num_layers=num_layers,\n            activation=activation,\n            optimizer_name=optimizer_name,\n            lr_unified=lr_unified,\n            alpha=alpha,\n            n_epochs=N_EPOCHS,\n            verbose=False\n        )\n        \n        print(f\"  Validation MSE: {val_error:.6f}\")\n        results.append(val_error)\n    \n    return np.array(results)\n\n# Test the objective function\nprint(\"Testing objective function with 2 configurations...\")\nX_test = np.array([\n    [32, 2, \"Tanh\", \"Adam\", 3.0, 0.06],    # Baseline config\n    [64, 3, \"ReLU\", \"AdamW\", 2.0, 0.04]    # Alternative config\n], dtype=object)\ntest_results = objective_pinn(X_test)\nprint(f\"\\nTest results: {test_results}\")\n\nTesting objective function with 2 configurations...\n\nConfiguration 1/2:\n  l1=32, num_layers=2, activation=Tanh, \n  optimizer=Adam, lr_unified=3.0000, alpha=0.0600\n  Validation MSE: 0.130621\n\nConfiguration 2/2:\n  l1=64, num_layers=3, activation=ReLU, \n  optimizer=AdamW, lr_unified=2.0000, alpha=0.0400\n  Validation MSE: 0.127441\n\nTest results: [0.13062107 0.12744086]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#run-the-optimization",
    "href": "pinns_2_hyperparameter_tuning.html#run-the-optimization",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "25.2 Run the Optimization",
    "text": "25.2 Run the Optimization\nUse tensorboard --logdir=runs from a shell in the current directory (where this notebook is located) to visualize the optimization process.\n\n# Define search space with var_trans for automatic log-scale handling\nbounds = [\n    (16, 128),                                      # l1: neurons per layer (16 to 128)\n    (1, 4),                                         # num_layers: 1 to 4 hidden layers\n    (\"Tanh\", \"ReLU\", \"Sigmoid\", \"GELU\"),         # activation: activation function\n    (\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"),          # optimizer: optimizer algorithm\n    (0.1, 10.0),                                    # lr_unified: learning rate (0.1 to 10)\n    (0.01, 1.0)                                     # alpha: physics weight (0.01 to 1.0)\n]\n\nvar_type = [\"int\", \"int\", \"factor\", \"factor\", \"float\", \"float\"]\nvar_name = [\"l1\", \"num_layers\", \"activation\", \"optimizer\", \"lr_unified\", \"alpha\"]\n\n# Use var_trans to handle log-scale transformations automatically\n# Factor variables don't need transformations (None)\nvar_trans = [None, None, None, None, \"log10\", \"log10\"]\n\n# Create optimizer\noptimizer = SpotOptim(\n    fun=objective_pinn,\n    bounds=bounds,\n    var_type=var_type,\n    var_name=var_name,\n    var_trans=var_trans,  # Automatic log-scale handling!\n    max_iter=MAX_ITER,\n    n_initial=10,\n    seed=42,\n    verbose=True,\n    tensorboard_clean=True,\n    tensorboard_log=True\n)\n\nFactor variable at dimension 2:\n  Levels: ['Tanh', 'ReLU', 'Sigmoid', 'GELU']\n  Mapped to integers: 0 to 3\nFactor variable at dimension 3:\n  Levels: ['Adam', 'SGD', 'RMSprop', 'AdamW']\n  Mapped to integers: 0 to 3\nRemoved old TensorBoard logs: runs/spotoptim_20251202_024345\nCleaned 1 old TensorBoard log directory\nTensorBoard logging enabled: runs/spotoptim_20251202_033330\n\n\nDisplay search space configuration. The transcolumn shows applied transformations. lr_unified and alpha use log10 transformation internally. This enables efficient exploration of log-scale parameters. All values shown are in original scale (not transformed).\n\n# Display search space configuration\ndesign_table = optimizer.print_design_table(tablefmt=\"github\")\nprint(design_table)\n\n| name       | type   | lower   | upper   | default   | trans   |\n|------------|--------|---------|---------|-----------|---------|\n| l1         | int    | 16.0    | 128.0   | 72        | -       |\n| num_layers | int    | 1.0     | 4.0     | 2         | -       |\n| activation | factor | Tanh    | GELU    | Sigmoid   | -       |\n| optimizer  | factor | Adam    | AdamW   | RMSprop   | -       |\n| lr_unified | float  | 0.1     | 10.0    | 5.05      | log10   |\n| alpha      | float  | 0.01    | 1.0     | 0.505     | log10   |\n\n\nRun optimization\n\nresult = optimizer.optimize()\n\n\nConfiguration 1/10:\n  l1=19, num_layers=3, activation=ReLU, \n  optimizer=SGD, lr_unified=9.5756, alpha=0.1603\n  Validation MSE: 0.194649\n\nConfiguration 2/10:\n  l1=30, num_layers=3, activation=ReLU, \n  optimizer=Adam, lr_unified=0.8430, alpha=0.0412\n  Validation MSE: 0.175142\n\nConfiguration 3/10:\n  l1=110, num_layers=4, activation=ReLU, \n  optimizer=AdamW, lr_unified=1.9457, alpha=0.3866\n  Validation MSE: 0.125290\n\nConfiguration 4/10:\n  l1=74, num_layers=1, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=0.1014, alpha=0.1050\n  Validation MSE: 0.188408\n\nConfiguration 5/10:\n  l1=41, num_layers=3, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=0.5877, alpha=0.7301\n  Validation MSE: 0.095178\n\nConfiguration 6/10:\n  l1=52, num_layers=1, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=0.2023, alpha=0.0145\n  Validation MSE: 0.184968\n\nConfiguration 7/10:\n  l1=71, num_layers=2, activation=Sigmoid, \n  optimizer=SGD, lr_unified=3.2551, alpha=0.4300\n  Validation MSE: 0.199493\n\nConfiguration 8/10:\n  l1=120, num_layers=3, activation=ReLU, \n  optimizer=AdamW, lr_unified=0.3330, alpha=0.0220\n  Validation MSE: 0.144155\n\nConfiguration 9/10:\n  l1=98, num_layers=2, activation=Tanh, \n  optimizer=SGD, lr_unified=4.3915, alpha=0.0293\n  Validation MSE: 0.182948\n\nConfiguration 10/10:\n  l1=87, num_layers=2, activation=GELU, \n  optimizer=SGD, lr_unified=1.4861, alpha=0.0949\n  Validation MSE: nan\nWarning: 1 initial design point(s) returned NaN/inf and will be ignored (reduced from 10 to 9 points)\nNote: Initial design size (9) is smaller than requested (10) due to NaN/inf values\nInitial best: f(x) = 0.095178\n\nConfiguration 1/1:\n  l1=41, num_layers=3, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=0.5938, alpha=0.7968\n  Validation MSE: 0.094611\nIteration 1: New best f(x) = 0.094611\n\nConfiguration 1/1:\n  l1=41, num_layers=3, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=0.9299, alpha=1.0000\n  Validation MSE: 0.130813\nIteration 2: f(x) = 0.130813\n\nConfiguration 1/1:\n  l1=110, num_layers=4, activation=ReLU, \n  optimizer=AdamW, lr_unified=1.9457, alpha=0.3866\n  Validation MSE: 0.105465\nIteration 3: f(x) = 0.105465\n\nConfiguration 1/1:\n  l1=52, num_layers=3, activation=ReLU, \n  optimizer=RMSprop, lr_unified=0.1454, alpha=0.0135\n  Validation MSE: 0.159544\nIteration 4: f(x) = 0.159544\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=115, num_layers=1, activation=Tanh, \n  optimizer=SGD, lr_unified=2.9394, alpha=0.0115\n  Validation MSE: nan\nWarning: Found 1 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 0.3155)\nIteration 5: f(x) = 0.365183\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=41, num_layers=2, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=6.4153, alpha=0.0157\n  Validation MSE: 0.190298\nIteration 6: f(x) = 0.190298\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=77, num_layers=3, activation=Sigmoid, \n  optimizer=SGD, lr_unified=4.4305, alpha=0.0194\n  Validation MSE: 0.202042\nIteration 7: f(x) = 0.202042\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=43, num_layers=2, activation=Sigmoid, \n  optimizer=SGD, lr_unified=0.6789, alpha=0.0502\n  Validation MSE: 0.203887\nIteration 8: f(x) = 0.203887\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=119, num_layers=3, activation=GELU, \n  optimizer=RMSprop, lr_unified=2.1892, alpha=0.5140\n  Validation MSE: 0.228413\nIteration 9: f(x) = 0.228413\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=116, num_layers=2, activation=Sigmoid, \n  optimizer=Adam, lr_unified=0.6885, alpha=0.2024\n  Validation MSE: 0.180719\nIteration 10: f(x) = 0.180719\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=62, num_layers=4, activation=Tanh, \n  optimizer=RMSprop, lr_unified=0.2720, alpha=0.6832\n  Validation MSE: 0.087061\nIteration 11: New best f(x) = 0.087061\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=73, num_layers=3, activation=Tanh, \n  optimizer=SGD, lr_unified=1.1299, alpha=0.2924\n  Validation MSE: 0.186883\nIteration 12: f(x) = 0.186883\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=91, num_layers=2, activation=Sigmoid, \n  optimizer=AdamW, lr_unified=0.2225, alpha=0.0161\n  Validation MSE: 0.194576\nIteration 13: f(x) = 0.194576\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=112, num_layers=2, activation=GELU, \n  optimizer=SGD, lr_unified=2.7386, alpha=0.0480\n  Validation MSE: nan\nWarning: Found 1 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 0.5429)\nIteration 14: f(x) = 0.529060\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=47, num_layers=2, activation=GELU, \n  optimizer=Adam, lr_unified=3.4640, alpha=0.8417\n  Validation MSE: 0.128958\nIteration 15: f(x) = 0.128958\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=66, num_layers=3, activation=ReLU, \n  optimizer=SGD, lr_unified=2.3213, alpha=0.0124\n  Validation MSE: nan\nWarning: Found 1 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 0.8074)\nIteration 16: f(x) = 0.872169\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=95, num_layers=2, activation=Sigmoid, \n  optimizer=Adam, lr_unified=4.6858, alpha=0.8132\n  Validation MSE: 0.000360\nIteration 17: New best f(x) = 0.000360\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=79, num_layers=1, activation=Tanh, \n  optimizer=SGD, lr_unified=0.1654, alpha=0.0163\n  Validation MSE: 0.195575\nIteration 18: f(x) = 0.195575\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=70, num_layers=3, activation=ReLU, \n  optimizer=SGD, lr_unified=1.7893, alpha=0.6472\n  Validation MSE: nan\nWarning: Found 1 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 1.3620)\nIteration 19: f(x) = 1.514328\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=44, num_layers=3, activation=Tanh, \n  optimizer=RMSprop, lr_unified=5.6818, alpha=0.0218\n  Validation MSE: 6.802989\nIteration 20: f(x) = 6.802989\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=111, num_layers=3, activation=ReLU, \n  optimizer=Adam, lr_unified=4.0470, alpha=0.2395\n  Validation MSE: 0.127627\nIteration 21: f(x) = 0.127627\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=41, num_layers=1, activation=ReLU, \n  optimizer=AdamW, lr_unified=9.3784, alpha=0.3473\n  Validation MSE: 0.171482\nIteration 22: f(x) = 0.171482\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=113, num_layers=2, activation=GELU, \n  optimizer=SGD, lr_unified=0.4088, alpha=0.0688\n  Validation MSE: 0.181295\nIteration 23: f(x) = 0.181295\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=106, num_layers=2, activation=ReLU, \n  optimizer=SGD, lr_unified=5.4687, alpha=0.5656\n  Validation MSE: nan\nWarning: Found 1 NaN/inf value(s), replacing with adaptive penalty (max + 3*std = 10.3793)\nIteration 24: f(x) = 10.355925\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=24, num_layers=3, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=0.4724, alpha=0.0123\n  Validation MSE: 0.143761\nIteration 25: f(x) = 0.143761\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=96, num_layers=1, activation=GELU, \n  optimizer=SGD, lr_unified=0.5396, alpha=0.6141\n  Validation MSE: 0.189695\nIteration 26: f(x) = 0.189695\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=112, num_layers=3, activation=Tanh, \n  optimizer=SGD, lr_unified=0.1361, alpha=0.0246\n  Validation MSE: 0.195050\nIteration 27: f(x) = 0.195050\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=76, num_layers=2, activation=GELU, \n  optimizer=AdamW, lr_unified=0.2194, alpha=0.0255\n  Validation MSE: 0.166782\nIteration 28: f(x) = 0.166782\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=102, num_layers=2, activation=ReLU, \n  optimizer=Adam, lr_unified=0.6220, alpha=0.1496\n  Validation MSE: 0.178802\nIteration 29: f(x) = 0.178802\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=86, num_layers=3, activation=ReLU, \n  optimizer=Adam, lr_unified=1.2365, alpha=0.3194\n  Validation MSE: 0.127320\nIteration 30: f(x) = 0.127320\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=101, num_layers=2, activation=ReLU, \n  optimizer=AdamW, lr_unified=7.3601, alpha=0.0647\n  Validation MSE: 0.130081\nIteration 31: f(x) = 0.130081\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=112, num_layers=2, activation=Sigmoid, \n  optimizer=AdamW, lr_unified=0.1439, alpha=0.4666\n  Validation MSE: 0.192847\nIteration 32: f(x) = 0.192847\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=96, num_layers=4, activation=GELU, \n  optimizer=AdamW, lr_unified=7.7483, alpha=0.4474\n  Validation MSE: 0.112189\nIteration 33: f(x) = 0.112189\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=122, num_layers=2, activation=ReLU, \n  optimizer=RMSprop, lr_unified=2.3122, alpha=0.0979\n  Validation MSE: 0.229986\nIteration 34: f(x) = 0.229986\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=30, num_layers=1, activation=GELU, \n  optimizer=RMSprop, lr_unified=3.3613, alpha=0.3171\n  Validation MSE: 0.187535\nIteration 35: f(x) = 0.187535\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=64, num_layers=3, activation=GELU, \n  optimizer=RMSprop, lr_unified=0.8964, alpha=0.6261\n  Validation MSE: 0.195397\nIteration 36: f(x) = 0.195397\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=35, num_layers=4, activation=Tanh, \n  optimizer=AdamW, lr_unified=0.2055, alpha=0.0157\n  Validation MSE: 0.183670\nIteration 37: f(x) = 0.183670\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=18, num_layers=2, activation=ReLU, \n  optimizer=SGD, lr_unified=0.2767, alpha=0.5381\n  Validation MSE: 0.203944\nIteration 38: f(x) = 0.203944\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=68, num_layers=2, activation=Tanh, \n  optimizer=RMSprop, lr_unified=1.6975, alpha=0.0526\n  Validation MSE: 2.660376\nIteration 39: f(x) = 2.660376\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=98, num_layers=4, activation=Sigmoid, \n  optimizer=RMSprop, lr_unified=3.4266, alpha=0.1841\n  Validation MSE: 0.874758\nIteration 40: f(x) = 0.874758\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\n\nConfiguration 1/1:\n  l1=87, num_layers=3, activation=Sigmoid, \n  optimizer=SGD, lr_unified=2.5483, alpha=0.0127\n  Validation MSE: 0.202666\nIteration 41: f(x) = 0.202666\nTensorBoard writer closed. View logs with: tensorboard --logdir=runs/spotoptim_20251202_033330",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#best-configuration",
    "href": "pinns_2_hyperparameter_tuning.html#best-configuration",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "26.1 Best Configuration",
    "text": "26.1 Best Configuration\nDisplay best hyperparameters using print_best() method. With var_trans, results are already in original scale!\n\noptimizer.print_best(result)\n\n\nBest Solution Found:\n--------------------------------------------------\n  l1: 95\n  num_layers: 2\n  activation: Sigmoid\n  optimizer: Adam\n  lr_unified: 4.6858\n  alpha: 0.8132\n  Objective Value: 0.0004\n  Total Evaluations: 50\n\n\nStore values for later use in visualizations. Values are already in original scale thanks to var_trans. Factor variables are returned as strings.\n\nbest_l1 = int(result.x[0])\nbest_num_layers = int(result.x[1])\nbest_activation = result.x[2]\nbest_optimizer = result.x[3]\nbest_lr_unified = result.x[4]\nbest_alpha = result.x[5]\nbest_val_error = result.fun\n\nprint(f\"Best activation: {best_activation}\")\nprint(f\"Best optimizer: {best_optimizer}\")\n\nBest activation: Sigmoid\nBest optimizer: Adam\n\n\n\n26.1.1 Results Table with Importance Scores\nDisplay comprehensive results table with importance scores\n\ntable = optimizer.print_results_table(show_importance=True, tablefmt=\"github\")\nprint(table)\n\n| name       | type   | lower   | upper   | tuned              | trans   |   importance | stars   |\n|------------|--------|---------|---------|--------------------|---------|--------------|---------|\n| l1         | int    | 16.0    | 128.0   | 95                 | -       |         5.74 | *       |\n| num_layers | int    | 1.0     | 4.0     | 2                  | -       |         3.42 | *       |\n| activation | factor | Tanh    | GELU    | Sigmoid            | -       |        38.13 | *       |\n| optimizer  | factor | Adam    | AdamW   | Adam               | -       |         6.76 | *       |\n| lr_unified | float  | 0.1     | 10.0    | 4.685806654938922  | log10   |        41.27 | *       |\n| alpha      | float  | 0.01    | 1.0     | 0.8131651565643412 | log10   |         4.68 | *       |\n\nInterpretation: ***: &gt;95%, **: &gt;50%, *: &gt;1%, .: &gt;0.1%",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#optimization-history",
    "href": "pinns_2_hyperparameter_tuning.html#optimization-history",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "26.2 Optimization History",
    "text": "26.2 Optimization History\n\noptimizer.plot_progress(log_y=True, ylabel=\"Validation MSE\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#surrogate-visualization",
    "href": "pinns_2_hyperparameter_tuning.html#surrogate-visualization",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "26.3 Surrogate Visualization",
    "text": "26.3 Surrogate Visualization\nVisualize the surrogate model’s learned response surface for the most important hyperparameter combinations:\n\n# Plot top 3 most important hyperparameter combinations\noptimizer.plot_important_hyperparameter_contour(max_imp=3)\n\nPlotting surrogate contours for top 3 most important parameters:\n  lr_unified: importance = 41.27% (type: float)\n  activation: importance = 38.13% (type: factor)\n  optimizer: importance = 6.76% (type: factor)\n\nGenerating 3 surrogate plots...\n  Plotting lr_unified vs activation\n\n\n\n\n\n\n\n\n\n  Plotting lr_unified vs optimizer\n\n\n\n\n\n\n\n\n\n  Plotting activation vs optimizer",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#parameter-distribution-analysis",
    "href": "pinns_2_hyperparameter_tuning.html#parameter-distribution-analysis",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "26.4 Parameter Distribution Analysis",
    "text": "26.4 Parameter Distribution Analysis\n\noptimizer.plot_parameter_scatter(\n    result,\n    ylabel=\"Validation MSE\",\n    cmap=\"plasma\",\n    figsize=(14, 12)\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#sensitivity-analysis-spearman-correlation",
    "href": "pinns_2_hyperparameter_tuning.html#sensitivity-analysis-spearman-correlation",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "31.1 Sensitivity Analysis (Spearman Correlation)",
    "text": "31.1 Sensitivity Analysis (Spearman Correlation)\n\n# Use the new sensitivity_spearman() method for tabular output\noptimizer.sensitivity_spearman()\n\n\nSensitivity Analysis (Spearman Correlation):\n--------------------------------------------------\n  l1                  : +0.093 (p=0.520)\n  num_layers          : -0.243 (p=0.089)\n  activation          : (categorical variable, use visual inspection)\n  optimizer           : (categorical variable, use visual inspection)\n  lr_unified          : +0.119 (p=0.410)\n  alpha               : -0.313 (p=0.027) *",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#key-findings",
    "href": "pinns_2_hyperparameter_tuning.html#key-findings",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "32.1 Key Findings",
    "text": "32.1 Key Findings\n\n# Get optimization history for statistics\nhistory = optimizer.y_\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"HYPERPARAMETER OPTIMIZATION SUMMARY\")\nprint(\"=\"*70)\n\nprint(\"\\n1. BEST CONFIGURATION FOUND:\")\nprint(f\"   - Neurons per layer (l1): {best_l1}\")\nprint(f\"   - Number of hidden layers: {best_num_layers}\")\nprint(f\"   - Activation function: {best_activation}\")\nprint(f\"   - Optimizer: {best_optimizer}\")\nprint(f\"   - Learning rate: {best_lr_unified:.4f}\")\nprint(f\"   - Physics weight (alpha): {best_alpha:.4f}\")\n\nprint(\"\\n2. PERFORMANCE:\")\nprint(f\"   - Validation MSE: {best_val_error:.6f}\")\nprint(f\"   - Full domain MSE: {full_mse:.6f}\")\nprint(f\"   - Maximum absolute error: {max_error:.6f}\")\n\nprint(\"\\n3. OPTIMIZATION STATISTICS:\")\nprint(f\"   - Total evaluations: {result.nfev}\")\nprint(f\"   - Initial best: {history[0]:.6f}\")\nprint(f\"   - Final best: {best_val_error:.6f}\")\nprint(f\"   - Improvement: {(1 - best_val_error/history[0])*100:.1f}%\")\n\nprint(\"\\n4. COMPARISON TO BASELINE:\")\nprint(f\"   - Baseline MSE: {baseline_error:.6f}\")\nprint(f\"   - Optimized MSE: {best_val_error:.6f}\")\nprint(f\"   - Improvement: {(1 - best_val_error/baseline_error)*100:.1f}%\")\n\nprint(\"\\n\" + \"=\"*70)\n\n\n======================================================================\nHYPERPARAMETER OPTIMIZATION SUMMARY\n======================================================================\n\n1. BEST CONFIGURATION FOUND:\n   - Neurons per layer (l1): 95\n   - Number of hidden layers: 2\n   - Activation function: Sigmoid\n   - Optimizer: Adam\n   - Learning rate: 4.6858\n   - Physics weight (alpha): 0.8132\n\n2. PERFORMANCE:\n   - Validation MSE: 0.000360\n   - Full domain MSE: 0.000267\n   - Maximum absolute error: 0.083369\n\n3. OPTIMIZATION STATISTICS:\n   - Total evaluations: 50\n   - Initial best: 0.194649\n   - Final best: 0.000360\n   - Improvement: 99.8%\n\n4. COMPARISON TO BASELINE:\n   - Baseline MSE: 0.058316\n   - Optimized MSE: 0.000360\n   - Improvement: 99.4%\n\n======================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#recommendations",
    "href": "pinns_2_hyperparameter_tuning.html#recommendations",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "32.2 Recommendations",
    "text": "32.2 Recommendations\nBased on the hyperparameter optimization results:\n\nNetwork Architecture:\n\nThe optimal architecture was found with {best_l1} neurons and {best_num_layers} hidden layers\nBest activation function: {best_activation}\nThis balances model capacity with training efficiency\n\nOptimizer Selection:\n\nBest optimizer: {best_optimizer}\nDifferent optimizers have different convergence characteristics for PINNs\n\nLearning Rate:\n\nOptimal unified learning rate: {best_lr_unified:.4f}\nThis translates to an actual Adam learning rate of {best_lr_unified * 0.001:.6f}\n\nPhysics Loss Weight:\n\nOptimal alpha: {best_alpha:.4f}\nThis balances data fitting with physics constraint satisfaction\n\nTraining Strategy:\n\nStart with a broad search space to explore different architectures\nUse var_trans with “log10” for learning rate and physics weight parameters\nThis enables efficient exploration of log-scale parameters without manual transformations\nValidate on held-out data to prevent overfitting to training points\n\nBenefits of var_trans and Factor Variables:\n\nFactor variables: Categorical choices (activation, optimizer) handled automatically\nSpotOptim maps strings to integers internally and back to strings in results\nCleaner code: No manual 10**x conversions in objective function\nFewer errors: Eliminates confusion about which scale values are in\nBetter optimization: Searches efficiently in transformed space\nEasier interpretation: All results displayed in original scale",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#using-these-results",
    "href": "pinns_2_hyperparameter_tuning.html#using-these-results",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "32.3 Using These Results",
    "text": "32.3 Using These Results\nTo use the optimized configuration in your own PINN problems:\n# Create optimized PINN\nmodel = LinearRegressor(\n    input_dim=1,\n    output_dim=1,\n    l1={best_l1},\n    num_hidden_layers={best_num_layers},\n    activation=\"{best_activation}\",\n    lr={best_lr_unified:.4f}\n)\n\noptimizer = model.get_optimizer(\"{best_optimizer}\")\n\n# Use alpha={best_alpha:.4f} for physics loss weight\nloss = data_loss + {best_alpha:.4f} * physics_loss",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#using-var_trans-for-your-hyperparameter-optimization",
    "href": "pinns_2_hyperparameter_tuning.html#using-var_trans-for-your-hyperparameter-optimization",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "32.4 Using var_trans for Your Hyperparameter Optimization",
    "text": "32.4 Using var_trans for Your Hyperparameter Optimization\nWhen setting up optimization for your own PINN problems:\nfrom spotoptim import SpotOptim\n\n# Define search space with factor variables and log-scale parameters\nbounds = [\n    (16, 128),                                    # neurons (integer)\n    (1, 4),                                       # layers (integer)\n    (\"Tanh\", \"ReLU\", \"Sigmoid\", \"GELU\"),       # activation (factor)\n    (\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"),        # optimizer (factor)\n    (0.1, 10.0),                                  # learning rate (log-scale)\n    (0.01, 1.0)                                   # physics weight (log-scale)\n]\n\nvar_type = [\"int\", \"int\", \"factor\", \"factor\", \"float\", \"float\"]\nvar_trans = [None, None, None, None, \"log10\", \"log10\"]\n\nopt = SpotOptim(\n    fun=your_objective_function,\n    bounds=bounds,\n    var_type=var_type,\n    var_trans=var_trans,  # Automatic log-scale and factor handling!\n    max_iter=MAX_ITER,\n    n_initial=10\n)\n\nresult = opt.optimize()\nYour objective function receives parameters in original scale - no manual transformations needed!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "pinns_2_hyperparameter_tuning.html#future-directions",
    "href": "pinns_2_hyperparameter_tuning.html#future-directions",
    "title": "19  Hyperparameter Tuning for Physics-Informed Neural Networks",
    "section": "32.5 Future Directions",
    "text": "32.5 Future Directions\nConsider exploring:\n\nAdaptive physics weights that change during training\nArchitecture search including skip connections or residual blocks\nBatch size optimization as an additional hyperparameter\nMulti-objective optimization balancing accuracy and computational cost\nTransfer learning from pre-optimized configurations\nLearning rate schedules with different decay strategies\n\n\nNote: The specific optimal values depend on the problem, data distribution, and computational budget. Always validate results on held-out test data.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Hyperparameter Tuning for Physics-Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html",
    "href": "acquisition_failure.html",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "",
    "text": "20.1 What is Acquisition Failure?\nSpotOptim provides sophisticated fallback strategies for handling acquisition function failures during optimization. This ensures robust optimization even when the surrogate model struggles to suggest new points.\nDuring surrogate-based optimization, the acquisition function suggests new points to evaluate. However, sometimes the suggested point is too close to existing points (within tolerance_x distance), which would provide little new information. When this happens, SpotOptim uses a fallback strategy to propose an alternative point.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#fallback-strategies",
    "href": "acquisition_failure.html#fallback-strategies",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.2 Fallback Strategies",
    "text": "20.2 Fallback Strategies\nSpotOptim supports two fallback strategies, controlled by the acquisition_failure_strategy parameter:\n\n20.2.1 1. Random Space-Filling Design (Default)\nStrategy name: \"random\"\nThis strategy uses Latin Hypercube Sampling (LHS) to generate a new space-filling point. LHS ensures good coverage of the search space by dividing each dimension into equal-probability intervals.\nWhen to use:\n\nGeneral-purpose optimization\nWhen you want simplicity and good space-filling properties\nDefault choice for most problems\n\nExample:\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=10,\n    acquisition_failure_strategy=\"random\",  # Default\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nTensorBoard logging disabled\nInitial best: f(x) = 1.910611\nIteration 1: New best f(x) = 0.047029\nIteration 2: New best f(x) = 0.022945\nIteration 3: New best f(x) = 0.003183\nIteration 4: New best f(x) = 0.000005\nIteration 5: New best f(x) = 0.000001\nIteration 6: New best f(x) = 0.000001\nIteration 7: New best f(x) = 0.000001\nIteration 8: New best f(x) = 0.000001\nIteration 9: f(x) = 0.000001\nIteration 10: f(x) = 0.000001\nIteration 11: New best f(x) = 0.000001\nIteration 12: f(x) = 0.000001\nIteration 13: f(x) = 0.000001\nIteration 14: f(x) = 0.000001\nIteration 15: f(x) = 0.000001\nIteration 16: f(x) = 0.000001\nIteration 17: f(x) = 0.000001\nIteration 18: f(x) = 0.000001\nIteration 19: f(x) = 0.000001\nIteration 20: f(x) = 0.000001\nIteration 21: f(x) = 0.000001\nIteration 22: f(x) = 0.000001\nIteration 23: f(x) = 0.000001\nIteration 24: f(x) = 0.000001\nIteration 25: f(x) = 0.000001\nIteration 26: f(x) = 0.000001\nIteration 27: f(x) = 0.000001\nIteration 28: f(x) = 0.000001\nIteration 29: f(x) = 0.000001\nIteration 30: f(x) = 0.000001\nIteration 31: f(x) = 0.000001\nIteration 32: f(x) = 0.000001\nIteration 33: f(x) = 0.000001\nIteration 34: f(x) = 0.000001\nIteration 35: f(x) = 0.000001\nIteration 36: f(x) = 0.000001\nIteration 37: f(x) = 0.000001\nIteration 38: f(x) = 0.000001\nIteration 39: f(x) = 0.000001\nIteration 40: f(x) = 0.000001\n\n\n\n\n20.2.2 2. Morris-Mitchell Minimizing Point\nStrategy name: \"mm\"\nThis strategy finds a point that maximizes the minimum distance to all existing points. It evaluates 100 candidate points and selects the one with the largest minimum distance to the already-evaluated points, providing excellent space-filling properties.\nWhen to use:\n\nWhen you want to ensure maximum exploration\nFor problems where avoiding clustering of points is critical\nWhen the search space has been heavily sampled in some regions\n\nExample:\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef rosenbrock(X):\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=100,\n    n_initial=20,\n    acquisition_failure_strategy=\"mm\",  # Morris-Mitchell\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nTensorBoard logging disabled\nInitial best: f(x) = 1.808504\nIteration 1: f(x) = 405.130265\nIteration 2: New best f(x) = 0.700479\nIteration 3: f(x) = 3.023480\nIteration 4: New best f(x) = 0.089801\nIteration 5: f(x) = 0.110801\nIteration 6: f(x) = 0.095351\nIteration 7: New best f(x) = 0.083392\nIteration 8: New best f(x) = 0.080909\nIteration 9: New best f(x) = 0.079802\nIteration 10: New best f(x) = 0.072451\nIteration 11: New best f(x) = 0.057699\nIteration 12: New best f(x) = 0.053620\nIteration 13: New best f(x) = 0.049605\nIteration 14: New best f(x) = 0.042981\nIteration 15: New best f(x) = 0.036730\nIteration 16: New best f(x) = 0.033454\nIteration 17: New best f(x) = 0.029379\nIteration 18: New best f(x) = 0.025681\nIteration 19: New best f(x) = 0.023939\nIteration 20: New best f(x) = 0.021221\nIteration 21: New best f(x) = 0.018070\nIteration 22: New best f(x) = 0.015747\nIteration 23: f(x) = 0.015999\nIteration 24: New best f(x) = 0.015112\nIteration 25: New best f(x) = 0.012345\nIteration 26: New best f(x) = 0.009886\nIteration 27: New best f(x) = 0.009609\nIteration 28: New best f(x) = 0.009434\nIteration 29: New best f(x) = 0.009203\nIteration 30: New best f(x) = 0.008749\nIteration 31: New best f(x) = 0.008243\nIteration 32: New best f(x) = 0.008106\nIteration 33: New best f(x) = 0.008000\nIteration 34: f(x) = 0.008102\nIteration 35: f(x) = 0.008077\nIteration 36: f(x) = 0.008119\nIteration 37: New best f(x) = 0.007992\nIteration 38: f(x) = 0.008011\nIteration 39: f(x) = 0.008033\nIteration 40: New best f(x) = 0.007962\nIteration 41: f(x) = 0.008005\nIteration 42: New best f(x) = 0.007842\nIteration 43: New best f(x) = 0.007399\nIteration 44: New best f(x) = 0.005592\nIteration 45: New best f(x) = 0.004372\nIteration 46: New best f(x) = 0.003297\nIteration 47: New best f(x) = 0.003034\nIteration 48: New best f(x) = 0.002795\nIteration 49: New best f(x) = 0.002577\nIteration 50: New best f(x) = 0.002463\nIteration 51: New best f(x) = 0.002407\nIteration 52: New best f(x) = 0.002376\nIteration 53: New best f(x) = 0.002288\nIteration 54: New best f(x) = 0.002222\nIteration 55: New best f(x) = 0.002172\nIteration 56: New best f(x) = 0.002124\nIteration 57: f(x) = 0.002163\nIteration 58: f(x) = 0.002132\nIteration 59: New best f(x) = 0.002124\nIteration 60: New best f(x) = 0.002091\nIteration 61: New best f(x) = 0.002085\nIteration 62: f(x) = 0.002104\nIteration 63: f(x) = 0.002087\nIteration 64: New best f(x) = 0.002056\nIteration 65: New best f(x) = 0.002035\nIteration 66: f(x) = 0.002072\nIteration 67: New best f(x) = 0.002007\nIteration 68: New best f(x) = 0.001956\nIteration 69: New best f(x) = 0.001935\nIteration 70: New best f(x) = 0.001842\nIteration 71: f(x) = 0.001968\nIteration 72: f(x) = 0.001843\nIteration 73: New best f(x) = 0.001835\nIteration 74: New best f(x) = 0.001701\nIteration 75: New best f(x) = 0.001631\nIteration 76: New best f(x) = 0.001392\nIteration 77: New best f(x) = 0.001049\nIteration 78: New best f(x) = 0.000810\nIteration 79: New best f(x) = 0.000634\nIteration 80: New best f(x) = 0.000497",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#how-it-works",
    "href": "acquisition_failure.html#how-it-works",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.3 How It Works",
    "text": "20.3 How It Works\nThe acquisition failure handling is integrated into the optimization process:\n\nAcquisition optimization: SpotOptim uses differential evolution to optimize the acquisition function\nDistance check: The proposed point is checked against existing points using tolerance_x\nFallback activation: If the point is too close, _handle_acquisition_failure() is called\nStrategy execution: The configured fallback strategy generates a new point\nEvaluation: The fallback point is evaluated and added to the dataset",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#comparison-of-strategies",
    "href": "acquisition_failure.html#comparison-of-strategies",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.4 Comparison of Strategies",
    "text": "20.4 Comparison of Strategies\n\n\n\nAspect\nRandom (LHS)\nMorris-Mitchell\n\n\n\n\nComputation\nVery fast\nModerate (100 candidates)\n\n\nSpace-filling\nGood\nExcellent\n\n\nExploration\nBalanced\nMaximum distance\n\n\nClustering avoidance\nGood\nBest\n\n\nRecommended for\nGeneral use\nHeavily sampled spaces",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#complete-example-comparing-strategies",
    "href": "acquisition_failure.html#complete-example-comparing-strategies",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.5 Complete Example: Comparing Strategies",
    "text": "20.5 Complete Example: Comparing Strategies\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef ackley(X):\n    \"\"\"Ackley function - multimodal test function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\n# Test with random strategy\nprint(\"=\" * 60)\nprint(\"Testing with Random Space-Filling Strategy\")\nprint(\"=\" * 60)\n\nopt_random = SpotOptim(\n    fun=ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    acquisition_failure_strategy=\"random\",\n    tolerance_x=0.1,  # Relatively large tolerance to trigger failures\n    seed=42,\n    verbose=True\n)\n\nresult_random = opt_random.optimize()\n\nprint(f\"\\nRandom Strategy Results:\")\nprint(f\"  Best value: {result_random.fun:.6f}\")\nprint(f\"  Best point: {result_random.x}\")\nprint(f\"  Total evaluations: {result_random.nfev}\")\n\n# Test with Morris-Mitchell strategy\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Testing with Morris-Mitchell Strategy\")\nprint(\"=\" * 60)\n\nopt_mm = SpotOptim(\n    fun=ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=15,\n    acquisition_failure_strategy=\"mm\",\n    tolerance_x=0.1,  # Same tolerance\n    seed=42,\n    verbose=True\n)\n\nresult_mm = opt_mm.optimize()\n\nprint(f\"\\nMorris-Mitchell Strategy Results:\")\nprint(f\"  Best value: {result_mm.fun:.6f}\")\nprint(f\"  Best point: {result_mm.x}\")\nprint(f\"  Total evaluations: {result_mm.nfev}\")\n\n# Compare\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Comparison\")\nprint(\"=\" * 60)\nprint(f\"Random strategy:        {result_random.fun:.6f}\")\nprint(f\"Morris-Mitchell strategy: {result_mm.fun:.6f}\")\nif result_random.fun &lt; result_mm.fun:\n    print(\"→ Random strategy found better solution\")\nelse:\n    print(\"→ Morris-Mitchell strategy found better solution\")\n\n============================================================\nTesting with Random Space-Filling Strategy\n============================================================\nTensorBoard logging disabled\nInitial best: f(x) = 7.177375\nIteration 1: New best f(x) = 5.975822\nIteration 2: New best f(x) = 4.585872\nIteration 3: New best f(x) = 3.624193\nIteration 4: f(x) = 3.775836\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 5: f(x) = 7.428910\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 6: f(x) = 11.307695\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 7: f(x) = 11.588702\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 8: f(x) = 7.741328\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 9: f(x) = 8.547707\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 10: f(x) = 10.258140\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 11: f(x) = 10.575833\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 12: f(x) = 3.973820\nIteration 13: New best f(x) = 3.254219\nIteration 14: f(x) = 3.726104\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 15: f(x) = 9.023210\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 16: f(x) = 4.449845\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 17: f(x) = 11.616761\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 18: f(x) = 8.521779\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 19: f(x) = 9.840296\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 20: f(x) = 12.575946\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 21: f(x) = 7.719827\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 22: f(x) = 6.588107\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 23: f(x) = 9.186450\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 24: f(x) = 7.957337\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 25: f(x) = 13.092857\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 26: f(x) = 10.747619\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 27: f(x) = 9.894215\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 28: f(x) = 9.482454\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 29: f(x) = 6.720219\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 30: f(x) = 6.321851\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 31: f(x) = 6.841321\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 32: f(x) = 11.918429\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 33: f(x) = 13.292524\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 34: f(x) = 8.518795\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 35: f(x) = 12.534822\n\nRandom Strategy Results:\n  Best value: 3.254219\n  Best point: [0.03533184 0.66379523]\n  Total evaluations: 50\n\n============================================================\nTesting with Morris-Mitchell Strategy\n============================================================\nTensorBoard logging disabled\nInitial best: f(x) = 7.177375\nIteration 1: New best f(x) = 5.975822\nIteration 2: New best f(x) = 4.585872\nIteration 3: New best f(x) = 3.624193\nIteration 4: f(x) = 3.775836\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 5: f(x) = 12.759495\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 6: f(x) = 13.023769\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 7: f(x) = 10.937206\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 8: f(x) = 7.780549\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 9: f(x) = 12.396463\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 10: f(x) = 12.719725\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 11: f(x) = 13.078957\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 12: f(x) = 12.813177\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 13: f(x) = 11.674342\nIteration 14: f(x) = 3.967415\nIteration 15: f(x) = 3.756184\nIteration 16: New best f(x) = 3.159408\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 17: f(x) = 11.221948\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 18: f(x) = 8.775229\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 19: f(x) = 11.789243\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 20: f(x) = 4.971384\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 21: f(x) = 9.983363\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 22: f(x) = 10.021573\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 23: f(x) = 6.575245\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 24: f(x) = 11.527738\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 25: f(x) = 12.133804\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 26: f(x) = 10.457280\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 27: f(x) = 11.003827\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 28: f(x) = 13.704437\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 29: f(x) = 10.955961\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 30: f(x) = 12.121347\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 31: f(x) = 7.325542\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 32: f(x) = 4.492325\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 33: f(x) = 6.456039\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 34: f(x) = 10.870934\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using Morris-Mitchell minimizing point as fallback.\nIteration 35: f(x) = 10.677536\n\nMorris-Mitchell Strategy Results:\n  Best value: 3.159408\n  Best point: [-0.00800104  0.71750603]\n  Total evaluations: 50\n\n============================================================\nComparison\n============================================================\nRandom strategy:        3.254219\nMorris-Mitchell strategy: 3.159408\n→ Morris-Mitchell strategy found better solution",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#advanced-usage-setting-tolerance",
    "href": "acquisition_failure.html#advanced-usage-setting-tolerance",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.6 Advanced Usage: Setting Tolerance",
    "text": "20.6 Advanced Usage: Setting Tolerance\nThe tolerance_x parameter controls when the fallback strategy is triggered. A larger tolerance means points need to be farther apart, triggering the fallback more often:\n\ndef simple_objective(X):\n    \"\"\"Simple quadratic function for demonstration\"\"\"\n    return np.sum(X**2, axis=1)\n\nbounds_demo = [(-5, 5), (-5, 5)]\n\n# Strict tolerance (smaller value) - fewer fallbacks\noptimizer_strict = SpotOptim(\n    fun=simple_objective,\n    bounds=bounds_demo,\n    tolerance_x=1e-6,  # Very small - almost never triggers fallback\n    acquisition_failure_strategy=\"mm\",\n    max_iter=20,\n    seed=42\n)\n\n# Relaxed tolerance (larger value) - more fallbacks\noptimizer_relaxed = SpotOptim(\n    fun=simple_objective,\n    bounds=bounds_demo,\n    tolerance_x=0.5,  # Larger - triggers fallback more often\n    acquisition_failure_strategy=\"mm\",\n    max_iter=20,\n    seed=42\n)\n\nprint(f\"Strict tolerance setup complete\")\nprint(f\"Relaxed tolerance setup complete\")\n\nStrict tolerance setup complete\nRelaxed tolerance setup complete",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#best-practices",
    "href": "acquisition_failure.html#best-practices",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.7 Best Practices",
    "text": "20.7 Best Practices\n\n20.7.1 1. Use Random for Most Problems\nThe random strategy (default) is sufficient for most optimization problems:\n\ndef my_objective(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=my_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    acquisition_failure_strategy=\"random\",  # Good default choice\n    max_iter=20,\n    seed=42\n)\nprint(\"Random strategy optimizer created\")\n\nRandom strategy optimizer created\n\n\n\n\n20.7.2 2. Use Morris-Mitchell for Intensive Sampling\nWhen you have a large budget and want maximum exploration:\n\ndef expensive_objective(X):\n    \"\"\"Simulated expensive objective function\"\"\"\n    return np.sum((X - 1)**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=expensive_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,  # Large budget\n    acquisition_failure_strategy=\"mm\",  # Maximize space coverage\n    seed=42\n)\nprint(\"Morris-Mitchell optimizer for intensive sampling created\")\n\nMorris-Mitchell optimizer for intensive sampling created\n\n\n\n\n20.7.3 3. Monitor Fallback Activations\nEnable verbose mode to see when fallbacks are triggered:\n\ndef test_objective(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=test_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    acquisition_failure_strategy=\"mm\",\n    max_iter=20,\n    verbose=True,  # Shows fallback messages\n    seed=42\n)\nprint(\"Optimizer with verbose mode created\")\n\nTensorBoard logging disabled\nOptimizer with verbose mode created\n\n\n\n\n20.7.4 4. Adjust Tolerance Based on Problem Scale\nFor problems with small search spaces, use smaller tolerance:\n\ndef scale_objective(X):\n    return np.sum(X**2, axis=1)\n\n# Small search space\noptimizer_small = SpotOptim(\n    fun=scale_objective,\n    bounds=[(-1, 1), (-1, 1)],\n    tolerance_x=0.01,  # Small tolerance for small space\n    acquisition_failure_strategy=\"random\",\n    max_iter=20,\n    seed=42\n)\n\n# Large search space\noptimizer_large = SpotOptim(\n    fun=scale_objective,\n    bounds=[(-100, 100), (-100, 100)],\n    tolerance_x=1.0,  # Larger tolerance for large space\n    acquisition_failure_strategy=\"mm\",\n    max_iter=20,\n    seed=42\n)\n\nprint(f\"Small space optimizer created (bounds: [-1, 1])\")\nprint(f\"Large space optimizer created (bounds: [-100, 100])\")\n\nSmall space optimizer created (bounds: [-1, 1])\nLarge space optimizer created (bounds: [-100, 100])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#technical-details",
    "href": "acquisition_failure.html#technical-details",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.8 Technical Details",
    "text": "20.8 Technical Details\n\n20.8.1 Morris-Mitchell Implementation\nThe Morris-Mitchell strategy:\n\nGenerates 100 candidate points using Latin Hypercube Sampling\nFor each candidate, calculates the minimum distance to all existing points\nSelects the candidate with the maximum minimum distance\n\nThis ensures the new point is as far as possible from the densest region of evaluated points.\n\n\n20.8.2 Random Strategy Implementation\nThe random strategy:\n\nGenerates a single point using Latin Hypercube Sampling\nEnsures the point is within bounds\nApplies variable type repairs (rounding for int/factor variables)\n\nThis is computationally efficient while maintaining good space-filling properties.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "acquisition_failure.html#summary",
    "href": "acquisition_failure.html#summary",
    "title": "20  Acquisition Failure Handling in SpotOptim",
    "section": "20.9 Summary",
    "text": "20.9 Summary\n\nDefault strategy (\"random\"): Fast, good space-filling, suitable for most problems\nMorris-Mitchell (\"mm\"): Better space-filling, maximizes minimum distance, ideal for intensive sampling\nTrigger: Activated when acquisition-proposed point is too close to existing points (within tolerance_x)\nControl: Set via acquisition_failure_strategy parameter\nMonitoring: Enable verbose=True to see when fallbacks occur\n\nChoose the strategy that best matches your optimization goals: - Use \"random\" for general-purpose optimization - Use \"mm\" when you want maximum exploration and have a generous function evaluation budget",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Acquisition Failure Handling in SpotOptim</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html",
    "href": "diabetes_dataset.html",
    "title": "21  Diabetes Dataset Utilities",
    "section": "",
    "text": "21.1 Overview\nSpotOptim provides convenient utilities for working with the sklearn diabetes dataset, including PyTorch Dataset and DataLoader implementations. These utilities simplify data loading, preprocessing, and model training for regression tasks.\nThe diabetes dataset contains 10 baseline variables (age, sex, body mass index, average blood pressure, and six blood serum measurements) for 442 diabetes patients. The target is a quantitative measure of disease progression one year after baseline.\nModule: spotoptim.data.diabetes\nKey Components:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#overview",
    "href": "diabetes_dataset.html#overview",
    "title": "21  Diabetes Dataset Utilities",
    "section": "",
    "text": "DiabetesDataset: PyTorch Dataset class\nget_diabetes_dataloaders(): Convenience function for complete data pipeline",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#quick-start",
    "href": "diabetes_dataset.html#quick-start",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.2 Quick Start",
    "text": "21.2 Quick Start\n\n21.2.1 Basic Usage\n\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom sklearn.datasets import load_diabetes\nfrom spotoptim.data.diabetes import DiabetesDataset\nimport numpy as np\n\n# Load data\ndiabetes = load_diabetes()\nX = diabetes.data\ny = diabetes.target.reshape(-1, 1)\n\n# Now create the dataset\ndataset = DiabetesDataset(X, y, transform=None, target_transform=None)\n# Load data with default settings\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders()\n\n# Iterate through batches\nfor batch_X, batch_y in train_loader:\n    print(f\"Batch features: {batch_X.shape}\")  # (32, 10)\n    print(f\"Batch targets: {batch_y.shape}\")   # (32, 1)\n    break\n\nBatch features: torch.Size([32, 10])\nBatch targets: torch.Size([32, 1])\n\n\n\n\n21.2.2 Training a Model\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n# Load data\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.2,\n    batch_size=32,\n    scale_features=True,\n    random_state=42\n)\n\n# Create model\nmodel = LinearRegressor(\n    input_dim=10,\n    output_dim=1,\n    l1=64,\n    num_hidden_layers=2,\n    activation=\"ReLU\"\n)\n\n# Setup training\ncriterion = nn.MSELoss()\noptimizer = model.get_optimizer(\"Adam\", lr=0.01)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    for batch_X, batch_y in train_loader:\n        # Forward pass\n        predictions = model(batch_X)\n        loss = criterion(predictions, batch_y)\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    \n    avg_train_loss = train_loss / len(train_loader)\n    \n    if (epoch + 1) % 20 == 0:\n        print(f\"Epoch {epoch+1}/{num_epochs}: Loss = {avg_train_loss:.4f}\")\n\n# Evaluation\nmodel.eval()\ntest_loss = 0.0\n\nwith torch.no_grad():\n    for batch_X, batch_y in test_loader:\n        predictions = model(batch_X)\n        loss = criterion(predictions, batch_y)\n        test_loss += loss.item()\n\navg_test_loss = test_loss / len(test_loader)\nprint(f\"Test MSE: {avg_test_loss:.4f}\")\n\nEpoch 20/100: Loss = 27403.5895\nEpoch 40/100: Loss = 28056.5541\nEpoch 60/100: Loss = 29527.9121\nEpoch 80/100: Loss = 28477.6191\nEpoch 100/100: Loss = 28261.8906\nTest MSE: 26448.1296",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#function-reference",
    "href": "diabetes_dataset.html#function-reference",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.3 Function Reference",
    "text": "21.3 Function Reference\n\n21.3.1 get_diabetes_dataloaders()\nLoads the sklearn diabetes dataset and returns configured PyTorch DataLoaders.\nSignature:\n\nget_diabetes_dataloaders(\n    test_size=0.2,\n    batch_size=32,\n    shuffle_train=True,\n    shuffle_test=False,\n    random_state=42,\n    scale_features=True,\n    num_workers=0,\n    pin_memory=False\n)\n\n(&lt;torch.utils.data.dataloader.DataLoader at 0x1194f7230&gt;,\n &lt;torch.utils.data.dataloader.DataLoader at 0x1196684d0&gt;,\n StandardScaler())\n\n\nParameters:\n\n\n\n\n\n\n\n\n\nParameter\nType\nDefault\nDescription\n\n\n\n\ntest_size\nfloat\n0.2\nProportion of dataset for testing (0.0 to 1.0)\n\n\nbatch_size\nint\n32\nNumber of samples per batch\n\n\nshuffle_train\nbool\nTrue\nWhether to shuffle training data\n\n\nshuffle_test\nbool\nFalse\nWhether to shuffle test data\n\n\nrandom_state\nint\n42\nRandom seed for train/test split\n\n\nscale_features\nbool\nTrue\nWhether to standardize features\n\n\nnum_workers\nint\n0\nNumber of subprocesses for data loading\n\n\npin_memory\nbool\nFalse\nWhether to pin memory (useful for GPU)\n\n\n\nReturns:\n\ntrain_loader (DataLoader): Training data loader\ntest_loader (DataLoader): Test data loader\nscaler (StandardScaler or None): Fitted scaler if scale_features=True, else None\n\nExample:\n\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Custom configuration\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.3,\n    batch_size=64,\n    shuffle_train=True,\n    scale_features=True,\n    random_state=123\n)\n\nprint(f\"Training batches: {len(train_loader)}\")\nprint(f\"Test batches: {len(test_loader)}\")\nprint(f\"Scaler mean: {scaler.mean_[:3]}\")  # First 3 features\n\nTraining batches: 5\nTest batches: 3\nScaler mean: [-0.00056537  0.00132258  0.00027836]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#diabetesdataset-class",
    "href": "diabetes_dataset.html#diabetesdataset-class",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.4 DiabetesDataset Class",
    "text": "21.4 DiabetesDataset Class\nPyTorch Dataset implementation for the diabetes dataset.\nSignature:\n\nDiabetesDataset(X, y, transform=None, target_transform=None)\n\n&lt;spotoptim.data.diabetes.DiabetesDataset at 0x1195a9550&gt;\n\n\nParameters:\n\nX (np.ndarray): Feature matrix of shape (n_samples, n_features)\ny (np.ndarray): Target values of shape (n_samples,) or (n_samples, 1)\ntransform (callable, optional): Transform to apply to features\ntarget_transform (callable, optional): Transform to apply to targets\n\nAttributes:\n\nX (torch.Tensor): Feature tensor (n_samples, n_features)\ny (torch.Tensor): Target tensor (n_samples, 1)\nn_features (int): Number of features (10 for diabetes)\nn_samples (int): Number of samples\n\nMethods:\n\n__len__(): Returns number of samples\n__getitem__(idx): Returns tuple (features, target) for given index\n\n\n21.4.1 Manual Dataset Creation\n\nfrom spotoptim.data import DiabetesDataset\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import DataLoader\n\n# Load raw data\ndiabetes = load_diabetes()\nX, y = diabetes.data, diabetes.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Scale features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create datasets\ntrain_dataset = DiabetesDataset(X_train, y_train)\ntest_dataset = DiabetesDataset(X_test, y_test)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Inspect dataset\nprint(f\"Dataset size: {len(train_dataset)}\")\nprint(f\"Features shape: {train_dataset.X.shape}\")\nprint(f\"Targets shape: {train_dataset.y.shape}\")\n\n# Get a sample\nfeatures, target = train_dataset[0]\nprint(f\"Sample features: {features.shape}\")  # (10,)\nprint(f\"Sample target: {target.shape}\")      # (1,)\n\nDataset size: 353\nFeatures shape: torch.Size([353, 10])\nTargets shape: torch.Size([353, 1])\nSample features: torch.Size([10])\nSample target: torch.Size([1])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#advanced-usage",
    "href": "diabetes_dataset.html#advanced-usage",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.5 Advanced Usage",
    "text": "21.5 Advanced Usage\n\n21.5.1 Custom Transforms\n\nfrom spotoptim.data import DiabetesDataset\nfrom sklearn.datasets import load_diabetes\nimport torch\n\n# Define custom transforms\ndef add_noise(x):\n    \"\"\"Add Gaussian noise to features.\"\"\"\n    return x + torch.randn_like(x) * 0.01\n\ndef log_transform(y):\n    \"\"\"Apply log transform to target.\"\"\"\n    return torch.log1p(y)\n\n# Load data\ndiabetes = load_diabetes()\nX, y = diabetes.data, diabetes.target\n\n# Create dataset with transforms\ndataset = DiabetesDataset(\n    X, y,\n    transform=add_noise,\n    target_transform=log_transform\n)\n\n# Transforms are applied when accessing items\nfeatures, target = dataset[0]\n\n\n\n21.5.2 Different Train/Test Splits\n\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# 70/30 split\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.3,\n    random_state=42\n)\nprint(f\"Training samples: {len(train_loader.dataset)}\")  # ~310\nprint(f\"Test samples: {len(test_loader.dataset)}\")       # ~132\n\n# 90/10 split\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    test_size=0.1,\n    random_state=42\n)\nprint(f\"Training samples: {len(train_loader.dataset)}\")  # ~398\nprint(f\"Test samples: {len(test_loader.dataset)}\")       # ~44\n\nTraining samples: 309\nTest samples: 133\nTraining samples: 397\nTest samples: 45\n\n\n\n\n21.5.3 Without Feature Scaling\n\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Load without scaling (useful for tree-based models)\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=False\n)\n\nprint(f\"Scaler: {scaler}\")  # None\n\n# Data is in original scale\nfor batch_X, batch_y in train_loader:\n    print(f\"Mean: {batch_X.mean(dim=0)[:3]}\")  # Non-zero values\n    break\n\nScaler: None\nMean: tensor([0.0112, 0.0090, 0.0071])\n\n\n\n\n21.5.4 Larger Batch Sizes\n\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Larger batches for faster training (if memory allows)\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=128\n)\nprint(f\"Batches per epoch: {len(train_loader)}\")  # Fewer batches\n\n# Smaller batches for more gradient updates\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=8\n)\nprint(f\"Batches per epoch: {len(train_loader)}\")  # More batches\n\nBatches per epoch: 3\nBatches per epoch: 45\n\n\n\n\n21.5.5 GPU Training with Pin Memory\n\nimport torch\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Enable pin_memory for faster GPU transfer\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=32,\n    pin_memory=True  # Set to True when using GPU\n)\n\n# Move model to GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training loop with GPU\nfor batch_X, batch_y in train_loader:\n    # Data is already pinned, faster transfer to GPU\n    batch_X = batch_X.to(device, non_blocking=True)\n    batch_y = batch_y.to(device, non_blocking=True)\n    \n    # ... training code ...\n\n/Users/bartz/workspace/spotoptim-cookbook/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n\n'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#complete-training-example",
    "href": "diabetes_dataset.html#complete-training-example",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.6 Complete Training Example",
    "text": "21.6 Complete Training Example\nHere’s a complete example showing data loading, model training, and evaluation:\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\ndef train_diabetes_model():\n    \"\"\"Train a neural network on the diabetes dataset.\"\"\"\n    \n    # Load data\n    train_loader, test_loader, scaler = get_diabetes_dataloaders(\n        test_size=0.2,\n        batch_size=32,\n        scale_features=True,\n        random_state=42\n    )\n    \n    # Create model\n    model = LinearRegressor(\n        input_dim=10,\n        output_dim=1,\n        l1=128,\n        num_hidden_layers=3,\n        activation=\"ReLU\"\n    )\n    \n    # Setup training\n    criterion = nn.MSELoss()\n    optimizer = model.get_optimizer(\"Adam\", lr=0.001, weight_decay=1e-5)\n    \n    # Training configuration\n    num_epochs = 200\n    best_test_loss = float('inf')\n    \n    print(\"Starting training...\")\n    print(f\"Training samples: {len(train_loader.dataset)}\")\n    print(f\"Test samples: {len(test_loader.dataset)}\")\n    print(f\"Batches per epoch: {len(train_loader)}\")\n    print(\"-\" * 60)\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        \n        for batch_X, batch_y in train_loader:\n            # Forward pass\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        avg_train_loss = train_loss / len(train_loader)\n        \n        # Evaluation phase\n        model.eval()\n        test_loss = 0.0\n        \n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        \n        # Track best model\n        if avg_test_loss &lt; best_test_loss:\n            best_test_loss = avg_test_loss\n            # Could save model here: torch.save(model.state_dict(), 'best_model.pt')\n        \n        # Print progress\n        if (epoch + 1) % 20 == 0:\n            print(f\"Epoch {epoch+1:3d}/{num_epochs}: \"\n                  f\"Train Loss = {avg_train_loss:.4f}, \"\n                  f\"Test Loss = {avg_test_loss:.4f}\")\n    \n    print(\"-\" * 60)\n    print(f\"Training complete!\")\n    print(f\"Best test loss: {best_test_loss:.4f}\")\n    \n    return model, best_test_loss\n\n# Run training\nif __name__ == \"__main__\":\n    model, best_loss = train_diabetes_model()\n\nStarting training...\nTraining samples: 353\nTest samples: 89\nBatches per epoch: 12\n------------------------------------------------------------\nEpoch  20/200: Train Loss = 32185.4316, Test Loss = 26615.8522\nEpoch  40/200: Train Loss = 36408.3407, Test Loss = 26610.5462\nEpoch  60/200: Train Loss = 30173.0195, Test Loss = 26605.3607\nEpoch  80/200: Train Loss = 32168.7126, Test Loss = 26600.1322\nEpoch 100/200: Train Loss = 29449.2580, Test Loss = 26594.7956\nEpoch 120/200: Train Loss = 29915.3262, Test Loss = 26589.2812\nEpoch 140/200: Train Loss = 28895.5913, Test Loss = 26583.5964\nEpoch 160/200: Train Loss = 29078.1483, Test Loss = 26577.7493\nEpoch 180/200: Train Loss = 27673.1718, Test Loss = 26571.7415\nEpoch 200/200: Train Loss = 27919.2334, Test Loss = 26565.5312\n------------------------------------------------------------\nTraining complete!\nBest test loss: 26565.5312",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#integration-with-spotoptim",
    "href": "diabetes_dataset.html#integration-with-spotoptim",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.7 Integration with SpotOptim",
    "text": "21.7 Integration with SpotOptim\nUse the diabetes dataset for hyperparameter optimization with SpotOptim:\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\ndef evaluate_model(X):\n    \"\"\"Objective function for SpotOptim.\n    \n    Args:\n        X: Array of hyperparameters [lr, l1, num_hidden_layers]\n        \n    Returns:\n        Array of validation losses\n    \"\"\"\n    results = []\n    \n    for params in X:\n        lr, l1, num_hidden_layers = params\n        lr = 10 ** lr  # Log scale for learning rate\n        l1 = int(l1)\n        num_hidden_layers = int(num_hidden_layers)\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(\n            test_size=0.2,\n            batch_size=32,\n            random_state=42\n        )\n        \n        # Create model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=num_hidden_layers,\n            activation=\"ReLU\"\n        )\n        \n        # Train briefly\n        criterion = nn.MSELoss()\n        optimizer = model.get_optimizer(\"Adam\", lr=lr)\n        \n        num_epochs = 50\n        for epoch in range(num_epochs):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n        \n        results.append(test_loss / len(test_loader))\n    \n    return np.array(results)\n\n# Optimize hyperparameters\noptimizer = SpotOptim(\n    fun=evaluate_model,\n    bounds=[\n        (-4, -2),   # log10(lr): 0.0001 to 0.01\n        (16, 128),  # l1: number of neurons\n        (0, 4)      # num_hidden_layers\n    ],\n    var_type=[\"float\", \"int\", \"int\"],\n    max_iter=30,\n    n_initial=10,\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\nprint(f\"Best hyperparameters found:\")\nprint(f\"  Learning rate: {10**result.x[0]:.6f}\")\nprint(f\"  Hidden neurons (l1): {int(result.x[1])}\")\nprint(f\"  Hidden layers: {int(result.x[2])}\")\nprint(f\"  Best MSE: {result.fun:.4f}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 26576.426432\nIteration 1: f(x) = 26608.509115\nIteration 2: f(x) = 26581.524740\nIteration 3: f(x) = 26687.589193\nIteration 4: f(x) = 26594.492188\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 5: f(x) = 26646.508464\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 6: f(x) = 26614.145833\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 7: New best f(x) = 26573.561198\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 8: f(x) = 26648.697266\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 9: f(x) = 26629.848307\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 10: f(x) = 26651.464193\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 11: f(x) = 26638.150391\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 12: f(x) = 26629.367839\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 13: f(x) = 26592.171224\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 14: New best f(x) = 26545.990885\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 15: f(x) = 26735.894531\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 16: f(x) = 26633.803385\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 17: f(x) = 26578.136719\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 18: f(x) = 26649.640625\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 19: f(x) = 26583.694010\n  Attempt 2/10: Previous point was duplicate after rounding, trying fallback\nAcquisition failure: Using random space-filling design as fallback.\nIteration 20: f(x) = 26621.816406\nBest hyperparameters found:\n  Learning rate: 0.007645\n  Hidden neurons (l1): 96\n  Hidden layers: 3\n  Best MSE: 26545.9909",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#best-practices",
    "href": "diabetes_dataset.html#best-practices",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.8 Best Practices",
    "text": "21.8 Best Practices\n\n21.8.1 1. Always Use Feature Scaling\n\n# Good: Features are standardized\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=True\n)\n\nNeural networks typically perform better with normalized inputs.\n\n\n21.8.2 2. Set Random Seeds for Reproducibility\n\n# Reproducible train/test splits\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    random_state=42\n)\n\n# Also set PyTorch seed\nimport torch\ntorch.manual_seed(42)\n\n&lt;torch._C.Generator at 0x112ed59d0&gt;\n\n\n\n\n21.8.3 3. Don’t Shuffle Test Data\n\n# Good: Test data in consistent order\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    shuffle_train=True,   # Shuffle training data\n    shuffle_test=False    # Don't shuffle test data\n)\n\nThis ensures consistent evaluation metrics across runs.\n\n\n21.8.4 4. Choose Appropriate Batch Size\n\n# Small dataset (442 samples) - moderate batch size works well\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=32  # Good balance for this dataset\n)\n\nToo large: Fewer gradient updates per epoch\nToo small: Noisy gradients, slower training\n\n\n21.8.5 5. Save the Scaler for Production\n\nimport pickle\nimport numpy as np\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Train with scaling\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=True\n)\n\n# Save scaler for production use\nwith open('scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\n\n# Later: Load and use on new data\nwith open('scaler.pkl', 'rb') as f:\n    loaded_scaler = pickle.load(f)\n\n# Create some example new data (same shape as diabetes features)\nnew_data = np.random.randn(5, 10)  # 5 samples, 10 features\nnew_data_scaled = loaded_scaler.transform(new_data)\n\nprint(f\"Original data shape: {new_data.shape}\")\nprint(f\"Scaled data shape: {new_data_scaled.shape}\")\nprint(f\"Scaled data mean: {new_data_scaled.mean(axis=0)[:3]}\")  # Should be close to 0\n\nOriginal data shape: (5, 10)\nScaled data shape: (5, 10)\nScaled data mean: [-4.61156932 -6.86691399  2.65486478]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#troubleshooting",
    "href": "diabetes_dataset.html#troubleshooting",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.9 Troubleshooting",
    "text": "21.9 Troubleshooting\n\n21.9.1 Issue: Out of Memory\nSolution: Reduce batch size or disable pin_memory\n\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    batch_size=16,      # Smaller batches\n    pin_memory=False    # Disable if not using GPU\n)\n\n\n\n21.9.2 Issue: Different Data Ranges\nSymptom: Model not converging, loss is NaN\nSolution: Ensure feature scaling is enabled\n\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    scale_features=True  # Must be True for neural networks\n)\n\n\n\n21.9.3 Issue: Non-Reproducible Results\nSolution: Set all random seeds\n\nimport torch\nimport numpy as np\n\n# Set all seeds\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    random_state=42,\n    shuffle_train=False  # Disable shuffle for full reproducibility\n)\n\n\n\n21.9.4 Issue: Slow Data Loading\nSolution: Use multiple workers (if not on Windows)\n\ntrain_loader, test_loader, scaler = get_diabetes_dataloaders(\n    num_workers=4,      # Use 4 subprocesses\n    pin_memory=True     # Enable for GPU\n)\n\nNote: On Windows, set num_workers=0 to avoid multiprocessing issues.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "diabetes_dataset.html#summary",
    "href": "diabetes_dataset.html#summary",
    "title": "21  Diabetes Dataset Utilities",
    "section": "21.10 Summary",
    "text": "21.10 Summary\nThe diabetes dataset utilities in SpotOptim provide:\n\nEasy data loading: One function call gets complete data pipeline\nPyTorch integration: Native Dataset and DataLoader support\nPreprocessing included: Automatic feature scaling and train/test splitting\nFlexible configuration: Control batch size, splitting, scaling, and more\nProduction ready: Save scalers and ensure reproducibility\n\nFor more examples, see: - examples/diabetes_dataset_example.py - notebooks/demos.ipynb - Test suite: tests/test_diabetes_dataset.py",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Diabetes Dataset Utilities</span>"
    ]
  },
  {
    "objectID": "factor_variables.html",
    "href": "factor_variables.html",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "",
    "text": "22.1 Overview\nSpotOptim supports factor variables for optimizing categorical hyperparameters, such as activation functions, optimizers, or any discrete string-based choices. Factor variables are automatically converted between string values (external interface) and integers (internal optimization), making categorical optimization seamless.\nWhat are Factor Variables?\nFactor variables allow you to specify categorical choices as tuples of strings in the bounds. SpotOptim handles the conversion:\nModule: spotoptim.SpotOptim\nKey Features:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#overview",
    "href": "factor_variables.html#overview",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "",
    "text": "String tuples in bounds → Internal integer mapping (0, 1, 2, …)\nOptimization uses integers internally for surrogate modeling\nObjective function receives strings after automatic conversion\nResults return strings (not integers)\n\n\n\n\nDefine categorical choices as string tuples: (\"ReLU\", \"Sigmoid\", \"Tanh\")\nAutomatic integer↔︎string conversion\nSeamless integration with neural network hyperparameters\nMix factor variables with numeric/integer variables",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#quick-start",
    "href": "factor_variables.html#quick-start",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.2 Quick Start",
    "text": "22.2 Quick Start\n\n22.2.1 Basic Factor Variable Usage\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective_function(X):\n    \"\"\"Objective function receives string values.\"\"\"\n    results = []\n    for params in X:\n        activation = params[0]  # This is a string!\n        print(f\"Testing activation: {activation}\")\n        \n        # Simple scoring based on activation choice (for demonstration)\n        # In real use, you would train a model and return actual performance\n        scores = {\n            \"ReLU\": 3500.0,\n            \"Sigmoid\": 4200.0,\n            \"Tanh\": 3800.0,\n            \"LeakyReLU\": 3600.0\n        }\n        score = scores.get(activation, 5000.0) + np.random.normal(0, 100)\n        results.append(score)\n    return np.array(results)  # Return numpy array\n\n# Define bounds with factor variable\noptimizer = SpotOptim(\n    fun=objective_function,\n    bounds=[(\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")],\n    var_type=[\"factor\"],\n    max_iter=20,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"\\nBest activation: {result.x[0]}\")  # Returns string, e.g., \"ReLU\"\nprint(f\"Best score: {result.fun:.4f}\")\n\nTesting activation: ReLU\nTesting activation: Sigmoid\nTesting activation: Tanh\nTesting activation: LeakyReLU\nTesting activation: Tanh\nTesting activation: Sigmoid\nTesting activation: Sigmoid\nTesting activation: Sigmoid\nTesting activation: Sigmoid\nTesting activation: ReLU\nTesting activation: Sigmoid\nTesting activation: Tanh\nTesting activation: LeakyReLU\nTesting activation: Sigmoid\nTesting activation: LeakyReLU\nTesting activation: Tanh\nTesting activation: Sigmoid\nTesting activation: LeakyReLU\nTesting activation: Sigmoid\nTesting activation: Tanh\n\nBest activation: ReLU\nBest score: 3348.6884\n\n\n\n\n22.2.2 Neural Network Activation Function Optimization\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport numpy as np\n\ndef train_and_evaluate(X):\n    \"\"\"Train models with different activation functions.\"\"\"\n    results = []\n    \n    for params in X:\n        activation = params[0]  # String: \"ReLU\", \"Sigmoid\", etc.\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders()\n        \n        # Create model with the activation function\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=64,\n            num_hidden_layers=2,\n            activation=activation  # Pass string directly!\n        )\n        \n        # Train model\n        optimizer = model.get_optimizer(\"Adam\", lr=0.01)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(50):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_loss = test_loss / len(test_loader)\n        results.append(avg_loss)\n    \n    return np.array(results)  # Return numpy array\n\n# Optimize activation function choice\noptimizer = SpotOptim(\n    fun=train_and_evaluate,\n    bounds=[(\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\", \"ELU\")],\n    var_type=[\"factor\"],\n    max_iter=30\n)\n\nresult = optimizer.optimize()\nprint(f\"Best activation function: {result.x[0]}\")\nprint(f\"Best test MSE: {result.fun:.4f}\")\n\nBest activation function: Sigmoid\nBest test MSE: 26429.1458",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#mixed-variable-types",
    "href": "factor_variables.html#mixed-variable-types",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.3 Mixed Variable Types",
    "text": "22.3 Mixed Variable Types\n\n22.3.1 Combining Factor, Integer, and Continuous Variables\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\ndef comprehensive_optimization(X):\n    \"\"\"Optimize learning rate, layer size, depth, and activation.\"\"\"\n    results = []\n    \n    for params in X:\n        log_lr = params[0]      # Continuous (log scale)\n        l1 = int(params[1])     # Integer\n        n_layers = int(params[2])  # Integer\n        activation = params[3]   # Factor (string)\n        \n        lr = 10 ** log_lr  # Convert from log scale\n        \n        print(f\"lr={lr:.6f}, l1={l1}, layers={n_layers}, activation={activation}\")\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(\n            batch_size=32,\n            random_state=42\n        )\n        \n        # Create model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=n_layers,\n            activation=activation\n        )\n        \n        # Train\n        optimizer = model.get_optimizer(\"Adam\", lr=lr)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(30):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        results.append(test_loss / len(test_loader))\n    \n    return np.array(results)\n\n# Optimize all four hyperparameters simultaneously\noptimizer = SpotOptim(\n    fun=comprehensive_optimization,\n    bounds=[\n        (-4, -2),                                    # log10(learning_rate)\n        (16, 128),                                   # l1 (neurons per layer)\n        (0, 4),                                      # num_hidden_layers\n        (\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")   # activation function\n    ],\n    var_type=[\"float\", \"int\", \"int\", \"factor\"],\n    max_iter=50\n)\n\nresult = optimizer.optimize()\n\n# Results contain original string values\nprint(\"\\nOptimization Results:\")\nprint(f\"Best learning rate: {10**result.x[0]:.6f}\")\nprint(f\"Best layer size: {int(result.x[1])}\")\nprint(f\"Best num layers: {int(result.x[2])}\")\nprint(f\"Best activation: {result.x[3]}\")  # String value!\nprint(f\"Best test MSE: {result.fun:.4f}\")\n\nlr=0.000251, l1=59, layers=4, activation=Tanh\nlr=0.000202, l1=19, layers=2, activation=Tanh\nlr=0.008242, l1=120, layers=3, activation=Sigmoid\nlr=0.001797, l1=106, layers=3, activation=Tanh\nlr=0.000461, l1=37, layers=0, activation=ReLU\nlr=0.004534, l1=77, layers=1, activation=Sigmoid\nlr=0.000134, l1=45, layers=3, activation=Tanh\nlr=0.002915, l1=63, layers=2, activation=ReLU\nlr=0.000967, l1=90, layers=1, activation=Sigmoid\nlr=0.001075, l1=96, layers=2, activation=LeakyReLU\nlr=0.009664, l1=121, layers=3, activation=Sigmoid\nlr=0.008196, l1=120, layers=3, activation=Sigmoid\nlr=0.000323, l1=32, layers=2, activation=Sigmoid\nlr=0.000303, l1=103, layers=0, activation=Sigmoid\nlr=0.000786, l1=116, layers=2, activation=Sigmoid\nlr=0.000287, l1=85, layers=2, activation=ReLU\nlr=0.000122, l1=75, layers=0, activation=Tanh\nlr=0.000114, l1=42, layers=4, activation=Sigmoid\nlr=0.000907, l1=116, layers=0, activation=Sigmoid\nlr=0.002209, l1=74, layers=3, activation=Tanh\nlr=0.000205, l1=25, layers=1, activation=LeakyReLU\nlr=0.000206, l1=100, layers=2, activation=Sigmoid\nlr=0.001159, l1=92, layers=3, activation=Sigmoid\nlr=0.003951, l1=75, layers=3, activation=ReLU\nlr=0.000539, l1=65, layers=1, activation=Tanh\nlr=0.001011, l1=60, layers=3, activation=ReLU\nlr=0.000892, l1=96, layers=1, activation=Tanh\nlr=0.009354, l1=30, layers=3, activation=Tanh\nlr=0.009866, l1=105, layers=4, activation=Tanh\nlr=0.000180, l1=51, layers=3, activation=Sigmoid\nlr=0.000586, l1=47, layers=1, activation=Tanh\nlr=0.000655, l1=89, layers=1, activation=Sigmoid\nlr=0.001742, l1=121, layers=1, activation=LeakyReLU\nlr=0.004944, l1=108, layers=1, activation=Sigmoid\nlr=0.008129, l1=91, layers=0, activation=Sigmoid\nlr=0.000971, l1=119, layers=3, activation=Sigmoid\nlr=0.003548, l1=23, layers=2, activation=ReLU\nlr=0.008469, l1=86, layers=1, activation=Tanh\nlr=0.000273, l1=51, layers=1, activation=LeakyReLU\nlr=0.007849, l1=71, layers=4, activation=Tanh\nlr=0.007052, l1=33, layers=2, activation=Sigmoid\nlr=0.001792, l1=92, layers=2, activation=LeakyReLU\nlr=0.004704, l1=87, layers=2, activation=Tanh\nlr=0.000768, l1=60, layers=0, activation=Tanh\nlr=0.001451, l1=53, layers=3, activation=Tanh\nlr=0.003151, l1=85, layers=1, activation=Sigmoid\nlr=0.000458, l1=99, layers=3, activation=Tanh\nlr=0.000401, l1=128, layers=1, activation=Sigmoid\nlr=0.000124, l1=96, layers=0, activation=Sigmoid\nlr=0.003221, l1=90, layers=4, activation=Tanh\n\nOptimization Results:\nBest learning rate: 0.008242\nBest layer size: 120\nBest num layers: 3\nBest activation: Sigmoid\nBest test MSE: 26388.9297",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#multiple-factor-variables",
    "href": "factor_variables.html#multiple-factor-variables",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.4 Multiple Factor Variables",
    "text": "22.4 Multiple Factor Variables\n\n22.4.1 Optimizing Both Activation and Optimizer\n\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport torch.nn as nn\nimport numpy as np\n\ndef optimize_activation_and_optimizer(X):\n    \"\"\"Optimize both activation function and optimizer choice.\"\"\"\n    results = []\n    \n    for params in X:\n        activation = params[0]      # Factor variable 1\n        optimizer_name = params[1]  # Factor variable 2\n        lr = 10 ** params[2]        # Continuous variable\n        \n        train_loader, test_loader, _ = get_diabetes_dataloaders()\n        \n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=64,\n            num_hidden_layers=2,\n            activation=activation\n        )\n        \n        # Use the optimizer string\n        optimizer = model.get_optimizer(optimizer_name, lr=lr)\n        criterion = nn.MSELoss()\n        \n        # Train\n        for epoch in range(30):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        results.append(test_loss / len(test_loader))\n    \n    return np.array(results)  # Return numpy array\n\n# Two factor variables + one continuous\nopt = SpotOptim(\n    fun=optimize_activation_and_optimizer,\n    bounds=[\n        (\"ReLU\", \"Tanh\", \"Sigmoid\", \"LeakyReLU\"),    # Activation\n        (\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"),         # Optimizer\n        (-4, -2)                                      # log10(lr)\n    ],\n    var_type=[\"factor\", \"factor\", \"float\"],\n    max_iter=40\n)\n\nresult = opt.optimize()\nprint(f\"Best activation: {result.x[0]}\")\nprint(f\"Best optimizer: {result.x[1]}\")\nprint(f\"Best learning rate: {10**result.x[2]:.6f}\")\n\nBest activation: ReLU\nBest optimizer: SGD\nBest learning rate: 0.001522",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#advanced-usage",
    "href": "factor_variables.html#advanced-usage",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.5 Advanced Usage",
    "text": "22.5 Advanced Usage\n\n22.5.1 Custom Categorical Choices\nFactor variables work with any string values, not just activation functions:\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef train_model_with_config(dropout_policy, batch_norm, weight_init):\n    \"\"\"Simulate model training with different configurations.\"\"\"\n    # In real use, this would train an actual model\n    # Here we return synthetic scores for demonstration\n    base_score = 3000.0\n    \n    # Dropout impact\n    dropout_scores = {\"none\": 200, \"light\": 0, \"heavy\": 100}\n    # Batch norm impact\n    bn_scores = {\"before\": -50, \"after\": 0, \"none\": 150}\n    # Weight init impact\n    init_scores = {\"xavier\": 0, \"kaiming\": -30, \"normal\": 100}\n    \n    score = (base_score + \n             dropout_scores.get(dropout_policy, 0) + \n             bn_scores.get(batch_norm, 0) + \n             init_scores.get(weight_init, 0) +\n             np.random.normal(0, 50))\n    \n    return score\n\ndef train_with_config(X):\n    \"\"\"Objective function with various categorical choices.\"\"\"\n    results = []\n    \n    for params in X:\n        dropout_policy = params[0]  # \"none\", \"light\", \"heavy\"\n        batch_norm = params[1]       # \"before\", \"after\", \"none\"\n        weight_init = params[2]      # \"xavier\", \"kaiming\", \"normal\"\n        \n        # Use these strings to configure your model\n        score = train_model_with_config(\n            dropout_policy=dropout_policy,\n            batch_norm=batch_norm,\n            weight_init=weight_init\n        )\n        results.append(score)\n    \n    return np.array(results)  # Return numpy array\n\noptimizer = SpotOptim(\n    fun=train_with_config,\n    bounds=[\n        (\"none\", \"light\", \"heavy\"),           # Dropout policy\n        (\"before\", \"after\", \"none\"),          # Batch norm position\n        (\"xavier\", \"kaiming\", \"normal\")       # Weight initialization\n    ],\n    var_type=[\"factor\", \"factor\", \"factor\"],\n    max_iter=25,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(\"Best configuration:\")\nprint(f\"  Dropout: {result.x[0]}\")\nprint(f\"  Batch norm: {result.x[1]}\")\nprint(f\"  Weight init: {result.x[2]}\")\nprint(f\"  Score: {result.fun:.4f}\")\n\nBest configuration:\n  Dropout: light\n  Batch norm: before\n  Weight init: xavier\n  Score: 2914.8566\n\n\n\n\n22.5.2 Viewing All Evaluated Configurations\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport numpy as np\n\ndef train_and_evaluate(X):\n    \"\"\"Train models with different activation functions.\"\"\"\n    results = []\n    \n    for params in X:\n        l1 = int(params[0])         # Integer: layer size\n        activation = params[1]       # String: activation function\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders()\n        \n        # Create model with the activation function\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=2,\n            activation=activation  # Pass string directly!\n        )\n        \n        # Train model\n        optimizer = model.get_optimizer(\"Adam\", lr=0.01)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(50):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_loss = test_loss / len(test_loader)\n        results.append(avg_loss)\n    \n    return np.array(results)\n\noptimizer = SpotOptim(\n    fun=train_and_evaluate,\n    bounds=[\n        (16, 128),                                   # Layer size\n        (\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")   # Activation\n    ],\n    var_type=[\"int\", \"factor\"],  # IMPORTANT: Specify variable types!\n    max_iter=30,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Access all evaluated configurations\nprint(\"\\nAll evaluated configurations:\")\nprint(\"Layer Size | Activation | Test MSE\")\nprint(\"-\" * 42)\nfor i in range(min(10, len(result.X))):  # Show first 10\n    l1 = int(result.X[i, 0])\n    activation = result.X[i, 1]  # String value!\n    loss = result.y[i]\n    print(f\"{l1:10d} | {activation:10s} | {loss:.4f}\")\n\n# Find top 5 configurations\nsorted_indices = result.y.argsort()[:5]\nprint(\"\\nTop 5 configurations:\")\nfor idx in sorted_indices:\n    print(f\"l1={int(result.X[idx, 0]):3d}, \"\n          f\"activation={result.X[idx, 1]:10s}, \"\n          f\"MSE={result.y[idx]:.4f}\")\n\n\nAll evaluated configurations:\nLayer Size | Activation | Test MSE\n------------------------------------------\n        41 | Tanh       | 26615.0638\n       118 | Sigmoid    | 26259.8366\n        26 | Tanh       | 26569.0000\n       108 | Sigmoid    | 26385.2038\n        71 | LeakyReLU  | 26577.3887\n        34 | Tanh       | 26612.4915\n        87 | ReLU       | 26537.1999\n       101 | Tanh       | 26523.3379\n        55 | Sigmoid    | 26540.6159\n        74 | ReLU       | 26590.8177\n\nTop 5 configurations:\nl1=118, activation=Sigmoid   , MSE=26259.8366\nl1=127, activation=Sigmoid   , MSE=26354.7051\nl1=108, activation=Sigmoid   , MSE=26385.2038\nl1= 66, activation=Sigmoid   , MSE=26431.9232\nl1= 94, activation=LeakyReLU , MSE=26459.4186",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#how-it-works",
    "href": "factor_variables.html#how-it-works",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.6 How It Works",
    "text": "22.6 How It Works\n\n22.6.1 Internal Mechanism\nSpotOptim handles factor variables through automatic conversion:\n\nInitialization: String tuples in bounds are detected\n\nbounds = [(\"ReLU\", \"Sigmoid\", \"Tanh\")]\n# Internally mapped to: {0: \"ReLU\", 1: \"Sigmoid\", 2: \"Tanh\"}\n# Bounds become: [(0, 2)]\n\nSampling: Initial design samples from [0, n_levels-1] and rounds to integers\n\n# Samples might be: [0.3, 1.8, 2.1]\n# After rounding: [0, 2, 2]\n\nEvaluation: Before calling objective function, integers → strings\n\n# [0, 2, 2] → [\"ReLU\", \"Tanh\", \"Tanh\"]\n# Objective function receives strings\n\nOptimization: Surrogate model works with integers [0, n_levels-1]\nResults: Final results mapped back to strings\n\nresult.x[0]  # Returns \"ReLU\", not 0\nresult.X     # All rows contain strings for factor variables\n\narray([[41.0, 'Tanh'],\n       [118.0, 'Sigmoid'],\n       [26.0, 'Tanh'],\n       [108.0, 'Sigmoid'],\n       [71.0, 'LeakyReLU'],\n       [34.0, 'Tanh'],\n       [87.0, 'ReLU'],\n       [101.0, 'Tanh'],\n       [55.0, 'Sigmoid'],\n       [74.0, 'ReLU'],\n       [119.0, 'ReLU'],\n       [20.0, 'Tanh'],\n       [87.0, 'Tanh'],\n       [107.0, 'LeakyReLU'],\n       [75.0, 'Tanh'],\n       [53.0, 'Tanh'],\n       [35.0, 'Sigmoid'],\n       [93.0, 'Sigmoid'],\n       [38.0, 'Tanh'],\n       [96.0, 'Sigmoid'],\n       [112.0, 'Tanh'],\n       [127.0, 'Sigmoid'],\n       [54.0, 'Sigmoid'],\n       [64.0, 'LeakyReLU'],\n       [115.0, 'Sigmoid'],\n       [75.0, 'Sigmoid'],\n       [42.0, 'Sigmoid'],\n       [66.0, 'Sigmoid'],\n       [94.0, 'LeakyReLU'],\n       [79.0, 'Tanh']], dtype=object)\n\n\n\n\n\n22.6.2 Variable Type Auto-Detection\nIf you don’t specify var_type, SpotOptim automatically detects factor variables:\n\n# Example 1: Explicit var_type (recommended)\n# This shows the syntax - replace my_function with your actual function\n\n# optimizer = SpotOptim(\n#     fun=my_function,\n#     bounds=[(-4, -2), (\"ReLU\", \"Tanh\")],\n#     var_type=[\"float\", \"factor\"]  # Explicit\n# )\n\n# Example 2: Auto-detection (works but less explicit)\n# optimizer = SpotOptim(\n#     fun=my_function,\n#     bounds=[(-4, -2), (\"ReLU\", \"Tanh\")]\n#     # var_type automatically set to [\"float\", \"factor\"]\n# )\n\n# Here's a working example:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef demo_function(X):\n    results = []\n    for params in X:\n        lr = 10 ** params[0]  # Continuous parameter\n        activation = params[1]  # Factor parameter\n        score = 3000 + lr * 100 + {\"ReLU\": 0, \"Tanh\": 50}.get(activation, 100)\n        results.append(score + np.random.normal(0, 10))\n    return np.array(results)\n\n# With explicit var_type (recommended)\noptimizer = SpotOptim(\n    fun=demo_function,\n    bounds=[(-4, -2), (\"ReLU\", \"Tanh\")],\n    var_type=[\"float\", \"factor\"],  # Explicit is clearer\n    max_iter=10,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"Best lr: {10**result.x[0]:.6f}, Best activation: {result.x[1]}\")\n\nBest lr: 0.006734, Best activation: ReLU",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#complete-example-full-workflow",
    "href": "factor_variables.html#complete-example-full-workflow",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.7 Complete Example: Full Workflow",
    "text": "22.7 Complete Example: Full Workflow\n\n\"\"\"\nComplete example: Neural network hyperparameter optimization with factor variables.\n\"\"\"\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n\ndef objective_function(X):\n    \"\"\"Train and evaluate models with given hyperparameters.\"\"\"\n    results = []\n    \n    for params in X:\n        # Extract hyperparameters\n        log_lr = params[0]\n        l1 = int(params[1])\n        num_layers = int(params[2])\n        activation = params[3]  # String!\n        \n        lr = 10 ** log_lr\n        \n        print(f\"Testing: lr={lr:.6f}, l1={l1}, layers={num_layers}, \"\n              f\"activation={activation}\")\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(\n            test_size=0.2,\n            batch_size=32,\n            random_state=42\n        )\n        \n        # Create and train model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=num_layers,\n            activation=activation\n        )\n        \n        optimizer = model.get_optimizer(\"Adam\", lr=lr)\n        criterion = nn.MSELoss()\n        \n        # Training loop\n        num_epochs = 30\n        for epoch in range(num_epochs):\n            model.train()\n            for batch_X, batch_y in train_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluation\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results.append(avg_test_loss)\n        print(f\"  → Test MSE: {avg_test_loss:.4f}\")\n    \n    return np.array(results)\n\n\ndef main():\n    print(\"=\" * 80)\n    print(\"Neural Network Hyperparameter Optimization with Factor Variables\")\n    print(\"=\" * 80)\n    \n    # Define optimization problem\n    optimizer = SpotOptim(\n        fun=objective_function,\n        bounds=[\n            (-4, -2),                                    # log10(learning_rate)\n            (16, 128),                                   # l1 (neurons)\n            (0, 4),                                      # num_hidden_layers\n            (\"ReLU\", \"Sigmoid\", \"Tanh\", \"LeakyReLU\")   # activation (factor!)\n        ],\n        var_type=[\"float\", \"int\", \"int\", \"factor\"],\n        max_iter=50,\n        seed=42\n    )\n    \n    # Run optimization\n    print(\"\\nStarting optimization...\")\n    result = optimizer.optimize()\n    \n    # Display results\n    print(\"\\n\" + \"=\" * 80)\n    print(\"OPTIMIZATION RESULTS\")\n    print(\"=\" * 80)\n    print(f\"Best learning rate: {10**result.x[0]:.6f}\")\n    print(f\"Best layer size (l1): {int(result.x[1])}\")\n    print(f\"Best num hidden layers: {int(result.x[2])}\")\n    print(f\"Best activation function: {result.x[3]}\")  # String value!\n    print(f\"Best test MSE: {result.fun:.4f}\")\n    \n    # Show top 5 configurations\n    print(\"\\n\" + \"=\" * 80)\n    print(\"TOP 5 CONFIGURATIONS\")\n    print(\"=\" * 80)\n    sorted_indices = result.y.argsort()[:5]\n    print(f\"{'Rank':&lt;6} {'LR':&lt;12} {'L1':&lt;6} {'Layers':&lt;8} \"\n          f\"{'Activation':&lt;12} {'MSE':&lt;10}\")\n    print(\"-\" * 80)\n    for rank, idx in enumerate(sorted_indices, 1):\n        lr = 10 ** result.X[idx, 0]\n        l1 = int(result.X[idx, 1])\n        layers = int(result.X[idx, 2])\n        activation = result.X[idx, 3]\n        mse = result.y[idx]\n        print(f\"{rank:&lt;6} {lr:&lt;12.6f} {l1:&lt;6} {layers:&lt;8} \"\n              f\"{activation:&lt;12} {mse:&lt;10.4f}\")\n    \n    # Train final model with best configuration\n    print(\"\\n\" + \"=\" * 80)\n    print(\"TRAINING FINAL MODEL\")\n    print(\"=\" * 80)\n    \n    best_lr = 10 ** result.x[0]\n    best_l1 = int(result.x[1])\n    best_layers = int(result.x[2])\n    best_activation = result.x[3]\n    \n    print(f\"Configuration: lr={best_lr:.6f}, l1={best_l1}, \"\n          f\"layers={best_layers}, activation={best_activation}\")\n    \n    train_loader, test_loader, _ = get_diabetes_dataloaders(\n        test_size=0.2,\n        batch_size=32,\n        random_state=42\n    )\n    \n    final_model = LinearRegressor(\n        input_dim=10,\n        output_dim=1,\n        l1=best_l1,\n        num_hidden_layers=best_layers,\n        activation=best_activation\n    )\n    \n    optimizer_final = final_model.get_optimizer(\"Adam\", lr=best_lr)\n    criterion = nn.MSELoss()\n    \n    # Extended training\n    num_epochs = 100\n    print(f\"\\nTraining for {num_epochs} epochs...\")\n    for epoch in range(num_epochs):\n        final_model.train()\n        train_loss = 0.0\n        for batch_X, batch_y in train_loader:\n            predictions = final_model(batch_X)\n            loss = criterion(predictions, batch_y)\n            optimizer_final.zero_grad()\n            loss.backward()\n            optimizer_final.step()\n            train_loss += loss.item()\n        \n        if (epoch + 1) % 20 == 0:\n            avg_train_loss = train_loss / len(train_loader)\n            print(f\"Epoch {epoch+1}/{num_epochs}: Train MSE = {avg_train_loss:.4f}\")\n    \n    # Final evaluation\n    final_model.eval()\n    final_test_loss = 0.0\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            predictions = final_model(batch_X)\n            final_test_loss += criterion(predictions, batch_y).item()\n    \n    final_avg_loss = final_test_loss / len(test_loader)\n    print(f\"\\nFinal Test MSE: {final_avg_loss:.4f}\")\n    print(\"=\" * 80)\n\n\nif __name__ == \"__main__\":\n    main()\n\n================================================================================\nNeural Network Hyperparameter Optimization with Factor Variables\n================================================================================\n\nStarting optimization...\nTesting: lr=0.007002, l1=101, layers=2, activation=ReLU\n  → Test MSE: 26576.7441\nTesting: lr=0.000604, l1=50, layers=2, activation=ReLU\n  → Test MSE: 26611.8971\nTesting: lr=0.000149, l1=67, layers=1, activation=Tanh\n  → Test MSE: 26620.4427\nTesting: lr=0.000296, l1=40, layers=0, activation=Tanh\n  → Test MSE: 26649.3874\nTesting: lr=0.004887, l1=116, layers=2, activation=Sigmoid\n  → Test MSE: 26603.0677\nTesting: lr=0.001772, l1=124, layers=3, activation=Sigmoid\n  → Test MSE: 26628.8171\nTesting: lr=0.001107, l1=36, layers=4, activation=Sigmoid\n  → Test MSE: 26690.4375\nTesting: lr=0.003708, l1=20, layers=1, activation=LeakyReLU\n  → Test MSE: 26625.1406\nTesting: lr=0.000861, l1=90, layers=1, activation=Tanh\n  → Test MSE: 26663.5436\nTesting: lr=0.000237, l1=78, layers=3, activation=Tanh\n  → Test MSE: 26636.8327\nTesting: lr=0.007097, l1=101, layers=2, activation=ReLU\n  → Test MSE: 26611.8639\nTesting: lr=0.009463, l1=24, layers=0, activation=LeakyReLU\n  → Test MSE: 26538.2507\nTesting: lr=0.000761, l1=94, layers=4, activation=Tanh\n  → Test MSE: 26660.1315\nTesting: lr=0.003722, l1=82, layers=1, activation=Tanh\n  → Test MSE: 26642.9954\nTesting: lr=0.007645, l1=96, layers=3, activation=Sigmoid\n  → Test MSE: 26608.2467\nTesting: lr=0.000769, l1=40, layers=1, activation=Tanh\n  → Test MSE: 26646.4844\nTesting: lr=0.000235, l1=109, layers=4, activation=LeakyReLU\n  → Test MSE: 26656.9453\nTesting: lr=0.000359, l1=76, layers=3, activation=Sigmoid\n  → Test MSE: 26641.3125\nTesting: lr=0.004959, l1=50, layers=2, activation=Tanh\n  → Test MSE: 26672.2969\nTesting: lr=0.002494, l1=57, layers=3, activation=LeakyReLU\n  → Test MSE: 26637.2363\nTesting: lr=0.005807, l1=20, layers=0, activation=Sigmoid\n  → Test MSE: 26534.3021\nTesting: lr=0.002939, l1=19, layers=1, activation=Sigmoid\n  → Test MSE: 26699.0189\nTesting: lr=0.001263, l1=98, layers=4, activation=ReLU\n  → Test MSE: 26641.7142\nTesting: lr=0.001226, l1=105, layers=3, activation=Sigmoid\n  → Test MSE: 26471.5111\nTesting: lr=0.004431, l1=32, layers=1, activation=Sigmoid\n  → Test MSE: 26672.5007\nTesting: lr=0.001367, l1=58, layers=2, activation=Sigmoid\n  → Test MSE: 26698.2975\nTesting: lr=0.006778, l1=81, layers=4, activation=Tanh\n  → Test MSE: 26586.1068\nTesting: lr=0.002189, l1=112, layers=4, activation=Sigmoid\n  → Test MSE: 26744.4154\nTesting: lr=0.004558, l1=24, layers=2, activation=Tanh\n  → Test MSE: 26626.5319\nTesting: lr=0.000658, l1=125, layers=0, activation=Tanh\n  → Test MSE: 26646.7487\nTesting: lr=0.000272, l1=119, layers=2, activation=Tanh\n  → Test MSE: 26633.6217\nTesting: lr=0.000133, l1=64, layers=2, activation=Tanh\n  → Test MSE: 26655.9245\nTesting: lr=0.002172, l1=70, layers=2, activation=LeakyReLU\n  → Test MSE: 26641.1471\nTesting: lr=0.000223, l1=28, layers=3, activation=Sigmoid\n  → Test MSE: 26714.4674\nTesting: lr=0.006065, l1=53, layers=3, activation=Sigmoid\n  → Test MSE: 26648.6836\nTesting: lr=0.000352, l1=42, layers=4, activation=ReLU\n  → Test MSE: 26624.9941\nTesting: lr=0.003464, l1=124, layers=2, activation=Tanh\n  → Test MSE: 26603.6211\nTesting: lr=0.000219, l1=37, layers=3, activation=ReLU\n  → Test MSE: 26669.9779\nTesting: lr=0.002619, l1=70, layers=3, activation=ReLU\n  → Test MSE: 26631.3457\nTesting: lr=0.004686, l1=123, layers=2, activation=ReLU\n  → Test MSE: 26585.0286\nTesting: lr=0.000165, l1=44, layers=0, activation=ReLU\n  → Test MSE: 26657.3737\nTesting: lr=0.000917, l1=93, layers=1, activation=Sigmoid\n  → Test MSE: 26651.9902\nTesting: lr=0.001789, l1=117, layers=1, activation=Tanh\n  → Test MSE: 26610.1680\nTesting: lr=0.000134, l1=101, layers=4, activation=Sigmoid\n  → Test MSE: 26854.7656\nTesting: lr=0.004937, l1=108, layers=2, activation=ReLU\n  → Test MSE: 26624.2904\nTesting: lr=0.004047, l1=93, layers=1, activation=ReLU\n  → Test MSE: 26604.5143\nTesting: lr=0.000997, l1=112, layers=4, activation=Tanh\n  → Test MSE: 26622.6172\nTesting: lr=0.005449, l1=52, layers=4, activation=Sigmoid\n  → Test MSE: 26723.8392\nTesting: lr=0.000409, l1=63, layers=3, activation=Sigmoid\n  → Test MSE: 26629.7383\nTesting: lr=0.000371, l1=45, layers=3, activation=LeakyReLU\n  → Test MSE: 26649.8965\n\n================================================================================\nOPTIMIZATION RESULTS\n================================================================================\nBest learning rate: 0.001226\nBest layer size (l1): 105\nBest num hidden layers: 3\nBest activation function: Sigmoid\nBest test MSE: 26471.5111\n\n================================================================================\nTOP 5 CONFIGURATIONS\n================================================================================\nRank   LR           L1     Layers   Activation   MSE       \n--------------------------------------------------------------------------------\n1      0.001226     105    3        Sigmoid      26471.5111\n2      0.005807     20     0        Sigmoid      26534.3021\n3      0.009463     24     0        LeakyReLU    26538.2507\n4      0.007002     101    2        ReLU         26576.7441\n5      0.004686     123    2        ReLU         26585.0286\n\n================================================================================\nTRAINING FINAL MODEL\n================================================================================\nConfiguration: lr=0.001226, l1=105, layers=3, activation=Sigmoid\n\nTraining for 100 epochs...\nEpoch 20/100: Train MSE = 27900.2235\nEpoch 40/100: Train MSE = 27627.3497\nEpoch 60/100: Train MSE = 31102.8076\nEpoch 80/100: Train MSE = 27668.1839\nEpoch 100/100: Train MSE = 30941.5116\n\nFinal Test MSE: 26693.2852\n================================================================================",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#best-practices",
    "href": "factor_variables.html#best-practices",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.8 Best Practices",
    "text": "22.8 Best Practices\n\n22.8.1 Do’s\n✅ Use descriptive string values\n\nbounds=[(\"xavier_uniform\", \"kaiming_normal\", \"orthogonal\")]\n\n✅ Explicitly specify var_type for clarity\n\nvar_type=[\"float\", \"int\", \"factor\"]\n\n✅ Access results as strings\n\n# Example: Accessing factor variable results as strings\n# (This assumes you've run an optimization with activation as a factor variable)\n\n# If you have a result from the previous examples:\n# best_activation = result.x[3]  # For 4-parameter optimization\n# Or for simpler cases:\n# best_activation = result.x[0]  # For single-parameter optimization\n\n# Example with inline optimization:\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef quick_test(X):\n    results = []\n    for params in X:\n        activation = params[0]\n        score = {\"ReLU\": 3500, \"Tanh\": 3600}.get(activation, 4000)\n        results.append(score + np.random.normal(0, 50))\n    return np.array(results)\n\nopt = SpotOptim(\n    fun=quick_test,\n    bounds=[(\"ReLU\", \"Tanh\")],\n    var_type=[\"factor\"],\n    max_iter=10,\n    seed=42\n)\nresult = opt.optimize()\n\n# Access as string - this is the correct way\nbest_activation = result.x[0]  # String value like \"ReLU\"\nprint(f\"Best activation: {best_activation} (type: {type(best_activation).__name__})\")\n\n# You can use it directly in your model\n# model = LinearRegressor(activation=best_activation)\n\nBest activation: ReLU (type: str)\n\n\n✅ Mix factor variables with numeric/integer variables\n\nbounds=[(-4, -2), (16, 128), (\"ReLU\", \"Tanh\")]\nvar_type=[\"float\", \"int\", \"factor\"]\n\n\n\n22.8.2 Don’ts\n❌ Don’t use integers in factor bounds\n\n# Wrong: Use strings, not integers\nbounds=[(0, 1, 2)]  # Wrong!\nbounds=[(\"ReLU\", \"Sigmoid\", \"Tanh\")]  # Correct!\n\n❌ Don’t expect integers in objective function\n\ndef objective(X):\n    activation = X[0][2]\n    # activation is a string, not an integer!\n    # Don't do: if activation == 0:  # Wrong!\n    # Do: if activation == \"ReLU\":   # Correct!\n\n❌ Don’t manually convert factor variables\n\n# SpotOptim handles conversion automatically\n# Don't do manual mapping in your objective function\n\n❌ Don’t use empty tuples\n\n# Wrong: Empty tuple\nbounds=[()]\n\n# Correct: At least one string\nbounds=[(\"ReLU\",)]  # Single choice (will be treated as fixed)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#troubleshooting",
    "href": "factor_variables.html#troubleshooting",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.9 Troubleshooting",
    "text": "22.9 Troubleshooting\n\n22.9.1 Common Issues\nIssue: Objective function receives integers instead of strings\nSolution: Ensure you’re using the latest version of SpotOptim with factor variable support. Factor variables are automatically converted before calling the objective function.\n\nIssue: ValueError: could not convert string to float\nSolution: This occurs if there’s a version mismatch. Update SpotOptim to ensure the object array conversion is implemented correctly.\n\nIssue: Results show integers instead of strings\nSolution: Check that you’re accessing result.x (mapped values) instead of internal arrays. The result object automatically maps factor variables to their original strings.\n\nIssue: Single-level factor variables cause dimension reduction\nBehavior: If a factor variable has only one choice, e.g., (\"ReLU\",), SpotOptim treats it as a fixed dimension and may reduce the dimensionality. This is expected behavior.\nSolution: Use at least two choices for optimization, or remove single-choice dimensions from bounds.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#summary",
    "href": "factor_variables.html#summary",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.10 Summary",
    "text": "22.10 Summary\nFactor variables in SpotOptim enable:\n\n✅ Categorical optimization: Optimize over discrete string choices\n✅ Automatic conversion: Seamless integer↔︎string mapping\n✅ Neural network hyperparameters: Optimize activation functions, optimizers, etc.\n✅ Mixed variable types: Combine with continuous and integer variables\n✅ Clean interface: Objective functions work with strings directly\n✅ String results: Final results contain original string values\n\nFactor variables make categorical hyperparameter optimization as easy as continuous optimization!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "factor_variables.html#see-also",
    "href": "factor_variables.html#see-also",
    "title": "22  Factor Variables for Categorical Hyperparameters",
    "section": "22.11 See Also",
    "text": "22.11 See Also\n\nLinearRegressor Documentation - Neural network class supporting string-based activation functions\nDiabetes Dataset Utilities - Data loading utilities used in examples\nVariable Types - Overview of all variable types in SpotOptim\nSave and Load - Saving and loading optimization results with factor variables",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Factor Variables for Categorical Hyperparameters</span>"
    ]
  },
  {
    "objectID": "transformations.html",
    "href": "transformations.html",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "",
    "text": "23.1 Overview\nSpotOptim supports automatic variable transformations to improve optimization in scaled search spaces. Instead of manually handling transformations (e.g., log-scale for learning rates), you can specify transformations via the var_trans parameter, and SpotOptim handles everything internally.\nWhat are Variable Transformations?\nVariable transformations allow you to specify how search space dimensions should be scaled during optimization:\nModule: spotoptim.SpotOptim\nKey Features:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#overview",
    "href": "transformations.html#overview",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "",
    "text": "Original scale (user interface): Input bounds, output results, plots\nTransformed scale (internal): Surrogate modeling, acquisition optimization\nAutomatic conversion: SpotOptim handles all transformations transparently\n\n\n\n\nDefine transformations via var_trans parameter: [\"log10\", \"sqrt\", None, ...]\nOptimization occurs in transformed space (better for surrogate models)\nAll external interfaces use original scale (intuitive for users)\nSupported transformations: log10, log/ln, sqrt, exp, square, cube, inv/reciprocal\nMix transformed and non-transformed variables",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#why-use-transformations",
    "href": "transformations.html#why-use-transformations",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.2 Why Use Transformations?",
    "text": "23.2 Why Use Transformations?\n\n23.2.1 Problem: Poorly Scaled Search Spaces\nSome hyperparameters span multiple orders of magnitude:\n\nLearning rates: 0.0001 to 1.0 (4 orders of magnitude)\nRegularization: 0.001 to 100 (5 orders of magnitude)\nNetwork sizes: 10 to 1000 neurons\n\nDirect optimization in these spaces is inefficient because:\n\nSurrogate models struggle with extreme scales\nUniform sampling wastes evaluations in unimportant regions\nAcquisition functions behave poorly with skewed distributions\n\n\n\n23.2.2 Solution: Logarithmic and Other Transformations\nTransform the space for optimization while maintaining user-friendly interfaces:\n# Without transformations (manual approach)\nbounds = [(-4, 0)]  # log10(lr): awkward for users\nlr = 10 ** params[0]  # Manual transformation in objective\n\n# With transformations (automatic)\nbounds = [(0.0001, 1.0)]  # lr in natural scale\nvar_trans = [\"log10\"]  # SpotOptim handles transformation\nlr = params[0]  # Already in original scale!",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#quick-start",
    "href": "transformations.html#quick-start",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.3 Quick Start",
    "text": "23.3 Quick Start\n\n23.3.1 Basic Log-Scale Transformation\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective_function(X):\n    \"\"\"Objective receives parameters in ORIGINAL scale.\"\"\"\n    results = []\n    for params in X:\n        lr = params[0]  # Already in [0.001, 0.1] - original scale!\n        alpha = params[1]  # Already in [0.01, 1.0] - original scale!\n        \n        # Simulate model training\n        score = (lr - 0.01)**2 + (alpha - 0.1)**2 + np.random.normal(0, 0.01)\n        results.append(score)\n    \n    return np.array(results)\n\n# Create optimizer with transformations\noptimizer = SpotOptim(\n    fun=objective_function,\n    bounds=[\n        (0.001, 0.1),    # learning rate (original scale)\n        (0.01, 1.0)      # alpha (original scale)\n    ],\n    var_trans=[\"log10\", \"log10\"],  # Both use log10 transformation\n    var_name=[\"lr\", \"alpha\"],\n    max_iter=20,\n    seed=42\n)\n\n# Run optimization\nresult = optimizer.optimize()\n\nprint(f\"Best lr: {result.x[0]:.6f}\")      # In original scale\nprint(f\"Best alpha: {result.x[1]:.6f}\")   # In original scale\nprint(f\"Best score: {result.fun:.6f}\")\n\nBest lr: 0.002118\nBest alpha: 0.103430\nBest score: -0.022418",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#supported-transformations",
    "href": "transformations.html#supported-transformations",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.4 Supported Transformations",
    "text": "23.4 Supported Transformations\nSpotOptim supports the following transformations:\n\n\n\n\n\n\n\n\n\nTransformation\nForward (x → t)\nInverse (t → x)\nUse Case\n\n\n\n\n\"log10\"\nt = log₁₀(x)\nx = 10^t\nLearning rates, regularization\n\n\n\"log\" or \"ln\"\nt = ln(x)\nx = e^t\nNatural exponential scales\n\n\n\"sqrt\"\nt = √x\nx = t²\nModerate scaling\n\n\n\"exp\"\nt = e^x\nx = ln(t)\nInverse of natural log\n\n\n\"square\"\nt = x²\nx = √t\nInverse of sqrt\n\n\n\"cube\"\nt = x³\nx = ∛t\nStrong scaling\n\n\n\"inv\" or \"reciprocal\"\nt = 1/x\nx = 1/t\nReciprocal relationships\n\n\nNone or \"id\"\nt = x\nx = t\nNo transformation\n\n\n\n\n23.4.1 Transformation Guidelines\nWhen to use \"log10\" or \"log\":\n\nParameters spanning multiple orders of magnitude\nLearning rates: (1e-5, 1e-1) → uniform sampling in log space\nRegularization parameters: (1e-6, 1e2)\nBatch sizes, hidden units when range is large\n\nWhen to use \"sqrt\":\n\nModerate scaling (1-2 orders of magnitude)\nBatch sizes: (16, 512)\nNumber of neurons: (32, 256)\n\nWhen to use \"inv\" (reciprocal):\n\nInverse relationships (e.g., 1/temperature)\nWhen smaller values are more important\n\nWhen to use None:\n\nParameters with narrow ranges\nAlready well-scaled parameters\nCategorical indices (use with var_type=[\"factor\"])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#detailed-examples",
    "href": "transformations.html#detailed-examples",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.5 Detailed Examples",
    "text": "23.5 Detailed Examples\n\n23.5.1 Example 1: Neural Network Hyperparameter Tuning\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim import SpotOptim\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nimport numpy as np\n\ndef train_neural_network(X):\n    \"\"\"Train neural network with hyperparameters in original scale.\"\"\"\n    results = []\n    \n    for params in X:\n        # All parameters in original scale\n        hidden_size = int(params[0])  # [16, 256]\n        num_layers = int(params[1])   # [1, 4]\n        lr = params[2]                # [0.0001, 0.1]\n        weight_decay = params[3]      # [1e-6, 0.01]\n        \n        print(f\"Training: hidden={hidden_size}, layers={num_layers}, \"\n              f\"lr={lr:.6f}, wd={weight_decay:.6f}\")\n        \n        # Load data\n        train_loader, test_loader, _ = get_diabetes_dataloaders(batch_size=32)\n        \n        # Create model\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=hidden_size,\n            num_hidden_layers=num_layers,\n            activation=\"ReLU\",\n            lr=lr\n        )\n        \n        # Get optimizer with weight decay\n        optimizer = torch.optim.Adam(model.parameters(), \n                                     lr=lr, \n                                     weight_decay=weight_decay)\n        \n        # Train\n        model.train()\n        for epoch in range(50):\n            for batch_x, batch_y in train_loader:\n                optimizer.zero_grad()\n                outputs = model(batch_x)\n                loss = nn.MSELoss()(outputs, batch_y)\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        total_loss = 0\n        with torch.no_grad():\n            for batch_x, batch_y in test_loader:\n                outputs = model(batch_x)\n                loss = nn.MSELoss()(outputs, batch_y)\n                total_loss += loss.item()\n        \n        avg_loss = total_loss / len(test_loader)\n        results.append(avg_loss)\n    \n    return np.array(results)\n\n# Create optimizer with appropriate transformations\noptimizer = SpotOptim(\n    fun=train_neural_network,\n    bounds=[\n        (16, 256),           # hidden_size: moderate range\n        (1, 4),              # num_layers: small range\n        (0.0001, 0.1),       # lr: 3 orders of magnitude\n        (1e-6, 0.01)         # weight_decay: 4 orders of magnitude\n    ],\n    var_trans=[\n        \"sqrt\",              # sqrt for hidden_size\n        None,                # no transformation for num_layers\n        \"log10\",             # log10 for learning rate\n        \"log10\"              # log10 for weight_decay\n    ],\n    var_type=[\"int\", \"int\", \"float\", \"float\"],\n    var_name=[\"hidden_size\", \"num_layers\", \"lr\", \"weight_decay\"],\n    max_iter=30,\n    n_initial=10,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\nprint(\"\\nBest Configuration:\")\nprint(f\"  Hidden Size: {int(result.x[0])}\")\nprint(f\"  Num Layers: {int(result.x[1])}\")\nprint(f\"  Learning Rate: {result.x[2]:.6f}\")\nprint(f\"  Weight Decay: {result.x[3]:.8f}\")\nprint(f\"  Best Loss: {result.fun:.6f}\")\n\nTraining: hidden=225, layers=3, lr=0.001748, wd=0.000001\nTraining: hidden=81, layers=2, lr=0.003730, wd=0.000003\nTraining: hidden=25, layers=2, lr=0.000615, wd=0.001695\nTraining: hidden=49, layers=2, lr=0.000147, wd=0.000204\nTraining: hidden=196, layers=4, lr=0.007107, wd=0.000009\nTraining: hidden=121, layers=4, lr=0.025632, wd=0.000017\nTraining: hidden=100, layers=2, lr=0.072441, wd=0.000096\nTraining: hidden=169, layers=1, lr=0.000238, wd=0.004102\nTraining: hidden=100, layers=3, lr=0.001146, wd=0.001331\nTraining: hidden=36, layers=3, lr=0.021475, wd=0.000340\nTraining: hidden=81, layers=2, lr=0.004118, wd=0.000003\nTraining: hidden=81, layers=2, lr=0.002046, wd=0.000002\nTraining: hidden=81, layers=2, lr=0.001988, wd=0.000005\nTraining: hidden=36, layers=3, lr=0.047603, wd=0.000580\nTraining: hidden=25, layers=3, lr=0.027370, wd=0.000396\nTraining: hidden=100, layers=3, lr=0.006304, wd=0.000349\nTraining: hidden=100, layers=2, lr=0.002566, wd=0.000003\nTraining: hidden=81, layers=2, lr=0.002595, wd=0.000003\nTraining: hidden=81, layers=2, lr=0.001238, wd=0.000015\nTraining: hidden=81, layers=2, lr=0.005535, wd=0.000001\nTraining: hidden=81, layers=2, lr=0.001685, wd=0.000009\nTraining: hidden=81, layers=2, lr=0.000665, wd=0.000012\nTraining: hidden=100, layers=2, lr=0.001189, wd=0.000024\nTraining: hidden=81, layers=2, lr=0.001185, wd=0.000022\nTraining: hidden=81, layers=2, lr=0.003638, wd=0.000002\nTraining: hidden=81, layers=2, lr=0.000924, wd=0.000001\nTraining: hidden=81, layers=2, lr=0.002542, wd=0.000001\nTraining: hidden=81, layers=2, lr=0.002615, wd=0.000001\nTraining: hidden=81, layers=2, lr=0.010361, wd=0.000001\nTraining: hidden=81, layers=2, lr=0.001666, wd=0.000001\n\nBest Configuration:\n  Hidden Size: 81\n  Num Layers: 2\n  Learning Rate: 0.010361\n  Weight Decay: 0.00000136\n  Best Loss: 2534.970378\n\n\n\n\n23.5.2 Example 2: Physics-Informed Neural Networks (PINNs)\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef train_pinn(X):\n    \"\"\"Train PINN with hyperparameters in original scale.\"\"\"\n    results = []\n    \n    for params in X:\n        neurons = int(params[0])      # [16, 128]\n        layers = int(params[1])       # [1, 4]\n        lr = params[2]                # [0.1, 10.0]\n        alpha = params[3]             # [0.01, 1.0]\n        \n        # Simulate PINN training\n        # In practice, this would train an actual PINN model\n        val_error = 0.1 * (1/lr) + 0.05 * alpha + np.random.normal(0, 0.01)\n        results.append(val_error)\n    \n    return np.array(results)\n\n# Define optimization with transformations\noptimizer = SpotOptim(\n    fun=train_pinn,\n    bounds=[\n        (16, 128),           # neurons\n        (1, 4),              # layers\n        (0.1, 10.0),         # lr: covers 2 orders of magnitude\n        (0.01, 1.0)          # alpha: covers 2 orders of magnitude\n    ],\n    var_trans=[None, None, \"log10\", \"log10\"],\n    var_type=[\"int\", \"int\", \"float\", \"float\"],\n    var_name=[\"neurons\", \"layers\", \"lr\", \"alpha\"],\n    max_iter=20,\n    seed=42\n)\n\nresult = optimizer.optimize()\noptimizer.print_best(result)\n\n\nBest Solution Found:\n--------------------------------------------------\n  neurons: 86\n  layers: 4\n  lr: 4.0352\n  alpha: 0.0418\n  Objective Value: 0.0165\n  Total Evaluations: 20\n\n\n\n\n23.5.3 Example 3: Mixing Transformations\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef complex_objective(X):\n    \"\"\"Objective with multiple transformation types.\"\"\"\n    results = []\n    \n    for params in X:\n        # All in original scale\n        x1 = params[0]  # sqrt-transformed: [10, 1000]\n        x2 = params[1]  # log10-transformed: [0.001, 1.0]\n        x3 = params[2]  # no transformation: [-5, 5]\n        x4 = params[3]  # reciprocal: [0.1, 10]\n        \n        # Complex function\n        result = (\n            (x1/100 - 5)**2 + \n            (np.log10(x2) + 1.5)**2 + \n            x3**2 + \n            (1/x4 - 0.2)**2\n        )\n        results.append(result)\n    \n    return np.array(results)\n\noptimizer = SpotOptim(\n    fun=complex_objective,\n    bounds=[\n        (10, 1000),      # x1: moderate range\n        (0.001, 1.0),    # x2: log scale\n        (-5, 5),         # x3: symmetric range\n        (0.1, 10)        # x4: for reciprocal\n    ],\n    var_trans=[\"sqrt\", \"log10\", None, \"inv\"],\n    var_name=[\"x1_sqrt\", \"x2_log\", \"x3_linear\", \"x4_inv\"],\n    max_iter=30,\n    seed=42\n)\n\nresult = optimizer.optimize()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#viewing-transformations-in-tables",
    "href": "transformations.html#viewing-transformations-in-tables",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.6 Viewing Transformations in Tables",
    "text": "23.6 Viewing Transformations in Tables\nThe transformation type is displayed in the “trans” column of both design and results tables:\n\n23.6.1 Design Table (Before Optimization)\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\noptimizer = SpotOptim(\n    fun=lambda X: np.sum(X**2, axis=1),\n    bounds=[\n        (0.001, 1.0),\n        (0.01, 10.0),\n        (10, 1000),\n        (-5, 5)\n    ],\n    var_trans=[\"log10\", \"log\", \"sqrt\", None],\n    var_name=[\"lr\", \"alpha\", \"neurons\", \"bias\"],\n    max_iter=10\n)\n\n# Display design table\nprint(optimizer.print_design_table())\n\n| name    | type   |   lower |     upper |   default | trans   |\n|---------|--------|---------|-----------|-----------|---------|\n| lr      | float  |  0.0010 |    1.0000 |    0.5005 | log10   |\n| alpha   | float  |  0.0100 |   10.0000 |    5.0050 | log     |\n| neurons | float  | 10.0000 | 1000.0000 |  505.0000 | sqrt    |\n| bias    | float  | -5.0000 |    5.0000 |    0.0000 | -       |\n\n\nOutput:\n| name    | type   |    lower |    upper |   default | trans   |\n|---------|--------|----------|----------|-----------|---------|\n| lr      | num    |   0.0010 |   1.0000 |    0.5005 | log10   |\n| alpha   | num    |   0.0100 |  10.0000 |    5.0050 | log     |\n| neurons | num    |  10.0000 | 1000.0000 |  505.0000 | sqrt    |\n| bias    | num    |  -5.0000 |   5.0000 |    0.0000 | -       |\n\n\n23.6.2 Results Table (After Optimization)\n\nresult = optimizer.optimize()\n\n# Display results with transformations\nprint(optimizer.print_results_table())\n\n| name    | type   |   lower |     upper |   tuned | trans   |\n|---------|--------|---------|-----------|---------|---------|\n| lr      | float  |  0.0010 |    1.0000 |  0.0027 | log10   |\n| alpha   | float  |  0.0100 |   10.0000 |  0.0153 | log     |\n| neurons | float  | 10.0000 | 1000.0000 | 10.0604 | sqrt    |\n| bias    | float  | -5.0000 |    5.0000 | -3.0998 | -       |\n\n\nOutput shows the “trans” column with transformation types, helping you understand which parameters were optimized in which scale.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#internal-architecture",
    "href": "transformations.html#internal-architecture",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.7 Internal Architecture",
    "text": "23.7 Internal Architecture\nUnderstanding how transformations work internally can help debug issues and understand behavior:\n\n23.7.1 Flow Diagram\nUser Input (Original Scale)\n    ↓\n[Transform to Internal Scale]\n    ↓\nOptimization (Transformed Scale)\n  • Initial design generation\n  • Surrogate model fitting\n  • Acquisition function optimization\n    ↓\n[Inverse Transform to Original Scale]\n    ↓\nObjective Function Evaluation (Original Scale)\n    ↓\nStorage & Results (Original Scale)\n\n\n23.7.2 Key Components\n\nBounds Transformation (_transform_bounds()):\n\nCalled during initialization\nTransforms _original_lower and _original_upper → lower and upper\nUpdates self.bounds for internal use\n\nForward Transformation (_transform_X()):\n\nConverts from original scale to transformed scale\nUsed before surrogate fitting\nUsed when comparing distances\n\nInverse Transformation (_inverse_transform_X()):\n\nConverts from transformed scale to original scale\nUsed before function evaluation\nUsed when storing results\n\nStorage:\n\nself.X_ stores in original scale\nself.best_x_ stores in original scale\nAll external-facing data in original scale",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#best-practices",
    "href": "transformations.html#best-practices",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.8 Best Practices",
    "text": "23.8 Best Practices\n\n23.8.1 1. Choose Appropriate Transformations\n# Good: Log scale for learning rate\nbounds = [(1e-5, 1e-1)]\nvar_trans = [\"log10\"]\n\n# Bad: No transformation for wide range\nbounds = [(1e-5, 1e-1)]\nvar_trans = [None]  # Poor sampling distribution\n\n\n23.8.2 2. Match Transformation to Range\n# Wide range (&gt;3 orders of magnitude): use log\nbounds = [(1e-6, 1e-2)]\nvar_trans = [\"log10\"]\n\n# Moderate range (1-2 orders): use sqrt\nbounds = [(10, 500)]\nvar_trans = [\"sqrt\"]\n\n# Narrow range (&lt;1 order): no transformation\nbounds = [(-1, 1)]\nvar_trans = [None]\n\n\n23.8.3 3. Validate Transformation Choice\n# Check if transformation makes sense\nimport numpy as np\n\n# Original space\nx_orig = np.linspace(0.001, 1.0, 10)\nprint(\"Original:\", x_orig)\n\n# Log10 transformed space\nx_trans = np.log10(x_orig)\nprint(\"Transformed:\", x_trans)\nprint(\"Range ratio:\", np.ptp(x_trans) / np.ptp(x_orig))\n# Should be much more uniform distribution\n\n\n23.8.4 4. Combine with Variable Types\n# Mix transformations with variable types\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[\n        (10, 200),                          # int with sqrt\n        (\"ReLU\", \"Tanh\", \"Sigmoid\"),        # factor (no transform)\n        (0.0001, 0.1),                      # num with log10\n        (0.01, 1.0)                         # num with log10\n    ],\n    var_type=[\"int\", \"factor\", \"float\", \"float\"],\n    var_trans=[\"sqrt\", None, \"log10\", \"log10\"],\n    var_name=[\"neurons\", \"activation\", \"lr\", \"dropout\"]\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#troubleshooting",
    "href": "transformations.html#troubleshooting",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.9 Troubleshooting",
    "text": "23.9 Troubleshooting\n\n23.9.1 Issue: Values Out of Bounds\nProblem: Objective function receives values outside specified bounds.\nSolution: This should not happen with transformations. If it does:\n# Check transformation is applied correctly\nprint(f\"Original bounds: {optimizer._original_lower} to {optimizer._original_upper}\")\nprint(f\"Transformed bounds: {optimizer.lower} to {optimizer.upper}\")\nprint(f\"Transformations: {optimizer.var_trans}\")\n\n\n23.9.2 Issue: Poor Optimization Performance\nProblem: Optimization doesn’t find good solutions.\nPossible causes:\n\nWrong transformation type for the parameter scale\nTransformation not needed (adding unnecessary complexity)\nBounds too wide or too narrow\n\nSolution:\n# Try different transformations\nfor trans in [None, \"log10\", \"sqrt\"]:\n    optimizer = SpotOptim(\n        fun=objective,\n        bounds=[(0.001, 1.0)],\n        var_trans=[trans],\n        max_iter=20,\n        seed=42\n    )\n    result = optimizer.optimize()\n    print(f\"Transformation: {trans}, Best: {result.fun:.6f}\")\n\n\n23.9.3 Issue: Transformation Not Applied\nProblem: Transformation doesn’t seem to affect optimization.\nCheck:\n# Verify var_trans length matches dimensions\nprint(f\"Number of dimensions: {len(optimizer.bounds)}\")\nprint(f\"Number of transformations: {len(optimizer.var_trans)}\")\n# These must match!\n\n# Check transformation is not None/\"id\"\nprint(f\"Transformations: {optimizer.var_trans}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#comparison-manual-vs-automatic-transformations",
    "href": "transformations.html#comparison-manual-vs-automatic-transformations",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.10 Comparison: Manual vs Automatic Transformations",
    "text": "23.10 Comparison: Manual vs Automatic Transformations\n\n23.10.1 Manual Approach (Old Way)\ndef objective_manual(X):\n    \"\"\"Manual transformation - error-prone!\"\"\"\n    results = []\n    for params in X:\n        # Must remember to transform\n        lr = 10 ** params[0]  # Was in log scale\n        alpha = 10 ** params[1]  # Was in log scale\n        \n        # Use parameters\n        score = compute_score(lr, alpha)\n        results.append(score)\n    return np.array(results)\n\n# Bounds in log scale - confusing!\noptimizer = SpotOptim(\n    fun=objective_manual,\n    bounds=[(-4, -1), (-2, 0)],  # log10 scale\n    var_name=[\"log10_lr\", \"log10_alpha\"]  # Confusing names\n)\n\nresult = optimizer.optimize()\n# Must transform back for interpretation\nbest_lr = 10 ** result.x[0]\nbest_alpha = 10 ** result.x[1]\n\n\n23.10.2 Automatic Approach (New Way)\ndef objective_auto(X):\n    \"\"\"Automatic transformation - clean!\"\"\"\n    results = []\n    for params in X:\n        # Already in original scale\n        lr = params[0]\n        alpha = params[1]\n        \n        # Use parameters directly\n        score = compute_score(lr, alpha)\n        results.append(score)\n    return np.array(results)\n\n# Bounds in natural scale - intuitive!\noptimizer = SpotOptim(\n    fun=objective_auto,\n    bounds=[(0.0001, 0.1), (0.01, 1.0)],\n    var_trans=[\"log10\", \"log10\"],  # Specify transformation\n    var_name=[\"lr\", \"alpha\"]  # Natural names\n)\n\nresult = optimizer.optimize()\n# Results already in original scale\nbest_lr = result.x[0]\nbest_alpha = result.x[1]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "transformations.html#summary",
    "href": "transformations.html#summary",
    "title": "23  Variable Transformations for Search Space Scaling",
    "section": "23.11 Summary",
    "text": "23.11 Summary\nKey Takeaways:\n\n✅ Use var_trans to specify transformations for each dimension\n✅ Transformations improve optimization for poorly scaled spaces\n✅ All user interfaces (bounds, results, plots) use original scale\n✅ Optimization happens internally in transformed space\n✅ Common transformations: \"log10\" for learning rates, \"sqrt\" for moderate scaling\n✅ View transformations in tables with “trans” column\n\nWhen to Use:\n\nParameters spanning multiple orders of magnitude → \"log10\" or \"log\"\nModerate scaling (1-2 orders) → \"sqrt\"\nReciprocal relationships → \"inv\"\nWell-scaled parameters → None\n\nBenefits:\n\nBetter surrogate model performance\nMore efficient sampling\nImproved optimization convergence\nUser-friendly interface (no manual transformations in objective function)\n\n\nSee Also:\n\nVariable Types Manual - Integer, numeric, and factor types\nFactor Variables Manual - Categorical optimization\nReproducibility Manual - Setting seeds for consistent results",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Variable Transformations for Search Space Scaling</span>"
    ]
  },
  {
    "objectID": "kriging.html",
    "href": "kriging.html",
    "title": "24  Kriging Surrogate Integration",
    "section": "",
    "text": "24.1 Overview\nImplementation of a Kriging (Gaussian Process) surrogate model to SpotOptim, providing an alternative to scikit-learn’s GaussianProcessRegressor.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#module-structure",
    "href": "kriging.html#module-structure",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.2 Module Structure",
    "text": "24.2 Module Structure\nsrc/spotoptim/surrogate/\n├── __init__.py          # Module exports\n├── kriging.py           # Kriging implementation (~350 lines)\n└── README.md            # Module documentation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#kriging-class-srcspotoptimsurrogatekriging.py",
    "href": "kriging.html#kriging-class-srcspotoptimsurrogatekriging.py",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.3 Kriging Class (src/spotoptim/surrogate/kriging.py)",
    "text": "24.3 Kriging Class (src/spotoptim/surrogate/kriging.py)\nKey Features:\n\nScikit-learn compatible interface (fit(), predict())\nGaussian (RBF) kernel: R = exp(-D)\nAutomatic hyperparameter optimization via maximum likelihood\nCholesky decomposition for efficient linear algebra\nPrediction with uncertainty (return_std=True)\nReproducible results via seed parameter\n\nImplementation Details:\n\nlean, well-documented code\nNo external dependencies beyond NumPy, SciPy\nSimplified from spotpython.surrogate.kriging\nFocused on core functionality needed for SpotOptim\n\nParameters:\n\nnoise: Regularization (nugget effect)\nkernel: Currently ‘gauss’ (Gaussian/RBF)\nn_theta: Number of length scale parameters\nmin_theta, max_theta: Bounds for hyperparameter optimization\nseed: Random seed for reproducibility",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#integration-with-spotoptim",
    "href": "kriging.html#integration-with-spotoptim",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.4 Integration with SpotOptim",
    "text": "24.4 Integration with SpotOptim\nNo Changes Required to SpotOptim Core!\nThe existing surrogate parameter already supports any scikit-learn compatible model:\n\nfrom spotoptim import SpotOptim, Kriging\nimport numpy as np\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\nkriging = Kriging(seed=42)\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    surrogate=kriging,  # Just pass the Kriging instance\n    max_iter=30,\n    seed=42\n)\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Best point: {result.x}\")\n\nBest value: 0.012619\nBest point: [0.92767604 0.86917826]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#documentation",
    "href": "kriging.html#documentation",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.5 Documentation",
    "text": "24.5 Documentation\nAdded Example to notebooks/demos.ipynb\n\nDemonstrates Kriging vs GP comparison\nShows custom parameter usage",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#usage-examples",
    "href": "kriging.html#usage-examples",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.6 Usage Examples",
    "text": "24.6 Usage Examples\n\n24.6.1 Basic Usage\n\nfrom spotoptim import SpotOptim, Kriging\nimport numpy as np\n\ndef sphere(X):\n    \"\"\"Sphere function: f(x) = sum(x^2)\"\"\"\n    return np.sum(X**2, axis=1)\n\nkriging = Kriging(noise=1e-6, seed=42)\noptimizer = SpotOptim(\n    fun=sphere, \n    bounds=[(-5, 5), (-5, 5)], \n    surrogate=kriging,\n    max_iter=20,\n    seed=42\n)\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Best point: {result.x}\")\n\nBest value: 0.000000\nBest point: [2.04416182e-05 5.67177247e-04]\n\n\n\n\n24.6.2 Custom Parameters\n\nimport numpy as np\n\ndef ackley(X):\n    \"\"\"Ackley function - multimodal test function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\nkriging = Kriging(\n    noise=1e-4,\n    min_theta=-2.0,\n    max_theta=3.0,\n    seed=123\n)\n\noptimizer = SpotOptim(\n    fun=ackley,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=kriging,\n    max_iter=40,\n    seed=123\n)\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Best point: {result.x}\")\n\nBest value: 0.004040\nBest point: [ 0.00140328 -0.00013417]\n\n\n\n\n24.6.3 Prediction with Uncertainty\n\nfrom spotoptim import Kriging\nimport numpy as np\n\n# Generate training data\nnp.random.seed(42)\nX_train = np.random.uniform(-5, 5, (20, 2))\ny_train = np.sum(X_train**2, axis=1)\n\n# Generate test data\nX_test = np.random.uniform(-5, 5, (10, 2))\n\n# Fit model and predict with uncertainty\nmodel = Kriging(seed=42)\nmodel.fit(X_train, y_train)\ny_pred, y_std = model.predict(X_test, return_std=True)\n\nprint(f\"Predictions shape: {y_pred.shape}\")\nprint(f\"Uncertainties shape: {y_std.shape}\")\nprint(f\"Mean prediction: {y_pred.mean():.4f}\")\nprint(f\"Mean uncertainty: {y_std.mean():.4f}\")\n\nPredictions shape: (10,)\nUncertainties shape: (10,)\nMean prediction: 20.8065\nMean uncertainty: 0.0302",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#technical-details",
    "href": "kriging.html#technical-details",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.7 Technical Details",
    "text": "24.7 Technical Details\n\n24.7.1 Kriging vs GaussianProcessRegressor\n\n\n\nAspect\nKriging\nGaussianProcessRegressor\n\n\n\n\nLines of code\n~350\nComplex internal implementation\n\n\nDependencies\nNumPy, SciPy\nscikit-learn + dependencies\n\n\nKernel\nGaussian (RBF)\nMultiple types (Matern, RQ, etc.)\n\n\nHyperparameter opt\nDifferential Evolution\nL-BFGS-B with restarts\n\n\nUse case\nSimplified, explicit\nProduction, flexible\n\n\n\n\n\n24.7.2 Algorithm\n\nCorrelation Matrix:\n\nCompute squared distances: D_ij = Σ_k θ_k(x_ik - x_jk)²\nApply kernel: R_ij = exp(-D_ij)\nAdd nugget: R_ii += noise\n\nMaximum Likelihood:\n\nOptimize θ via differential evolution\nMinimize: (n/2)log(σ²) + (1/2)log|R|\nConcentrated likelihood (μ profiled out)\n\nPrediction:\n\nMean: f̂(x) = μ̂ + ψ(x)ᵀR⁻¹r\nVariance: s²(x) = σ̂²[1 + λ - ψ(x)ᵀR⁻¹ψ(x)]\nUses Cholesky decomposition for efficiency\n\n\n\n\n24.7.3 Key Arguments Passed from SpotOptim\nSpotOptim passes these to the surrogate via the standard interface:\nDuring fit:\n# Example of how SpotOptim uses the surrogate internally\nsurrogate.fit(X, y)\n\nX: Training points (n_initial or accumulated evaluations)\ny: Function values\n\nDuring predict:\n# Example of internal usage\nmu = surrogate.predict(x)[0]  # For acquisition='y'\nmu, sigma = surrogate.predict(x, return_std=True)  # For acquisition='ei', 'pi'\nImplicit parameters via seed:\n\nrandom_state=seed (for GaussianProcessRegressor)\nseed=seed (for Kriging)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#benefits",
    "href": "kriging.html#benefits",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.8 Benefits",
    "text": "24.8 Benefits\n\nSelf-contained: No heavy scikit-learn dependency for surrogate\nExplicit: Clear hyperparameter bounds and optimization\nEducational: Readable implementation of Kriging/GP\nFlexible: Easy to extend with new kernels or features\nCompatible: Works seamlessly with existing SpotOptim API",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#future-enhancements",
    "href": "kriging.html#future-enhancements",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.9 Future Enhancements",
    "text": "24.9 Future Enhancements\nPotential additions:\n\nAdditional kernels (Matern, Exponential, Cubic)\nAnisotropic hyperparameters (separate θ per dimension)\nGradient-enhanced predictions\nBatch predictions for efficiency\nParallel hyperparameter optimization\nARD (Automatic Relevance Determination)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "kriging.html#conclusion",
    "href": "kriging.html#conclusion",
    "title": "24  Kriging Surrogate Integration",
    "section": "24.10 Conclusion",
    "text": "24.10 Conclusion\nImplementation of a Kriging surrogate into SpotOptim with:\n\n✅ Full scikit-learn compatibility\n✅ Comprehensive test coverage (9 new tests)\n✅ Complete documentation\n✅ Example notebook\n✅ Zero breaking changes\n✅ All 25 tests passing",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Kriging Surrogate Integration</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html",
    "href": "learning_rate_mapping.html",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "",
    "text": "25.1 Overview\nSpotOptim provides a sophisticated learning rate mapping system through the map_lr() function, enabling a unified interface for learning rates across different PyTorch optimizers. This solves the challenge that different optimizers operate on vastly different learning rate scales.\nDifferent PyTorch optimizers use different default learning rates and optimal ranges:\nThis makes it difficult to compare optimizer performance fairly or optimize learning rates across different optimizers. The map_lr() function provides a unified scale where lr_unified=1.0 corresponds to each optimizer’s PyTorch default.\nModule: spotoptim.utils.mapping\nKey Features:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#overview",
    "href": "learning_rate_mapping.html#overview",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "",
    "text": "Adam: default 0.001, typical range 0.0001-0.01\nSGD: default 0.01, typical range 0.001-0.1\nRMSprop: default 0.01, typical range 0.001-0.1\n\n\n\n\n\nUnified learning rate scale across all optimizers\nFair comparison when evaluating different optimizers\nSimplified hyperparameter optimization\nBased on official PyTorch default learning rates\nSupports 13 major PyTorch optimizers",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#quick-start",
    "href": "learning_rate_mapping.html#quick-start",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.2 Quick Start",
    "text": "25.2 Quick Start\n\n25.2.1 Basic Usage\n\nfrom spotoptim.utils.mapping import map_lr\n\n# Get optimizer-specific learning rate from unified scale\nlr_adam = map_lr(1.0, \"Adam\")      # Returns 0.001 (Adam's default)\nlr_sgd = map_lr(1.0, \"SGD\")        # Returns 0.01 (SGD's default)\nlr_rmsprop = map_lr(1.0, \"RMSprop\")  # Returns 0.01 (RMSprop's default)\n\nprint(f\"Unified lr=1.0:\")\nprint(f\"  Adam:    {lr_adam}\")\nprint(f\"  SGD:     {lr_sgd}\")\nprint(f\"  RMSprop: {lr_rmsprop}\")\n\nUnified lr=1.0:\n  Adam:    0.001\n  SGD:     0.01\n  RMSprop: 0.01\n\n\n\n\n25.2.2 Scaling Learning Rates\n\nfrom spotoptim.utils.mapping import map_lr\n\n# Scale all learning rates by the same factor\nunified_lr = 0.5\n\nlr_adam = map_lr(unified_lr, \"Adam\")      # 0.5 * 0.001 = 0.0005\nlr_sgd = map_lr(unified_lr, \"SGD\")        # 0.5 * 0.01 = 0.005\nlr_rmsprop = map_lr(unified_lr, \"RMSprop\")  # 0.5 * 0.01 = 0.005\n\nprint(f\"Unified lr={unified_lr}:\")\nprint(f\"  Adam:    {lr_adam}\")\nprint(f\"  SGD:     {lr_sgd}\")\nprint(f\"  RMSprop: {lr_rmsprop}\")\n\nUnified lr=0.5:\n  Adam:    0.0005\n  SGD:     0.005\n  RMSprop: 0.005\n\n\n\n\n25.2.3 Integration with LinearRegressor\n\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n# Create model with unified learning rate\nmodel = LinearRegressor(\n    input_dim=10, \n    output_dim=1, \n    l1=32, \n    num_hidden_layers=2,\n    lr=1.0  # Unified learning rate\n)\n\n# Get optimizer - automatically uses mapped learning rate\noptimizer_adam = model.get_optimizer(\"Adam\")     # Gets 1.0 * 0.001 = 0.001\noptimizer_sgd = model.get_optimizer(\"SGD\")       # Gets 1.0 * 0.01 = 0.01\n\n# Verify the actual learning rates\nprint(f\"Adam actual lr: {optimizer_adam.param_groups[0]['lr']}\")\nprint(f\"SGD actual lr: {optimizer_sgd.param_groups[0]['lr']}\")\n\nAdam actual lr: 0.001\nSGD actual lr: 0.01",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#function-reference",
    "href": "learning_rate_mapping.html#function-reference",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.3 Function Reference",
    "text": "25.3 Function Reference\n\n25.3.1 map_lr(lr_unified, optimizer_name, use_default_scale=True)\nMaps a unified learning rate to an optimizer-specific learning rate.\nParameters:\n\nlr_unified (float): Unified learning rate multiplier. A value of 1.0 corresponds to the optimizer’s default learning rate. Typical range: [0.001, 100.0].\noptimizer_name (str): Name of the PyTorch optimizer. Must be one of: “Adadelta”, “Adagrad”, “Adam”, “AdamW”, “SparseAdam”, “Adamax”, “ASGD”, “LBFGS”, “NAdam”, “RAdam”, “RMSprop”, “Rprop”, “SGD”.\nuse_default_scale (bool, optional): Whether to scale by the optimizer’s default learning rate. If True (default), lr_unified is multiplied by the default lr. If False, returns lr_unified directly.\n\nReturns:\n\nfloat: The optimizer-specific learning rate.\n\nRaises:\n\nValueError: If optimizer_name is not supported.\nValueError: If lr_unified is not positive.\n\nExample:\n\nfrom spotoptim.utils.mapping import map_lr\n\n# Get default learning rates (unified lr = 1.0)\nlr = map_lr(1.0, \"Adam\")      # 0.001\nlr = map_lr(1.0, \"SGD\")       # 0.01\nlr = map_lr(1.0, \"RMSprop\")   # 0.01\n\n# Scale learning rates\nlr = map_lr(0.5, \"Adam\")      # 0.0005\nlr = map_lr(2.0, \"SGD\")       # 0.02\n\n# Without default scaling\nlr = map_lr(0.01, \"Adam\", use_default_scale=False)  # 0.01 (direct)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#supported-optimizers",
    "href": "learning_rate_mapping.html#supported-optimizers",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.4 Supported Optimizers",
    "text": "25.4 Supported Optimizers\nAll major PyTorch optimizers are supported with their default learning rates:\n\n\n\nOptimizer\nDefault LR\nTypical Range\nNotes\n\n\n\n\nAdam\n0.001\n0.0001-0.01\nMost popular, good default\n\n\nAdamW\n0.001\n0.0001-0.01\nAdam with weight decay\n\n\nAdamax\n0.002\n0.0001-0.01\nAdam variant with infinity norm\n\n\nNAdam\n0.002\n0.0001-0.01\nAdam with Nesterov momentum\n\n\nRAdam\n0.001\n0.0001-0.01\nRectified Adam\n\n\nSparseAdam\n0.001\n0.0001-0.01\nFor sparse gradients\n\n\nSGD\n0.01\n0.001-0.1\nClassic, needs momentum\n\n\nRMSprop\n0.01\n0.001-0.1\nGood for RNNs\n\n\nAdagrad\n0.01\n0.001-0.1\nAdaptive learning rate\n\n\nAdadelta\n1.0\n0.1-10.0\nExtension of Adagrad\n\n\nASGD\n0.01\n0.001-0.1\nAveraged SGD\n\n\nLBFGS\n1.0\n0.1-10.0\nSecond-order optimizer\n\n\nRprop\n0.01\n0.001-0.1\nResilient backpropagation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#use-cases",
    "href": "learning_rate_mapping.html#use-cases",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.5 Use Cases",
    "text": "25.5 Use Cases\n\n25.5.1 Comparing Different Optimizers\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\n\n# Load data\ntrain_loader, test_loader, _ = get_diabetes_dataloaders(batch_size=32, random_state=42)\n\n# Test different optimizers with unified learning rate\nunified_lr = 1.0\noptimizers_to_test = [\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"]\nresults = {}\n\nfor opt_name in optimizers_to_test:\n    # Reset for fair comparison\n    torch.manual_seed(42)\n    model = LinearRegressor(input_dim=10, output_dim=1, l1=32, \n                           num_hidden_layers=2, lr=unified_lr)\n    \n    # Create optimizer with mapped learning rate\n    if opt_name == \"SGD\":\n        optimizer = model.get_optimizer(opt_name, momentum=0.9)\n    else:\n        optimizer = model.get_optimizer(opt_name)\n    \n    criterion = nn.MSELoss()\n    \n    # Train\n    model.train()\n    for epoch in range(50):\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            loss.backward()\n            optimizer.step()\n    \n    # Evaluate\n    model.eval()\n    test_loss = 0.0\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            predictions = model(batch_X)\n            test_loss += criterion(predictions, batch_y).item()\n    \n    avg_test_loss = test_loss / len(test_loader)\n    results[opt_name] = avg_test_loss\n    \n    print(f\"{opt_name:10s}: Test MSE = {avg_test_loss:.4f} \"\n          f\"(actual lr = {optimizer.param_groups[0]['lr']:.6f})\")\n\n# Find best optimizer\nbest_opt = min(results, key=results.get)\nprint(f\"\\nBest optimizer: {best_opt} with MSE = {results[best_opt]:.4f}\")\n\nAdam      : Test MSE = 3859.4478 (actual lr = 0.001000)\nSGD       : Test MSE = 5271.6840 (actual lr = 0.010000)\nRMSprop   : Test MSE = 2769.5164 (actual lr = 0.010000)\nAdamW     : Test MSE = 3866.1197 (actual lr = 0.001000)\n\nBest optimizer: RMSprop with MSE = 2769.5164\n\n\n\n\n25.5.2 Hyperparameter Optimization with SpotOptim\nNote, N_INITIAL and MAX_ITER are kept small for demonstration; increase for real use.\n\nfrom spotoptim import SpotOptim\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\nimport torch.nn as nn\nimport torch\nimport numpy as np\n\nMAX_ITER = 10\nN_INITIAL = 5\n\ndef train_and_evaluate(X):\n    \"\"\"Objective function for hyperparameter optimization.\"\"\"\n    results = []\n    \n    # Load data once\n    train_loader, test_loader, _ = get_diabetes_dataloaders(\n        batch_size=32, random_state=42\n    )\n    \n    for params in X:\n        # Extract hyperparameters\n        lr_unified = 10 ** params[0]  # Log scale\n        optimizer_name = params[1]     # Factor variable\n        l1 = int(params[2])           # Integer\n        num_layers = int(params[3])   # Integer\n        \n        # Create model with unified learning rate\n        model = LinearRegressor(\n            input_dim=10,\n            output_dim=1,\n            l1=l1,\n            num_hidden_layers=num_layers,\n            lr=lr_unified  # Automatically mapped per optimizer\n        )\n        \n        # Get optimizer (lr already mapped internally)\n        if optimizer_name == \"SGD\":\n            optimizer = model.get_optimizer(optimizer_name, momentum=0.9)\n        else:\n            optimizer = model.get_optimizer(optimizer_name)\n        \n        criterion = nn.MSELoss()\n        \n        # Train\n        model.train()\n        for epoch in range(30):\n            for batch_X, batch_y in train_loader:\n                optimizer.zero_grad()\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results.append(avg_test_loss)\n    \n    return np.array(results)\n\n# Optimize learning rate, optimizer choice, and architecture\noptimizer = SpotOptim(\n    fun=train_and_evaluate,\n    bounds=[\n        (-4, 0),                           # log10(lr_unified): [0.0001, 1.0]\n        (\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"),  # Optimizer choice\n        (16, 128),                         # Layer size\n        (1, 3)                             # Number of hidden layers\n    ],\n    var_type=[\"float\", \"factor\", \"int\", \"int\"],\n    max_iter=MAX_ITER,\n    n_initial=N_INITIAL,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Display results\nprint(\"\\nOptimization Results:\")\nprint(f\"Best unified lr: {10**result.x[0]:.6f}\")\nprint(f\"Best optimizer: {result.x[1]}\")\nprint(f\"Best layer size: {int(result.x[2])}\")\nprint(f\"Best num layers: {int(result.x[3])}\")\nprint(f\"Best test MSE: {result.fun:.4f}\")\n\n# Show actual learning rate used\nfrom spotoptim.utils.mapping import map_lr\nactual_lr = map_lr(10**result.x[0], result.x[1])\nprint(f\"Actual {result.x[1]} learning rate: {actual_lr:.6f}\")\n\n\nOptimization Results:\nBest unified lr: 0.305454\nBest optimizer: RMSprop\nBest layer size: 118\nBest num layers: 2\nBest test MSE: 2770.3857\nActual RMSprop learning rate: 0.003055\n\n\n\n\n25.5.3 Log-Scale Hyperparameter Search\n\nfrom spotoptim.utils.mapping import map_lr\nimport numpy as np\n\n# Common pattern: sample unified lr from log scale\nlog_lr_range = np.linspace(-4, 0, 10)  # [-4, -3.56, ..., 0]\noptimizers = [\"Adam\", \"SGD\", \"RMSprop\"]\n\nprint(\"Log-scale learning rate search:\")\nprint()\nprint(f\"{'log_lr':&lt;10} {'unified_lr':&lt;12} {'Adam':&lt;12} {'SGD':&lt;12} {'RMSprop':&lt;12}\")\nprint(\"-\" * 60)\n\nfor log_lr in log_lr_range:\n    lr_unified = 10 ** log_lr\n    lr_adam = map_lr(lr_unified, \"Adam\")\n    lr_sgd = map_lr(lr_unified, \"SGD\")\n    lr_rmsprop = map_lr(lr_unified, \"RMSprop\")\n    \n    print(f\"{log_lr:&lt;10.2f} {lr_unified:&lt;12.6f} {lr_adam:&lt;12.8f} \"\n          f\"{lr_sgd:&lt;12.8f} {lr_rmsprop:&lt;12.8f}\")\n\nLog-scale learning rate search:\n\nlog_lr     unified_lr   Adam         SGD          RMSprop     \n------------------------------------------------------------\n-4.00      0.000100     0.00000010   0.00000100   0.00000100  \n-3.56      0.000278     0.00000028   0.00000278   0.00000278  \n-3.11      0.000774     0.00000077   0.00000774   0.00000774  \n-2.67      0.002154     0.00000215   0.00002154   0.00002154  \n-2.22      0.005995     0.00000599   0.00005995   0.00005995  \n-1.78      0.016681     0.00001668   0.00016681   0.00016681  \n-1.33      0.046416     0.00004642   0.00046416   0.00046416  \n-0.89      0.129155     0.00012915   0.00129155   0.00129155  \n-0.44      0.359381     0.00035938   0.00359381   0.00359381  \n0.00       1.000000     0.00100000   0.01000000   0.01000000  \n\n\n\n\n25.5.4 Custom Learning Rate Schedules\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.utils.mapping import map_lr\n\n# Create model with unified lr\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\n\n# Get initial optimizer\noptimizer = model.get_optimizer(\"Adam\")\ninitial_lr = optimizer.param_groups[0]['lr']\nprint(f\"Initial learning rate: {initial_lr}\")\n\n# Use PyTorch learning rate scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n\n# Training with scheduler\nfor epoch in range(100):\n    # ... training code ...\n    scheduler.step()\n    \n    if (epoch + 1) % 30 == 0:\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f\"Epoch {epoch+1}: lr = {current_lr:.8f}\")\n\nInitial learning rate: 0.001\nEpoch 30: lr = 0.00010000\nEpoch 60: lr = 0.00001000\nEpoch 90: lr = 0.00000100\n\n\n\n\n25.5.5 Direct Usage Without LinearRegressor\n\nimport torch\nimport torch.nn as nn\nfrom spotoptim.utils.mapping import map_lr\n\n# Define your own model\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(10, 32)\n        self.fc2 = nn.Linear(32, 1)\n    \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        return self.fc2(x)\n\nmodel = MyModel()\n\n# Use map_lr to get optimizer-specific learning rate\nunified_lr = 2.0\noptimizer_name = \"Adam\"\n\nactual_lr = map_lr(unified_lr, optimizer_name)\noptimizer = torch.optim.Adam(model.parameters(), lr=actual_lr)\n\nprint(f\"Unified lr: {unified_lr}\")\nprint(f\"Actual {optimizer_name} lr: {actual_lr}\")\n\nUnified lr: 2.0\nActual Adam lr: 0.002",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#best-practices",
    "href": "learning_rate_mapping.html#best-practices",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.6 Best Practices",
    "text": "25.6 Best Practices\n\n25.6.1 Choosing Unified Learning Rate\nFor initial experiments:\n\nStart with lr=1.0 (gives defaults for all optimizers)\nTest with lr=0.1, lr=1.0, lr=10.0 to get a sense of scale\n\nFor hyperparameter optimization:\n\nUse log scale: sample from [-4, 0] or [-3, 1]\nConvert with lr_unified = 10 ** log_lr\nThis gives reasonable ranges for all optimizers\n\nFor fine-tuning:\n\nIf training is unstable: try smaller lr (e.g., 0.1 or 0.5)\nIf training is too slow: try larger lr (e.g., 2.0 or 5.0)\nMonitor loss curves to adjust\n\n\n\n25.6.2 Optimizer Selection Guidelines\nAdam family (Adam, AdamW, NAdam, RAdam):\n\n✅ Good default choice for most tasks\n✅ Adaptive learning rates per parameter\n✅ Works well out of the box\nUse lr=1.0 as starting point\n\nSGD:\n\n✅ Good for large datasets\n✅ Often achieves better generalization\n⚠️ Requires momentum (e.g., 0.9)\nUse lr=1.0 with momentum=0.9\n\nRMSprop:\n\n✅ Good for recurrent networks\n✅ Handles non-stationary objectives\nUse lr=1.0 as starting point\n\nOthers (Adadelta, Adagrad, etc.):\n\nSpecialized use cases\nStart with lr=1.0 and adjust\n\n\n\n25.6.3 Common Patterns\n# Pattern 1: Quick optimizer comparison\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\nfor opt in [\"Adam\", \"SGD\", \"RMSprop\"]:\n    optimizer = model.get_optimizer(opt)\n    # ... train and compare ...\n\n# Pattern 2: Hyperparameter optimization\ndef objective(X):\n    lr_unified = 10 ** X[:, 0]  # Log scale\n    optimizer_name = X[:, 1]     # Factor\n    # ... use unified lr ...\n\n# Pattern 3: Override model's lr\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\noptimizer = model.get_optimizer(\"Adam\", lr=2.0)  # Override with 2.0\n\n# Pattern 4: Direct mapping\nfrom spotoptim.utils.mapping import map_lr\nlr_actual = map_lr(unified_lr, optimizer_name)\noptimizer = torch.optim.Adam(params, lr=lr_actual)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#troubleshooting",
    "href": "learning_rate_mapping.html#troubleshooting",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.7 Troubleshooting",
    "text": "25.7 Troubleshooting\n\n25.7.1 Issue: Training is unstable (loss explodes)\nSolution: Learning rate is too high. Try:\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=0.1)  # Reduce from 1.0\n\n\n25.7.2 Issue: Training is too slow (loss decreases very slowly)\nSolution: Learning rate is too low. Try:\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=5.0)  # Increase from 1.0\n\n\n25.7.3 Issue: Different results across optimizer runs\nSolution: Set random seed for reproducibility:\nimport torch\ntorch.manual_seed(42)\n\n\n25.7.4 Issue: Want to use raw learning rate without mapping\nSolution: Use use_default_scale=False:\nfrom spotoptim.utils.mapping import map_lr\nlr = map_lr(0.001, \"Adam\", use_default_scale=False)  # Returns 0.001 directly\n\n\n25.7.5 Issue: Optimizer not supported\nSolution: Check supported optimizers:\nfrom spotoptim.utils.mapping import OPTIMIZER_DEFAULT_LR\nprint(\"Supported optimizers:\", list(OPTIMIZER_DEFAULT_LR.keys()))",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#technical-details",
    "href": "learning_rate_mapping.html#technical-details",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.8 Technical Details",
    "text": "25.8 Technical Details\n\n25.8.1 How It Works\nThe mapping is simple but effective:\nactual_lr = lr_unified * default_lr[optimizer_name]\nFor example:\n\nmap_lr(1.0, \"Adam\") → 1.0 * 0.001 = 0.001\nmap_lr(0.5, \"SGD\") → 0.5 * 0.01 = 0.005\nmap_lr(2.0, \"RMSprop\") → 2.0 * 0.01 = 0.02\n\nThis ensures that the same unified learning rate gives optimizer-specific learning rates in their typical working ranges.\n\n\n25.8.2 Design Rationale\nWhy use defaults as scaling factors?\nPyTorch’s default learning rates are carefully chosen to work well for typical use cases. By using them as scaling factors:\n\nlr=1.0 always gives sensible defaults\nScaling preserves the relative relationships between optimizers\nEach optimizer stays in its optimal range\nEasy to understand and explain\n\nComparison with spotPython’s approach:\nspotPython uses lr = lr_mult * default_lr in optimizer_handler(). Our implementation:\n\n✅ Separates mapping logic (testable, reusable)\n✅ Provides standalone function (map_lr())\n✅ Comprehensive error handling and validation\n✅ Extensive documentation and examples\n✅ Full integration with LinearRegressor\n\n\n\n25.8.3 Default Learning Rates\nAll values verified against PyTorch documentation:\nOPTIMIZER_DEFAULT_LR = {\n    \"Adadelta\": 1.0,\n    \"Adagrad\": 0.01,\n    \"Adam\": 0.001,\n    \"AdamW\": 0.001,\n    \"SparseAdam\": 0.001,\n    \"Adamax\": 0.002,\n    \"ASGD\": 0.01,\n    \"LBFGS\": 1.0,\n    \"NAdam\": 0.002,\n    \"RAdam\": 0.001,\n    \"RMSprop\": 0.01,\n    \"Rprop\": 0.01,\n    \"SGD\": 0.01,\n}",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#examples",
    "href": "learning_rate_mapping.html#examples",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.9 Examples",
    "text": "25.9 Examples\n\n25.9.1 Complete Example: Optimizer Comparison Study\n\n\"\"\"\nComplete example: Compare optimizers with unified learning rate interface.\n\"\"\"\nimport torch\nimport torch.nn as nn\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\nfrom spotoptim.utils.mapping import map_lr\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\ntorch.manual_seed(42)\n\n# Load data\ntrain_loader, test_loader, _ = get_diabetes_dataloaders(\n    batch_size=32, \n    random_state=42\n)\n\n# Test configurations\noptimizers = [\"Adam\", \"SGD\", \"RMSprop\", \"AdamW\"]\nunified_lrs = [0.5, 1.0, 2.0]\n\n# Store results\nresults = {}\n\nprint(\"Training models with different optimizers and learning rates...\")\nprint()\n\nfor unified_lr in unified_lrs:\n    results[unified_lr] = {}\n    \n    for opt_name in optimizers:\n        # Reset model for fair comparison\n        torch.manual_seed(42)\n        \n        # Create model with unified lr\n        model = LinearRegressor(\n            input_dim=10, \n            output_dim=1, \n            l1=32, \n            num_hidden_layers=2,\n            lr=unified_lr\n        )\n        \n        # Get optimizer\n        if opt_name == \"SGD\":\n            optimizer = model.get_optimizer(opt_name, momentum=0.9)\n        else:\n            optimizer = model.get_optimizer(opt_name)\n        \n        actual_lr = optimizer.param_groups[0]['lr']\n        criterion = nn.MSELoss()\n        \n        # Track training loss\n        train_losses = []\n        \n        # Train\n        model.train()\n        for epoch in range(50):\n            epoch_loss = 0.0\n            for batch_X, batch_y in train_loader:\n                optimizer.zero_grad()\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                loss.backward()\n                optimizer.step()\n                epoch_loss += loss.item()\n            \n            avg_epoch_loss = epoch_loss / len(train_loader)\n            train_losses.append(avg_epoch_loss)\n        \n        # Evaluate on test set\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results[unified_lr][opt_name] = {\n            'train_losses': train_losses,\n            'test_loss': avg_test_loss,\n            'actual_lr': actual_lr\n        }\n        \n        print(f\"Unified lr={unified_lr:.1f}, {opt_name:10s}: \"\n              f\"actual_lr={actual_lr:.6f}, test_MSE={avg_test_loss:.4f}\")\n\n# Display summary\nprint()\nprint(\"=\" * 70)\nprint(\"Summary: Best configurations\")\nprint(\"=\" * 70)\n\nfor unified_lr in unified_lrs:\n    best_opt = min(results[unified_lr].items(), \n                   key=lambda x: x[1]['test_loss'])\n    opt_name, metrics = best_opt\n    \n    print(f\"Unified lr={unified_lr:.1f}: {opt_name:10s} \"\n          f\"(test MSE={metrics['test_loss']:.4f}, \"\n          f\"actual lr={metrics['actual_lr']:.6f})\")\n\n# Find overall best\nbest_overall = None\nbest_overall_loss = float('inf')\n\nfor unified_lr in unified_lrs:\n    for opt_name, metrics in results[unified_lr].items():\n        if metrics['test_loss'] &lt; best_overall_loss:\n            best_overall_loss = metrics['test_loss']\n            best_overall = (unified_lr, opt_name, metrics['actual_lr'])\n\nprint()\nprint(f\"Overall best: unified_lr={best_overall[0]:.1f}, \"\n      f\"optimizer={best_overall[1]}, \"\n      f\"test_MSE={best_overall_loss:.4f}\")\nprint(f\"Actual learning rate used: {best_overall[2]:.6f}\")\n\nTraining models with different optimizers and learning rates...\n\nUnified lr=0.5, Adam      : actual_lr=0.000500, test_MSE=5095.8747\nUnified lr=0.5, SGD       : actual_lr=0.005000, test_MSE=5291.3903\nUnified lr=0.5, RMSprop   : actual_lr=0.005000, test_MSE=2828.7084\nUnified lr=0.5, AdamW     : actual_lr=0.000500, test_MSE=5107.9592\nUnified lr=1.0, Adam      : actual_lr=0.001000, test_MSE=3859.4478\nUnified lr=1.0, SGD       : actual_lr=0.010000, test_MSE=5271.6840\nUnified lr=1.0, RMSprop   : actual_lr=0.010000, test_MSE=2769.5164\nUnified lr=1.0, AdamW     : actual_lr=0.001000, test_MSE=3866.1197\nUnified lr=2.0, Adam      : actual_lr=0.002000, test_MSE=3160.6882\nUnified lr=2.0, SGD       : actual_lr=0.020000, test_MSE=nan\nUnified lr=2.0, RMSprop   : actual_lr=0.020000, test_MSE=2883.3345\nUnified lr=2.0, AdamW     : actual_lr=0.002000, test_MSE=3162.8034\n\n======================================================================\nSummary: Best configurations\n======================================================================\nUnified lr=0.5: RMSprop    (test MSE=2828.7084, actual lr=0.005000)\nUnified lr=1.0: RMSprop    (test MSE=2769.5164, actual lr=0.010000)\nUnified lr=2.0: RMSprop    (test MSE=2883.3345, actual lr=0.020000)\n\nOverall best: unified_lr=1.0, optimizer=RMSprop, test_MSE=2769.5164\nActual learning rate used: 0.010000",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#see-also",
    "href": "learning_rate_mapping.html#see-also",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.10 See Also",
    "text": "25.10 See Also\n\nLinearRegressor Documentation - Neural network class with lr parameter\nDiabetes Dataset Utilities - Data loading for examples\nHyperparameter Optimization - Using map_lr with SpotOptim\nPyTorch Optimizer Documentation - Official PyTorch reference",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "learning_rate_mapping.html#references",
    "href": "learning_rate_mapping.html#references",
    "title": "25  Learning Rate Mapping for Unified Optimizer Interface",
    "section": "25.11 References",
    "text": "25.11 References\n\nKingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv:1412.6980.\nLoshchilov, I., & Hutter, F. (2017). Decoupled weight decay regularization. arXiv:1711.05101.\nPyTorch Team. (2023). PyTorch Optimizer Documentation. https://pytorch.org/docs/stable/optim.html",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Learning Rate Mapping for Unified Optimizer Interface</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html",
    "href": "unified_learning_rate.html",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "",
    "text": "26.1 Overview\nThis module provides a sophisticated unified learning rate interface for PyTorch optimizers through the map_lr() function and integration with LinearRegressor.\nDifferent PyTorch optimizers operate on vastly different learning rate scales:\nThis makes it difficult to:\nThe map_lr() function solves this by providing a unified learning rate scale where lr=1.0 corresponds to each optimizer’s PyTorch default.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#overview",
    "href": "unified_learning_rate.html#overview",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "",
    "text": "Adam typically uses lr ~ 0.0001-0.001\nSGD typically uses lr ~ 0.01-0.1\nRMSprop typically uses lr ~ 0.001-0.01\n\n\n\nCompare optimizer performance fairly\nOptimize learning rate as a hyperparameter across different optimizers\nSwitch between optimizers without retuning learning rates",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#key-features",
    "href": "unified_learning_rate.html#key-features",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.2 Key Features",
    "text": "26.2 Key Features\n\n✅ Unified Interface: Single learning rate parameter works across all optimizers\n✅ Fair Comparison: Same unified lr gives optimizer-specific optimal ranges\n✅ Hyperparameter Optimization: Optimize one learning rate for multiple optimizers\n✅ Backward Compatible: Existing code continues to work\n✅ Well-tested: 36 comprehensive tests covering all use cases\n✅ Documented: Extensive docstrings and examples",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#usage",
    "href": "unified_learning_rate.html#usage",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.3 Usage",
    "text": "26.3 Usage\n\n26.3.1 Basic Usage with LinearRegressor\n\nfrom spotoptim.nn.linear_regressor import LinearRegressor\n\n# Create model with unified lr=1.0 (gives each optimizer its default)\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=1.0)\n\n# Adam gets 0.001 (its default)\noptimizer_adam = model.get_optimizer(\"Adam\")\n\n# SGD gets 0.01 (its default)\noptimizer_sgd = model.get_optimizer(\"SGD\")\n\n# RMSprop gets 0.01 (its default)\noptimizer_rmsprop = model.get_optimizer(\"RMSprop\")\n\n\n\n26.3.2 Using Custom Unified Learning Rate\n\n# Using lr=0.5 scales all optimizers by 0.5\nmodel = LinearRegressor(input_dim=10, output_dim=1, lr=0.5)\n\noptimizer_adam = model.get_optimizer(\"Adam\")     # Gets 0.5 * 0.001 = 0.0005\noptimizer_sgd = model.get_optimizer(\"SGD\")       # Gets 0.5 * 0.01 = 0.005\n\n\n\n26.3.3 Direct Use of map_lr()\n\nfrom spotoptim.utils.mapping import map_lr\n\n# Map unified lr to optimizer-specific lr\nlr_adam = map_lr(1.0, \"Adam\")      # Returns 0.001\nlr_sgd = map_lr(1.0, \"SGD\")        # Returns 0.01\nlr_rmsprop = map_lr(1.0, \"RMSprop\")  # Returns 0.01\n\n# Scale by 2x\nlr_adam = map_lr(2.0, \"Adam\")      # Returns 0.002\nlr_sgd = map_lr(2.0, \"SGD\")        # Returns 0.02\n\n\n\n26.3.4 Hyperparameter Optimization\n\nfrom spotoptim import SpotOptim\nfrom spotoptim.nn.linear_regressor import LinearRegressor\nfrom spotoptim.data import get_diabetes_dataloaders\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\ndef train_model(X):\n    \"\"\"Objective function for hyperparameter optimization.\"\"\"\n    results = []\n    \n    # Load data once\n    train_loader, test_loader, _ = get_diabetes_dataloaders(batch_size=32, random_state=42)\n    \n    for params in X:\n        lr_unified = 10 ** params[0]  # Log scale: [-4, 0]\n        optimizer_name = params[1]     # Factor: \"Adam\", \"SGD\", \"RMSprop\"\n        \n        # Create model with unified lr - automatically scaled per optimizer\n        torch.manual_seed(42)\n        model = LinearRegressor(input_dim=10, output_dim=1, l1=32, num_hidden_layers=2, lr=lr_unified)\n        optimizer = model.get_optimizer(optimizer_name)\n        \n        criterion = nn.MSELoss()\n        \n        # Train\n        model.train()\n        for epoch in range(30):\n            for batch_X, batch_y in train_loader:\n                optimizer.zero_grad()\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                loss.backward()\n                optimizer.step()\n        \n        # Evaluate\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                test_loss += criterion(predictions, batch_y).item()\n        \n        avg_test_loss = test_loss / len(test_loader)\n        results.append(avg_test_loss)\n    \n    return np.array(results)\n\n# Optimize unified lr across different optimizers\nspot_optimizer = SpotOptim(\n    fun=train_model,\n    bounds=[(-4, 0), (\"Adam\", \"SGD\", \"RMSprop\")],\n    var_type=[\"float\", \"factor\"],\n    max_iter=10,  # Small for demo\n    n_initial=5,\n    seed=42\n)\nresult = spot_optimizer.optimize()\n\nprint(f\"\\nBest unified lr: {10**result.x[0]:.6f}\")\nprint(f\"Best optimizer: {result.x[1]}\")\nprint(f\"Best test MSE: {result.fun:.4f}\")\n\n# Show actual learning rate used\nfrom spotoptim.utils.mapping import map_lr\nactual_lr = map_lr(10**result.x[0], result.x[1])\nprint(f\"Actual {result.x[1]} learning rate: {actual_lr:.6f}\")\n\n\nBest unified lr: 0.003144\nBest optimizer: SGD\nBest test MSE: 4135.5200\nActual SGD learning rate: 0.000031",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#supported-optimizers",
    "href": "unified_learning_rate.html#supported-optimizers",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.4 Supported Optimizers",
    "text": "26.4 Supported Optimizers\nAll major PyTorch optimizers are supported with their default learning rates:\n\n\n\nOptimizer\nDefault LR\nTypical Range\n\n\n\n\nAdam\n0.001\n0.0001-0.01\n\n\nAdamW\n0.001\n0.0001-0.01\n\n\nAdamax\n0.002\n0.0001-0.01\n\n\nNAdam\n0.002\n0.0001-0.01\n\n\nRAdam\n0.001\n0.0001-0.01\n\n\nSGD\n0.01\n0.001-0.1\n\n\nRMSprop\n0.01\n0.001-0.1\n\n\nAdagrad\n0.01\n0.001-0.1\n\n\nAdadelta\n1.0\n0.1-10.0\n\n\nASGD\n0.01\n0.001-0.1\n\n\nLBFGS\n1.0\n0.1-10.0\n\n\nRprop\n0.01\n0.001-0.1",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#api-reference",
    "href": "unified_learning_rate.html#api-reference",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.5 API Reference",
    "text": "26.5 API Reference\n\n26.5.1 map_lr(lr_unified, optimizer_name, use_default_scale=True)\nMaps a unified learning rate to an optimizer-specific learning rate.\nParameters:\n\nlr_unified (float): Unified learning rate multiplier. Typical range: [0.001, 100.0]\noptimizer_name (str): Name of the PyTorch optimizer\nuse_default_scale (bool): Whether to scale by optimizer’s default (default: True)\n\nReturns:\n\nfloat: The optimizer-specific learning rate\n\nExample:\nlr = map_lr(1.0, \"Adam\")  # Returns 0.001 (Adam's default)\nlr = map_lr(0.5, \"SGD\")   # Returns 0.005 (0.5 * SGD's default)\n\n\n26.5.2 LinearRegressor(..., lr=1.0)\nParameter:\n\nlr (float): Unified learning rate multiplier. Default: 1.0\n\nNew Behavior in get_optimizer():\n\nIf lr is not specified, uses self.lr\nAutomatically maps unified lr to optimizer-specific lr\nCan override model’s lr by passing lr parameter",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#design-rationale",
    "href": "unified_learning_rate.html#design-rationale",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.6 Design Rationale",
    "text": "26.6 Design Rationale\n\n26.6.1 Why Unified Learning Rates?\nThe approach is based on spotPython’s optimizer_handler() but improved:\n\nSeparation of Concerns: Mapping logic in separate, testable module\nFlexibility: Can be used independently or integrated with models\nTransparency: Clear mapping based on PyTorch defaults\nExtensibility: Easy to add new optimizers\nType Safety: Comprehensive error handling and validation\n\n\n\n26.6.2 Comparison with spotPython\n\n\n\nFeature\nspotPython\nspotoptim\n\n\n\n\nApproach\nlr_mult * default_lr\nmap_lr(lr_unified, optimizer)\n\n\nModule\noptimizer_handler()\nmap_lr() + integration\n\n\nTesting\nMinimal\n36 comprehensive tests\n\n\nDocumentation\nBasic\nExtensive with examples\n\n\nReusability\nCoupled\nStandalone function\n\n\nError Handling\nBasic\nComprehensive validation\n\n\n\n\n\n26.6.3 Log-scale Optimization\nFor hyperparameter optimization, use log-scale for unified lr:\n# Sample from log10 scale [-4, 0]\nlog_lr = -2.5  # Sampled value\nlr_unified = 10 ** log_lr  # 0.00316\n\n# Map to optimizer-specific\nlr_adam = map_lr(lr_unified, \"Adam\")  # 0.00316 * 0.001 = 0.00000316\nlr_sgd = map_lr(lr_unified, \"SGD\")    # 0.00316 * 0.01 = 0.0000316\nThis gives a reasonable search range across all optimizers.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#examples",
    "href": "unified_learning_rate.html#examples",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.7 Examples",
    "text": "26.7 Examples\nSee examples/unified_learning_rate_demo.py for comprehensive examples including: 1. Basic unified interface usage 2. Custom unified learning rates 3. Training with different optimizers 4. Direct use of map_lr() 5. Log-scale hyperparameter optimization 6. Complete hyperparameter optimization scenario",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#references",
    "href": "unified_learning_rate.html#references",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.8 References",
    "text": "26.8 References\n\nPyTorch Optimizer Documentation\nspotPython’s optimizer_handler() function (inspiration)\nHyperparameter Optimization Best Practices",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#contributing",
    "href": "unified_learning_rate.html#contributing",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.9 Contributing",
    "text": "26.9 Contributing\nWhen adding new optimizers:\n\nAdd default lr to OPTIMIZER_DEFAULT_LR dict in mapping.py\nVerify the default against PyTorch documentation\nAdd tests in test_mapping.py\nUpdate this README",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "unified_learning_rate.html#license",
    "href": "unified_learning_rate.html#license",
    "title": "26  Unified Learning Rate Interface in SpotOptim",
    "section": "26.10 License",
    "text": "26.10 License\nSame as spotoptim package (see main LICENSE file).",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Unified Learning Rate Interface in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html",
    "href": "multiobjective.html",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "",
    "text": "27.1 Overview\nSpotOptim supports multi-objective optimization functions with automatic detection and flexible scalarization strategies. This implementation follows the same approach as the Spot class from spotPython.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#what-was-implemented",
    "href": "multiobjective.html#what-was-implemented",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.2 What Was Implemented",
    "text": "27.2 What Was Implemented\n\n27.2.1 1. Core Functionality\nParameter:\n\nfun_mo2so (callable, optional): Function to convert multi-objective values to single-objective\n\nTakes array of shape (n_samples, n_objectives)\nReturns array of shape (n_samples,)\nIf None, uses first objective (default behavior)\n\n\nAttribute:\n\ny_mo (ndarray or None): Stores all multi-objective function values\n\nShape: (n_samples, n_objectives) for multi-objective problems\nNone for single-objective problems\n\n\nMethods:\n\n_get_shape(y): Get shape of objective function output\n_store_mo(y_mo): Store multi-objective values with automatic appending\n_mo2so(y_mo): Convert multi-objective to single-objective values\n\nThe method _evaluate_function(X) automatically detects multi-objective functions. It calls _mo2so() to convert multi-objective to single-objective. It also stores the original multi-objective values in y_mo. And it returns single-objective values for optimization.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#usage-examples",
    "href": "multiobjective.html#usage-examples",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.3 Usage Examples",
    "text": "27.3 Usage Examples\n\n27.3.1 Example 1: Default Behavior (Use First Objective)\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef bi_objective(X):\n    \"\"\"Two conflicting objectives.\"\"\"\n    obj1 = np.sum(X**2, axis=1)          # Minimize at origin\n    obj2 = np.sum((X - 2)**2, axis=1)    # Minimize at (2, 2)\n    return np.column_stack([obj1, obj2])\n\noptimizer = SpotOptim(\n    fun=bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\nprint(f\"Best x: {result.x}\")                    # Near [0, 0]\nprint(f\"Best f(x): {result.fun}\")               # Minimizes obj1\nprint(f\"MO values stored: {optimizer.y_mo.shape}\")  # (30, 2)\n\nBest x: [3.31436760e-04 4.18312302e-05]\nBest f(x): 1.1160017787260647e-07\nMO values stored: (30, 2)\n\n\n\n\n27.3.2 Example 2: Weighted Sum Scalarization\n\ndef weighted_sum(y_mo):\n    \"\"\"Equal weighting of objectives.\"\"\"\n    return 0.5 * y_mo[:, 0] + 0.5 * y_mo[:, 1]\n\noptimizer = SpotOptim(\n    fun=bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    fun_mo2so=weighted_sum,  # Custom conversion\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"Compromise solution: {result.x}\")  # Near [1, 1]\n\nCompromise solution: [1.00110134 1.0000297 ]\n\n\n\n\n27.3.3 Example 3: Min-Max Scalarization\n\ndef min_max(y_mo):\n    \"\"\"Minimize the maximum objective.\"\"\"\n    return np.max(y_mo, axis=1)\n\noptimizer = SpotOptim(\n    fun=bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=15,\n    fun_mo2so=min_max,\n    seed=42\n)\n\nresult = optimizer.optimize()\n# Finds solution with balanced objective values\n\n\n\n27.3.4 Example 4: Three or More Objectives\n\ndef three_objectives(X):\n    \"\"\"Three different norms.\"\"\"\n    obj1 = np.sum(X**2, axis=1)           # L2 norm\n    obj2 = np.sum(np.abs(X), axis=1)      # L1 norm\n    obj3 = np.max(np.abs(X), axis=1)      # L-infinity norm\n    return np.column_stack([obj1, obj2, obj3])\n\ndef custom_scalarization(y_mo):\n    \"\"\"Weighted combination.\"\"\"\n    return 0.4 * y_mo[:, 0] + 0.3 * y_mo[:, 1] + 0.3 * y_mo[:, 2]\n\noptimizer = SpotOptim(\n    fun=three_objectives,\n    bounds=[(-5, 5), (-5, 5), (-5, 5)],\n    max_iter=35,\n    n_initial=20,\n    fun_mo2so=custom_scalarization,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n\n\n27.3.5 Example 5: With Noise Handling\n\ndef noisy_bi_objective(X):\n    \"\"\"Noisy multi-objective function.\"\"\"\n    noise1 = np.random.normal(0, 0.05, X.shape[0])\n    noise2 = np.random.normal(0, 0.05, X.shape[0])\n    \n    obj1 = np.sum(X**2, axis=1) + noise1\n    obj2 = np.sum((X - 1)**2, axis=1) + noise2\n    return np.column_stack([obj1, obj2])\n\noptimizer = SpotOptim(\n    fun=noisy_bi_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=40,\n    n_initial=20,\n    repeats_initial=3,      # Handle noise\n    repeats_surrogate=2,\n    seed=42\n)\n\nresult = optimizer.optimize()\n# Works seamlessly with noise handling",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#common-scalarization-strategies",
    "href": "multiobjective.html#common-scalarization-strategies",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.4 Common Scalarization Strategies",
    "text": "27.4 Common Scalarization Strategies\n\n27.4.1 1. Weighted Sum\n\ndef weighted_sum(y_mo, weights=[0.5, 0.5]):\n    return sum(w * y_mo[:, i] for i, w in enumerate(weights))\n\nUse when: Objectives have similar scales and you want linear trade-offs\n\n\n27.4.2 2. Weighted Sum with Normalization\n\ndef normalized_weighted_sum(y_mo, weights=[0.5, 0.5]):\n    # Normalize each objective to [0, 1]\n    y_norm = (y_mo - y_mo.min(axis=0)) / (y_mo.max(axis=0) - y_mo.min(axis=0) + 1e-10)\n    return sum(w * y_norm[:, i] for i, w in enumerate(weights))\n\nUse when: Objectives have very different scales\n\n\n27.4.3 3. Min-Max (Chebyshev)\n\ndef min_max(y_mo):\n    return np.max(y_mo, axis=1)\n\nUse when: You want balanced performance across all objectives\n\n\n27.4.4 4. Target Achievement\n\ndef target_achievement(y_mo, targets=[0.0, 0.0]):\n    # Minimize deviation from targets\n    return np.sum((y_mo - targets)**2, axis=1)\n\nUse when: You have specific target values for each objective\n\n\n27.4.5 5. Product\n\ndef product(y_mo):\n    return np.prod(y_mo + 1e-10, axis=1)  # Add small value to avoid zero\n\nUse when: All objectives should be minimized together",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#integration-with-other-features",
    "href": "multiobjective.html#integration-with-other-features",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.5 Integration with Other Features",
    "text": "27.5 Integration with Other Features\nMulti-objective support works seamlessly with:\n✅ Noise Handling - Use repeats_initial and repeats_surrogate\n✅ OCBA - Use ocba_delta for intelligent re-evaluation\n✅ TensorBoard Logging - Logs converted single-objective values\n✅ Dimension Reduction - Fixed dimensions work normally\n✅ Custom Variable Names - var_name parameter supported",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#implementation-details",
    "href": "multiobjective.html#implementation-details",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.6 Implementation Details",
    "text": "27.6 Implementation Details\n\n27.6.1 Automatic Detection\nSpotOptim automatically detects multi-objective functions:\n\nIf function returns 2D array (n_samples, n_objectives), it’s multi-objective\nIf function returns 1D array (n_samples,), it’s single-objective\n\n\n\n27.6.2 Data Flow\nUser Function → y_mo (raw) → _mo2so() → y_ (single-objective)\n                    ↓\n               y_mo (stored)\n\nFunction returns multi-objective values\n_store_mo() saves them in y_mo attribute\n_mo2so() converts to single-objective using fun_mo2so or default\nSurrogate model optimizes the single-objective values\nAll original multi-objective values remain accessible in y_mo\n\n\n\n27.6.3 Backward Compatibility\n✅ Fully backward compatible:\n\nSingle-objective functions work unchanged\nfun_mo2so defaults to None\ny_mo is None for single-objective problems\nNo breaking changes to existing code",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#limitations-and-notes",
    "href": "multiobjective.html#limitations-and-notes",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.7 Limitations and Notes",
    "text": "27.7 Limitations and Notes\n\n27.7.1 What This Is\n\n✅ Scalarization approach to multi-objective optimization\n✅ Single solution found per optimization run\n✅ Different scalarizations → different Pareto solutions\n✅ Suitable for preference-based multi-objective optimization\n\n\n\n27.7.2 What This Is Not\n\n❌ Not a true multi-objective optimizer (doesn’t find Pareto front)\n❌ Doesn’t generate multiple solutions in one run\n❌ Not suitable for discovering entire Pareto front\n\n\n\n27.7.3 For True Multi-Objective Optimization\nFor finding the complete Pareto front, consider specialized tools:\n\npymoo: Comprehensive multi-objective optimization framework\nplatypus: Multi-objective optimization library\nNSGA-II, MOEA/D: Dedicated multi-objective algorithms",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#demo-script",
    "href": "multiobjective.html#demo-script",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.8 Demo Script",
    "text": "27.8 Demo Script\nRun the comprehensive demo (the demos files are located in the examples folder):\npython demo_multiobjective.py\nThis demonstrates:\n\nDefault behavior (first objective)\nWeighted sum scalarization\nMin-max scalarization\nNoisy multi-objective optimization\nThree-objective optimization",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "multiobjective.html#summary",
    "href": "multiobjective.html#summary",
    "title": "27  Multi-Objective Optimization Support in SpotOptim",
    "section": "27.9 Summary",
    "text": "27.9 Summary\nSpotOptim provides flexible multi-objective optimization support through:\n\nAutomatic detection of multi-objective functions\nCustomizable scalarization strategies via fun_mo2so\nComplete storage of multi-objective values in y_mo\nFull integration with existing features (noise, OCBA, TensorBoard, etc.)\n100% backward compatible with existing code\n\nThis implementation mirrors the approach used in spotPython’s Spot class, providing consistency across the ecosystem.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Multi-Objective Optimization Support in SpotOptim</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html",
    "href": "plot_surrogate.html",
    "title": "28  Surrogate Model Visualization",
    "section": "",
    "text": "28.1 Overview\nThis document describes the plot_surrogate() method added to the SpotOptim class, which provides visualization capabilities similar to the plotkd() function in the spotpython package.\nThe plot_surrogate() method creates a comprehensive 4-panel visualization of the fitted surrogate model, showing both predictions and uncertainty estimates across two selected dimensions.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#features",
    "href": "plot_surrogate.html#features",
    "title": "28  Surrogate Model Visualization",
    "section": "28.2 Features",
    "text": "28.2 Features\n\n3D Surface Plots: Visualize the surrogate’s predictions and uncertainty as 3D surfaces\nContour Plots: View 2D contours with overlaid evaluation points\nMulti-dimensional Support: Visualize any two dimensions of higher-dimensional problems\nCustomizable Appearance: Control colors, resolution, transparency, and more",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#usage",
    "href": "plot_surrogate.html#usage",
    "title": "28  Surrogate Model Visualization",
    "section": "28.3 Usage",
    "text": "28.3 Usage\n\n28.3.1 Basic Usage\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Define objective function\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\n# Run optimization\noptimizer = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)], max_iter=20)\nresult = optimizer.optimize()\n\n# Visualize the surrogate model\noptimizer.plot_surrogate(i=0, j=1, show=True)\n\n\n\n\n\n\n\n\n\n\n28.3.2 With Custom Parameters\n\noptimizer.plot_surrogate(\n    i=0,                          # First dimension to plot\n    j=1,                          # Second dimension to plot\n    var_name=['x1', 'x2'],        # Variable names for axes\n    add_points=True,              # Show evaluated points\n    cmap='viridis',               # Colormap\n    alpha=0.7,                    # Surface transparency\n    num=100,                      # Grid resolution\n    contour_levels=25,            # Number of contour levels\n    grid_visible=True,            # Show grid on contours\n    figsize=(12, 10),             # Figure size\n    show=True                     # Display immediately\n)\n\n\n\n\n\n\n\n\n\n\n28.3.3 Higher-Dimensional Problems\nFor problems with more than 2 dimensions, plot_surrogate() creates a 2D slice by fixing all other dimensions at their mean values:\n\n# 4D optimization problem\ndef sphere_4d(X):\n    return np.sum(X**2, axis=1)\n\nbounds = [(-3, 3)] * 4\noptimizer = SpotOptim(fun=sphere_4d, bounds=bounds, max_iter=20)\nresult = optimizer.optimize()\n\n# Visualize dimensions 0 and 2 (dimensions 1 and 3 fixed at mean)\noptimizer.plot_surrogate(\n    i=0, j=2,\n    var_name=['x0', 'x1', 'x2', 'x3']\n)\n\n# Visualize different dimension pair\noptimizer.plot_surrogate(i=1, j=3, var_name=['x0', 'x1', 'x2', 'x3'])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#plot-interpretation",
    "href": "plot_surrogate.html#plot-interpretation",
    "title": "28  Surrogate Model Visualization",
    "section": "28.4 Plot Interpretation",
    "text": "28.4 Plot Interpretation\nThe visualization consists of 4 panels:\n\n28.4.1 Top Left: Prediction Surface\n\nShows the surrogate model’s predicted function values as a 3D surface\nHelps understand the model’s belief about the objective function landscape\nLower values (blue in default colormap) indicate predicted minima\n\n\n\n28.4.2 Top Right: Prediction Uncertainty Surface\n\nShows the standard deviation of predictions as a 3D surface\nIndicates where the model is uncertain and might benefit from more samples\nLower values (blue) indicate high confidence, higher values (red) indicate uncertainty\n\n\n\n28.4.3 Bottom Left: Prediction Contour with Points\n\n2D contour plot of predictions\nRed dots show the actual points evaluated during optimization\nUseful for understanding the exploration-exploitation trade-off\n\n\n\n28.4.4 Bottom Right: Uncertainty Contour with Points\n\n2D contour plot of prediction uncertainty\nShows how uncertainty decreases around evaluated points\nHelps identify unexplored regions",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#parameters",
    "href": "plot_surrogate.html#parameters",
    "title": "28  Surrogate Model Visualization",
    "section": "28.5 Parameters",
    "text": "28.5 Parameters\n\n28.5.1 Dimension Selection\n\ni (int, default=0): Index of first dimension to plot\nj (int, default=1): Index of second dimension to plot\n\n\n\n28.5.2 Appearance\n\nvar_name (list of str, optional): Names for each dimension\ncmap (str, default=‘jet’): Matplotlib colormap name\nalpha (float, default=0.8): Surface transparency (0=transparent, 1=opaque)\nfigsize (tuple, default=(12, 10)): Figure size in inches (width, height)\n\n\n\n28.5.3 Grid and Resolution\n\nnum (int, default=100): Number of grid points per dimension\ncontour_levels (int, default=30): Number of contour levels\ngrid_visible (bool, default=True): Show grid lines on contour plots\n\n\n\n28.5.4 Color Scaling\n\nvmin (float, optional): Minimum value for color scale\nvmax (float, optional): Maximum value for color scale\n\n\n\n28.5.5 Display\n\nshow (bool, default=True): Display plot immediately\nadd_points (bool, default=True): Overlay evaluated points on contours",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#examples",
    "href": "plot_surrogate.html#examples",
    "title": "28  Surrogate Model Visualization",
    "section": "28.6 Examples",
    "text": "28.6 Examples\n\n28.6.1 Example 1: 2D Rosenbrock Function\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    X = np.atleast_2d(X)\n    x, y = X[:, 0], X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=30,\n    seed=42\n)\nresult = optimizer.optimize()\n\n# Visualize with custom colormap\noptimizer.plot_surrogate(\n    var_name=['x', 'y'],\n    cmap='coolwarm',\n    add_points=True\n)\n\n\n\n\n\n\n\n\n\n\n28.6.2 Example 2: Using Kriging Surrogate\n\nimport numpy as np\nfrom spotoptim import SpotOptim, Kriging\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=Kriging(seed=42),  # Use Kriging instead of GP\n    max_iter=20\n)\nresult = optimizer.optimize()\n\n# The plotting works the same with any surrogate\noptimizer.plot_surrogate(var_name=['x1', 'x2'])\n\n\n\n\n\n\n\n\n\n\n28.6.3 Example 3: Comparing Different Dimension Pairs\n\n# 3D problem - visualize all dimension pairs\ndef sphere_3d(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere_3d,\n    bounds=[(-5, 5)] * 3,\n    max_iter=25\n)\nresult = optimizer.optimize()\n\n# Dimensions 0 vs 1\noptimizer.plot_surrogate(i=0, j=1, var_name=['x0', 'x1', 'x2'])\n\n# Dimensions 0 vs 2\noptimizer.plot_surrogate(i=0, j=2, var_name=['x0', 'x1', 'x2'])\n\n# Dimensions 1 vs 2\noptimizer.plot_surrogate(i=1, j=2, var_name=['x0', 'x1', 'x2'])",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#tips-and-best-practices",
    "href": "plot_surrogate.html#tips-and-best-practices",
    "title": "28  Surrogate Model Visualization",
    "section": "28.7 Tips and Best Practices",
    "text": "28.7 Tips and Best Practices\n\nRun Optimization First: Always call optimize() before plot_surrogate()\nChoose Dimensions Wisely: For high-dimensional problems, plot dimensions that you suspect are most important or interactive\nAdjust Resolution: Use lower num values (e.g., 50) for faster plotting, higher values (e.g., 200) for smoother surfaces\nColor Scales: Set vmin and vmax explicitly when comparing multiple plots to ensure consistent color scales\nUncertainty Analysis: High uncertainty areas (bright colors in uncertainty plots) are good candidates for additional sampling\nExploration vs Exploitation: Red dots clustered in low-prediction areas show exploitation; spread-out dots show exploration",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#comparison-with-spotpythons-plotkd",
    "href": "plot_surrogate.html#comparison-with-spotpythons-plotkd",
    "title": "28  Surrogate Model Visualization",
    "section": "28.8 Comparison with spotpython’s plotkd()",
    "text": "28.8 Comparison with spotpython’s plotkd()\nThe plot_surrogate() method is inspired by spotpython’s plotkd() function but adapted for SpotOptim’s simplified interface:\n\n28.8.1 Similarities\n\nSame 4-panel layout (2 surfaces + 2 contours)\nVisualizes predictions and uncertainty\nSupports dimension selection and customization\n\n\n\n28.8.2 Differences\n\nIntegration: Method of SpotOptim class (no separate function needed)\nSimpler: Fewer parameters, more sensible defaults\nAutomatic: Uses optimizer’s bounds and data automatically\nType Handling: Automatically applies variable type constraints (int/float/factor)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#error-handling",
    "href": "plot_surrogate.html#error-handling",
    "title": "28  Surrogate Model Visualization",
    "section": "28.9 Error Handling",
    "text": "28.9 Error Handling\nThe method validates inputs and provides clear error messages:\n# Before optimization runs\noptimizer.plot_surrogate()  # ValueError: No optimization data available\n\n# Invalid dimension indices\noptimizer.plot_surrogate(i=5, j=1)  # ValueError: i must be less than n_dim\n\n# Same dimension twice\noptimizer.plot_surrogate(i=0, j=0)  # ValueError: i and j must be different",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "plot_surrogate.html#see-also",
    "href": "plot_surrogate.html#see-also",
    "title": "28  Surrogate Model Visualization",
    "section": "28.10 See Also",
    "text": "28.10 See Also\n\nnotebooks/demos.ipynb: Example 4 demonstrates plot_surrogate()\nexamples/plot_surrogate_demo.py: Standalone example script\ntests/test_plot_surrogate.py: Comprehensive test suite",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Surrogate Model Visualization</span>"
    ]
  },
  {
    "objectID": "point_selection.html",
    "href": "point_selection.html",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "",
    "text": "29.1 Overview\nThis feature automatically selects a subset of evaluated points for surrogate model training when the total number of points exceeds a specified threshold.\nIt is implemented as a point selection mechanism for SpotOptim that mirrors the functionality in spotpython’s Spot class.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "point_selection.html#implementation-details",
    "href": "point_selection.html#implementation-details",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "29.2 Implementation Details",
    "text": "29.2 Implementation Details\n\n29.2.1 Parameters\nAdded to SpotOptim.__init__:\n\nmax_surrogate_points (int, optional): Maximum number of points to use for surrogate fitting\nselection_method (str, default=‘distant’): Method for selecting points (‘distant’ or ‘best’)\n\n\n\n29.2.2 Methods\n\n_select_distant_points(X, y, k)\n\nUses K-means clustering to find k clusters\nSelects the point closest to each cluster center\nEnsures space-filling properties for surrogate training\nMimics spotpython.utils.aggregate.select_distant_points\n\n_select_best_cluster(X, y, k)\n\nUses K-means clustering to find k clusters\nComputes mean objective value for each cluster\nSelects all points from the cluster with the best (lowest) mean value\nMimics spotpython.utils.aggregate.select_best_cluster\n\n_selection_dispatcher(X, y)\n\nDispatcher method that routes to the appropriate selection function\nReturns all points if max_surrogate_points is None\nMimics spotpython.spot.spot.Spot.selection_dispatcher\n\n\nThe method _fit_surrogate(X, y) checks if X.shape[0] &gt; self.max_surrogate_points. If true, it calls _selection_dispatcher to get a subset. Then, it fits the surrogate only on the selected points. This implementation matches the logic in spotpython.spot.spot.Spot.fit_surrogate",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "point_selection.html#key-differences-from-spotpython",
    "href": "point_selection.html#key-differences-from-spotpython",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "29.3 Key Differences from spotpython",
    "text": "29.3 Key Differences from spotpython\nWhile the implementation follows spotpython’s design, there is a difference: spotoptim uses a simplified clustering, it uses sklearn’s KMeans directly instead of a custom implementation.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "point_selection.html#example-usage",
    "href": "point_selection.html#example-usage",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "29.4 Example Usage",
    "text": "29.4 Example Usage\nThis example demonstrates the point selection feature with a limited number of surrogate points. Increase MAX_ITER, N_INITIAL, and MAX_SURROGATE_POINTS to see more pronounced effects.\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\nMAX_ITER = 20\nN_INITIAL = 5\nMAX_SURROGATE_POINTS = 10\n\n# Define an example objective function\ndef sphere(X):\n    \"\"\"Simple sphere function for demonstration\"\"\"\n    return np.sum(X**2, axis=1)\n\nbounds = [(-5, 5), (-5, 5), (-5, 5)]\n\n# Without point selection (default behavior)\noptimizer1 = SpotOptim(\n    fun=sphere,\n    bounds=bounds,\n    max_iter=MAX_ITER,\n    n_initial=N_INITIAL,\n    seed=42\n)\nresult1 = optimizer1.optimize()\nprint(f\"Without selection - Best value: {result1.fun:.6f}\")\nprint(f\"Total points evaluated: {result1.nfev}\")\n\n# With point selection using distant method\noptimizer2 = SpotOptim(\n    fun=sphere,\n    bounds=bounds,\n    max_iter=MAX_ITER,\n    n_initial=N_INITIAL,\n    max_surrogate_points=MAX_SURROGATE_POINTS,\n    selection_method='distant',\n    seed=42\n)\nresult2 = optimizer2.optimize()\nprint(f\"\\nWith 'distant' selection - Best value: {result2.fun:.6f}\")\nprint(f\"Total points evaluated: {result2.nfev}\")\nprint(f\"Max surrogate points: {optimizer2.max_surrogate_points}\")\n\n# With point selection using best cluster method\noptimizer3 = SpotOptim(\n    fun=sphere,\n    bounds=bounds,\n    max_iter=MAX_ITER,\n    n_initial=N_INITIAL,\n    max_surrogate_points=MAX_SURROGATE_POINTS,\n    selection_method='best',\n    seed=42\n)\nresult3 = optimizer3.optimize()\nprint(f\"\\nWith 'best' selection - Best value: {result3.fun:.6f}\")\nprint(f\"Total points evaluated: {result3.nfev}\")\nprint(f\"Max surrogate points: {optimizer3.max_surrogate_points}\")\n\nWithout selection - Best value: 0.000034\nTotal points evaluated: 20\n\nWith 'distant' selection - Best value: 2.380385\nTotal points evaluated: 20\nMax surrogate points: 10\n\nWith 'best' selection - Best value: 2.549832\nTotal points evaluated: 20\nMax surrogate points: 10",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "point_selection.html#benefits",
    "href": "point_selection.html#benefits",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "29.5 Benefits",
    "text": "29.5 Benefits\n\nScalability: Enables efficient optimization with many function evaluations\nComputational efficiency: Reduces surrogate training time for large datasets\nMaintained accuracy: Careful point selection preserves model quality\nFlexibility: Two selection methods for different optimization scenarios",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "point_selection.html#comparison-with-spotpython",
    "href": "point_selection.html#comparison-with-spotpython",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "29.6 Comparison with spotpython",
    "text": "29.6 Comparison with spotpython\n\n\n\nFeature\nspotpython\nSpotOptim\n\n\n\n\nPoint selection via clustering\n✓\n✓\n\n\n‘distant’ method\n✓\n✓\n\n\n‘best’ method\n✓\n✓\n\n\nSelection dispatcher\n✓\n✓\n\n\nNyström approximation\n✓\n✗\n\n\nModular design\n✓ (utils.aggregate)\n✓ (class methods)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "point_selection.html#references",
    "href": "point_selection.html#references",
    "title": "29  Point Selection Implementation in SpotOptim",
    "section": "29.7 References",
    "text": "29.7 References\n\nspotpython implementation: src/spotpython/spot/spot.py lines 1646-1778\nspotpython utilities: src/spotpython/utils/aggregate.py lines 262-336",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Point Selection Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html",
    "href": "save_load.html",
    "title": "30  Save and Load in SpotOptim",
    "section": "",
    "text": "30.1 Key Concepts\nSpotOptim provides comprehensive save and load functionality for serializing optimization configurations and results. This enables distributed workflows where experiments are defined locally, executed remotely, and analyzed back on the local machine.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#key-concepts",
    "href": "save_load.html#key-concepts",
    "title": "30  Save and Load in SpotOptim",
    "section": "",
    "text": "30.1.1 Experiments vs Results\nSpotOptim distinguishes between two types of saved data:\n\nExperiment (*_exp.pkl): Configuration only, excluding the objective function and results. Used to transfer optimization setup to remote machines.\nResult (*_res.pkl): Complete optimization state including configuration, all evaluations, and results. Used to save and analyze completed optimizations.\n\n\n\n30.1.2 What Gets Saved\n\n\n\nComponent\nExperiment\nResult\n\n\n\n\nConfiguration (bounds, parameters)\n✓\n✓\n\n\nObjective function\n✗\n✗\n\n\nEvaluations (X, y)\n✗\n✓\n\n\nBest solution\n✗\n✓\n\n\nSurrogate model\nExcluded*\n✓\n\n\nTensorBoard writer\n✗\n✗\n\n\n\n*Surrogate model is excluded from experiments and automatically recreated when loaded.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#quick-start",
    "href": "save_load.html#quick-start",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.2 Quick Start",
    "text": "30.2 Quick Start\n\n30.2.1 Basic Save and Load\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    \"\"\"Simple sphere function\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create and configure optimizer\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    seed=42\n)\n\n# Run optimization\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\n\n# Save complete results\noptimizer.save_result(prefix=\"sphere_opt\")\n# Creates: sphere_opt_res.pkl\n\n# Later: load and analyze results\nloaded_opt = SpotOptim.load_result(\"sphere_opt_res.pkl\")\nprint(f\"Loaded best value: {loaded_opt.best_y_:.6f}\")\nprint(f\"Total evaluations: {loaded_opt.counter}\")\n\nBest value: 0.000001\nExperiment saved to sphere_opt_res.pkl\nResult saved to sphere_opt_res.pkl\nLoaded result from sphere_opt_res.pkl\nLoaded best value: 0.000001\nTotal evaluations: 20",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#distributed-workflow",
    "href": "save_load.html#distributed-workflow",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.3 Distributed Workflow",
    "text": "30.3 Distributed Workflow\nThe save/load functionality enables a powerful workflow for distributed optimization:\n\n30.3.1 Step 1: Define Experiment Locally\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Define a placeholder function (will be replaced on remote machine)\ndef placeholder(X):\n    \"\"\"Placeholder function - will be replaced remotely\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Define configuration locally\noptimizer = SpotOptim(\n    fun=placeholder,  # Temporary function\n    bounds=[(-10, 10), (-10, 10), (-10, 10)],\n    max_iter=20,\n    n_initial=10,\n    seed=42,\n    verbose=True\n)\n\n# Save experiment configuration\noptimizer.save_experiment(prefix=\"remote_job_001\")\n# Creates: remote_job_001_exp.pkl\n\nprint(\"Experiment saved. Transfer remote_job_001_exp.pkl to remote machine.\")\nprint(\"The objective function will be replaced on the remote machine.\")\n\nTensorBoard logging disabled\nExperiment saved to remote_job_001_exp.pkl\nExperiment saved. Transfer remote_job_001_exp.pkl to remote machine.\nThe objective function will be replaced on the remote machine.\n\n\n\n\n30.3.2 Step 2: Execute on Remote Machine\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\n# Define objective function on remote machine\ndef expensive_function(X):\n    \"\"\"Expensive simulation or computation\"\"\"\n    # Your expensive computation here\n    return np.sum(X**2, axis=1) + 0.1 * np.sum(np.sin(10 * X), axis=1)\n\n# Load experiment configuration\noptimizer = SpotOptim.load_experiment(\"remote_job_001_exp.pkl\")\nprint(\"Experiment loaded successfully\")\n\n# Attach objective function (must be done after loading)\noptimizer.fun = expensive_function\n\n# Run optimization\nresult = optimizer.optimize()\nprint(f\"Optimization complete. Best value: {result.fun:.6f}\")\n\n# Save results\noptimizer.save_result(prefix=\"remote_job_001\")\n# Creates: remote_job_001_res.pkl\n\nprint(\"Results saved. Transfer remote_job_001_res.pkl back to local machine.\")\n\nLoaded experiment from remote_job_001_exp.pkl\nExperiment loaded successfully\nInitial best: f(x) = 46.587622\nIteration 1: f(x) = 57.963676\nIteration 2: f(x) = 49.624579\nIteration 3: New best f(x) = 45.184938\nIteration 4: New best f(x) = 41.587740\nIteration 5: New best f(x) = 3.846258\nIteration 6: New best f(x) = 1.484084\nIteration 7: New best f(x) = 0.167743\nIteration 8: f(x) = 0.210425\nIteration 9: f(x) = 0.364727\nIteration 10: f(x) = 0.271020\nOptimization complete. Best value: 0.167743\nExperiment saved to remote_job_001_res.pkl\nResult saved to remote_job_001_res.pkl\nResults saved. Transfer remote_job_001_res.pkl back to local machine.\n\n\n\n\n30.3.3 Step 3: Analyze Results Locally\n\nfrom spotoptim import SpotOptim\nimport matplotlib.pyplot as plt\n\n# Load results from remote execution\noptimizer = SpotOptim.load_result(\"remote_job_001_res.pkl\")\n\n# Access all optimization data\nprint(f\"Best value found: {optimizer.best_y_:.6f}\")\nprint(f\"Best point: {optimizer.best_x_}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Number of iterations: {optimizer.n_iter_}\")\n\n# Analyze convergence\nplt.figure(figsize=(10, 6))\nplt.plot(optimizer.y_, 'o-', alpha=0.6, label='Evaluations')\nplt.plot(range(len(optimizer.y_)), \n         [optimizer.y_[:i+1].min() for i in range(len(optimizer.y_))],\n         'r-', linewidth=2, label='Best so far')\nplt.xlabel('Iteration')\nplt.ylabel('Objective Value')\nplt.title('Optimization Progress')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Access all evaluated points\nprint(f\"\\nAll evaluated points shape: {optimizer.X_.shape}\")\nprint(f\"All objective values shape: {optimizer.y_.shape}\")\n\nLoaded result from remote_job_001_res.pkl\nBest value found: 0.167743\nBest point: [ 0.17516921  0.34614876 -0.05559165]\nTotal evaluations: 20\nNumber of iterations: 10\n\n\n\n\n\n\n\n\n\n\nAll evaluated points shape: (20, 3)\nAll objective values shape: (20,)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#advanced-usage",
    "href": "save_load.html#advanced-usage",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.4 Advanced Usage",
    "text": "30.4 Advanced Usage\n\n30.4.1 Custom Filenames and Paths\n\nimport os\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    seed=42\n)\n\n# Save with custom filename\noptimizer.save_experiment(\n    filename=\"custom_name.pkl\",\n    verbosity=1\n)\n\n# Save to specific directory\nos.makedirs(\"experiments/batch_001\", exist_ok=True)\noptimizer.save_experiment(\n    prefix=\"exp_001\",\n    path=\"experiments/batch_001\",\n    verbosity=1\n)\n# Creates: experiments/batch_001/exp_001_exp.pkl\n\nExperiment saved to custom_name.pkl\nExperiment saved to experiments/batch_001/exp_001_exp.pkl\n\n\n\n\n30.4.2 Overwrite Protection\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)], max_iter=20)\nresult = optimizer.optimize()\n\n# First save\noptimizer.save_result(prefix=\"my_result\")\n\n# Try to save again - raises FileExistsError by default\ntry:\n    optimizer.save_result(prefix=\"my_result\")\nexcept FileExistsError as e:\n    print(f\"File already exists: {e}\")\n\n# Explicitly allow overwriting\noptimizer.save_result(prefix=\"my_result\", overwrite=True)\nprint(\"File overwritten successfully\")\n\nExperiment saved to my_result_res.pkl\nResult saved to my_result_res.pkl\nExperiment saved to my_result_res.pkl\nResult saved to my_result_res.pkl\nExperiment saved to my_result_res.pkl\nResult saved to my_result_res.pkl\nFile overwritten successfully\n\n\n\n\n30.4.3 Loading and Continuing Optimization\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Initial optimization\nopt1 = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    seed=42\n)\nresult1 = opt1.optimize()\nopt1.save_result(prefix=\"checkpoint\")\n\nprint(f\"Initial optimization: {result1.nfev} evaluations, best={result1.fun:.6f}\")\n\n# Load and continue\nopt2 = SpotOptim.load_result(\"checkpoint_res.pkl\")\nopt2.fun = objective  # Re-attach function\nopt2.max_iter = 25  # Increase budget\n\n# Continue optimization\nresult2 = opt2.optimize()\nprint(f\"After continuation: {result2.nfev} evaluations, best={result2.fun:.6f}\")\n\nExperiment saved to checkpoint_res.pkl\nResult saved to checkpoint_res.pkl\nInitial optimization: 20 evaluations, best=0.000001\nLoaded result from checkpoint_res.pkl\nAfter continuation: 25 evaluations, best=0.000002",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#working-with-noisy-functions",
    "href": "save_load.html#working-with-noisy-functions",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.5 Working with Noisy Functions",
    "text": "30.5 Working with Noisy Functions\nSave and load preserves noise statistics for reproducible analysis:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_objective(X):\n    \"\"\"Objective with measurement noise\"\"\"\n    true_value = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, X.shape[0])\n    return true_value + noise\n\n# Optimize noisy function with repeated evaluations\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    repeats_initial=3,    # Repeat initial points\n    repeats_surrogate=2,  # Repeat surrogate points\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\n# Save results (includes noise statistics)\noptimizer.save_result(prefix=\"noisy_opt\")\n\n# Load and analyze noise statistics\nloaded_opt = SpotOptim.load_result(\"noisy_opt_res.pkl\")\n\nprint(f\"Noise handling enabled: {loaded_opt.noise}\")\nprint(f\"Best mean value: {loaded_opt.best_y_:.6f}\")\n\nif loaded_opt.mean_y is not None:\n    print(f\"Mean values available: {len(loaded_opt.mean_y)}\")\n    print(f\"Variance values available: {len(loaded_opt.var_y)}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 2.223853, mean best: f(x) = 2.371573\nExperiment saved to noisy_opt_res.pkl\nResult saved to noisy_opt_res.pkl\nLoaded result from noisy_opt_res.pkl\nNoise handling enabled: True\nBest mean value: 2.223853\nMean values available: 10\nVariance values available: 10",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#working-with-different-variable-types",
    "href": "save_load.html#working-with-different-variable-types",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.6 Working with Different Variable Types",
    "text": "30.6 Working with Different Variable Types\nSave and load preserves variable type information:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef mixed_objective(X):\n    \"\"\"Objective with mixed variable types\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create optimizer with mixed variable types\noptimizer = SpotOptim(\n    fun=mixed_objective,\n    bounds=[(-5, 5), (-5, 5), (-5, 5), (-5, 5)],\n    var_type=[\"float\", \"int\", \"factor\", \"float\"],\n    var_name=[\"continuous\", \"integer\", \"categorical\", \"another_cont\"],\n    max_iter=20,\n    n_initial=10,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Save results\noptimizer.save_result(prefix=\"mixed_vars\")\n\n# Load results\nloaded_opt = SpotOptim.load_result(\"mixed_vars_res.pkl\")\n\nprint(\"Variable types preserved:\")\nprint(f\"  var_type: {loaded_opt.var_type}\")\nprint(f\"  var_name: {loaded_opt.var_name}\")\n\n# Verify integer variables are still integers\nprint(f\"\\nInteger variable (dim 1) values:\")\nprint(loaded_opt.X_[:5, 1])  # Should be integers\n\nExperiment saved to mixed_vars_res.pkl\nResult saved to mixed_vars_res.pkl\nLoaded result from mixed_vars_res.pkl\nVariable types preserved:\n  var_type: ['float', 'int', 'factor', 'float']\n  var_name: ['continuous', 'integer', 'categorical', 'another_cont']\n\nInteger variable (dim 1) values:\n[ 3. -2. -0. -3.  4.]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#best-practices",
    "href": "save_load.html#best-practices",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.7 Best Practices",
    "text": "30.7 Best Practices\n\n30.7.1 1. Always Re-attach the Objective Function\nAfter loading an experiment, you must re-attach the objective function:\n\n# Load experiment\noptimizer = SpotOptim.load_experiment(\"experiment_exp.pkl\")\n\n# REQUIRED: Re-attach function\noptimizer.fun = your_objective_function\n\n# Now you can optimize\nresult = optimizer.optimize()\n\n\n\n30.7.2 2. Use Meaningful Prefixes\nOrganize your experiments with descriptive prefixes:\n\n# Good practice: descriptive prefixes\noptimizer.save_experiment(prefix=\"sphere_d10_seed42\")\noptimizer.save_experiment(prefix=\"rosenbrock_n100_lhs\")\noptimizer.save_result(prefix=\"final_run_2024_11_15\")\n\n# Avoid: generic names\noptimizer.save_experiment(prefix=\"exp1\")  # Not descriptive\noptimizer.save_result(prefix=\"result\")     # Hard to track\n\n\n\n30.7.3 3. Save Experiments Before Remote Execution\n\n# Define locally\noptimizer = SpotOptim(bounds=bounds, max_iter=20, seed=42)\noptimizer.save_experiment(prefix=\"remote_job\")\n\n# Transfer file to remote machine\n# Execute remotely\n# Transfer results back\n# Analyze locally\n\n\n\n30.7.4 4. Version Your Experiments\n\nimport datetime\n\n# Add timestamp to prefix\ntimestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nprefix = f\"experiment_{timestamp}\"\n\noptimizer.save_experiment(prefix=prefix)\n# Creates: experiment_20241115_143022_exp.pkl\n\n\n\n30.7.5 5. Handle File Paths Robustly\n\nimport os\n\n# Create directory structure\nexp_dir = \"experiments/batch_001\"\nos.makedirs(exp_dir, exist_ok=True)\n\n# Save with full path\noptimizer.save_experiment(\n    prefix=\"exp_001\",\n    path=exp_dir\n)\n\n# Load with full path\nexp_file = os.path.join(exp_dir, \"exp_001_exp.pkl\")\nloaded_opt = SpotOptim.load_experiment(exp_file)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#complete-example-multi-machine-workflow",
    "href": "save_load.html#complete-example-multi-machine-workflow",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.8 Complete Example: Multi-Machine Workflow",
    "text": "30.8 Complete Example: Multi-Machine Workflow\nHere’s a complete example demonstrating the entire workflow:\n\n30.8.1 Local Machine (Setup)\n\n# setup_experiment.py\nimport numpy as np\nfrom spotoptim import SpotOptim\nimport os\n\n# Placeholder function for experiment setup\ndef placeholder_func(X):\n    return np.sum(X**2, axis=1)\n\n# Create experiments directory\nos.makedirs(\"experiments\", exist_ok=True)\n\n# Define multiple experiments\nexperiments = [\n    {\"seed\": 42, \"max_iter\": 20, \"prefix\": \"exp_seed42\"},\n    {\"seed\": 123, \"max_iter\": 20, \"prefix\": \"exp_seed123\"},\n    {\"seed\": 999, \"max_iter\": 20, \"prefix\": \"exp_seed999\"},\n]\n\nfor exp_config in experiments:\n    optimizer = SpotOptim(\n        fun=placeholder_func,  # Placeholder - will be replaced remotely\n        bounds=[(-10, 10), (-10, 10), (-10, 10)],\n        max_iter=exp_config[\"max_iter\"],\n        n_initial=10,\n        seed=exp_config[\"seed\"],\n        verbose=False\n    )\n    \n    optimizer.save_experiment(\n        prefix=exp_config[\"prefix\"],\n        path=\"experiments\"\n    )\n    \n    print(f\"Created: experiments/{exp_config['prefix']}_exp.pkl\")\n\nprint(\"\\nAll experiments created. Transfer 'experiments' folder to remote machine.\")\n\nExperiment saved to experiments/exp_seed42_exp.pkl\nCreated: experiments/exp_seed42_exp.pkl\nExperiment saved to experiments/exp_seed123_exp.pkl\nCreated: experiments/exp_seed123_exp.pkl\nExperiment saved to experiments/exp_seed999_exp.pkl\nCreated: experiments/exp_seed999_exp.pkl\n\nAll experiments created. Transfer 'experiments' folder to remote machine.\n\n\n\n\n30.8.2 Remote Machine (Execution)\n\n# run_experiments.py\nimport numpy as np\nfrom spotoptim import SpotOptim\nimport os\nimport glob\n\ndef complex_objective(X):\n    \"\"\"Complex multimodal objective function\"\"\"\n    term1 = np.sum(X**2, axis=1)\n    term2 = 10 * np.sum(np.cos(2 * np.pi * X), axis=1)\n    term3 = 0.1 * np.sum(np.sin(5 * np.pi * X), axis=1)\n    return term1 - term2 + term3\n\n# Find all experiment files\nexp_files = glob.glob(\"experiments/*_exp.pkl\")\nprint(f\"Found {len(exp_files)} experiments to run\")\n\n# Run each experiment\nfor exp_file in exp_files:\n    print(f\"\\nProcessing: {exp_file}\")\n    \n    # Load experiment\n    optimizer = SpotOptim.load_experiment(exp_file)\n    \n    # Attach objective\n    optimizer.fun = complex_objective\n    \n    # Run optimization\n    result = optimizer.optimize()\n    print(f\"  Best value: {result.fun:.6f}\")\n    \n    # Save result (same prefix, different suffix)\n    prefix = os.path.basename(exp_file).replace(\"_exp.pkl\", \"\")\n    optimizer.save_result(\n        prefix=prefix,\n        path=\"experiments\"\n    )\n    print(f\"  Saved: experiments/{prefix}_res.pkl\")\n\nprint(\"\\nAll experiments completed. Transfer results back to local machine.\")\n\nFound 3 experiments to run\n\nProcessing: experiments/exp_seed999_exp.pkl\nLoaded experiment from experiments/exp_seed999_exp.pkl\n  Best value: -9.121049\nExperiment saved to experiments/exp_seed999_res.pkl\nResult saved to experiments/exp_seed999_res.pkl\n  Saved: experiments/exp_seed999_res.pkl\n\nProcessing: experiments/exp_seed42_exp.pkl\nLoaded experiment from experiments/exp_seed42_exp.pkl\n  Best value: -5.807748\nExperiment saved to experiments/exp_seed42_res.pkl\nResult saved to experiments/exp_seed42_res.pkl\n  Saved: experiments/exp_seed42_res.pkl\n\nProcessing: experiments/exp_seed123_exp.pkl\nLoaded experiment from experiments/exp_seed123_exp.pkl\n  Best value: -8.050942\nExperiment saved to experiments/exp_seed123_res.pkl\nResult saved to experiments/exp_seed123_res.pkl\n  Saved: experiments/exp_seed123_res.pkl\n\nAll experiments completed. Transfer results back to local machine.\n\n\n\n\n30.8.3 Local Machine (Analysis)\n\n# analyze_results.py\nimport numpy as np\nfrom spotoptim import SpotOptim\nimport glob\nimport matplotlib.pyplot as plt\n\n# Find all result files\nresult_files = glob.glob(\"experiments/*_res.pkl\")\nprint(f\"Found {len(result_files)} results to analyze\")\n\n# Load and compare results\nresults = []\nfor res_file in result_files:\n    opt = SpotOptim.load_result(res_file)\n    results.append({\n        \"file\": res_file,\n        \"best_value\": opt.best_y_,\n        \"best_point\": opt.best_x_,\n        \"n_evals\": opt.counter,\n        \"seed\": opt.seed\n    })\n    print(f\"{res_file}: best={opt.best_y_:.6f}, evals={opt.counter}\")\n\n# Find best overall result\nbest = min(results, key=lambda x: x[\"best_value\"])\nprint(f\"\\nBest result:\")\nprint(f\"  File: {best['file']}\")\nprint(f\"  Value: {best['best_value']:.6f}\")\nprint(f\"  Point: {best['best_point']}\")\nprint(f\"  Seed: {best['seed']}\")\n\n# Plot convergence comparison\nplt.figure(figsize=(12, 6))\n\nfor res_file in result_files:\n    opt = SpotOptim.load_result(res_file)\n    seed = opt.seed\n    cummin = [opt.y_[:i+1].min() for i in range(len(opt.y_))]\n    plt.plot(cummin, label=f\"Seed {seed}\", linewidth=2, alpha=0.7)\n\nplt.xlabel(\"Iteration\", fontsize=12)\nplt.ylabel(\"Best Value Found\", fontsize=12)\nplt.title(\"Optimization Progress Comparison\", fontsize=14)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(\"experiments/convergence_comparison.png\", dpi=150)\nprint(\"\\nConvergence plot saved to: experiments/convergence_comparison.png\")\n\nFound 3 results to analyze\nLoaded result from experiments/exp_seed42_res.pkl\nexperiments/exp_seed42_res.pkl: best=-5.807748, evals=20\nLoaded result from experiments/exp_seed999_res.pkl\nexperiments/exp_seed999_res.pkl: best=-9.121049, evals=20\nLoaded result from experiments/exp_seed123_res.pkl\nexperiments/exp_seed123_res.pkl: best=-8.050942, evals=20\n\nBest result:\n  File: experiments/exp_seed999_res.pkl\n  Value: -9.121049\n  Point: [-1.05626884 -0.90533225  0.363701  ]\n  Seed: 999\nLoaded result from experiments/exp_seed42_res.pkl\nLoaded result from experiments/exp_seed999_res.pkl\nLoaded result from experiments/exp_seed123_res.pkl\n\nConvergence plot saved to: experiments/convergence_comparison.png",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#technical-details",
    "href": "save_load.html#technical-details",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.9 Technical Details",
    "text": "30.9 Technical Details\n\n30.9.1 Serialization Method\nSpotOptim uses Python’s built-in pickle module for serialization. This provides:\n\nStandard library: No additional dependencies required\nCompatibility: Works with numpy arrays, sklearn models, scipy functions\nPerformance: Efficient serialization of large datasets\n\n\n\n30.9.2 Component Reinitialization\nWhen loading experiments, certain components are automatically recreated:\n\nSurrogate model: Gaussian Process with default kernel\nLHS sampler: Latin Hypercube Sampler with original seed\n\nThis ensures loaded experiments can continue optimization without manual configuration.\n\n\n30.9.3 Excluded Components\nSome components cannot be pickled and are automatically excluded:\n\nObjective function (fun): Lambda functions and local functions cannot be reliably pickled\nTensorBoard writer (tb_writer): File handles cannot be serialized\nSurrogate model (experiments only): Recreated on load for experiments\n\n\n\n30.9.4 File Format\nFiles are saved using pickle’s highest protocol:\n\nwith open(filename, \"wb\") as handle:\n    pickle.dump(optimizer_state, handle, protocol=pickle.HIGHEST_PROTOCOL)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#troubleshooting",
    "href": "save_load.html#troubleshooting",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.10 Troubleshooting",
    "text": "30.10 Troubleshooting\n\n30.10.1 Issue: “AttributeError: ‘SpotOptim’ object has no attribute ‘fun’”\nCause: Objective function not re-attached after loading experiment.\nSolution: Always re-attach the function after loading:\n\nopt = SpotOptim.load_experiment(\"exp.pkl\")\nopt.fun = your_objective_function  # Add this line\nresult = opt.optimize()\n\n\n\n30.10.2 Issue: “FileNotFoundError: Experiment file not found”\nCause: Incorrect file path or file doesn’t exist.\nSolution: Check file path and ensure file exists:\n\nimport os\n\nfilename = \"experiment_exp.pkl\"\nif os.path.exists(filename):\n    opt = SpotOptim.load_experiment(filename)\nelse:\n    print(f\"File not found: {filename}\")\n\n\n\n30.10.3 Issue: “FileExistsError: File already exists”\nCause: Attempting to save over an existing file without overwrite=True.\nSolution: Either use a different prefix or enable overwriting:\n\n# Option 1: Use different prefix\noptimizer.save_result(prefix=\"my_result_v2\")\n\n# Option 2: Enable overwriting\noptimizer.save_result(prefix=\"my_result\", overwrite=True)\n\n\n\n30.10.4 Issue: Results differ after loading\nCause: Random state not preserved or function behavior changed.\nSolution: Ensure you’re using the same seed and function definition:\n\n# When saving\noptimizer = SpotOptim(..., seed=42)  # Use fixed seed\n\n# When loading and continuing\nloaded_opt = SpotOptim.load_result(\"result_res.pkl\")\nloaded_opt.fun = same_objective_function  # Same function definition",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "save_load.html#see-also",
    "href": "save_load.html#see-also",
    "title": "30  Save and Load in SpotOptim",
    "section": "30.11 See Also",
    "text": "30.11 See Also\n\nReproducibility Manual: Learn about using seeds for reproducible results\nTensorBoard Manual: Monitor optimization progress in real-time",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Save and Load in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html",
    "href": "success_rate.html",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "",
    "text": "31.1 What is Success Rate?\nSpotOptim tracks the success rate of the optimization process, which measures how often the optimizer finds improvements over recent evaluations. This metric helps you understand whether the optimization is making progress or has stalled.\nThe success rate is a rolling metric that tracks the percentage of recent evaluations that improved upon the best value found so far. It’s calculated over a sliding window of the last 100 evaluations.\nKey Points: - A “success” occurs when a new evaluation finds a value better (smaller) than the best found so far - The rate is computed over the last 100 evaluations (window size) - Values range from 0.0 (no recent improvements) to 1.0 (all recent evaluations improved) - Helps identify when optimization is stalling and may need adjustment",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#first-example",
    "href": "success_rate.html#first-example",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.2 First Example",
    "text": "31.2 First Example\n\nStart TensorBoard to visualize success rate in real-time:\n\ntensorboard --logdir=runs\nThe execute the following code:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef rosenbrock(X):\n    \"\"\"Rosenbrock function - challenging optimization problem\"\"\"\n    x = X[:, 0]\n    y = X[:, 1]\n    return (1 - x)**2 + 100 * (y - x**2)**2\n\n# Run optimization with periodic success rate checks\noptimizer = SpotOptim(\n    fun=rosenbrock,\n    bounds=[(-2, 2), (-2, 2)],\n    max_iter=20,\n    n_initial=10,\n    tensorboard_log=True,\n    tensorboard_clean=True,\n    seed=42\n)\n\nresult = optimizer.optimize()\n\n# Analyze final success rate\nprint(f\"\\nOptimization Results:\")\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Final success rate: {optimizer.success_rate:.2%}\")\n\n# Interpret the result\nif optimizer.success_rate &gt; 0.5:\n    print(\"→ High success rate: Optimization is still making good progress\")\nelif optimizer.success_rate &gt; 0.2:\n    print(\"→ Medium success rate: Approaching convergence\")\nelse:\n    print(\"→ Low success rate: Optimization has likely converged\")\n\n\nOptimization Results:\nBest value: 0.011538\nTotal evaluations: 20\nFinal success rate: 30.00%\n→ Medium success rate: Approaching convergence",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#second-example",
    "href": "success_rate.html#second-example",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.3 Second Example",
    "text": "31.3 Second Example\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    \"\"\"Simple sphere function: f(x) = sum(x^2)\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Create optimizer\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    verbose=True\n)\n\n# Run optimization\nresult = optimizer.optimize()\n\n# Check success rate\nprint(f\"Final success rate: {optimizer.success_rate:.2%}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 1.926385\nIteration 1: New best f(x) = 1.416269\nIteration 2: New best f(x) = 0.997639\nIteration 3: New best f(x) = 0.349986\nIteration 4: New best f(x) = 0.052770\nIteration 5: New best f(x) = 0.020227\nIteration 6: New best f(x) = 0.003399\nIteration 7: New best f(x) = 0.001745\nIteration 8: New best f(x) = 0.000003\nIteration 9: New best f(x) = 0.000003\nIteration 10: f(x) = 0.000003\nFinal success rate: 90.00%\nTotal evaluations: 20",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#accessing-success-rate",
    "href": "success_rate.html#accessing-success-rate",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.4 Accessing Success Rate",
    "text": "31.4 Accessing Success Rate\nThe success rate is stored in the success_rate attribute:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(fun=sphere, bounds=[(-5, 5), (-5, 5)], max_iter=20)\nresult = optimizer.optimize()\n\n# Access success rate\ncurrent_rate = optimizer.success_rate\nprint(f\"Success rate: {current_rate:.2%}\")\n\n# Also available via getter method\nrate = optimizer._get_success_rate()\nprint(f\"Via getter method: {rate:.2%}\")\n\nSuccess rate: 80.00%\nVia getter method: 80.00%",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#interpreting-success-rate",
    "href": "success_rate.html#interpreting-success-rate",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.5 Interpreting Success Rate",
    "text": "31.5 Interpreting Success Rate\n\n31.5.1 High Success Rate (&gt; 0.5)\nSuccess Rate: 75%\nInterpretation: The optimizer is finding improvements frequently. This typically indicates: - The optimization is in an exploratory phase - The surrogate model is effectively guiding the search - There’s still room for improvement in the search space\nAction: Continue optimization - progress is good!\n\n\n31.5.2 Medium Success Rate (0.2 - 0.5)\nSuccess Rate: 35%\nInterpretation: The optimizer occasionally finds improvements. This suggests: - The search is becoming more refined - The optimizer is balancing exploration and exploitation - Approaching a local or global optimum\nAction: Monitor progress and consider stopping criteria.\n\n\n31.5.3 Low Success Rate (&lt; 0.2)\nSuccess Rate: 8%\nInterpretation: Few recent evaluations improve the best value. This may indicate: - The optimization has converged to a (local) optimum - The search is stuck in a plateau region - The budget may be exhausted in terms of meaningful progress\nAction: Consider stopping optimization or adjusting parameters.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#tensorboard-visualization",
    "href": "success_rate.html#tensorboard-visualization",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.6 TensorBoard Visualization",
    "text": "31.6 TensorBoard Visualization\nWhen TensorBoard logging is enabled, success rate is automatically logged and can be visualized in real-time:\n\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    tensorboard_log=True,  # Enable logging\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nView in TensorBoard:\ntensorboard --logdir=runs\nIn the TensorBoard interface, look for: - SCALARS tab → success_rate: Rolling success rate over iterations - Compare multiple runs side-by-side - Identify when optimization stalls",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#example-comparing-multiple-runs",
    "href": "success_rate.html#example-comparing-multiple-runs",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.7 Example: Comparing Multiple Runs",
    "text": "31.7 Example: Comparing Multiple Runs\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef ackley(X):\n    \"\"\"Ackley function - multimodal test function\"\"\"\n    a = 20\n    b = 0.2\n    c = 2 * np.pi\n    n = X.shape[1]\n    \n    sum_sq = np.sum(X**2, axis=1)\n    sum_cos = np.sum(np.cos(c * X), axis=1)\n    \n    return -a * np.exp(-b * np.sqrt(sum_sq / n)) - np.exp(sum_cos / n) + a + np.e\n\n# Run with different configurations\nconfigs = [\n    {\"n_initial\": 10, \"max_iter\": 30, \"name\": \"Small initial\"},\n    {\"n_initial\": 20, \"max_iter\": 30, \"name\": \"Large initial\"},\n]\n\nresults = []\nfor config in configs:\n    optimizer = SpotOptim(\n        fun=ackley,\n        bounds=[(-5, 5), (-5, 5)],\n        n_initial=config[\"n_initial\"],\n        max_iter=config[\"max_iter\"],\n        seed=42,\n        verbose=False\n    )\n    result = optimizer.optimize()\n    \n    results.append({\n        \"name\": config[\"name\"],\n        \"best_value\": result.fun,\n        \"success_rate\": optimizer.success_rate,\n        \"n_evals\": optimizer.counter\n    })\n    \n    print(f\"\\n{config['name']}:\")\n    print(f\"  Best value: {result.fun:.6f}\")\n    print(f\"  Success rate: {optimizer.success_rate:.2%}\")\n    print(f\"  Evaluations: {optimizer.counter}\")\n\n# Find best configuration\nbest = min(results, key=lambda x: x[\"best_value\"])\nprint(f\"\\nBest configuration: {best['name']}\")\nprint(f\"  Achieved: f(x) = {best['best_value']:.6f}\")\nprint(f\"  Final success rate: {best['success_rate']:.2%}\")\n\n\nSmall initial:\n  Best value: 0.012066\n  Success rate: 50.00%\n  Evaluations: 30\n\nLarge initial:\n  Best value: 0.006596\n  Success rate: 30.00%\n  Evaluations: 30\n\nBest configuration: Large initial\n  Achieved: f(x) = 0.006596\n  Final success rate: 30.00%",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#success-rate-with-noisy-functions",
    "href": "success_rate.html#success-rate-with-noisy-functions",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.8 Success Rate with Noisy Functions",
    "text": "31.8 Success Rate with Noisy Functions\nFor noisy functions (when repeats_initial &gt; 1 or repeats_surrogate &gt; 1), the success rate tracks improvements in the raw y values, not the aggregated means:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_sphere(X):\n    \"\"\"Sphere function with Gaussian noise\"\"\"\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.5, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=10,\n    repeats_initial=3,    # 3 evaluations per initial point\n    repeats_surrogate=2,  # 2 evaluations per new point\n    seed=42,\n    verbose=True\n)\n\nresult = optimizer.optimize()\n\nprint(f\"\\nNoisy Optimization Results:\")\nprint(f\"Best raw value: {optimizer.min_y:.6f}\")\nprint(f\"Best mean value: {optimizer.min_mean_y:.6f}\")\nprint(f\"Success rate: {optimizer.success_rate:.2%}\")\nprint(f\"Total evaluations: {optimizer.counter}\")\nprint(f\"Unique design points: {optimizer.mean_X.shape[0]}\")\n\nTensorBoard logging disabled\nInitial best: f(x) = 2.066599, mean best: f(x) = 2.467212\n\nNoisy Optimization Results:\nBest raw value: 2.066599\nBest mean value: 2.467212\nSuccess rate: 0.00%\nTotal evaluations: 30\nUnique design points: 10\n\n\nNote: With noisy functions, the success rate may be lower because: - Noise can mask true improvements - Multiple evaluations of the same point contribute to the window - Focus on the mean values (min_mean_y) for better assessment",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#advanced-custom-window-size",
    "href": "success_rate.html#advanced-custom-window-size",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.9 Advanced: Custom Window Size",
    "text": "31.9 Advanced: Custom Window Size\nThe success rate is calculated over a window of 100 evaluations by default. This is controlled by the window_size attribute:\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=10\n)\n\n# Check default window size\nprint(f\"Window size: {optimizer.window_size}\")  # 100\n\n# The window size is set during initialization\n# To use a different window, you would need to modify it\n# before running optimization (not typically recommended)\n\nWindow size: 100",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#best-practices",
    "href": "success_rate.html#best-practices",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.10 Best Practices",
    "text": "31.10 Best Practices\n\n31.10.1 1. Monitor During Long Runs\nFor expensive optimization runs, periodically check success rate:\n# Could be implemented with callbacks in future versions\n# For now, success rate is updated automatically and logged to TensorBoard\n\n\n31.10.2 2. Combine with TensorBoard\nAlways enable TensorBoard logging for visual monitoring:\noptimizer = SpotOptim(\n    fun=expensive_function,\n    bounds=bounds,\n    max_iter=25,\n    tensorboard_log=True,  # Track success_rate visually\n    tensorboard_path=\"runs/long_optimization\"\n)\n\n\n31.10.3 3. Use as Stopping Criterion\nConsider stopping when success rate drops very low:\n# Manual stopping check (conceptual)\nif optimizer.success_rate &lt; 0.05 and optimizer.counter &gt; 50:\n    print(\"Success rate very low - optimization has likely converged\")\n\n\n31.10.4 4. Compare Different Strategies\nUse success rate to compare optimization strategies:\nstrategies = [\"ei\", \"pi\", \"y\"]  # Different acquisition functions\nfor acq in strategies:\n    opt = SpotOptim(fun=obj, bounds=bnds, acquisition=acq, max_iter=25)\n    result = opt.optimize()\n    print(f\"{acq}: success_rate={opt.success_rate:.2%}, best={result.fun:.6f}\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#technical-details",
    "href": "success_rate.html#technical-details",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.11 Technical Details",
    "text": "31.11 Technical Details\n\n31.11.1 How Success is Counted\nA new evaluation y_new is considered a success if:\ny_new &lt; best_y_so_far\nwhere best_y_so_far is the minimum value found in all previous evaluations.\n\n\n31.11.2 Rolling Window Calculation\nThe success rate is computed as:\nsuccess_rate = (number of successes in last 100 evals) / (window size)\n\nWindow size defaults to 100\nIf fewer than 100 evaluations have been performed, the window size is the number of evaluations\nThe window slides forward with each new evaluation\n\n\n\n31.11.3 Update Frequency\nThe success rate is updated after: 1. Initial design evaluation 2. Each iteration’s new point evaluation(s) 3. OCBA re-evaluations (if applicable)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "success_rate.html#summary",
    "href": "success_rate.html#summary",
    "title": "31  Success Rate Tracking in SpotOptim",
    "section": "31.12 Summary",
    "text": "31.12 Summary\n\nSuccess rate measures the percentage of recent evaluations that improve the best value\nCalculated over a rolling window of the last 100 evaluations\nValues range from 0.0 to 1.0\nHigh rates (&gt;0.5) indicate active progress\nLow rates (&lt;0.2) suggest convergence\nAutomatically logged to TensorBoard when logging is enabled\nAvailable via optimizer.success_rate attribute after optimization\n\nUse success rate to: - ✓ Monitor optimization progress in real-time - ✓ Identify when to stop optimization - ✓ Compare different optimization strategies - ✓ Assess optimization difficulty for different problems",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Success Rate Tracking in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html",
    "href": "tensorboard_clean.html",
    "title": "32  TensorBoard Log Cleaning Feature in SpotOptim",
    "section": "",
    "text": "32.1 Usage\nAutomatic cleaning of old TensorBoard log directories with the tensorboard_clean parameter.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#usage",
    "href": "tensorboard_clean.html#usage",
    "title": "32  TensorBoard Log Cleaning Feature in SpotOptim",
    "section": "",
    "text": "32.1.1 Basic Usage\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef sphere(X):\n    \"\"\"Simple sphere function\"\"\"\n    return np.sum(X**2, axis=1)\n\n# Remove old logs and create new log directory\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    tensorboard_log=True,\n    tensorboard_clean=True,  # Removes all subdirectories in 'runs'\n    verbose=True,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Logs saved to: runs/{optimizer.tensorboard_path}\")\n\nRemoved old TensorBoard logs: runs/spotoptim_20251202_035203\nCleaned 1 old TensorBoard log directory\nTensorBoard logging enabled: runs/spotoptim_20251202_035212\nInitial best: f(x) = 2.420807\nIteration 1: New best f(x) = 2.390307\nIteration 2: New best f(x) = 1.813139\nIteration 3: New best f(x) = 0.009007\nIteration 4: New best f(x) = 0.001900\nIteration 5: New best f(x) = 0.000973\nIteration 6: New best f(x) = 0.000001\nIteration 7: New best f(x) = 0.000001\nIteration 8: f(x) = 0.000001\nIteration 9: New best f(x) = 0.000001\nIteration 10: f(x) = 0.000001\nTensorBoard writer closed. View logs with: tensorboard --logdir=runs/spotoptim_20251202_035212\nBest value: 0.000001\nLogs saved to: runs/runs/spotoptim_20251202_035212\n\n\n\n\n32.1.2 Use Cases\n\n\n\ntensorboard_log\ntensorboard_clean\nBehavior\n\n\n\n\nTrue\nTrue\nClean old logs, create new log directory\n\n\nTrue\nFalse\nPreserve old logs, create new log directory\n\n\nFalse\nTrue\nClean old logs, no new logging\n\n\nFalse\nFalse\nNo logging, no cleaning (default)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#implementation-details",
    "href": "tensorboard_clean.html#implementation-details",
    "title": "32  TensorBoard Log Cleaning Feature in SpotOptim",
    "section": "32.2 Implementation Details",
    "text": "32.2 Implementation Details\n\n32.2.1 Cleaning Method\ndef _clean_tensorboard_logs(self) -&gt; None:\n    \"\"\"Clean old TensorBoard log directories from the runs folder.\"\"\"\n    if self.tensorboard_clean:\n        runs_dir = \"runs\"\n        if os.path.exists(runs_dir) and os.path.isdir(runs_dir):\n            # Get all subdirectories in runs\n            subdirs = [\n                os.path.join(runs_dir, d)\n                for d in os.listdir(runs_dir)\n                if os.path.isdir(os.path.join(runs_dir, d))\n            ]\n            \n            # Remove each subdirectory\n            for subdir in subdirs:\n                try:\n                    shutil.rmtree(subdir)\n                    if self.verbose:\n                        print(f\"Removed old TensorBoard logs: {subdir}\")\n                except Exception as e:\n                    if self.verbose:\n                        print(f\"Warning: Could not remove {subdir}: {e}\")\n\n\n32.2.2 Execution Flow\n\nUser creates SpotOptim instance with tensorboard_clean=True\nDuring initialization, _clean_tensorboard_logs() is called\nMethod checks if ‘runs’ directory exists\nRemoves all subdirectories (but preserves files)\nIf tensorboard_log=True, a new log directory is created\nOptimization proceeds normally",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#safety-features",
    "href": "tensorboard_clean.html#safety-features",
    "title": "32  TensorBoard Log Cleaning Feature in SpotOptim",
    "section": "32.3 Safety Features",
    "text": "32.3 Safety Features\n\nOnly removes directories, not files in ‘runs’ folder\nHandles missing ‘runs’ directory gracefully\nError handling for permission issues\nVerbose output shows what’s being removed\nDefault is False to prevent accidental deletion",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard_clean.html#warning",
    "href": "tensorboard_clean.html#warning",
    "title": "32  TensorBoard Log Cleaning Feature in SpotOptim",
    "section": "32.4 Warning",
    "text": "32.4 Warning\n⚠️ IMPORTANT: Setting tensorboard_clean=True permanently deletes all subdirectories in the ‘runs’ folder. Make sure to save important logs elsewhere before enabling this feature.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>TensorBoard Log Cleaning Feature in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html",
    "href": "tensorboard.html",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "",
    "text": "33.1 Quick Start\nSpotOptim supports TensorBoard logging for monitoring optimization progress in real-time.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#quick-start",
    "href": "tensorboard.html#quick-start",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "",
    "text": "33.1.1 1. Enable TensorBoard Logging\n\nfrom spotoptim import SpotOptim\nimport numpy as np\n\ndef sphere(X):\n    return np.sum(X**2, axis=1)\n\noptimizer = SpotOptim(\n    fun=sphere,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    tensorboard_log=True,  # Enable logging\n    tensorboard_clean=True,\n    verbose=True,\n    seed=42\n)\n\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Logs saved to: runs/{optimizer.tensorboard_path}\")\n\nRemoved old TensorBoard logs: runs/spotoptim_20251202_035219\nCleaned 1 old TensorBoard log directory\nTensorBoard logging enabled: runs/spotoptim_20251202_035226\nInitial best: f(x) = 2.420807\nIteration 1: New best f(x) = 2.390307\nIteration 2: New best f(x) = 1.813139\nIteration 3: New best f(x) = 0.009007\nIteration 4: New best f(x) = 0.001900\nIteration 5: New best f(x) = 0.000973\nIteration 6: New best f(x) = 0.000001\nIteration 7: New best f(x) = 0.000001\nIteration 8: f(x) = 0.000001\nIteration 9: New best f(x) = 0.000001\nIteration 10: f(x) = 0.000001\nTensorBoard writer closed. View logs with: tensorboard --logdir=runs/spotoptim_20251202_035226\nBest value: 0.000001\nLogs saved to: runs/runs/spotoptim_20251202_035226\n\n\n\n\n33.1.2 2. View Logs in TensorBoard\nIn a separate terminal, run:\ntensorboard --logdir=runs\nThen open your browser to http://localhost:6006",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#cleaning-old-logs",
    "href": "tensorboard.html#cleaning-old-logs",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.2 Cleaning Old Logs",
    "text": "33.2 Cleaning Old Logs\nYou can automatically remove old TensorBoard logs before starting a new optimization:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    tensorboard_log=True,\n    tensorboard_clean=True,  # Remove old logs from 'runs' directory\n    verbose=True\n)\nWarning: This permanently deletes all subdirectories in the runs folder. Make sure to save important logs elsewhere before enabling this feature.\n\n33.2.1 Use Cases\n\nClean Start - Remove old logs and create new one:\ntensorboard_log=True, tensorboard_clean=True\nPreserve History - Keep old logs and add new one (default):\ntensorboard_log=True, tensorboard_clean=False\nJust Clean - Remove old logs without new logging:\ntensorboard_log=False, tensorboard_clean=True",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#custom-log-directory",
    "href": "tensorboard.html#custom-log-directory",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.3 Custom Log Directory",
    "text": "33.3 Custom Log Directory\nSpecify a custom path for TensorBoard logs:\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    tensorboard_log=True,\n    tensorboard_path=\"my_experiments/run_001\",\n    ...\n)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#what-gets-logged",
    "href": "tensorboard.html#what-gets-logged",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.4 What Gets Logged",
    "text": "33.4 What Gets Logged\n\n33.4.1 Scalar Metrics\nFor Deterministic Functions:\n\ny_values/min: Best (minimum) y value found so far\ny_values/last: Most recently evaluated y value\nX_best/x0, X_best/x1, ...: Coordinates of the best point\n\nFor Noisy Functions (repeats &gt; 1):\n\ny_values/min: Best single evaluation\ny_values/mean_best: Best mean y value\ny_values/last: Most recent evaluation\ny_variance_at_best: Variance at the best mean point\nX_mean_best/x0, X_mean_best/x1, ...: Coordinates of best mean point\n\n\n\n33.4.2 Hyperparameters\nEach function evaluation is logged with:\n\nInput coordinates (x0, x1, x2, …)\nFunction value (hp_metric)\n\nThis allows you to explore the relationship between hyperparameters and objective values in the HPARAMS tab.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#examples",
    "href": "tensorboard.html#examples",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.5 Examples",
    "text": "33.5 Examples\n\n33.5.1 Basic Usage\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\noptimizer = SpotOptim(\n    fun=lambda X: np.sum(X**2, axis=1),\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    tensorboard_log=True,\n    tensorboard_clean=True,\n    verbose=True,\n    seed=42\n)\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\n\nRemoved old TensorBoard logs: runs/spotoptim_20251202_035226\nCleaned 1 old TensorBoard log directory\nTensorBoard logging enabled: runs/spotoptim_20251202_035229\nInitial best: f(x) = 2.420807\nIteration 1: New best f(x) = 2.390307\nIteration 2: New best f(x) = 1.813139\nIteration 3: New best f(x) = 0.009007\nIteration 4: New best f(x) = 0.001900\nIteration 5: New best f(x) = 0.000973\nIteration 6: New best f(x) = 0.000001\nIteration 7: New best f(x) = 0.000001\nIteration 8: f(x) = 0.000001\nIteration 9: New best f(x) = 0.000001\nIteration 10: f(x) = 0.000001\nTensorBoard writer closed. View logs with: tensorboard --logdir=runs/spotoptim_20251202_035229\nBest value: 0.000001\n\n\n\n\n33.5.2 Noisy Optimization\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_objective(X):\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    repeats_initial=3,\n    repeats_surrogate=2,\n    tensorboard_log=True,\n    tensorboard_clean=True,\n    tensorboard_path=\"runs/noisy_exp\",\n    seed=42\n)\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\n\nBest value: 2.216536\n\n\n\n\n33.5.3 With OCBA\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_objective(X):\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=20,\n    n_initial=10,\n    repeats_initial=2,\n    ocba_delta=3,  # Re-evaluate 3 promising points per iteration\n    tensorboard_log=True,\n    tensorboard_clean=True,\n    seed=42\n)\nresult = optimizer.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\n\nBest value: 2.447609",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#comparing-multiple-runs",
    "href": "tensorboard.html#comparing-multiple-runs",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.6 Comparing Multiple Runs",
    "text": "33.6 Comparing Multiple Runs\nRun multiple optimizations with different settings:\n# Run 1: Standard\nopt1 = SpotOptim(..., tensorboard_path=\"runs/standard\")\nopt1.optimize()\n\n# Run 2: With OCBA\nopt2 = SpotOptim(..., ocba_delta=3, tensorboard_path=\"runs/with_ocba\")\nopt2.optimize()\n\n# Run 3: More initial points\nopt3 = SpotOptim(..., n_initial=20, tensorboard_path=\"runs/more_initial\")\nopt3.optimize()\nThen view all runs together:\ntensorboard --logdir=runs",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#tensorboard-features",
    "href": "tensorboard.html#tensorboard-features",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.7 TensorBoard Features",
    "text": "33.7 TensorBoard Features\n\n33.7.1 SCALARS Tab\n\nView convergence curves\nCompare optimization progress across runs\nTrack how metrics change over iterations\n\n\n\n33.7.2 HPARAMS Tab\n\nExplore hyperparameter space\nSee which parameter combinations work best\nIdentify patterns in successful configurations\n\n\n\n33.7.3 Text Tab\n\nView configuration details\nCheck run metadata",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#tips",
    "href": "tensorboard.html#tips",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.8 Tips",
    "text": "33.8 Tips\n\nOrganize Experiments: Use descriptive tensorboard_path names:\ntensorboard_path=f\"runs/exp_{date}_{config_name}\"\nCompare Algorithms: Run multiple optimization strategies and compare:\n# Different acquisition functions\nfor acq in ['ei', 'pi', 'y']:\n    opt = SpotOptim(..., acquisition=acq, tensorboard_path=f\"runs/acq_{acq}\")\n    opt.optimize()\nClean Up Old Runs: Use tensorboard_clean=True for automatic cleanup, or manually:\nrm -rf runs/old_experiment\nPort Conflicts: If port 6006 is busy, use a different port:\ntensorboard --logdir=runs --port=6007",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#demo-scripts",
    "href": "tensorboard.html#demo-scripts",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.9 Demo Scripts",
    "text": "33.9 Demo Scripts\nRun the comprehensive TensorBoard demo:\npython demo_tensorboard.py\nThis demonstrates:\n\nDeterministic optimization (Rosenbrock function)\nNoisy optimization with repeated evaluations\nOCBA for intelligent re-evaluation\n\nRun the log cleaning demo:\npython demo_tensorboard_clean.py\nThis demonstrates:\n\nCreating multiple log directories\nPreserving old logs (default behavior)\nCleaning old logs automatically\nCleaning without creating new logs\n\nThis demonstrates:\n\nDeterministic optimization (Rosenbrock function)\nNoisy optimization with repeated evaluations\nOCBA for intelligent re-evaluation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#troubleshooting",
    "href": "tensorboard.html#troubleshooting",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.10 Troubleshooting",
    "text": "33.10 Troubleshooting\nQ: TensorBoard shows “No dashboards are active” A: Make sure you’ve run an optimization with tensorboard_log=True first.\nQ: Can’t see my latest run A: Refresh TensorBoard (click the reload button in the upper right).\nQ: How do I stop TensorBoard? A: Press Ctrl+C in the terminal where TensorBoard is running.\nQ: Logs taking up too much space? A: Use tensorboard_clean=True to automatically remove old logs, or manually delete old run directories.\nQ: How do I remove all old logs at once? A: Set tensorboard_clean=True when creating your optimizer. This will remove all subdirectories in the runs folder.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#related-parameters",
    "href": "tensorboard.html#related-parameters",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.11 Related Parameters",
    "text": "33.11 Related Parameters\n\ntensorboard_log (bool): Enable/disable logging (default: False)\ntensorboard_path (str): Custom log directory (default: auto-generated with timestamp)\ntensorboard_clean (bool): Remove old logs from ‘runs’ directory before starting (default: False)\nverbose (bool): Print progress to console (default: False)\nvar_name (list): Custom names for variables (used in TensorBoard labels)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "tensorboard.html#performance-notes",
    "href": "tensorboard.html#performance-notes",
    "title": "33  TensorBoard Logging in SpotOptim",
    "section": "33.12 Performance Notes",
    "text": "33.12 Performance Notes\nTensorBoard logging has minimal overhead:\n\n&lt; 1% slowdown for typical optimizations\nEvent files are efficiently buffered and written\nWriter is properly closed after optimization completes",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>TensorBoard Logging in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html",
    "href": "var_type.html",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "",
    "text": "34.1 Overview\nThis document describes the var_type implementation in SpotOptim, which allows users to specify different data types for optimization variables.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html#supported-variable-types",
    "href": "var_type.html#supported-variable-types",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "34.2 Supported Variable Types",
    "text": "34.2 Supported Variable Types\nSpotOptim supports three main data types:\n\n34.2.1 1. ‘float’\n\nPurpose: Continuous optimization with Python floats\nBehavior: No rounding applied, values remain continuous\nUse case: Standard continuous optimization variables\nExample: Temperature (23.5°C), Distance (1.234m)\n\n\n\n34.2.2 2. ‘int’\n\nPurpose: Discrete integer optimization\nBehavior: Float values are automatically rounded to integers\nUse case: Count variables, discrete parameters\nExample: Number of layers (5), Population size (100)\n\n\n\n34.2.3 3. ‘factor’\n\nPurpose: Unordered categorical data\nBehavior: Internally mapped to integer values (0, 1, 2, …)\nUse case: Categorical choices like colors, algorithms, modes\nExample: Color (“red”→0, “green”→1, “blue”→2)\nNote: The actual string-to-int mapping is external to SpotOptim; the optimizer works with the integer representation",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html#implementation-details",
    "href": "var_type.html#implementation-details",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "34.3 Implementation Details",
    "text": "34.3 Implementation Details\n\n34.3.1 Where var_type is Used\nThe var_type parameter is properly propagated throughout the optimization process:\n\nInitialization (__init__):\n\nStored as self.var_type\nDefault: [\"float\"] * n_dim if not specified\n\nInitial Design Generation (_generate_initial_design):\n\nApplies type constraints via _repair_non_numeric()\nEnsures initial points respect variable types\n\nNew Point Suggestion (_suggest_next_point):\n\nApplies type constraints to acquisition function optimization results\nEnsures suggested points respect variable types\n\nUser-Provided Initial Design (optimize):\n\nApplies type constraints to X0 if provided\nEnsures consistency regardless of input source\n\nMesh Grid Generation (_generate_mesh_grid):\n\nUsed for plotting, respects variable types\nEnsures visualization shows correct discrete/continuous behavior\n\n\n\n\n34.3.2 Core Method: _repair_non_numeric()\nThis method enforces variable type constraints:\ndef _repair_non_numeric(self, X: np.ndarray, var_type: List[str]) -&gt; np.ndarray:\n    \"\"\"Round non-continuous values to integers.\"\"\"\n    mask = np.isin(var_type, [\"float\"], invert=True)\n    X[:, mask] = np.around(X[:, mask])\n    return X\nLogic:\n\nVariables with type 'float': No change (continuous)\nVariables with type 'int' or 'factor': Rounded to integers",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html#example-usage",
    "href": "var_type.html#example-usage",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "34.4 Example Usage",
    "text": "34.4 Example Usage\n\n34.4.1 Example 1: All Float Variables (Default)\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Example 1: All float variables (default)\nopt1 = SpotOptim(\n    fun=lambda X: np.sum(X**2, axis=1),\n    bounds=[(0, 10), (0, 10), (0, 10)],\n    max_iter=20,\n    n_initial=10,\n    seed=42\n    # var_type defaults to [\"float\", \"float\", \"float\"]\n)\nresult1 = opt1.optimize()\nprint(f\"Best value: {result1.fun:.6f}\")\nprint(f\"Best point (floats): {result1.x}\")\n\nBest value: 0.000000\nBest point (floats): [0. 0. 0.]\n\n\n\n\n34.4.2 Example 2: Pure Integer Optimization\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef discrete_func(X):\n    return np.sum(X**2, axis=1)\n\nbounds = [(-5, 5), (-5, 5)]\nvar_type = [\"int\", \"int\"]\n\nopt = SpotOptim(\n    fun=discrete_func,\n    bounds=bounds,\n    var_type=var_type,\n    max_iter=20,\n    n_initial=10,\n    seed=42\n)\n\nresult = opt.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Best point (integers): {result.x}\")\nprint(f\"Note: Values are rounded to integers\")\n\nBest value: 0.000000\nBest point (integers): [ 0. -0.]\nNote: Values are rounded to integers\n\n\n\n\n34.4.3 Example 3: Categorical (Factor) Variables\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef categorical_func(X):\n    # Assume X[:, 0] represents 3 categories: 0, 1, 2\n    # Category 0 is best\n    return (X[:, 0]**2) + (X[:, 1]**2)\n\nbounds = [(0, 2), (0, 3)]  # 3 and 4 categories respectively\nvar_type = [\"factor\", \"factor\"]\n\nopt = SpotOptim(\n    fun=categorical_func,\n    bounds=bounds,\n    var_type=var_type,\n    max_iter=20,\n    n_initial=10,\n    seed=42\n)\n\nresult = opt.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Best point (categories): {result.x}\")\nprint(f\"Note: Values are integers representing categories\")\n\nBest value: 0.000000\nBest point (categories): [0. 0.]\nNote: Values are integers representing categories\n\n\n\n\n34.4.4 Example 4: Mixed Variable Types\n\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef mixed_func(X):\n    # X[:, 0]: continuous temperature\n    # X[:, 1]: discrete number of iterations\n    # X[:, 2]: categorical algorithm choice (0, 1, 2)\n    return X[:, 0]**2 + X[:, 1]**2 + X[:, 2]**2\n\nbounds = [(-5, 5), (1, 100), (0, 2)]\nvar_type = [\"float\", \"int\", \"factor\"]\nvar_name = [\"temperature\", \"iterations\", \"algorithm\"]\n\nopt = SpotOptim(\n    fun=mixed_func,\n    bounds=bounds,\n    var_type=var_type,\n    var_name=var_name,\n    max_iter=20,\n    n_initial=10,\n    seed=42\n)\n\nresult = opt.optimize()\nprint(f\"Best value: {result.fun:.6f}\")\nprint(f\"Best point: {result.x}\")\nprint(f\"  {var_name[0]} (float): {result.x[0]:.6f}\")\nprint(f\"  {var_name[1]} (int): {int(result.x[1])}\")\nprint(f\"  {var_name[2]} (factor): {int(result.x[2])}\")\n\nBest value: 1.000010\nBest point: [-0.00309017  1.          0.        ]\n  temperature (float): -0.003090\n  iterations (int): 1\n  algorithm (factor): 0",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html#key-findings",
    "href": "var_type.html#key-findings",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "34.5 Key Findings",
    "text": "34.5 Key Findings\n\nType Persistence: Variable types are correctly maintained throughout the entire optimization process, from initial design through all iterations.\nAutomatic Enforcement: The _repair_non_numeric() method is called at all critical points, ensuring type constraints are never violated.\nThree Explicit Types: Only 'float', 'int', and 'factor' are supported. The legacy 'num' type has been removed for clarity.\nUser-Provided Data: Type constraints are applied even to user-provided initial designs, ensuring consistency.\nPlotting Compatibility: The plotting functionality respects variable types, ensuring correct visualization of discrete vs. continuous variables.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html#recommendations",
    "href": "var_type.html#recommendations",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "34.6 Recommendations",
    "text": "34.6 Recommendations\n\nAlways specify var_type explicitly for clarity, especially in mixed-type problems\nUse appropriate bounds for factor variables (e.g., (0, n_categories-1))\nExternal mapping for string categories: Maintain your own mapping dictionary outside SpotOptim (e.g., {\"red\": 0, \"green\": 1, \"blue\": 2})\nValidation: The current implementation doesn’t validate var_type length matches bounds length - users should ensure this manually",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "var_type.html#future-enhancements-optional",
    "href": "var_type.html#future-enhancements-optional",
    "title": "34  Variable Type (var_type) Implementation in SpotOptim",
    "section": "34.7 Future Enhancements (Optional)",
    "text": "34.7 Future Enhancements (Optional)\nPotential improvements that could be added:\n\nValidation: Add validation in __init__ to check len(var_type) == len(bounds)\nString Categories: Add built-in support for automatic string-to-int mapping\nOrdered Categories: Support ordered categorical variables (ordinal data)\nType Checking: Validate that var_type values are one of the allowed strings\nBounds Checking: Warn if factor bounds are not integer ranges",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Variable Type (var_type) Implementation in SpotOptim</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arlot, Sylvain, Alain Celisse, et al. 2010. “A Survey of\nCross-Validation Procedures for Model Selection.” Statistics\nSurveys 4: 40–79.\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf\nMersmann, eds. 2022. Hyperparameter Tuning for\nMachine and Deep Learning with R - A Practical Guide.\nSpringer.\n\n\nBox, G E P. 1957. “Evolutionary operation: A\nmethod for increasing industrial productivity.”\nApplied Statistics 6: 81–101.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling.\nWiley.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning. Second. Springer.\n\n\nJohnson, M. E., L. M. Moore, and D. Ylvisaker. 1990. “Minimax and\nMaximin Distance Designs.” Journal of Statistical Planning\nand Inference 26 (2): 131–48.\n\n\nJones, Donald R., Matthias Schonlau, and William J. Welch. 1998.\n“Efficient Global Optimization of Expensive Black-Box\nFunctions.” Journal of Global Optimization 13 (4):\n455–92.\n\n\nKeane, Andrew J, and Prasanth B Nair. 2005. Computational Approaches\nfor Aerospace Design: The Pursuit of Excellence. Wiley.\n\n\nKohavi, Ron. 1995. “A Study of Cross-Validation and Bootstrap for\nAccuracy Estimation and Model Selection.” In Proceedings of\nthe 14th International Joint Conference on Artificial Intelligence -\nVolume 2, 1137–43. IJCAI’95. San Francisco, CA, USA: Morgan\nKaufmann Publishers Inc.\n\n\nMicchelli, Charles A. 1986. “Interpolation of Scattered Data:\nDistance Matrices and Conditionally Positive Definite Functions.”\nConstructive Approximation 2 (1): 11–22. https://doi.org/10.1007/BF01893414.\n\n\nMočkus, J. 1974. “On Bayesian Methods for\nSeeking the Extremum.” In Optimization Techniques\nIFIP Technical Conference, 400–404.\n\n\nMorris, Max D., and Toby J. Mitchell. 1995. “Exploratory Designs\nfor Computational Experiments.” Journal of Statistical\nPlanning and Inference 43 (3): 381–402. https://doi.org/https://doi.org/10.1016/0378-3758(94)00035-T.\n\n\nPoggio, T, and F Girosi. 1990. “Regularization Algorithms for\nLearning That Are Equivalent to Multilayer Networks.”\nScience 247 (4945): 978–82. https://doi.org/10.1126/science.247.4945.978.\n\n\nRaymer, Daniel P. 2006. Aircraft Design: A Conceptual Approach.\nAIAA.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer\nExperiments. Berlin, Heidelberg, New York: Springer.\n\n\nVapnik, V N. 1998. Statistical learning\ntheory. Wiley; Wiley.",
    "crumbs": [
      "References"
    ]
  }
]